{
  "discovered_at": "2026-01-11T15:36:39.671091Z",
  "sources_checked": [
    "skillsmp_top",
    "skillsmp",
    "anthropic_official"
  ],
  "total_skills": 114,
  "total_with_skill_md": 114,
  "skills": [
    {
      "name": "cache-components",
      "slug": "cache-components",
      "source": "skillsmp_top",
      "owner": "vercel",
      "repo_name": "next.js",
      "repository_url": "https://github.com/vercel/next.js",
      "skill_path": ".claude-plugin/plugins/cache-components/skills/cache-components",
      "github_metadata": {
        "stars": 137082,
        "description": "The React Framework",
        "default_branch": "canary",
        "pushed_at": "2026-01-11T07:03:03Z",
        "created_at": "2016-10-05T23:32:51Z",
        "language": "JavaScript",
        "license": "MIT",
        "open_issues": 3218,
        "forks": 30252
      },
      "skill_md": {
        "found": true,
        "path": ".claude-plugin/plugins/cache-components/skills/cache-components/SKILL.md",
        "branch": "canary",
        "content": "---\nname: cache-components\ndescription: |\n  Expert guidance for Next.js Cache Components and Partial Prerendering (PPR).\n\n  **PROACTIVE ACTIVATION**: Use this skill automatically when working in Next.js projects that have `cacheComponents: true` in their next.config.ts/next.config.js. When this config is detected, proactively apply Cache Components patterns and best practices to all React Server Component implementations.\n\n  **DETECTION**: At the start of a session in a Next.js project, check for `cacheComponents: true` in next.config. If enabled, this skill's patterns should guide all component authoring, data fetching, and caching decisions.\n\n  **USE CASES**: Implementing 'use cache' directive, configuring cache lifetimes with cacheLife(), tagging cached data with cacheTag(), invalidating caches with updateTag()/revalidateTag(), optimizing static vs dynamic content boundaries, debugging cache issues, and reviewing Cache Component implementations.\n---\n\n# Next.js Cache Components\n\n> **Auto-activation**: This skill activates automatically in projects with `cacheComponents: true` in next.config.\n\n## Project Detection\n\nWhen starting work in a Next.js project, check if Cache Components are enabled:\n\n```bash\n# Check next.config.ts or next.config.js for cacheComponents\ngrep -r \"cacheComponents\" next.config.* 2>/dev/null\n```\n\nIf `cacheComponents: true` is found, apply this skill's patterns proactively when:\n\n- Writing React Server Components\n- Implementing data fetching\n- Creating Server Actions with mutations\n- Optimizing page performance\n- Reviewing existing component code\n\nCache Components enable **Partial Prerendering (PPR)** - mixing static HTML shells with dynamic streaming content for optimal performance.\n\n## Philosophy: Code Over Configuration\n\nCache Components represents a shift from **segment configuration** to **compositional code**:\n\n| Before (Deprecated)                     | After (Cache Components)                  |\n| --------------------------------------- | ----------------------------------------- |\n| `export const revalidate = 3600`        | `cacheLife('hours')` inside `'use cache'` |\n| `export const dynamic = 'force-static'` | Use `'use cache'` and Suspense boundaries |\n| All-or-nothing static/dynamic           | Granular: static shell + cached + dynamic |\n\n**Key Principle**: Components co-locate their caching, not just their data. Next.js provides build-time feedback to guide you toward optimal patterns.\n\n## Core Concept\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                   Static Shell                       â”‚\nâ”‚  (Sent immediately to browser)                       â”‚\nâ”‚                                                      â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\nâ”‚  â”‚   Header    â”‚  â”‚  Cached     â”‚  â”‚  Suspense   â”‚  â”‚\nâ”‚  â”‚  (static)   â”‚  â”‚  Content    â”‚  â”‚  Fallback   â”‚  â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â”‚\nâ”‚                                           â”‚         â”‚\nâ”‚                                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”‚\nâ”‚                                    â”‚  Dynamic    â”‚  â”‚\nâ”‚                                    â”‚  (streams)  â”‚  â”‚\nâ”‚                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n## Mental Model: The Caching Decision Tree\n\nWhen writing a React Server Component, ask these questions in order:\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Does this component fetch data or perform I/O?          â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                      â”‚\n           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n           â”‚   YES               â”‚ NO â†’ Pure component, no action needed\n           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                      â”‚\n    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n    â”‚ Does it depend on request context? â”‚\n    â”‚ (cookies, headers, searchParams)   â”‚\n    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                      â”‚\n         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n         â”‚                         â”‚\n    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”\n    â”‚   YES   â”‚              â”‚    NO     â”‚\n    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜\n         â”‚                         â”‚\n         â”‚                   â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n         â”‚                   â”‚ Can this be cached?   â”‚\n         â”‚                   â”‚ (same for all users?) â”‚\n         â”‚                   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n         â”‚                         â”‚\n         â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n         â”‚              â”‚                     â”‚\n         â”‚         â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”\n         â”‚         â”‚   YES   â”‚          â”‚    NO     â”‚\n         â”‚         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜\n         â”‚              â”‚                     â”‚\n         â”‚              â–¼                     â”‚\n         â”‚         'use cache'                â”‚\n         â”‚         + cacheTag()               â”‚\n         â”‚         + cacheLife()              â”‚\n         â”‚                                    â”‚\n         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                        â”‚\n                        â–¼\n              Wrap in <Suspense>\n              (dynamic streaming)\n```\n\n**Key insight**: The `'use cache'` directive is for data that's the _same across users_. User-specific data stays dynamic with Suspense.\n\n## Quick Start\n\n### Enable Cache Components\n\n```typescript\n// next.config.ts\nimport type { NextConfig } from 'next'\n\nconst nextConfig: NextConfig = {\n  cacheComponents: true,\n}\n\nexport default nextConfig\n```\n\n### Basic Usage\n\n```tsx\n// Cached component - output included in static shell\nasync function CachedPosts() {\n  'use cache'\n  const posts = await db.posts.findMany()\n  return <PostList posts={posts} />\n}\n\n// Page with static + cached + dynamic content\nexport default async function BlogPage() {\n  return (\n    <>\n      <Header /> {/* Static */}\n      <CachedPosts /> {/* Cached */}\n      <Suspense fallback={<Skeleton />}>\n        <DynamicComments /> {/* Dynamic - streams */}\n      </Suspense>\n    </>\n  )\n}\n```\n\n## Core APIs\n\n### 1. `'use cache'` Directive\n\nMarks code as cacheable. Can be applied at three levels:\n\n```tsx\n// File-level: All exports are cached\n'use cache'\nexport async function getData() {\n  /* ... */\n}\nexport async function Component() {\n  /* ... */\n}\n\n// Component-level\nasync function UserCard({ id }: { id: string }) {\n  'use cache'\n  const user = await fetchUser(id)\n  return <Card>{user.name}</Card>\n}\n\n// Function-level\nasync function fetchWithCache(url: string) {\n  'use cache'\n  return fetch(url).then((r) => r.json())\n}\n```\n\n**Important**: All cached functions must be `async`.\n\n### 2. `cacheLife()` - Control Cache Duration\n\n```tsx\nimport { cacheLife } from 'next/cache'\n\nasync function Posts() {\n  'use cache'\n  cacheLife('hours') // Use a predefined profile\n\n  // Or custom configuration:\n  cacheLife({\n    stale: 60, // 1 min - client cache validity\n    revalidate: 3600, // 1 hr - start background refresh\n    expire: 86400, // 1 day - absolute expiration\n  })\n\n  return await db.posts.findMany()\n}\n```\n\n**Predefined profiles**: `'default'`, `'seconds'`, `'minutes'`, `'hours'`, `'days'`, `'weeks'`, `'max'`\n\n### 3. `cacheTag()` - Tag for Invalidation\n\n```tsx\nimport { cacheTag } from 'next/cache'\n\nasync function BlogPosts() {\n  'use cache'\n  cacheTag('posts')\n  cacheLife('days')\n\n  return await db.posts.findMany()\n}\n\nasync function UserProfile({ userId }: { userId: string }) {\n  'use cache'\n  cacheTag('users', `user-${userId}`) // Multiple tags\n\n  return await db.users.findUnique({ where: { id: userId } })\n}\n```\n\n### 4. `updateTag()` - Immediate Invalidation\n\nFor **read-your-own-writes** semantics:\n\n```tsx\n'use server'\nimport { updateTag } from 'next/cache'\n\nexport async function createPost(formData: FormData) {\n  await db.posts.create({ data: formData })\n\n  updateTag('posts') // Client immediately sees fresh data\n}\n```\n\n### 5. `revalidateTag()` - Background Revalidation\n\nFor stale-while-revalidate pattern:\n\n```tsx\n'use server'\nimport { revalidateTag } from 'next/cache'\n\nexport async function updatePost(id: string, data: FormData) {\n  await db.posts.update({ where: { id }, data })\n\n  revalidateTag('posts', 'max') // Serve stale, refresh in background\n}\n```\n\n## When to Use Each Pattern\n\n| Content Type | API                 | Behavior                              |\n| ------------ | ------------------- | ------------------------------------- |\n| **Static**   | No directive        | Rendered at build time                |\n| **Cached**   | `'use cache'`       | Included in static shell, revalidates |\n| **Dynamic**  | Inside `<Suspense>` | Streams at request time               |\n\n## Parameter Permutations & Subshells\n\n**Critical Concept**: With Cache Components, Next.js renders ALL permutations of provided parameters to create reusable subshells.\n\n```tsx\n// app/products/[category]/[slug]/page.tsx\nexport async function generateStaticParams() {\n  return [\n    { category: 'jackets', slug: 'classic-bomber' },\n    { category: 'jackets', slug: 'essential-windbreaker' },\n    { category: 'accessories', slug: 'thermal-fleece-gloves' },\n  ]\n}\n```\n\nNext.js renders these routes:\n\n```\n/products/jackets/classic-bomber        â† Full params (complete page)\n/products/jackets/essential-windbreaker â† Full params (complete page)\n/products/accessories/thermal-fleece-gloves â† Full params (complete page)\n/products/jackets/[slug]                â† Partial params (category subshell)\n/products/accessories/[slug]            â† Partial params (category subshell)\n/products/[category]/[slug]             â† No params (fallback shell)\n```\n\n**Why this matters**: The category subshell (`/products/jackets/[slug]`) can be reused for ANY jacket product, even ones not in `generateStaticParams`. Users navigating to an unlisted jacket get the cached category shell immediately, with product details streaming in.\n\n### `generateStaticParams` Requirements\n\nWith Cache Components enabled:\n\n1. **Must provide at least one parameter** - Empty arrays now cause build errors (prevents silent production failures)\n2. **Params prove static safety** - Providing params lets Next.js verify no dynamic APIs are called\n3. **Partial params create subshells** - Each unique permutation generates a reusable shell\n\n```tsx\n// âŒ ERROR with Cache Components\nexport function generateStaticParams() {\n  return [] // Build error: must provide at least one param\n}\n\n// âœ… CORRECT: Provide real params\nexport async function generateStaticParams() {\n  const products = await getPopularProducts()\n  return products.map(({ category, slug }) => ({ category, slug }))\n}\n```\n\n## Cache Key = Arguments\n\nArguments become part of the cache key:\n\n```tsx\n// Different userId = different cache entry\nasync function UserData({ userId }: { userId: string }) {\n  'use cache'\n  cacheTag(`user-${userId}`)\n\n  return await fetchUser(userId)\n}\n```\n\n## Build-Time Feedback\n\nCache Components provides early feedback during development. These build errors **guide you toward optimal patterns**:\n\n### Error: Dynamic data outside Suspense\n\n```\nError: Accessing cookies/headers/searchParams outside a Suspense boundary\n```\n\n**Solution**: Wrap dynamic components in `<Suspense>`:\n\n```tsx\n<Suspense fallback={<Skeleton />}>\n  <ComponentThatUsesCookies />\n</Suspense>\n```\n\n### Error: Uncached data outside Suspense\n\n```\nError: Accessing uncached data outside Suspense\n```\n\n**Solution**: Either cache the data or wrap in Suspense:\n\n```tsx\n// Option 1: Cache it\nasync function ProductData({ id }: { id: string }) {\n  'use cache'\n  return await db.products.findUnique({ where: { id } })\n}\n\n// Option 2: Make it dynamic with Suspense\n;<Suspense fallback={<Loading />}>\n  <DynamicProductData id={id} />\n</Suspense>\n```\n\n### Error: Request data inside cache\n\n```\nError: Cannot access cookies/headers inside 'use cache'\n```\n\n**Solution**: Extract runtime data outside cache boundary (see \"Handling Runtime Data\" above).\n\n## Additional Resources\n\n- For complete API reference, see [REFERENCE.md](REFERENCE.md)\n- For common patterns and recipes, see [PATTERNS.md](PATTERNS.md)\n- For debugging and troubleshooting, see [TROUBLESHOOTING.md](TROUBLESHOOTING.md)\n\n## Code Generation Guidelines\n\nWhen generating Cache Component code:\n\n1. **Always use `async`** - All cached functions must be async\n2. **Place `'use cache'` first** - Must be first statement in function body\n3. **Call `cacheLife()` early** - Should follow `'use cache'` directive\n4. **Tag meaningfully** - Use semantic tags that match your invalidation needs\n5. **Extract runtime data** - Move `cookies()`/`headers()` outside cached scope\n6. **Wrap dynamic content** - Use `<Suspense>` for non-cached async components\n\n---\n\n## Proactive Application (When Cache Components Enabled)\n\nWhen `cacheComponents: true` is detected in the project, **automatically apply these patterns**:\n\n### When Writing Data Fetching Components\n\nAsk yourself: \"Can this data be cached?\" If yes, add `'use cache'`:\n\n```tsx\n// Before: Uncached fetch\nasync function ProductList() {\n  const products = await db.products.findMany()\n  return <Grid products={products} />\n}\n\n// After: With caching\nasync function ProductList() {\n  'use cache'\n  cacheTag('products')\n  cacheLife('hours')\n\n  const products = await db.products.findMany()\n  return <Grid products={products} />\n}\n```\n\n### When Writing Server Actions\n\nAlways invalidate relevant caches after mutations:\n\n```tsx\n'use server'\nimport { updateTag } from 'next/cache'\n\nexport async function createProduct(data: FormData) {\n  await db.products.create({ data })\n  updateTag('products') // Don't forget!\n}\n```\n\n### When Composing Pages\n\nStructure with static shell + cached content + dynamic streaming:\n\n```tsx\nexport default async function Page() {\n  return (\n    <>\n      <StaticHeader /> {/* No cache needed */}\n      <CachedContent /> {/* 'use cache' */}\n      <Suspense fallback={<Skeleton />}>\n        <DynamicUserContent /> {/* Streams at runtime */}\n      </Suspense>\n    </>\n  )\n}\n```\n\n### When Reviewing Code\n\nFlag these issues in Cache Components projects:\n\n- [ ] Data fetching without `'use cache'` where caching would benefit\n- [ ] Missing `cacheTag()` calls (makes invalidation impossible)\n- [ ] Missing `cacheLife()` (relies on defaults which may not be appropriate)\n- [ ] Server Actions without `updateTag()`/`revalidateTag()` after mutations\n- [ ] `cookies()`/`headers()` called inside `'use cache'` scope\n- [ ] Dynamic components without `<Suspense>` boundaries\n- [ ] **DEPRECATED**: `export const revalidate` - replace with `cacheLife()` in `'use cache'`\n- [ ] **DEPRECATED**: `export const dynamic` - replace with Suspense + cache boundaries\n- [ ] Empty `generateStaticParams()` return - must provide at least one param\n"
      },
      "discovered_at": "2026-01-11T15:35:48.733405Z",
      "fetch_error": null
    },
    {
      "name": "frontend-testing",
      "slug": "frontend-testing",
      "source": "skillsmp_top",
      "owner": "langgenius",
      "repo_name": "dify",
      "repository_url": "https://github.com/langgenius/dify",
      "skill_path": ".claude/skills/frontend-testing",
      "github_metadata": {
        "stars": 125521,
        "description": "Production-ready platform for agentic workflow development.",
        "default_branch": "main",
        "pushed_at": "2026-01-11T13:54:46Z",
        "created_at": "2023-04-12T07:40:24Z",
        "language": "Python",
        "license": "NOASSERTION",
        "open_issues": 645,
        "forks": 19516
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/frontend-testing/SKILL.md",
        "branch": "main",
        "content": "---\nname: frontend-testing\ndescription: Generate Vitest + React Testing Library tests for Dify frontend components, hooks, and utilities. Triggers on testing, spec files, coverage, Vitest, RTL, unit tests, integration tests, or write/review test requests.\n---\n\n# Dify Frontend Testing Skill\n\nThis skill enables Claude to generate high-quality, comprehensive frontend tests for the Dify project following established conventions and best practices.\n\n> **âš ï¸ Authoritative Source**: This skill is derived from `web/testing/testing.md`. Use Vitest mock/timer APIs (`vi.*`).\n\n## When to Apply This Skill\n\nApply this skill when the user:\n\n- Asks to **write tests** for a component, hook, or utility\n- Asks to **review existing tests** for completeness\n- Mentions **Vitest**, **React Testing Library**, **RTL**, or **spec files**\n- Requests **test coverage** improvement\n- Uses `pnpm analyze-component` output as context\n- Mentions **testing**, **unit tests**, or **integration tests** for frontend code\n- Wants to understand **testing patterns** in the Dify codebase\n\n**Do NOT apply** when:\n\n- User is asking about backend/API tests (Python/pytest)\n- User is asking about E2E tests (Playwright/Cypress)\n- User is only asking conceptual questions without code context\n\n## Quick Reference\n\n### Tech Stack\n\n| Tool | Version | Purpose |\n|------|---------|---------|\n| Vitest | 4.0.16 | Test runner |\n| React Testing Library | 16.0 | Component testing |\n| jsdom | - | Test environment |\n| nock | 14.0 | HTTP mocking |\n| TypeScript | 5.x | Type safety |\n\n### Key Commands\n\n```bash\n# Run all tests\npnpm test\n\n# Watch mode\npnpm test:watch\n\n# Run specific file\npnpm test path/to/file.spec.tsx\n\n# Generate coverage report\npnpm test:coverage\n\n# Analyze component complexity\npnpm analyze-component <path>\n\n# Review existing test\npnpm analyze-component <path> --review\n```\n\n### File Naming\n\n- Test files: `ComponentName.spec.tsx` (same directory as component)\n- Integration tests: `web/__tests__/` directory\n\n## Test Structure Template\n\n```typescript\nimport { render, screen, fireEvent, waitFor } from '@testing-library/react'\nimport Component from './index'\n\n// âœ… Import real project components (DO NOT mock these)\n// import Loading from '@/app/components/base/loading'\n// import { ChildComponent } from './child-component'\n\n// âœ… Mock external dependencies only\nvi.mock('@/service/api')\nvi.mock('next/navigation', () => ({\n  useRouter: () => ({ push: vi.fn() }),\n  usePathname: () => '/test',\n}))\n\n// Shared state for mocks (if needed)\nlet mockSharedState = false\n\ndescribe('ComponentName', () => {\n  beforeEach(() => {\n    vi.clearAllMocks()  // âœ… Reset mocks BEFORE each test\n    mockSharedState = false  // âœ… Reset shared state\n  })\n\n  // Rendering tests (REQUIRED)\n  describe('Rendering', () => {\n    it('should render without crashing', () => {\n      // Arrange\n      const props = { title: 'Test' }\n      \n      // Act\n      render(<Component {...props} />)\n      \n      // Assert\n      expect(screen.getByText('Test')).toBeInTheDocument()\n    })\n  })\n\n  // Props tests (REQUIRED)\n  describe('Props', () => {\n    it('should apply custom className', () => {\n      render(<Component className=\"custom\" />)\n      expect(screen.getByRole('button')).toHaveClass('custom')\n    })\n  })\n\n  // User Interactions\n  describe('User Interactions', () => {\n    it('should handle click events', () => {\n      const handleClick = vi.fn()\n      render(<Component onClick={handleClick} />)\n      \n      fireEvent.click(screen.getByRole('button'))\n      \n      expect(handleClick).toHaveBeenCalledTimes(1)\n    })\n  })\n\n  // Edge Cases (REQUIRED)\n  describe('Edge Cases', () => {\n    it('should handle null data', () => {\n      render(<Component data={null} />)\n      expect(screen.getByText(/no data/i)).toBeInTheDocument()\n    })\n\n    it('should handle empty array', () => {\n      render(<Component items={[]} />)\n      expect(screen.getByText(/empty/i)).toBeInTheDocument()\n    })\n  })\n})\n```\n\n## Testing Workflow (CRITICAL)\n\n### âš ï¸ Incremental Approach Required\n\n**NEVER generate all test files at once.** For complex components or multi-file directories:\n\n1. **Analyze & Plan**: List all files, order by complexity (simple â†’ complex)\n1. **Process ONE at a time**: Write test â†’ Run test â†’ Fix if needed â†’ Next\n1. **Verify before proceeding**: Do NOT continue to next file until current passes\n\n```\nFor each file:\n  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n  â”‚ 1. Write test                          â”‚\n  â”‚ 2. Run: pnpm test <file>.spec.tsx      â”‚\n  â”‚ 3. PASS? â†’ Mark complete, next file    â”‚\n  â”‚    FAIL? â†’ Fix first, then continue    â”‚\n  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### Complexity-Based Order\n\nProcess in this order for multi-file testing:\n\n1. ğŸŸ¢ Utility functions (simplest)\n1. ğŸŸ¢ Custom hooks\n1. ğŸŸ¡ Simple components (presentational)\n1. ğŸŸ¡ Medium components (state, effects)\n1. ğŸ”´ Complex components (API, routing)\n1. ğŸ”´ Integration tests (index files - last)\n\n### When to Refactor First\n\n- **Complexity > 50**: Break into smaller pieces before testing\n- **500+ lines**: Consider splitting before testing\n- **Many dependencies**: Extract logic into hooks first\n\n> ğŸ“– See `references/workflow.md` for complete workflow details and todo list format.\n\n## Testing Strategy\n\n### Path-Level Testing (Directory Testing)\n\nWhen assigned to test a directory/path, test **ALL content** within that path:\n\n- Test all components, hooks, utilities in the directory (not just `index` file)\n- Use incremental approach: one file at a time, verify each before proceeding\n- Goal: 100% coverage of ALL files in the directory\n\n### Integration Testing First\n\n**Prefer integration testing** when writing tests for a directory:\n\n- âœ… **Import real project components** directly (including base components and siblings)\n- âœ… **Only mock**: API services (`@/service/*`), `next/navigation`, complex context providers\n- âŒ **DO NOT mock** base components (`@/app/components/base/*`)\n- âŒ **DO NOT mock** sibling/child components in the same directory\n\n> See [Test Structure Template](#test-structure-template) for correct import/mock patterns.\n\n## Core Principles\n\n### 1. AAA Pattern (Arrange-Act-Assert)\n\nEvery test should clearly separate:\n\n- **Arrange**: Setup test data and render component\n- **Act**: Perform user actions\n- **Assert**: Verify expected outcomes\n\n### 2. Black-Box Testing\n\n- Test observable behavior, not implementation details\n- Use semantic queries (getByRole, getByLabelText)\n- Avoid testing internal state directly\n- **Prefer pattern matching over hardcoded strings** in assertions:\n\n```typescript\n// âŒ Avoid: hardcoded text assertions\nexpect(screen.getByText('Loading...')).toBeInTheDocument()\n\n// âœ… Better: role-based queries\nexpect(screen.getByRole('status')).toBeInTheDocument()\n\n// âœ… Better: pattern matching\nexpect(screen.getByText(/loading/i)).toBeInTheDocument()\n```\n\n### 3. Single Behavior Per Test\n\nEach test verifies ONE user-observable behavior:\n\n```typescript\n// âœ… Good: One behavior\nit('should disable button when loading', () => {\n  render(<Button loading />)\n  expect(screen.getByRole('button')).toBeDisabled()\n})\n\n// âŒ Bad: Multiple behaviors\nit('should handle loading state', () => {\n  render(<Button loading />)\n  expect(screen.getByRole('button')).toBeDisabled()\n  expect(screen.getByText('Loading...')).toBeInTheDocument()\n  expect(screen.getByRole('button')).toHaveClass('loading')\n})\n```\n\n### 4. Semantic Naming\n\nUse `should <behavior> when <condition>`:\n\n```typescript\nit('should show error message when validation fails')\nit('should call onSubmit when form is valid')\nit('should disable input when isReadOnly is true')\n```\n\n## Required Test Scenarios\n\n### Always Required (All Components)\n\n1. **Rendering**: Component renders without crashing\n1. **Props**: Required props, optional props, default values\n1. **Edge Cases**: null, undefined, empty values, boundary conditions\n\n### Conditional (When Present)\n\n| Feature | Test Focus |\n|---------|-----------|\n| `useState` | Initial state, transitions, cleanup |\n| `useEffect` | Execution, dependencies, cleanup |\n| Event handlers | All onClick, onChange, onSubmit, keyboard |\n| API calls | Loading, success, error states |\n| Routing | Navigation, params, query strings |\n| `useCallback`/`useMemo` | Referential equality |\n| Context | Provider values, consumer behavior |\n| Forms | Validation, submission, error display |\n\n## Coverage Goals (Per File)\n\nFor each test file generated, aim for:\n\n- âœ… **100%** function coverage\n- âœ… **100%** statement coverage\n- âœ… **>95%** branch coverage\n- âœ… **>95%** line coverage\n\n> **Note**: For multi-file directories, process one file at a time with full coverage each. See `references/workflow.md`.\n\n## Detailed Guides\n\nFor more detailed information, refer to:\n\n- `references/workflow.md` - **Incremental testing workflow** (MUST READ for multi-file testing)\n- `references/mocking.md` - Mock patterns and best practices\n- `references/async-testing.md` - Async operations and API calls\n- `references/domain-components.md` - Workflow, Dataset, Configuration testing\n- `references/common-patterns.md` - Frequently used testing patterns\n- `references/checklist.md` - Test generation checklist and validation steps\n\n## Authoritative References\n\n### Primary Specification (MUST follow)\n\n- **`web/testing/testing.md`** - The canonical testing specification. This skill is derived from this document.\n\n### Reference Examples in Codebase\n\n- `web/utils/classnames.spec.ts` - Utility function tests\n- `web/app/components/base/button/index.spec.tsx` - Component tests\n- `web/__mocks__/provider-context.ts` - Mock factory example\n\n### Project Configuration\n\n- `web/vitest.config.ts` - Vitest configuration\n- `web/vitest.setup.ts` - Test environment setup\n- `web/scripts/analyze-component.js` - Component analysis tool\n- Modules are not mocked automatically. Global mocks live in `web/vitest.setup.ts` (for example `react-i18next`, `next/image`); mock other modules like `ky` or `mime` locally in test files.\n"
      },
      "discovered_at": "2026-01-11T15:35:49.183166Z",
      "fetch_error": null
    },
    {
      "name": "skill-creator",
      "slug": "skill-creator",
      "source": "skillsmp_top",
      "owner": "langgenius",
      "repo_name": "dify",
      "repository_url": "https://github.com/langgenius/dify",
      "skill_path": ".claude/skills/skill-creator",
      "github_metadata": {
        "stars": 125521,
        "description": "Production-ready platform for agentic workflow development.",
        "default_branch": "main",
        "pushed_at": "2026-01-11T13:54:46Z",
        "created_at": "2023-04-12T07:40:24Z",
        "language": "Python",
        "license": "NOASSERTION",
        "open_issues": 645,
        "forks": 19516
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/skill-creator/SKILL.md",
        "branch": "main",
        "content": "---\nname: skill-creator\ndescription: Guide for creating effective skills. This skill should be used when users want to create a new skill (or update an existing skill) that extends Claude's capabilities with specialized knowledge, workflows, or tool integrations.\n---\n\n# Skill Creator\n\nThis skill provides guidance for creating effective skills.\n\n## About Skills\n\nSkills are modular, self-contained packages that extend Claude's capabilities by providing\nspecialized knowledge, workflows, and tools. Think of them as \"onboarding guides\" for specific\ndomains or tasksâ€”they transform Claude from a general-purpose agent into a specialized agent\nequipped with procedural knowledge that no model can fully possess.\n\n### What Skills Provide\n\n1. Specialized workflows - Multi-step procedures for specific domains\n2. Tool integrations - Instructions for working with specific file formats or APIs\n3. Domain expertise - Company-specific knowledge, schemas, business logic\n4. Bundled resources - Scripts, references, and assets for complex and repetitive tasks\n\n## Core Principles\n\n### Concise is Key\n\nThe context window is a public good. Skills share the context window with everything else Claude needs: system prompt, conversation history, other Skills' metadata, and the actual user request.\n\n**Default assumption: Claude is already very smart.** Only add context Claude doesn't already have. Challenge each piece of information: \"Does Claude really need this explanation?\" and \"Does this paragraph justify its token cost?\"\n\nPrefer concise examples over verbose explanations.\n\n### Set Appropriate Degrees of Freedom\n\nMatch the level of specificity to the task's fragility and variability:\n\n**High freedom (text-based instructions)**: Use when multiple approaches are valid, decisions depend on context, or heuristics guide the approach.\n\n**Medium freedom (pseudocode or scripts with parameters)**: Use when a preferred pattern exists, some variation is acceptable, or configuration affects behavior.\n\n**Low freedom (specific scripts, few parameters)**: Use when operations are fragile and error-prone, consistency is critical, or a specific sequence must be followed.\n\nThink of Claude as exploring a path: a narrow bridge with cliffs needs specific guardrails (low freedom), while an open field allows many routes (high freedom).\n\n### Anatomy of a Skill\n\nEvery skill consists of a required SKILL.md file and optional bundled resources:\n\n```\nskill-name/\nâ”œâ”€â”€ SKILL.md (required)\nâ”‚   â”œâ”€â”€ YAML frontmatter metadata (required)\nâ”‚   â”‚   â”œâ”€â”€ name: (required)\nâ”‚   â”‚   â””â”€â”€ description: (required)\nâ”‚   â””â”€â”€ Markdown instructions (required)\nâ””â”€â”€ Bundled Resources (optional)\n    â”œâ”€â”€ scripts/          - Executable code (Python/Bash/etc.)\n    â”œâ”€â”€ references/       - Documentation intended to be loaded into context as needed\n    â””â”€â”€ assets/           - Files used in output (templates, icons, fonts, etc.)\n```\n\n#### SKILL.md (required)\n\nEvery SKILL.md consists of:\n\n- **Frontmatter** (YAML): Contains `name` and `description` fields. These are the only fields that Claude reads to determine when the skill gets used, thus it is very important to be clear and comprehensive in describing what the skill is, and when it should be used.\n- **Body** (Markdown): Instructions and guidance for using the skill. Only loaded AFTER the skill triggers (if at all).\n\n#### Bundled Resources (optional)\n\n##### Scripts (`scripts/`)\n\nExecutable code (Python/Bash/etc.) for tasks that require deterministic reliability or are repeatedly rewritten.\n\n- **When to include**: When the same code is being rewritten repeatedly or deterministic reliability is needed\n- **Example**: `scripts/rotate_pdf.py` for PDF rotation tasks\n- **Benefits**: Token efficient, deterministic, may be executed without loading into context\n- **Note**: Scripts may still need to be read by Claude for patching or environment-specific adjustments\n\n##### References (`references/`)\n\nDocumentation and reference material intended to be loaded as needed into context to inform Claude's process and thinking.\n\n- **When to include**: For documentation that Claude should reference while working\n- **Examples**: `references/finance.md` for financial schemas, `references/mnda.md` for company NDA template, `references/policies.md` for company policies, `references/api_docs.md` for API specifications\n- **Use cases**: Database schemas, API documentation, domain knowledge, company policies, detailed workflow guides\n- **Benefits**: Keeps SKILL.md lean, loaded only when Claude determines it's needed\n- **Best practice**: If files are large (>10k words), include grep search patterns in SKILL.md\n- **Avoid duplication**: Information should live in either SKILL.md or references files, not both. Prefer references files for detailed information unless it's truly core to the skillâ€”this keeps SKILL.md lean while making information discoverable without hogging the context window. Keep only essential procedural instructions and workflow guidance in SKILL.md; move detailed reference material, schemas, and examples to references files.\n\n##### Assets (`assets/`)\n\nFiles not intended to be loaded into context, but rather used within the output Claude produces.\n\n- **When to include**: When the skill needs files that will be used in the final output\n- **Examples**: `assets/logo.png` for brand assets, `assets/slides.pptx` for PowerPoint templates, `assets/frontend-template/` for HTML/React boilerplate, `assets/font.ttf` for typography\n- **Use cases**: Templates, images, icons, boilerplate code, fonts, sample documents that get copied or modified\n- **Benefits**: Separates output resources from documentation, enables Claude to use files without loading them into context\n\n#### What to Not Include in a Skill\n\nA skill should only contain essential files that directly support its functionality. Do NOT create extraneous documentation or auxiliary files, including:\n\n- README.md\n- INSTALLATION_GUIDE.md\n- QUICK_REFERENCE.md\n- CHANGELOG.md\n- etc.\n\nThe skill should only contain the information needed for an AI agent to do the job at hand. It should not contain auxilary context about the process that went into creating it, setup and testing procedures, user-facing documentation, etc. Creating additional documentation files just adds clutter and confusion.\n\n### Progressive Disclosure Design Principle\n\nSkills use a three-level loading system to manage context efficiently:\n\n1. **Metadata (name + description)** - Always in context (~100 words)\n2. **SKILL.md body** - When skill triggers (<5k words)\n3. **Bundled resources** - As needed by Claude (Unlimited because scripts can be executed without reading into context window)\n\n#### Progressive Disclosure Patterns\n\nKeep SKILL.md body to the essentials and under 500 lines to minimize context bloat. Split content into separate files when approaching this limit. When splitting out content into other files, it is very important to reference them from SKILL.md and describe clearly when to read them, to ensure the reader of the skill knows they exist and when to use them.\n\n**Key principle:** When a skill supports multiple variations, frameworks, or options, keep only the core workflow and selection guidance in SKILL.md. Move variant-specific details (patterns, examples, configuration) into separate reference files.\n\n**Pattern 1: High-level guide with references**\n\n```markdown\n# PDF Processing\n\n## Quick start\n\nExtract text with pdfplumber:\n[code example]\n\n## Advanced features\n\n- **Form filling**: See [FORMS.md](FORMS.md) for complete guide\n- **API reference**: See [REFERENCE.md](REFERENCE.md) for all methods\n- **Examples**: See [EXAMPLES.md](EXAMPLES.md) for common patterns\n```\n\nClaude loads FORMS.md, REFERENCE.md, or EXAMPLES.md only when needed.\n\n**Pattern 2: Domain-specific organization**\n\nFor Skills with multiple domains, organize content by domain to avoid loading irrelevant context:\n\n```\nbigquery-skill/\nâ”œâ”€â”€ SKILL.md (overview and navigation)\nâ””â”€â”€ reference/\n    â”œâ”€â”€ finance.md (revenue, billing metrics)\n    â”œâ”€â”€ sales.md (opportunities, pipeline)\n    â”œâ”€â”€ product.md (API usage, features)\n    â””â”€â”€ marketing.md (campaigns, attribution)\n```\n\nWhen a user asks about sales metrics, Claude only reads sales.md.\n\nSimilarly, for skills supporting multiple frameworks or variants, organize by variant:\n\n```\ncloud-deploy/\nâ”œâ”€â”€ SKILL.md (workflow + provider selection)\nâ””â”€â”€ references/\n    â”œâ”€â”€ aws.md (AWS deployment patterns)\n    â”œâ”€â”€ gcp.md (GCP deployment patterns)\n    â””â”€â”€ azure.md (Azure deployment patterns)\n```\n\nWhen the user chooses AWS, Claude only reads aws.md.\n\n**Pattern 3: Conditional details**\n\nShow basic content, link to advanced content:\n\n```markdown\n# DOCX Processing\n\n## Creating documents\n\nUse docx-js for new documents. See [DOCX-JS.md](DOCX-JS.md).\n\n## Editing documents\n\nFor simple edits, modify the XML directly.\n\n**For tracked changes**: See [REDLINING.md](REDLINING.md)\n**For OOXML details**: See [OOXML.md](OOXML.md)\n```\n\nClaude reads REDLINING.md or OOXML.md only when the user needs those features.\n\n**Important guidelines:**\n\n- **Avoid deeply nested references** - Keep references one level deep from SKILL.md. All reference files should link directly from SKILL.md.\n- **Structure longer reference files** - For files longer than 100 lines, include a table of contents at the top so Claude can see the full scope when previewing.\n\n## Skill Creation Process\n\nSkill creation involves these steps:\n\n1. Understand the skill with concrete examples\n2. Plan reusable skill contents (scripts, references, assets)\n3. Initialize the skill (run init_skill.py)\n4. Edit the skill (implement resources and write SKILL.md)\n5. Package the skill (run package_skill.py)\n6. Iterate based on real usage\n\nFollow these steps in order, skipping only if there is a clear reason why they are not applicable.\n\n### Step 1: Understanding the Skill with Concrete Examples\n\nSkip this step only when the skill's usage patterns are already clearly understood. It remains valuable even when working with an existing skill.\n\nTo create an effective skill, clearly understand concrete examples of how the skill will be used. This understanding can come from either direct user examples or generated examples that are validated with user feedback.\n\nFor example, when building an image-editor skill, relevant questions include:\n\n- \"What functionality should the image-editor skill support? Editing, rotating, anything else?\"\n- \"Can you give some examples of how this skill would be used?\"\n- \"I can imagine users asking for things like 'Remove the red-eye from this image' or 'Rotate this image'. Are there other ways you imagine this skill being used?\"\n- \"What would a user say that should trigger this skill?\"\n\nTo avoid overwhelming users, avoid asking too many questions in a single message. Start with the most important questions and follow up as needed for better effectiveness.\n\nConclude this step when there is a clear sense of the functionality the skill should support.\n\n### Step 2: Planning the Reusable Skill Contents\n\nTo turn concrete examples into an effective skill, analyze each example by:\n\n1. Considering how to execute on the example from scratch\n2. Identifying what scripts, references, and assets would be helpful when executing these workflows repeatedly\n\nExample: When building a `pdf-editor` skill to handle queries like \"Help me rotate this PDF,\" the analysis shows:\n\n1. Rotating a PDF requires re-writing the same code each time\n2. A `scripts/rotate_pdf.py` script would be helpful to store in the skill\n\nExample: When designing a `frontend-webapp-builder` skill for queries like \"Build me a todo app\" or \"Build me a dashboard to track my steps,\" the analysis shows:\n\n1. Writing a frontend webapp requires the same boilerplate HTML/React each time\n2. An `assets/hello-world/` template containing the boilerplate HTML/React project files would be helpful to store in the skill\n\nExample: When building a `big-query` skill to handle queries like \"How many users have logged in today?\" the analysis shows:\n\n1. Querying BigQuery requires re-discovering the table schemas and relationships each time\n2. A `references/schema.md` file documenting the table schemas would be helpful to store in the skill\n\nTo establish the skill's contents, analyze each concrete example to create a list of the reusable resources to include: scripts, references, and assets.\n\n### Step 3: Initializing the Skill\n\nAt this point, it is time to actually create the skill.\n\nSkip this step only if the skill being developed already exists, and iteration or packaging is needed. In this case, continue to the next step.\n\nWhen creating a new skill from scratch, always run the `init_skill.py` script. The script conveniently generates a new template skill directory that automatically includes everything a skill requires, making the skill creation process much more efficient and reliable.\n\nUsage:\n\n```bash\nscripts/init_skill.py <skill-name> --path <output-directory>\n```\n\nThe script:\n\n- Creates the skill directory at the specified path\n- Generates a SKILL.md template with proper frontmatter and TODO placeholders\n- Creates example resource directories: `scripts/`, `references/`, and `assets/`\n- Adds example files in each directory that can be customized or deleted\n\nAfter initialization, customize or remove the generated SKILL.md and example files as needed.\n\n### Step 4: Edit the Skill\n\nWhen editing the (newly-generated or existing) skill, remember that the skill is being created for another instance of Claude to use. Include information that would be beneficial and non-obvious to Claude. Consider what procedural knowledge, domain-specific details, or reusable assets would help another Claude instance execute these tasks more effectively.\n\n#### Learn Proven Design Patterns\n\nConsult these helpful guides based on your skill's needs:\n\n- **Multi-step processes**: See references/workflows.md for sequential workflows and conditional logic\n- **Specific output formats or quality standards**: See references/output-patterns.md for template and example patterns\n\nThese files contain established best practices for effective skill design.\n\n#### Start with Reusable Skill Contents\n\nTo begin implementation, start with the reusable resources identified above: `scripts/`, `references/`, and `assets/` files. Note that this step may require user input. For example, when implementing a `brand-guidelines` skill, the user may need to provide brand assets or templates to store in `assets/`, or documentation to store in `references/`.\n\nAdded scripts must be tested by actually running them to ensure there are no bugs and that the output matches what is expected. If there are many similar scripts, only a representative sample needs to be tested to ensure confidence that they all work while balancing time to completion.\n\nAny example files and directories not needed for the skill should be deleted. The initialization script creates example files in `scripts/`, `references/`, and `assets/` to demonstrate structure, but most skills won't need all of them.\n\n#### Update SKILL.md\n\n**Writing Guidelines:** Always use imperative/infinitive form.\n\n##### Frontmatter\n\nWrite the YAML frontmatter with `name` and `description`:\n\n- `name`: The skill name\n- `description`: This is the primary triggering mechanism for your skill, and helps Claude understand when to use the skill.\n  - Include both what the Skill does and specific triggers/contexts for when to use it.\n  - Include all \"when to use\" information here - Not in the body. The body is only loaded after triggering, so \"When to Use This Skill\" sections in the body are not helpful to Claude.\n  - Example description for a `docx` skill: \"Comprehensive document creation, editing, and analysis with support for tracked changes, comments, formatting preservation, and text extraction. Use when Claude needs to work with professional documents (.docx files) for: (1) Creating new documents, (2) Modifying or editing content, (3) Working with tracked changes, (4) Adding comments, or any other document tasks\"\n\nDo not include any other fields in YAML frontmatter.\n\n##### Body\n\nWrite instructions for using the skill and its bundled resources.\n\n### Step 5: Packaging a Skill\n\nOnce development of the skill is complete, it must be packaged into a distributable .skill file that gets shared with the user. The packaging process automatically validates the skill first to ensure it meets all requirements:\n\n```bash\nscripts/package_skill.py <path/to/skill-folder>\n```\n\nOptional output directory specification:\n\n```bash\nscripts/package_skill.py <path/to/skill-folder> ./dist\n```\n\nThe packaging script will:\n\n1. **Validate** the skill automatically, checking:\n\n   - YAML frontmatter format and required fields\n   - Skill naming conventions and directory structure\n   - Description completeness and quality\n   - File organization and resource references\n\n2. **Package** the skill if validation passes, creating a .skill file named after the skill (e.g., `my-skill.skill`) that includes all files and maintains the proper directory structure for distribution. The .skill file is a zip file with a .skill extension.\n\nIf validation fails, the script will report the errors and exit without creating a package. Fix any validation errors and run the packaging command again.\n\n### Step 6: Iterate\n\nAfter testing the skill, users may request improvements. Often this happens right after using the skill, with fresh context of how the skill performed.\n\n**Iteration workflow:**\n\n1. Use the skill on real tasks\n2. Notice struggles or inefficiencies\n3. Identify how SKILL.md or bundled resources should be updated\n4. Implement changes and test again\n"
      },
      "discovered_at": "2026-01-11T15:35:49.571819Z",
      "fetch_error": null
    },
    {
      "name": "frontend-code-review",
      "slug": "frontend-code-review",
      "source": "skillsmp_top",
      "owner": "langgenius",
      "repo_name": "dify",
      "repository_url": "https://github.com/langgenius/dify",
      "skill_path": ".claude/skills/frontend-code-review",
      "github_metadata": {
        "stars": 125521,
        "description": "Production-ready platform for agentic workflow development.",
        "default_branch": "main",
        "pushed_at": "2026-01-11T13:54:46Z",
        "created_at": "2023-04-12T07:40:24Z",
        "language": "Python",
        "license": "NOASSERTION",
        "open_issues": 645,
        "forks": 19516
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/frontend-code-review/SKILL.md",
        "branch": "main",
        "content": "---\nname: frontend-code-review\ndescription: \"Trigger when the user requests a review of frontend files (e.g., `.tsx`, `.ts`, `.js`). Support both pending-change reviews and focused file reviews while applying the checklist rules.\"\n---\n\n# Frontend Code Review\n\n## Intent\nUse this skill whenever the user asks to review frontend code (especially `.tsx`, `.ts`, or `.js` files). Support two review modes:\n\n1. **Pending-change review** â€“ inspect staged/working-tree files slated for commit and flag checklist violations before submission.\n2. **File-targeted review** â€“ review the specific file(s) the user names and report the relevant checklist findings.\n\nStick to the checklist below for every applicable file and mode.\n\n## Checklist\nSee [references/code-quality.md](references/code-quality.md), [references/performance.md](references/performance.md), [references/business-logic.md](references/business-logic.md) for the living checklist split by categoryâ€”treat it as the canonical set of rules to follow.\n\nFlag each rule violation with urgency metadata so future reviewers can prioritize fixes.\n\n## Review Process\n1. Open the relevant component/module. Gather lines that relate to class names, React Flow hooks, prop memoization, and styling.\n2. For each rule in the review point, note where the code deviates and capture a representative snippet.\n3. Compose the review section per the template below. Group violations first by **Urgent** flag, then by category order (Code Quality, Performance, Business Logic).\n\n## Required output\nWhen invoked, the response must exactly follow one of the two templates:\n\n### Template A (any findings)\n```\n# Code review\nFound <N> urgent issues need to be fixed:\n\n## 1 <brief description of bug>\nFilePath: <path> line <line>\n<relevant code snippet or pointer>\n\n\n### Suggested fix\n<brief description of suggested fix>\n\n---\n... (repeat for each urgent issue) ...\n\nFound <M> suggestions for improvement:\n\n## 1 <brief description of suggestion>\nFilePath: <path> line <line>\n<relevant code snippet or pointer>\n\n\n### Suggested fix\n<brief description of suggested fix>\n\n---\n\n... (repeat for each suggestion) ...\n```\n\nIf there are no urgent issues, omit that section. If there are no suggestions, omit that section.\n\nIf the issue number is more than 10, summarize as \"10+ urgent issues\" or \"10+ suggestions\" and just output the first 10 issues.\n\nDon't compress the blank lines between sections; keep them as-is for readability.\n\nIf you use Template A (i.e., there are issues to fix) and at least one issue requires code changes, append a brief follow-up question after the structured output asking whether the user wants you to apply the suggested fix(es). For example: \"Would you like me to use the Suggested fix section to address these issues?\"\n\n### Template B (no issues)\n```\n## Code review\nNo issues found.\n```\n\n"
      },
      "discovered_at": "2026-01-11T15:35:50.038836Z",
      "fetch_error": null
    },
    {
      "name": "component-refactoring",
      "slug": "component-refactoring",
      "source": "skillsmp_top",
      "owner": "langgenius",
      "repo_name": "dify",
      "repository_url": "https://github.com/langgenius/dify",
      "skill_path": ".claude/skills/component-refactoring",
      "github_metadata": {
        "stars": 125521,
        "description": "Production-ready platform for agentic workflow development.",
        "default_branch": "main",
        "pushed_at": "2026-01-11T13:54:46Z",
        "created_at": "2023-04-12T07:40:24Z",
        "language": "Python",
        "license": "NOASSERTION",
        "open_issues": 645,
        "forks": 19516
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/component-refactoring/SKILL.md",
        "branch": "main",
        "content": "---\nname: component-refactoring\ndescription: Refactor high-complexity React components in Dify frontend. Use when `pnpm analyze-component --json` shows complexity > 50 or lineCount > 300, when the user asks for code splitting, hook extraction, or complexity reduction, or when `pnpm analyze-component` warns to refactor before testing; avoid for simple/well-structured components, third-party wrappers, or when the user explicitly wants testing without refactoring.\n---\n\n# Dify Component Refactoring Skill\n\nRefactor high-complexity React components in the Dify frontend codebase with the patterns and workflow below.\n\n> **Complexity Threshold**: Components with complexity > 50 (measured by `pnpm analyze-component`) should be refactored before testing.\n\n## Quick Reference\n\n### Commands (run from `web/`)\n\nUse paths relative to `web/` (e.g., `app/components/...`).\nUse `refactor-component` for refactoring prompts and `analyze-component` for testing prompts and metrics.\n\n```bash\ncd web\n\n# Generate refactoring prompt\npnpm refactor-component <path>\n\n# Output refactoring analysis as JSON\npnpm refactor-component <path> --json\n\n# Generate testing prompt (after refactoring)\npnpm analyze-component <path>\n\n# Output testing analysis as JSON\npnpm analyze-component <path> --json\n```\n\n### Complexity Analysis\n\n```bash\n# Analyze component complexity\npnpm analyze-component <path> --json\n\n# Key metrics to check:\n# - complexity: normalized score 0-100 (target < 50)\n# - maxComplexity: highest single function complexity\n# - lineCount: total lines (target < 300)\n```\n\n### Complexity Score Interpretation\n\n| Score | Level | Action |\n|-------|-------|--------|\n| 0-25 | ğŸŸ¢ Simple | Ready for testing |\n| 26-50 | ğŸŸ¡ Medium | Consider minor refactoring |\n| 51-75 | ğŸŸ  Complex | **Refactor before testing** |\n| 76-100 | ğŸ”´ Very Complex | **Must refactor** |\n\n## Core Refactoring Patterns\n\n### Pattern 1: Extract Custom Hooks\n\n**When**: Component has complex state management, multiple `useState`/`useEffect`, or business logic mixed with UI.\n\n**Dify Convention**: Place hooks in a `hooks/` subdirectory or alongside the component as `use-<feature>.ts`.\n\n```typescript\n// âŒ Before: Complex state logic in component\nconst Configuration: FC = () => {\n  const [modelConfig, setModelConfig] = useState<ModelConfig>(...)\n  const [datasetConfigs, setDatasetConfigs] = useState<DatasetConfigs>(...)\n  const [completionParams, setCompletionParams] = useState<FormValue>({})\n  \n  // 50+ lines of state management logic...\n  \n  return <div>...</div>\n}\n\n// âœ… After: Extract to custom hook\n// hooks/use-model-config.ts\nexport const useModelConfig = (appId: string) => {\n  const [modelConfig, setModelConfig] = useState<ModelConfig>(...)\n  const [completionParams, setCompletionParams] = useState<FormValue>({})\n  \n  // Related state management logic here\n  \n  return { modelConfig, setModelConfig, completionParams, setCompletionParams }\n}\n\n// Component becomes cleaner\nconst Configuration: FC = () => {\n  const { modelConfig, setModelConfig } = useModelConfig(appId)\n  return <div>...</div>\n}\n```\n\n**Dify Examples**:\n- `web/app/components/app/configuration/hooks/use-advanced-prompt-config.ts`\n- `web/app/components/app/configuration/debug/hooks.tsx`\n- `web/app/components/workflow/hooks/use-workflow.ts`\n\n### Pattern 2: Extract Sub-Components\n\n**When**: Single component has multiple UI sections, conditional rendering blocks, or repeated patterns.\n\n**Dify Convention**: Place sub-components in subdirectories or as separate files in the same directory.\n\n```typescript\n// âŒ Before: Monolithic JSX with multiple sections\nconst AppInfo = () => {\n  return (\n    <div>\n      {/* 100 lines of header UI */}\n      {/* 100 lines of operations UI */}\n      {/* 100 lines of modals */}\n    </div>\n  )\n}\n\n// âœ… After: Split into focused components\n// app-info/\n//   â”œâ”€â”€ index.tsx           (orchestration only)\n//   â”œâ”€â”€ app-header.tsx      (header UI)\n//   â”œâ”€â”€ app-operations.tsx  (operations UI)\n//   â””â”€â”€ app-modals.tsx      (modal management)\n\nconst AppInfo = () => {\n  const { showModal, setShowModal } = useAppInfoModals()\n  \n  return (\n    <div>\n      <AppHeader appDetail={appDetail} />\n      <AppOperations onAction={handleAction} />\n      <AppModals show={showModal} onClose={() => setShowModal(null)} />\n    </div>\n  )\n}\n```\n\n**Dify Examples**:\n- `web/app/components/app/configuration/` directory structure\n- `web/app/components/workflow/nodes/` per-node organization\n\n### Pattern 3: Simplify Conditional Logic\n\n**When**: Deep nesting (> 3 levels), complex ternaries, or multiple `if/else` chains.\n\n```typescript\n// âŒ Before: Deeply nested conditionals\nconst Template = useMemo(() => {\n  if (appDetail?.mode === AppModeEnum.CHAT) {\n    switch (locale) {\n      case LanguagesSupported[1]:\n        return <TemplateChatZh />\n      case LanguagesSupported[7]:\n        return <TemplateChatJa />\n      default:\n        return <TemplateChatEn />\n    }\n  }\n  if (appDetail?.mode === AppModeEnum.ADVANCED_CHAT) {\n    // Another 15 lines...\n  }\n  // More conditions...\n}, [appDetail, locale])\n\n// âœ… After: Use lookup tables + early returns\nconst TEMPLATE_MAP = {\n  [AppModeEnum.CHAT]: {\n    [LanguagesSupported[1]]: TemplateChatZh,\n    [LanguagesSupported[7]]: TemplateChatJa,\n    default: TemplateChatEn,\n  },\n  [AppModeEnum.ADVANCED_CHAT]: {\n    [LanguagesSupported[1]]: TemplateAdvancedChatZh,\n    // ...\n  },\n}\n\nconst Template = useMemo(() => {\n  const modeTemplates = TEMPLATE_MAP[appDetail?.mode]\n  if (!modeTemplates) return null\n  \n  const TemplateComponent = modeTemplates[locale] || modeTemplates.default\n  return <TemplateComponent appDetail={appDetail} />\n}, [appDetail, locale])\n```\n\n### Pattern 4: Extract API/Data Logic\n\n**When**: Component directly handles API calls, data transformation, or complex async operations.\n\n**Dify Convention**: Use `@tanstack/react-query` hooks from `web/service/use-*.ts` or create custom data hooks.\n\n```typescript\n// âŒ Before: API logic in component\nconst MCPServiceCard = () => {\n  const [basicAppConfig, setBasicAppConfig] = useState({})\n  \n  useEffect(() => {\n    if (isBasicApp && appId) {\n      (async () => {\n        const res = await fetchAppDetail({ url: '/apps', id: appId })\n        setBasicAppConfig(res?.model_config || {})\n      })()\n    }\n  }, [appId, isBasicApp])\n  \n  // More API-related logic...\n}\n\n// âœ… After: Extract to data hook using React Query\n// use-app-config.ts\nimport { useQuery } from '@tanstack/react-query'\nimport { get } from '@/service/base'\n\nconst NAME_SPACE = 'appConfig'\n\nexport const useAppConfig = (appId: string, isBasicApp: boolean) => {\n  return useQuery({\n    enabled: isBasicApp && !!appId,\n    queryKey: [NAME_SPACE, 'detail', appId],\n    queryFn: () => get<AppDetailResponse>(`/apps/${appId}`),\n    select: data => data?.model_config || {},\n  })\n}\n\n// Component becomes cleaner\nconst MCPServiceCard = () => {\n  const { data: config, isLoading } = useAppConfig(appId, isBasicApp)\n  // UI only\n}\n```\n\n**React Query Best Practices in Dify**:\n- Define `NAME_SPACE` for query key organization\n- Use `enabled` option for conditional fetching\n- Use `select` for data transformation\n- Export invalidation hooks: `useInvalidXxx`\n\n**Dify Examples**:\n- `web/service/use-workflow.ts`\n- `web/service/use-common.ts`\n- `web/service/knowledge/use-dataset.ts`\n- `web/service/knowledge/use-document.ts`\n\n### Pattern 5: Extract Modal/Dialog Management\n\n**When**: Component manages multiple modals with complex open/close states.\n\n**Dify Convention**: Modals should be extracted with their state management.\n\n```typescript\n// âŒ Before: Multiple modal states in component\nconst AppInfo = () => {\n  const [showEditModal, setShowEditModal] = useState(false)\n  const [showDuplicateModal, setShowDuplicateModal] = useState(false)\n  const [showConfirmDelete, setShowConfirmDelete] = useState(false)\n  const [showSwitchModal, setShowSwitchModal] = useState(false)\n  const [showImportDSLModal, setShowImportDSLModal] = useState(false)\n  // 5+ more modal states...\n}\n\n// âœ… After: Extract to modal management hook\ntype ModalType = 'edit' | 'duplicate' | 'delete' | 'switch' | 'import' | null\n\nconst useAppInfoModals = () => {\n  const [activeModal, setActiveModal] = useState<ModalType>(null)\n  \n  const openModal = useCallback((type: ModalType) => setActiveModal(type), [])\n  const closeModal = useCallback(() => setActiveModal(null), [])\n  \n  return {\n    activeModal,\n    openModal,\n    closeModal,\n    isOpen: (type: ModalType) => activeModal === type,\n  }\n}\n```\n\n### Pattern 6: Extract Form Logic\n\n**When**: Complex form validation, submission handling, or field transformation.\n\n**Dify Convention**: Use `@tanstack/react-form` patterns from `web/app/components/base/form/`.\n\n```typescript\n// âœ… Use existing form infrastructure\nimport { useAppForm } from '@/app/components/base/form'\n\nconst ConfigForm = () => {\n  const form = useAppForm({\n    defaultValues: { name: '', description: '' },\n    onSubmit: handleSubmit,\n  })\n  \n  return <form.Provider>...</form.Provider>\n}\n```\n\n## Dify-Specific Refactoring Guidelines\n\n### 1. Context Provider Extraction\n\n**When**: Component provides complex context values with multiple states.\n\n```typescript\n// âŒ Before: Large context value object\nconst value = {\n  appId, isAPIKeySet, isTrailFinished, mode, modelModeType,\n  promptMode, isAdvancedMode, isAgent, isOpenAI, isFunctionCall,\n  // 50+ more properties...\n}\nreturn <ConfigContext.Provider value={value}>...</ConfigContext.Provider>\n\n// âœ… After: Split into domain-specific contexts\n<ModelConfigProvider value={modelConfigValue}>\n  <DatasetConfigProvider value={datasetConfigValue}>\n    <UIConfigProvider value={uiConfigValue}>\n      {children}\n    </UIConfigProvider>\n  </DatasetConfigProvider>\n</ModelConfigProvider>\n```\n\n**Dify Reference**: `web/context/` directory structure\n\n### 2. Workflow Node Components\n\n**When**: Refactoring workflow node components (`web/app/components/workflow/nodes/`).\n\n**Conventions**:\n- Keep node logic in `use-interactions.ts`\n- Extract panel UI to separate files\n- Use `_base` components for common patterns\n\n```\nnodes/<node-type>/\n  â”œâ”€â”€ index.tsx              # Node registration\n  â”œâ”€â”€ node.tsx               # Node visual component\n  â”œâ”€â”€ panel.tsx              # Configuration panel\n  â”œâ”€â”€ use-interactions.ts    # Node-specific hooks\n  â””â”€â”€ types.ts               # Type definitions\n```\n\n### 3. Configuration Components\n\n**When**: Refactoring app configuration components.\n\n**Conventions**:\n- Separate config sections into subdirectories\n- Use existing patterns from `web/app/components/app/configuration/`\n- Keep feature toggles in dedicated components\n\n### 4. Tool/Plugin Components\n\n**When**: Refactoring tool-related components (`web/app/components/tools/`).\n\n**Conventions**:\n- Follow existing modal patterns\n- Use service hooks from `web/service/use-tools.ts`\n- Keep provider-specific logic isolated\n\n## Refactoring Workflow\n\n### Step 1: Generate Refactoring Prompt\n\n```bash\npnpm refactor-component <path>\n```\n\nThis command will:\n- Analyze component complexity and features\n- Identify specific refactoring actions needed\n- Generate a prompt for AI assistant (auto-copied to clipboard on macOS)\n- Provide detailed requirements based on detected patterns\n\n### Step 2: Analyze Details\n\n```bash\npnpm analyze-component <path> --json\n```\n\nIdentify:\n- Total complexity score\n- Max function complexity\n- Line count\n- Features detected (state, effects, API, etc.)\n\n### Step 3: Plan\n\nCreate a refactoring plan based on detected features:\n\n| Detected Feature | Refactoring Action |\n|------------------|-------------------|\n| `hasState: true` + `hasEffects: true` | Extract custom hook |\n| `hasAPI: true` | Extract data/service hook |\n| `hasEvents: true` (many) | Extract event handlers |\n| `lineCount > 300` | Split into sub-components |\n| `maxComplexity > 50` | Simplify conditional logic |\n\n### Step 4: Execute Incrementally\n\n1. **Extract one piece at a time**\n2. **Run lint, type-check, and tests after each extraction**\n3. **Verify functionality before next step**\n\n```\nFor each extraction:\n  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n  â”‚ 1. Extract code                        â”‚\n  â”‚ 2. Run: pnpm lint:fix                  â”‚\n  â”‚ 3. Run: pnpm type-check:tsgo           â”‚\n  â”‚ 4. Run: pnpm test                      â”‚\n  â”‚ 5. Test functionality manually         â”‚\n  â”‚ 6. PASS? â†’ Next extraction             â”‚\n  â”‚    FAIL? â†’ Fix before continuing       â”‚\n  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### Step 5: Verify\n\nAfter refactoring:\n\n```bash\n# Re-run refactor command to verify improvements\npnpm refactor-component <path>\n\n# If complexity < 25 and lines < 200, you'll see:\n# âœ… COMPONENT IS WELL-STRUCTURED\n\n# For detailed metrics:\npnpm analyze-component <path> --json\n\n# Target metrics:\n# - complexity < 50\n# - lineCount < 300\n# - maxComplexity < 30\n```\n\n## Common Mistakes to Avoid\n\n### âŒ Over-Engineering\n\n```typescript\n// âŒ Too many tiny hooks\nconst useButtonText = () => useState('Click')\nconst useButtonDisabled = () => useState(false)\nconst useButtonLoading = () => useState(false)\n\n// âœ… Cohesive hook with related state\nconst useButtonState = () => {\n  const [text, setText] = useState('Click')\n  const [disabled, setDisabled] = useState(false)\n  const [loading, setLoading] = useState(false)\n  return { text, setText, disabled, setDisabled, loading, setLoading }\n}\n```\n\n### âŒ Breaking Existing Patterns\n\n- Follow existing directory structures\n- Maintain naming conventions\n- Preserve export patterns for compatibility\n\n### âŒ Premature Abstraction\n\n- Only extract when there's clear complexity benefit\n- Don't create abstractions for single-use code\n- Keep refactored code in the same domain area\n\n## References\n\n### Dify Codebase Examples\n\n- **Hook extraction**: `web/app/components/app/configuration/hooks/`\n- **Component splitting**: `web/app/components/app/configuration/`\n- **Service hooks**: `web/service/use-*.ts`\n- **Workflow patterns**: `web/app/components/workflow/hooks/`\n- **Form patterns**: `web/app/components/base/form/`\n\n### Related Skills\n\n- `frontend-testing` - For testing refactored components\n- `web/testing/testing.md` - Testing specification\n"
      },
      "discovered_at": "2026-01-11T15:35:50.628082Z",
      "fetch_error": null
    },
    {
      "name": "electron-chromium-upgrade",
      "slug": "electron-chromium-upgrade",
      "source": "skillsmp_top",
      "owner": "electron",
      "repo_name": "electron",
      "repository_url": "https://github.com/electron/electron",
      "skill_path": ".claude/skills/electron-chromium-upgrade",
      "github_metadata": {
        "stars": 119701,
        "description": ":electron: Build cross-platform desktop apps with JavaScript, HTML, and CSS",
        "default_branch": "main",
        "pushed_at": "2026-01-11T13:00:36Z",
        "created_at": "2013-04-12T01:47:36Z",
        "language": "C++",
        "license": "MIT",
        "open_issues": 910,
        "forks": 16915
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/electron-chromium-upgrade/SKILL.md",
        "branch": "main",
        "content": "---\nname: electron-chromium-upgrade\ndescription: Guide for performing Chromium version upgrades in the Electron project. Use when working on the roller/chromium/main branch to fix patch conflicts during `e sync --3`. Covers the patch application workflow, conflict resolution, analyzing upstream Chromium changes, and proper commit formatting for patch fixes.\n---\n\n# Electron Chromium Upgrade: Phase One\n\n## Summary\n\nRun `e sync --3` repeatedly, fixing patch conflicts as they arise, until it succeeds. Then run `e patches all` and commit changes atomically.\n\n## Success Criteria\n\nPhase One is complete when:\n- `e sync --3` exits with code 0 (no patch failures)\n- `e patches all` has been run to export all changes\n- All changes are committed per the commit guidelines below\n\nDo not stop until these criteria are met.\n\n**CRITICAL** Do not delete or skip patches unless 100% certain the patch is no longer needed. Complicated conflicts or hard to resolve issues should be presented to the user after you have exhausted all other options. Do not delete the patch just because you can't solve it.\n\n## Context\n\nThe `roller/chromium/main` branch is created by automation to update Electron's Chromium dependency SHA. No work has been done to handle breaking changes between the old and new versions.\n\n**Key directories:**\n- Current directory: Electron repo (always run `e` commands here)\n- `..` (parent): Chromium repo (where most patches apply)\n- `patches/`: Patch files organized by target\n- `docs/development/patches.md`: Patch system documentation\n\n## Workflow\n\n1. Delete the `.git/rr-cache` in both the `electron` and `..` folder to ensure no accidental rerere replays occur from before this upgrade phase attempt started\n2. Run `e sync --3` (the `--3` flag enables 3-way merge, always required)\n3. If succeeds â†’ skip to step 6\n4. If patch fails:\n   - Identify target repo and patch from error output\n   - Analyze failure (see references/patch-analysis.md)\n   - Fix conflict in target repo's working directory\n   - Run `git am --continue` in affected repo\n   - Repeat until all patches for that repo apply\n   - IMPORTANT: Once `git am --continue` succeeds you MUST run `e patches {target}` to export fixes\n   - Return to step 1\n5. When `e sync --3` succeeds, run `e patches all`\n6. **Read `references/phase-one-commit-guidelines.md` NOW**, then commit changes following those instructions exactly.\n\nBefore committing any Phase One changes, you MUST read `references/phase-one-commit-guidelines.md` and follow its instructions exactly.\n\n## Commands Reference\n\n| Command | Purpose |\n|---------|---------|\n| `e sync --3` | Clone deps and apply patches with 3-way merge |\n| `git am --continue` | Continue after resolving conflict (run in target repo) |\n| `e patches {target}` | Export commits from target repo to patch files |\n| `e patches all` | Export all patches from all targets |\n| `e patches --list-targets` | List targets and config paths |\n\n## Patch System Mental Model\n\n```\npatches/{target}/*.patch  â†’  [e sync --3]  â†’  target repo commits\n                          â†  [e patches]   â†\n```\n\n## When to Edit Patches\n\n| Situation | Action |\n|-----------|--------|\n| During active `git am` conflict | Fix in target repo, then `git am --continue` |\n| Modifying patch outside conflict | Edit `.patch` file directly |\n| Creating new patch (rare, avoid) | Commit in target repo, then `e patches {target}` |\n\nFix existing patches 99% of the time rather than creating new ones.\n\n## Patch Fixing Rules\n\n1. **Preserve authorship**: Keep original author in TODO comments (from patch `From:` field)\n2. **Never change TODO assignees**: `TODO(name)` must retain original name\n3. **Update descriptions**: If upstream changed (e.g., `DCHECK` â†’ `CHECK_IS_TEST`), update patch commit message to reflect current state\n\n## Final Deliverable\n\nAfter Phase One, write a summary of every change: what was fixed, why, reasoning, and Chromium CL links.\n\n# Electron Chromium Upgrade: Phase Two\n\n## Summary\n\nRun `e build -k 999` repeatedly, fixing build issues as they arise, until it succeeds. Then run `e start --version` to validate Electron launches and commit changes atomically.\n\nRun Phase Two immediately after Phase One is complete.\n\n## Success Criteria\n\nPhase Two is complete when:\n- `e build -k 999` exits with code 0 (no build failures)\n- `e start --version` has been run to check Electron launches\n- All changes are committed per the commit guidelines below\n\nDo not stop until these criteria are met. Do not delete code or features, never comment out code in order to take short cut. Make all existing code, logic and intention work.\n\n## Context\n\nThe `roller/chromium/main` branch is created by automation to update Electron's Chromium dependency SHA. No work has been done to handle breaking changes between the old and new versions. Chromium APIs frequently are renamed or refactored. In every case the code in Electron must be updated to account for the change in Chromium, strongly avoid making changes to the code in chromium to fix Electrons build.\n\n**Key directories:**\n- Current directory: Electron repo (always run `e` commands here)\n- `..` (parent): Chromium repo (do not touch this code to fix build issues, just read it to obtain context)\n\n## Workflow\n\n1. Run `e build -k 999` (the `-k 999` flag is a flag to ninja to say \"do not stop until you find that many errors\" it is an attempt to get as much error\n  context as possible for each time we run build)\n2. If succeeds â†’ skip to step 6\n3. If build fails:\n    - Identify underlying file in \"electron\" from the compilation error message\n    - Analyze failure\n    - Fix build issue by adapting Electron's code for the change in Chromium\n    - Run `e build -t {target_that_failed}.o` to build just the failed target we were specifically fixing\n        - You can identify the target_that_failed from the failure line in the build log. E.g. `FAILED: 2e506007-8d5d-4f38-bdd1-b5cd77999a77 \"./obj/electron/chromium_src/chrome/process_singleton_posix.o\" CXX obj/electron/chromium_src/chrome/process_singleton_posix.o` the target name is `obj/electron/chromium_src/chrome/process_singleton_posix.o`\n    - **Read `references/phase-two-commit-guidelines.md` NOW**, then commit changes following those instructions exactly.\n    - Return to step 1\n4. **CRITICAL**: After ANY commit (especially patch commits), immediately run `git status` in the electron repo\n    - Look for other modified `.patch` files that only have index/hunk header changes\n    - These are dependent patches affected by your fix\n    - Commit them immediately with: `git commit -am \"chore: update patch hunk headers\"`\n    - This prevents losing track of necessary updates\n5. Return to step 1\n6. When `e build` succeeds, run `e start --version`\n7. Check if you have any pending changes in the Chromium repo by running `git status`\n    - If you have changes follow the instructions below in \"A. Patch Fixes\" to correctly commit those modifications into the appropriate patch file\n\nBefore committing any Phase Two changes, you MUST read `references/phase-two-commit-guidelines.md` and follow its instructions exactly.\n\n## Build Error Detection\n\nWhen monitoring `e build -k 999` output, filter for errors using this regex pattern:\nerror:|FAILED:|fatal:|subcommand failed|build finished\n\nThe build output is extremely verbose. Filtering is essential to catch errors quickly.\n\n## Commands Reference\n\n| Command | Purpose |\n|---------|---------|\n| `e build -k 999` | Builds Electron and won't stop until either all targets attempted or 999 errors found |\n| `e build -t {target}.o` | Build just one specific target to verify a fix |\n| `e start --version` | Validate Electron launches after successful build |\n\n## Two Types of Build Fixes\n\n### A. Patch Fixes (for files in chromium_src or patched Chromium files)\n\nWhen the error is in a file that Electron patches (check with `grep -l \"filename\" patches/chromium/*.patch`):\n\n1. Edit the file in the Chromium source tree (e.g., `/src/chrome/browser/...`)\n2. Create a fixup commit targeting the original patch commit:\n    ```bash\n    cd ..  # to chromium repo\n    git add <modified-file>\n    git commit --fixup=<original-patch-commit-hash>\n    GIT_SEQUENCE_EDITOR=: git rebase --autosquash --autostash -i <commit>^\n3. Export the updated patch: e patches chromium\n4. Commit the updated patch file in the electron repo following the `references/phase-one-commit-guidelines.md`, then commit changes following those instructions exactly. **READ THESE GUIDELINES BEFORE COMMITTING THESE CHANGES**\n\nTo find the original patch commit to fixup: `git log --oneline | grep -i \"keyword from patch name\"`\n\nThe base commit for rebase is the Chromium commit before patches were applied. Find it by checking the `refs/patches/upstream-head` ref.\n\nB. Electron Code Fixes (for files in shell/, electron/, etc.)\n\nWhen the error is in Electron's own source code:\n\n1. Edit files directly in the electron repo\n2. Commit directly (no patch export needed)\n\nDependent Patch Updates\n\nIMPORTANT: When you modify a patch, other patches that apply to the same file may have their hunk headers invalidated. After committing a patch fix:\n\n1. Run git status in the electron repo\n2. Look for other modified .patch files with just index/hunk header changes\n3. Commit these with: git commit -m \"chore: update patch hunk headers\"\n\n# Critical: Read Before Committing\n\n- Before ANY Phase One commits: Read `references/phase-one-commit-guidelines.md`\n- Before ANY Phase Two commits: Read `references/phase-two-commit-guidelines.md`\n\n# Skill Directory Structure\nThis skill has additional reference files in `references/`:\n- patch-analysis.md - How to analyze patch failures\n- phase-one-commit-guidelines.md - Commit format for Phase One\n- phase-two-commit-guidelines.md - Commit format for Phase Two\n\nRead these when referenced in the workflow steps."
      },
      "discovered_at": "2026-01-11T15:35:51.176746Z",
      "fetch_error": null
    },
    {
      "name": "add-uint-support",
      "slug": "add-uint-support",
      "source": "skillsmp_top",
      "owner": "pytorch",
      "repo_name": "pytorch",
      "repository_url": "https://github.com/pytorch/pytorch",
      "skill_path": ".claude/skills/add-uint-support",
      "github_metadata": {
        "stars": 96524,
        "description": "Tensors and Dynamic neural networks in Python with strong GPU acceleration",
        "default_branch": "main",
        "pushed_at": "2026-01-11T15:25:31Z",
        "created_at": "2016-08-13T05:26:41Z",
        "language": "Python",
        "license": "NOASSERTION",
        "open_issues": 17874,
        "forks": 26484
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/add-uint-support/SKILL.md",
        "branch": "main",
        "content": "---\nname: add-uint-support\ndescription: Add unsigned integer (uint) type support to PyTorch operators by updating AT_DISPATCH macros. Use when adding support for uint16, uint32, uint64 types to operators, kernels, or when user mentions enabling unsigned types, barebones unsigned types, or uint support.\n---\n\n# Add Unsigned Integer (uint) Support to Operators\n\nThis skill helps add support for unsigned integer types (uint16, uint32, uint64) to PyTorch operators by updating their AT_DISPATCH macros.\n\n## When to use this skill\n\nUse this skill when:\n- Adding uint16, uint32, or uint64 support to an operator\n- User mentions \"unsigned types\", \"uint support\", \"barebones unsigned types\"\n- Enabling support for kUInt16, kUInt32, kUInt64 in kernels\n- Working with operator implementations that need expanded type coverage\n\n## Quick reference\n\n**Add unsigned types to existing dispatch:**\n```cpp\n// Before\nAT_DISPATCH_V2(dtype, \"op\", AT_WRAP([&]() {\n  kernel<scalar_t>();\n}), AT_EXPAND(AT_ALL_TYPES));\n\n// After (method 1: add unsigned types explicitly)\nAT_DISPATCH_V2(dtype, \"op\", AT_WRAP([&]() {\n  kernel<scalar_t>();\n}), AT_EXPAND(AT_ALL_TYPES), AT_EXPAND(AT_BAREBONES_UNSIGNED_TYPES));\n\n// After (method 2: use V2 integral types if AT_INTEGRAL_TYPES present)\nAT_DISPATCH_V2(dtype, \"op\", AT_WRAP([&]() {\n  kernel<scalar_t>();\n}), AT_EXPAND(AT_INTEGRAL_TYPES_V2), AT_EXPAND(AT_FLOATING_TYPES));\n```\n\n## Type group reference\n\n**Unsigned type groups:**\n- `AT_BAREBONES_UNSIGNED_TYPES`: kUInt16, kUInt32, kUInt64\n- `AT_INTEGRAL_TYPES_V2`: AT_INTEGRAL_TYPES + AT_BAREBONES_UNSIGNED_TYPES\n\n**Relationship:**\n```cpp\nAT_INTEGRAL_TYPES          // kByte, kChar, kInt, kLong, kShort\nAT_BAREBONES_UNSIGNED_TYPES  // kUInt16, kUInt32, kUInt64\nAT_INTEGRAL_TYPES_V2       // INTEGRAL_TYPES + BAREBONES_UNSIGNED_TYPES\n```\n\n## Instructions\n\n### Step 1: Determine if conversion to V2 is needed\n\nCheck if the file uses AT_DISPATCH_V2:\n\n**If using old AT_DISPATCH:**\n- First convert to AT_DISPATCH_V2 using the at-dispatch-v2 skill\n- Then proceed with adding uint support\n\n**If already using AT_DISPATCH_V2:**\n- Proceed directly to Step 2\n\n### Step 2: Analyze the current dispatch macro\n\nIdentify what type groups are currently in use:\n\n```cpp\nAT_DISPATCH_V2(dtype, \"op\", AT_WRAP([&]() {\n  // body\n}), AT_EXPAND(AT_ALL_TYPES), kHalf, kBFloat16);\n    ^^^^^^^^^^^^^^^^^^^^^^^^^\n    Current type coverage\n```\n\nCommon patterns:\n- `AT_EXPAND(AT_ALL_TYPES)` â†’ includes AT_INTEGRAL_TYPES + AT_FLOATING_TYPES\n- `AT_EXPAND(AT_INTEGRAL_TYPES)` â†’ signed integers only\n- `AT_EXPAND(AT_FLOATING_TYPES)` â†’ floating point types\n\n### Step 3: Choose the uint addition method\n\nTwo approaches:\n\n**Method 1: Add AT_BAREBONES_UNSIGNED_TYPES explicitly**\n- Use when: You want to be explicit about adding uint support\n- Add `AT_EXPAND(AT_BAREBONES_UNSIGNED_TYPES)` to the type list\n\n**Method 2: Substitute AT_INTEGRAL_TYPES with AT_INTEGRAL_TYPES_V2**\n- Use when: The dispatch already uses `AT_EXPAND(AT_INTEGRAL_TYPES)`\n- More concise: replaces one type group with its superset\n- Only applicable if AT_INTEGRAL_TYPES is present\n\n### Step 4: Apply the transformation\n\n**Method 1 example:**\n```cpp\n// Before\nAT_DISPATCH_V2(\n    dtype,\n    \"min_values_cuda\",\n    AT_WRAP([&]() {\n      kernel_impl<scalar_t>(iter);\n    }),\n    AT_EXPAND(AT_ALL_TYPES),\n    kBFloat16, kHalf, kBool\n);\n\n// After (add unsigned types)\nAT_DISPATCH_V2(\n    dtype,\n    \"min_values_cuda\",\n    AT_WRAP([&]() {\n      kernel_impl<scalar_t>(iter);\n    }),\n    AT_EXPAND(AT_ALL_TYPES),\n    AT_EXPAND(AT_BAREBONES_UNSIGNED_TYPES),\n    kBFloat16, kHalf, kBool\n);\n```\n\n**Method 2 example:**\n```cpp\n// Before\nAT_DISPATCH_V2(\n    dtype,\n    \"integral_op\",\n    AT_WRAP([&]() {\n      kernel<scalar_t>();\n    }),\n    AT_EXPAND(AT_INTEGRAL_TYPES)\n);\n\n// After (substitute with V2)\nAT_DISPATCH_V2(\n    dtype,\n    \"integral_op\",\n    AT_WRAP([&]() {\n      kernel<scalar_t>();\n    }),\n    AT_EXPAND(AT_INTEGRAL_TYPES_V2)\n);\n```\n\n### Step 5: Handle AT_ALL_TYPES vs individual type groups\n\nIf the dispatch uses `AT_EXPAND(AT_ALL_TYPES)`:\n- `AT_ALL_TYPES` = `AT_INTEGRAL_TYPES` + `AT_FLOATING_TYPES`\n- To add uint: add `AT_EXPAND(AT_BAREBONES_UNSIGNED_TYPES)` to the list\n\nIf the dispatch separately lists INTEGRAL and FLOATING:\n```cpp\n// Before\nAT_EXPAND(AT_INTEGRAL_TYPES), AT_EXPAND(AT_FLOATING_TYPES)\n\n// After (Method 2 preferred)\nAT_EXPAND(AT_INTEGRAL_TYPES_V2), AT_EXPAND(AT_FLOATING_TYPES)\n```\n\n### Step 6: Verify all dispatch sites\n\nCheck the file for ALL dispatch macros that need uint support:\n- Some operators have multiple dispatch sites (CPU, CUDA, different functions)\n- Apply the transformation consistently across all sites\n- Ensure each gets the same type coverage updates\n\n### Step 7: Validate the changes\n\nCheck that:\n- [ ] AT_DISPATCH_V2 format is used (not old AT_DISPATCH)\n- [ ] Unsigned types are added via one of the two methods\n- [ ] All relevant dispatch sites in the file are updated\n- [ ] Type groups use `AT_EXPAND()`\n- [ ] Arguments are properly formatted and comma-separated\n\n## Common patterns\n\n### Pattern 1: AT_ALL_TYPES + extras\n\n```cpp\n// Before\nAT_DISPATCH_V2(dtype, \"op\", AT_WRAP([&]() {\n  kernel<scalar_t>();\n}), AT_EXPAND(AT_ALL_TYPES), kHalf, kBFloat16);\n\n// After\nAT_DISPATCH_V2(dtype, \"op\", AT_WRAP([&]() {\n  kernel<scalar_t>();\n}), AT_EXPAND(AT_ALL_TYPES), AT_EXPAND(AT_BAREBONES_UNSIGNED_TYPES), kHalf, kBFloat16);\n```\n\n### Pattern 2: Separate INTEGRAL + FLOATING\n\n```cpp\n// Before\nAT_DISPATCH_V2(dtype, \"op\", AT_WRAP([&]() {\n  kernel<scalar_t>();\n}), AT_EXPAND(AT_INTEGRAL_TYPES), AT_EXPAND(AT_FLOATING_TYPES));\n\n// After\nAT_DISPATCH_V2(dtype, \"op\", AT_WRAP([&]() {\n  kernel<scalar_t>();\n}), AT_EXPAND(AT_INTEGRAL_TYPES_V2), AT_EXPAND(AT_FLOATING_TYPES));\n```\n\n### Pattern 3: Old dispatch needs conversion first\n\n```cpp\n// Before (needs v2 conversion first)\nAT_DISPATCH_ALL_TYPES_AND2(kHalf, kBFloat16, dtype, \"op\", [&]() {\n  kernel<scalar_t>();\n});\n\n// After v2 conversion\nAT_DISPATCH_V2(dtype, \"op\", AT_WRAP([&]() {\n  kernel<scalar_t>();\n}), AT_EXPAND(AT_ALL_TYPES), kHalf, kBFloat16);\n\n// After adding uint support\nAT_DISPATCH_V2(dtype, \"op\", AT_WRAP([&]() {\n  kernel<scalar_t>();\n}), AT_EXPAND(AT_ALL_TYPES), AT_EXPAND(AT_BAREBONES_UNSIGNED_TYPES), kHalf, kBFloat16);\n```\n\n## Multiple dispatch sites example\n\nFor a file with multiple functions:\n\n```cpp\nvoid min_values_kernel_cuda(TensorIterator& iter) {\n  AT_DISPATCH_V2(iter.dtype(), \"min_values_cuda\", AT_WRAP([&]() {\n    impl<scalar_t>(iter);\n  }), AT_EXPAND(AT_ALL_TYPES), AT_EXPAND(AT_BAREBONES_UNSIGNED_TYPES), kBFloat16, kHalf);\n  //                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  //                           Added uint support\n}\n\nvoid min_launch_kernel(TensorIterator &iter) {\n  AT_DISPATCH_V2(iter.input_dtype(), \"min_cuda\", AT_WRAP([&]() {\n    gpu_reduce_kernel<scalar_t>(iter);\n  }), AT_EXPAND(AT_ALL_TYPES), AT_EXPAND(AT_BAREBONES_UNSIGNED_TYPES), kBFloat16, kHalf);\n  //                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  //                           Added uint support here too\n}\n```\n\n## Decision tree\n\nUse this decision tree to determine the approach:\n\n```\nIs the file using AT_DISPATCH_V2?\nâ”œâ”€ No â†’ Use at-dispatch-v2 skill first, then continue\nâ””â”€ Yes\n   â””â”€ Does it use AT_EXPAND(AT_INTEGRAL_TYPES)?\n      â”œâ”€ Yes â†’ Replace with AT_EXPAND(AT_INTEGRAL_TYPES_V2)\n      â””â”€ No â†’ Add AT_EXPAND(AT_BAREBONES_UNSIGNED_TYPES) to type list\n```\n\n## Edge cases\n\n### Case 1: Dispatch with only floating types\n\nIf the operator only supports floating point types, don't add uint support:\n\n```cpp\n// Leave as-is - floating point only operator\nAT_DISPATCH_V2(dtype, \"float_op\", AT_WRAP([&]() {\n  kernel<scalar_t>();\n}), AT_EXPAND(AT_FLOATING_TYPES), kHalf);\n```\n\n### Case 2: Complex types present\n\nUnsigned types work alongside complex types:\n\n```cpp\nAT_DISPATCH_V2(dtype, \"op\", AT_WRAP([&]() {\n  kernel<scalar_t>();\n}), AT_EXPAND(AT_ALL_TYPES),\n    AT_EXPAND(AT_BAREBONES_UNSIGNED_TYPES),\n    AT_EXPAND(AT_COMPLEX_TYPES),\n    kHalf, kBFloat16);\n```\n\n### Case 3: Already has uint support\n\nCheck if uint types are already present:\n- If `AT_INTEGRAL_TYPES_V2` is used â†’ already has uint support\n- If `AT_BAREBONES_UNSIGNED_TYPES` is already in list â†’ already has uint support\n- Skip the file if uint support is already present\n\n## Workflow\n\nWhen asked to add uint support:\n\n1. Read the target file\n2. Check if using AT_DISPATCH_V2:\n   - If not â†’ use at-dispatch-v2 skill first\n3. Identify all dispatch macro sites\n4. For each dispatch:\n   - Analyze current type groups\n   - Choose method (add BAREBONES_UNSIGNED or upgrade to V2)\n   - Apply transformation with Edit tool\n5. Show the user the changes\n6. Explain what was modified\n\n## Important notes\n\n- Always check if v2 conversion is needed first\n- Apply changes consistently across all dispatch sites in the file\n- Method 2 (AT_INTEGRAL_TYPES_V2) is cleaner when applicable\n- Method 1 (explicit AT_BAREBONES_UNSIGNED_TYPES) is more explicit\n- Unsigned types are: kUInt16, kUInt32, kUInt64 (not kByte which is uint8)\n- Some operators may not semantically support unsigned types - use judgment\n\n## Testing\n\nAfter adding uint support, the operator should accept uint16, uint32, and uint64 tensors. The user is responsible for functional testing.\n"
      },
      "discovered_at": "2026-01-11T15:35:51.650647Z",
      "fetch_error": null
    },
    {
      "name": "at-dispatch-v2",
      "slug": "at-dispatch-v2",
      "source": "skillsmp_top",
      "owner": "pytorch",
      "repo_name": "pytorch",
      "repository_url": "https://github.com/pytorch/pytorch",
      "skill_path": ".claude/skills/at-dispatch-v2",
      "github_metadata": {
        "stars": 96524,
        "description": "Tensors and Dynamic neural networks in Python with strong GPU acceleration",
        "default_branch": "main",
        "pushed_at": "2026-01-11T15:25:31Z",
        "created_at": "2016-08-13T05:26:41Z",
        "language": "Python",
        "license": "NOASSERTION",
        "open_issues": 17874,
        "forks": 26484
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/at-dispatch-v2/SKILL.md",
        "branch": "main",
        "content": "---\nname: at-dispatch-v2\ndescription: Convert PyTorch AT_DISPATCH macros to AT_DISPATCH_V2 format in ATen C++ code. Use when porting AT_DISPATCH_ALL_TYPES_AND*, AT_DISPATCH_FLOATING_TYPES*, or other dispatch macros to the new v2 API. For ATen kernel files, CUDA kernels, and native operator implementations.\n---\n\n# AT_DISPATCH to AT_DISPATCH_V2 Converter\n\nThis skill helps convert PyTorch's legacy AT_DISPATCH macros to the new AT_DISPATCH_V2 format, as defined in `aten/src/ATen/Dispatch_v2.h`.\n\n## When to use this skill\n\nUse this skill when:\n- Converting AT_DISPATCH_* macros to AT_DISPATCH_V2\n- Porting ATen kernels to use the new dispatch API\n- Working with files in `aten/src/ATen/native/` that use dispatch macros\n- User mentions \"AT_DISPATCH\", \"dispatch v2\", \"Dispatch_v2.h\", or macro conversion\n\n## Quick reference\n\n**Old format:**\n```cpp\nAT_DISPATCH_ALL_TYPES_AND3(kBFloat16, kHalf, kBool, dtype, \"kernel_name\", [&]() {\n  // lambda body\n});\n```\n\n**New format:**\n```cpp\nAT_DISPATCH_V2(dtype, \"kernel_name\", AT_WRAP([&]() {\n  // lambda body\n}), AT_EXPAND(AT_ALL_TYPES), kBFloat16, kHalf, kBool);\n```\n\n## Key transformations\n\n1. **Reorder arguments**: `scalar_type` and `name` come first, then lambda, then types\n2. **Wrap the lambda**: Use `AT_WRAP(lambda)` to handle internal commas\n3. **Expand type groups**: Use `AT_EXPAND(AT_ALL_TYPES)` instead of implicit expansion\n4. **List individual types**: Add extra types (kHalf, kBFloat16, etc.) after expanded groups\n5. **Add include**: `#include <ATen/Dispatch_v2.h>` near other Dispatch includes\n\n## Instructions\n\n### Step 1: Add the Dispatch_v2.h include\n\nAdd the v2 header near the existing `#include <ATen/Dispatch.h>`:\n\n```cpp\n#include <ATen/Dispatch.h>\n#include <ATen/Dispatch_v2.h>\n```\n\nKeep the old Dispatch.h include for now (other code may still need it).\n\n### Step 2: Identify the old dispatch pattern\n\nCommon patterns to convert:\n\n- `AT_DISPATCH_ALL_TYPES_AND{2,3,4}(type1, type2, ..., scalar_type, name, lambda)`\n- `AT_DISPATCH_FLOATING_TYPES_AND{2,3}(type1, type2, ..., scalar_type, name, lambda)`\n- `AT_DISPATCH_ALL_TYPES_AND_COMPLEX_AND{2,3}(type1, ..., scalar_type, name, lambda)`\n- `AT_DISPATCH_FLOATING_AND_COMPLEX_TYPES_AND{2,3}(type1, ..., scalar_type, name, lambda)`\n\n### Step 3: Map the old macro to type groups\n\nIdentify which type group macro corresponds to the base types:\n\n| Old macro base | AT_DISPATCH_V2 type group |\n|----------------|---------------------------|\n| `ALL_TYPES` | `AT_EXPAND(AT_ALL_TYPES)` |\n| `FLOATING_TYPES` | `AT_EXPAND(AT_FLOATING_TYPES)` |\n| `INTEGRAL_TYPES` | `AT_EXPAND(AT_INTEGRAL_TYPES)` |\n| `COMPLEX_TYPES` | `AT_EXPAND(AT_COMPLEX_TYPES)` |\n| `ALL_TYPES_AND_COMPLEX` | `AT_EXPAND(AT_ALL_TYPES_AND_COMPLEX)` |\n\nFor combined patterns, use multiple `AT_EXPAND()` entries:\n```cpp\n// Old: AT_DISPATCH_ALL_TYPES_AND_COMPLEX_AND2(...)\n// New: AT_EXPAND(AT_ALL_TYPES), AT_EXPAND(AT_COMPLEX_TYPES), type1, type2\n```\n\n### Step 4: Extract the individual types\n\nFrom `AT_DISPATCH_*_AND2(type1, type2, ...)` or `AT_DISPATCH_*_AND3(type1, type2, type3, ...)`, extract the individual types (type1, type2, etc.).\n\nThese become the trailing arguments after the type group:\n```cpp\nAT_DISPATCH_V2(..., AT_EXPAND(AT_ALL_TYPES), kBFloat16, kHalf, kBool)\n                                             ^^^^^^^^^^^^^^^^^^^^^^^^\n                                             Individual types from AND3\n```\n\n### Step 5: Transform to AT_DISPATCH_V2\n\nApply the transformation:\n\n**Pattern:**\n```cpp\nAT_DISPATCH_V2(\n  scalar_type,           // 1st: The dtype expression\n  \"name\",                // 2nd: The debug string\n  AT_WRAP(lambda),       // 3rd: The lambda wrapped in AT_WRAP\n  type_groups,           // 4th+: Type groups with AT_EXPAND()\n  individual_types       // Last: Individual types\n)\n```\n\n**Example transformation:**\n```cpp\n// BEFORE\nAT_DISPATCH_ALL_TYPES_AND3(\n    kBFloat16, kHalf, kBool,\n    iter.dtype(),\n    \"min_values_cuda\",\n    [&]() {\n      min_values_kernel_cuda_impl<scalar_t>(iter);\n    }\n);\n\n// AFTER\nAT_DISPATCH_V2(\n    iter.dtype(),\n    \"min_values_cuda\",\n    AT_WRAP([&]() {\n      min_values_kernel_cuda_impl<scalar_t>(iter);\n    }),\n    AT_EXPAND(AT_ALL_TYPES),\n    kBFloat16, kHalf, kBool\n);\n```\n\n### Step 6: Handle multi-line lambdas\n\nFor lambdas with internal commas or complex expressions, AT_WRAP is essential:\n\n```cpp\nAT_DISPATCH_V2(\n    dtype,\n    \"complex_kernel\",\n    AT_WRAP([&]() {\n      gpu_reduce_kernel<scalar_t, scalar_t>(\n        iter,\n        MinOps<scalar_t>{},\n        thrust::pair<scalar_t, int64_t>(upper_bound(), 0)  // Commas inside!\n      );\n    }),\n    AT_EXPAND(AT_ALL_TYPES)\n);\n```\n\n### Step 7: Verify the conversion\n\nCheck that:\n- [ ] `AT_WRAP()` wraps the entire lambda\n- [ ] Type groups use `AT_EXPAND()`\n- [ ] Individual types don't have `AT_EXPAND()` (just `kBFloat16`, not `AT_EXPAND(kBFloat16)`)\n- [ ] Argument order is: scalar_type, name, lambda, types\n- [ ] Include added: `#include <ATen/Dispatch_v2.h>`\n\n## Type group reference\n\nAvailable type group macros (use with `AT_EXPAND()`):\n\n```cpp\nAT_INTEGRAL_TYPES      // kByte, kChar, kInt, kLong, kShort\nAT_FLOATING_TYPES      // kDouble, kFloat\nAT_COMPLEX_TYPES       // kComplexDouble, kComplexFloat\nAT_QINT_TYPES         // kQInt8, kQUInt8, kQInt32\nAT_ALL_TYPES          // INTEGRAL_TYPES + FLOATING_TYPES\nAT_ALL_TYPES_AND_COMPLEX  // ALL_TYPES + COMPLEX_TYPES\nAT_INTEGRAL_TYPES_V2  // INTEGRAL_TYPES + unsigned types\nAT_BAREBONES_UNSIGNED_TYPES  // kUInt16, kUInt32, kUInt64\nAT_FLOAT8_TYPES       // Float8 variants\n```\n\n## Common patterns\n\n### Pattern: AT_DISPATCH_ALL_TYPES_AND2\n\n```cpp\n// Before\nAT_DISPATCH_ALL_TYPES_AND2(kHalf, kBFloat16, dtype, \"op\", [&]() {\n  kernel<scalar_t>(data);\n});\n\n// After\nAT_DISPATCH_V2(dtype, \"op\", AT_WRAP([&]() {\n  kernel<scalar_t>(data);\n}), AT_EXPAND(AT_ALL_TYPES), kHalf, kBFloat16);\n```\n\n### Pattern: AT_DISPATCH_FLOATING_TYPES_AND3\n\n```cpp\n// Before\nAT_DISPATCH_FLOATING_TYPES_AND3(kHalf, kBFloat16, kFloat8_e4m3fn,\n    tensor.scalar_type(), \"float_op\", [&] {\n  process<scalar_t>(tensor);\n});\n\n// After\nAT_DISPATCH_V2(tensor.scalar_type(), \"float_op\", AT_WRAP([&] {\n  process<scalar_t>(tensor);\n}), AT_EXPAND(AT_FLOATING_TYPES), kHalf, kBFloat16, kFloat8_e4m3fn);\n```\n\n### Pattern: AT_DISPATCH_ALL_TYPES_AND_COMPLEX_AND2\n\n```cpp\n// Before\nAT_DISPATCH_ALL_TYPES_AND_COMPLEX_AND2(\n    kComplexHalf, kHalf,\n    self.scalar_type(),\n    \"complex_op\",\n    [&] {\n      result = compute<scalar_t>(self);\n    }\n);\n\n// After\nAT_DISPATCH_V2(\n    self.scalar_type(),\n    \"complex_op\",\n    AT_WRAP([&] {\n      result = compute<scalar_t>(self);\n    }),\n    AT_EXPAND(AT_ALL_TYPES),\n    AT_EXPAND(AT_COMPLEX_TYPES),\n    kComplexHalf,\n    kHalf\n);\n```\n\n## Edge cases\n\n### Case 1: No extra types (rare)\n\n```cpp\n// Before\nAT_DISPATCH_ALL_TYPES(dtype, \"op\", [&]() { kernel<scalar_t>(); });\n\n// After\nAT_DISPATCH_V2(dtype, \"op\", AT_WRAP([&]() {\n  kernel<scalar_t>();\n}), AT_EXPAND(AT_ALL_TYPES));\n```\n\n### Case 2: Many individual types (AND4, AND5, etc.)\n\n```cpp\n// Before\nAT_DISPATCH_FLOATING_TYPES_AND4(kHalf, kBFloat16, kFloat8_e4m3fn, kFloat8_e5m2,\n    dtype, \"float8_op\", [&]() { kernel<scalar_t>(); });\n\n// After\nAT_DISPATCH_V2(dtype, \"float8_op\", AT_WRAP([&]() {\n  kernel<scalar_t>();\n}), AT_EXPAND(AT_FLOATING_TYPES), kHalf, kBFloat16, kFloat8_e4m3fn, kFloat8_e5m2);\n```\n\n### Case 3: Lambda with no captures\n\n```cpp\n// Before\nAT_DISPATCH_ALL_TYPES_AND2(kHalf, kBool, dtype, \"op\", []() {\n  static_kernel<scalar_t>();\n});\n\n// After\nAT_DISPATCH_V2(dtype, \"op\", AT_WRAP([]() {\n  static_kernel<scalar_t>();\n}), AT_EXPAND(AT_ALL_TYPES), kHalf, kBool);\n```\n\n## Benefits of AT_DISPATCH_V2\n\n1. **No arity in macro name**: Don't need different macros for AND2, AND3, AND4\n2. **Composable type sets**: Mix and match type groups with `AT_EXPAND()`\n3. **Extensible**: Easy to add more types without hitting macro limits\n4. **Clearer**: Type groups are explicit, not implicit in macro name\n\n## Important notes\n\n- Keep `#include <ATen/Dispatch.h>` - other code may need it\n- The `AT_WRAP()` is mandatory - prevents comma parsing issues in the lambda\n- Type groups need `AT_EXPAND()`, individual types don't\n- The v2 API is in `aten/src/ATen/Dispatch_v2.h` - refer to it for full docs\n- See the header file for the Python script to regenerate the macro implementation\n\n## Workflow\n\nWhen asked to convert AT_DISPATCH macros:\n\n1. Read the file to identify all AT_DISPATCH uses\n2. Add `#include <ATen/Dispatch_v2.h>` if not present\n3. For each dispatch macro:\n   - Identify the pattern and extract components\n   - Map the base type group\n   - Extract individual types\n   - Construct the AT_DISPATCH_V2 call\n   - Apply with Edit tool\n4. Show the user the complete converted file\n5. Explain what was changed\n\nDo NOT compile or test the code - focus on accurate conversion only.\n"
      },
      "discovered_at": "2026-01-11T15:35:52.283015Z",
      "fetch_error": null
    },
    {
      "name": "docstring",
      "slug": "docstring",
      "source": "skillsmp_top",
      "owner": "pytorch",
      "repo_name": "pytorch",
      "repository_url": "https://github.com/pytorch/pytorch",
      "skill_path": ".claude/skills/docstring",
      "github_metadata": {
        "stars": 96524,
        "description": "Tensors and Dynamic neural networks in Python with strong GPU acceleration",
        "default_branch": "main",
        "pushed_at": "2026-01-11T15:25:31Z",
        "created_at": "2016-08-13T05:26:41Z",
        "language": "Python",
        "license": "NOASSERTION",
        "open_issues": 17874,
        "forks": 26484
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/docstring/SKILL.md",
        "branch": "main",
        "content": "---\nname: docstring\ndescription: Write docstrings for PyTorch functions and methods following PyTorch conventions. Use when writing or updating docstrings in PyTorch code.\n---\n\n# PyTorch Docstring Writing Guide\n\nThis skill describes how to write docstrings for functions and methods in the PyTorch project, following the conventions in `torch/_tensor_docs.py` and `torch/nn/functional.py`.\n\n## General Principles\n\n- Use **raw strings** (`r\"\"\"...\"\"\"`) for all docstrings to avoid issues with LaTeX/math backslashes\n- Follow **Sphinx/reStructuredText** (reST) format for documentation\n- Be **concise but complete** - include all essential information\n- Always include **examples** when possible\n- Use **cross-references** to related functions/classes\n\n## Docstring Structure\n\n### 1. Function Signature (First Line)\n\nStart with the function signature showing all parameters:\n\n```python\nr\"\"\"function_name(param1, param2, *, kwarg1=default1, kwarg2=default2) -> ReturnType\n```\n\n**Notes:**\n- Include the function name\n- Show positional and keyword-only arguments (use `*` separator)\n- Include default values\n- Show return type annotation\n- This line should NOT end with a period\n\n### 2. Brief Description\n\nProvide a one-line description of what the function does:\n\n```python\nr\"\"\"conv2d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1) -> Tensor\n\nApplies a 2D convolution over an input image composed of several input\nplanes.\n```\n\n### 3. Mathematical Formulas (if applicable)\n\nUse Sphinx math directives for mathematical expressions:\n\n```python\n.. math::\n    \\text{Softmax}(x_{i}) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}\n```\n\nOr inline math: `:math:\\`x^2\\``\n\n### 4. Cross-References\n\nLink to related classes and functions using Sphinx roles:\n\n- `:class:\\`~torch.nn.ModuleName\\`` - Link to a class\n- `:func:\\`torch.function_name\\`` - Link to a function\n- `:meth:\\`~Tensor.method_name\\`` - Link to a method\n- `:attr:\\`attribute_name\\`` - Reference an attribute\n- The `~` prefix shows only the last component (e.g., `Conv2d` instead of `torch.nn.Conv2d`)\n\n**Example:**\n```python\nSee :class:`~torch.nn.Conv2d` for details and output shape.\n```\n\n### 5. Notes and Warnings\n\nUse admonitions for important information:\n\n```python\n.. note::\n    This function doesn't work directly with NLLLoss,\n    which expects the Log to be computed between the Softmax and itself.\n    Use log_softmax instead (it's faster and has better numerical properties).\n\n.. warning::\n    :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n    ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n    or :func:`torch.Tensor.detach`.\n```\n\n### 6. Args Section\n\nDocument all parameters with type annotations and descriptions:\n\n```python\nArgs:\n    input (Tensor): input tensor of shape :math:`(\\text{minibatch} , \\text{in\\_channels} , iH , iW)`\n    weight (Tensor): filters of shape :math:`(\\text{out\\_channels} , kH , kW)`\n    bias (Tensor, optional): optional bias tensor of shape :math:`(\\text{out\\_channels})`. Default: ``None``\n    stride (int or tuple): the stride of the convolving kernel. Can be a single number or a\n      tuple `(sH, sW)`. Default: 1\n```\n\n**Formatting rules:**\n- Parameter name in **lowercase**\n- Type in parentheses: `(Type)`, `(Type, optional)` for optional parameters\n- Description follows the type\n- For optional parameters, include \"Default: ``value``\" at the end\n- Use double backticks for inline code: ``` ``None`` ```\n- Indent continuation lines by 2 spaces\n\n### 7. Keyword Args Section (if applicable)\n\nSometimes keyword arguments are documented separately:\n\n```python\nKeyword args:\n    dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n        Default: if None, same :class:`torch.dtype` as this tensor.\n    device (:class:`torch.device`, optional): the desired device of returned tensor.\n        Default: if None, same :class:`torch.device` as this tensor.\n    requires_grad (bool, optional): If autograd should record operations on the\n        returned tensor. Default: ``False``.\n```\n\n### 8. Returns Section (if needed)\n\nDocument the return value:\n\n```python\nReturns:\n    Tensor: Sampled tensor of same shape as `logits` from the Gumbel-Softmax distribution.\n        If ``hard=True``, the returned samples will be one-hot, otherwise they will\n        be probability distributions that sum to 1 across `dim`.\n```\n\nOr simply include it in the function signature line if obvious from context.\n\n### 9. Examples Section\n\nAlways include examples when possible:\n\n```python\nExamples::\n\n    >>> inputs = torch.randn(33, 16, 30)\n    >>> filters = torch.randn(20, 16, 5)\n    >>> F.conv1d(inputs, filters)\n\n    >>> # With square kernels and equal stride\n    >>> filters = torch.randn(8, 4, 3, 3)\n    >>> inputs = torch.randn(1, 4, 5, 5)\n    >>> F.conv2d(inputs, filters, padding=1)\n```\n\n**Formatting rules:**\n- Use `Examples::` with double colon\n- Use `>>>` prompt for Python code\n- Include comments with `#` when helpful\n- Show actual output when it helps understanding (indent without `>>>`)\n\n### 10. External References\n\nLink to papers or external documentation:\n\n```python\n.. _Link Name:\n    https://arxiv.org/abs/1611.00712\n```\n\nReference them in text: ```See `Link Name`_```\n\n## Method Types\n\n### Native Python Functions\n\nFor regular Python functions, use a standard docstring:\n\n```python\ndef relu(input: Tensor, inplace: bool = False) -> Tensor:\n    r\"\"\"relu(input, inplace=False) -> Tensor\n\n    Applies the rectified linear unit function element-wise. See\n    :class:`~torch.nn.ReLU` for more details.\n    \"\"\"\n    # implementation\n```\n\n### C-Bound Functions (using add_docstr)\n\nFor C-bound functions, use `_add_docstr`:\n\n```python\nconv1d = _add_docstr(\n    torch.conv1d,\n    r\"\"\"\nconv1d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1) -> Tensor\n\nApplies a 1D convolution over an input signal composed of several input\nplanes.\n\nSee :class:`~torch.nn.Conv1d` for details and output shape.\n\nArgs:\n    input: input tensor of shape :math:`(\\text{minibatch} , \\text{in\\_channels} , iW)`\n    weight: filters of shape :math:`(\\text{out\\_channels} , kW)`\n    ...\n\"\"\",\n)\n```\n\n### In-Place Variants\n\nFor in-place operations (ending with `_`), reference the original:\n\n```python\nadd_docstr_all(\n    \"abs_\",\n    r\"\"\"\nabs_() -> Tensor\n\nIn-place version of :meth:`~Tensor.abs`\n\"\"\",\n)\n```\n\n### Alias Functions\n\nFor aliases, simply reference the original:\n\n```python\nadd_docstr_all(\n    \"absolute\",\n    r\"\"\"\nabsolute() -> Tensor\n\nAlias for :func:`abs`\n\"\"\",\n)\n```\n\n## Common Patterns\n\n### Shape Documentation\n\nUse LaTeX math notation for tensor shapes:\n\n```python\n:math:`(\\text{minibatch} , \\text{in\\_channels} , iH , iW)`\n```\n\n### Reusable Argument Definitions\n\nFor commonly used arguments, define them once and reuse:\n\n```python\ncommon_args = parse_kwargs(\n    \"\"\"\n    dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n        Default: if None, same as this tensor.\n\"\"\"\n)\n\n# Then use with .format():\nr\"\"\"\n...\n\nKeyword args:\n    {dtype}\n    {device}\n\"\"\".format(**common_args)\n```\n\n### Template Insertion\n\nInsert reproducibility notes or other common text:\n\n```python\nr\"\"\"\n{tf32_note}\n\n{cudnn_reproducibility_note}\n\"\"\".format(**reproducibility_notes, **tf32_notes)\n```\n\n## Complete Example\n\nHere's a complete example showing all elements:\n\n```python\ndef gumbel_softmax(\n    logits: Tensor,\n    tau: float = 1,\n    hard: bool = False,\n    eps: float = 1e-10,\n    dim: int = -1,\n) -> Tensor:\n    r\"\"\"\n    Sample from the Gumbel-Softmax distribution and optionally discretize.\n\n    Args:\n        logits (Tensor): `[..., num_features]` unnormalized log probabilities\n        tau (float): non-negative scalar temperature\n        hard (bool): if ``True``, the returned samples will be discretized as one-hot vectors,\n              but will be differentiated as if it is the soft sample in autograd. Default: ``False``\n        dim (int): A dimension along which softmax will be computed. Default: -1\n\n    Returns:\n        Tensor: Sampled tensor of same shape as `logits` from the Gumbel-Softmax distribution.\n            If ``hard=True``, the returned samples will be one-hot, otherwise they will\n            be probability distributions that sum to 1 across `dim`.\n\n    .. note::\n        This function is here for legacy reasons, may be removed from nn.Functional in the future.\n\n    Examples::\n        >>> logits = torch.randn(20, 32)\n        >>> # Sample soft categorical using reparametrization trick:\n        >>> F.gumbel_softmax(logits, tau=1, hard=False)\n        >>> # Sample hard categorical using \"Straight-through\" trick:\n        >>> F.gumbel_softmax(logits, tau=1, hard=True)\n\n    .. _Link 1:\n        https://arxiv.org/abs/1611.00712\n    \"\"\"\n    # implementation\n```\n\n## Quick Checklist\n\nWhen writing a PyTorch docstring, ensure:\n\n- [ ] Use raw string (`r\"\"\"`)\n- [ ] Include function signature on first line\n- [ ] Provide brief description\n- [ ] Document all parameters in Args section with types\n- [ ] Include default values for optional parameters\n- [ ] Use Sphinx cross-references (`:func:`, `:class:`, `:meth:`)\n- [ ] Add mathematical formulas if applicable\n- [ ] Include at least one example in Examples section\n- [ ] Add warnings/notes for important caveats\n- [ ] Link to related module class with `:class:`\n- [ ] Use proper math notation for tensor shapes\n- [ ] Follow consistent formatting and indentation\n\n## Common Sphinx Roles Reference\n\n- `:class:\\`~torch.nn.Module\\`` - Class reference\n- `:func:\\`torch.function\\`` - Function reference\n- `:meth:\\`~Tensor.method\\`` - Method reference\n- `:attr:\\`attribute\\`` - Attribute reference\n- `:math:\\`equation\\`` - Inline math\n- `:ref:\\`label\\`` - Internal reference\n- ``` ``code`` ``` - Inline code (use double backticks)\n\n## Additional Notes\n\n- **Indentation**: Use 4 spaces for code, 2 spaces for continuation of parameter descriptions\n- **Line length**: Try to keep lines under 100 characters when possible\n- **Periods**: End sentences with periods, but not the signature line\n- **Backticks**: Use double backticks for code: ``` ``True`` ``None`` ``False`` ```\n- **Types**: Common types are `Tensor`, `int`, `float`, `bool`, `str`, `tuple`, `list`, etc.\n"
      },
      "discovered_at": "2026-01-11T15:35:52.817113Z",
      "fetch_error": null
    },
    {
      "name": "skill-writer",
      "slug": "skill-writer",
      "source": "skillsmp_top",
      "owner": "pytorch",
      "repo_name": "pytorch",
      "repository_url": "https://github.com/pytorch/pytorch",
      "skill_path": ".claude/skills/skill-writer",
      "github_metadata": {
        "stars": 96524,
        "description": "Tensors and Dynamic neural networks in Python with strong GPU acceleration",
        "default_branch": "main",
        "pushed_at": "2026-01-11T15:25:31Z",
        "created_at": "2016-08-13T05:26:41Z",
        "language": "Python",
        "license": "NOASSERTION",
        "open_issues": 17874,
        "forks": 26484
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/skill-writer/SKILL.md",
        "branch": "main",
        "content": "---\nname: skill-writer\ndescription: Guide users through creating Agent Skills for Claude Code. Use when the user wants to create, write, author, or design a new Skill, or needs help with SKILL.md files, frontmatter, or skill structure.\n---\n\n# Skill Writer\n\nThis Skill helps you create well-structured Agent Skills for Claude Code that follow best practices and validation requirements.\n\n## When to use this Skill\n\nUse this Skill when:\n- Creating a new Agent Skill\n- Writing or updating SKILL.md files\n- Designing skill structure and frontmatter\n- Troubleshooting skill discovery issues\n- Converting existing prompts or workflows into Skills\n\n## Instructions\n\n### Step 1: Determine Skill scope\n\nFirst, understand what the Skill should do:\n\n1. **Ask clarifying questions**:\n   - What specific capability should this Skill provide?\n   - When should Claude use this Skill?\n   - What tools or resources does it need?\n   - Is this for personal use or team sharing?\n\n2. **Keep it focused**: One Skill = one capability\n   - Good: \"PDF form filling\", \"Excel data analysis\"\n   - Too broad: \"Document processing\", \"Data tools\"\n\n### Step 2: Choose Skill location\n\nDetermine where to create the Skill:\n\n**Personal Skills** (`~/.claude/skills/`):\n- Individual workflows and preferences\n- Experimental Skills\n- Personal productivity tools\n\n**Project Skills** (`.claude/skills/`):\n- Team workflows and conventions\n- Project-specific expertise\n- Shared utilities (committed to git)\n\n### Step 3: Create Skill structure\n\nCreate the directory and files:\n\n```bash\n# Personal\nmkdir -p ~/.claude/skills/skill-name\n\n# Project\nmkdir -p .claude/skills/skill-name\n```\n\nFor multi-file Skills:\n```\nskill-name/\nâ”œâ”€â”€ SKILL.md (required)\nâ”œâ”€â”€ reference.md (optional)\nâ”œâ”€â”€ examples.md (optional)\nâ”œâ”€â”€ scripts/\nâ”‚   â””â”€â”€ helper.py (optional)\nâ””â”€â”€ templates/\n    â””â”€â”€ template.txt (optional)\n```\n\n### Step 4: Write SKILL.md frontmatter\n\nCreate YAML frontmatter with required fields:\n\n```yaml\n---\nname: skill-name\ndescription: Brief description of what this does and when to use it\n---\n```\n\n**Field requirements**:\n\n- **name**:\n  - Lowercase letters, numbers, hyphens only\n  - Max 64 characters\n  - Must match directory name\n  - Good: `pdf-processor`, `git-commit-helper`\n  - Bad: `PDF_Processor`, `Git Commits!`\n\n- **description**:\n  - Max 1024 characters\n  - Include BOTH what it does AND when to use it\n  - Use specific trigger words users would say\n  - Mention file types, operations, and context\n\n**Optional frontmatter fields**:\n\n- **allowed-tools**: Restrict tool access (comma-separated list)\n  ```yaml\n  allowed-tools: Read, Grep, Glob\n  ```\n  Use for:\n  - Read-only Skills\n  - Security-sensitive workflows\n  - Limited-scope operations\n\n### Step 5: Write effective descriptions\n\nThe description is critical for Claude to discover your Skill.\n\n**Formula**: `[What it does] + [When to use it] + [Key triggers]`\n\n**Examples**:\n\nâœ… **Good**:\n```yaml\ndescription: Extract text and tables from PDF files, fill forms, merge documents. Use when working with PDF files or when the user mentions PDFs, forms, or document extraction.\n```\n\nâœ… **Good**:\n```yaml\ndescription: Analyze Excel spreadsheets, create pivot tables, and generate charts. Use when working with Excel files, spreadsheets, or analyzing tabular data in .xlsx format.\n```\n\nâŒ **Too vague**:\n```yaml\ndescription: Helps with documents\ndescription: For data analysis\n```\n\n**Tips**:\n- Include specific file extensions (.pdf, .xlsx, .json)\n- Mention common user phrases (\"analyze\", \"extract\", \"generate\")\n- List concrete operations (not generic verbs)\n- Add context clues (\"Use when...\", \"For...\")\n\n### Step 6: Structure the Skill content\n\nUse clear Markdown sections:\n\n```markdown\n# Skill Name\n\nBrief overview of what this Skill does.\n\n## Quick start\n\nProvide a simple example to get started immediately.\n\n## Instructions\n\nStep-by-step guidance for Claude:\n1. First step with clear action\n2. Second step with expected outcome\n3. Handle edge cases\n\n## Examples\n\nShow concrete usage examples with code or commands.\n\n## Best practices\n\n- Key conventions to follow\n- Common pitfalls to avoid\n- When to use vs. not use\n\n## Requirements\n\nList any dependencies or prerequisites:\n```bash\npip install package-name\n```\n\n## Advanced usage\n\nFor complex scenarios, see [reference.md](reference.md).\n```\n\n### Step 7: Add supporting files (optional)\n\nCreate additional files for progressive disclosure:\n\n**reference.md**: Detailed API docs, advanced options\n**examples.md**: Extended examples and use cases\n**scripts/**: Helper scripts and utilities\n**templates/**: File templates or boilerplate\n\nReference them from SKILL.md:\n```markdown\nFor advanced usage, see [reference.md](reference.md).\n\nRun the helper script:\n\\`\\`\\`bash\npython scripts/helper.py input.txt\n\\`\\`\\`\n```\n\n### Step 8: Validate the Skill\n\nCheck these requirements:\n\nâœ… **File structure**:\n- [ ] SKILL.md exists in correct location\n- [ ] Directory name matches frontmatter `name`\n\nâœ… **YAML frontmatter**:\n- [ ] Opening `---` on line 1\n- [ ] Closing `---` before content\n- [ ] Valid YAML (no tabs, correct indentation)\n- [ ] `name` follows naming rules\n- [ ] `description` is specific and < 1024 chars\n\nâœ… **Content quality**:\n- [ ] Clear instructions for Claude\n- [ ] Concrete examples provided\n- [ ] Edge cases handled\n- [ ] Dependencies listed (if any)\n\nâœ… **Testing**:\n- [ ] Description matches user questions\n- [ ] Skill activates on relevant queries\n- [ ] Instructions are clear and actionable\n\n### Step 9: Test the Skill\n\n1. **Restart Claude Code** (if running) to load the Skill\n\n2. **Ask relevant questions** that match the description:\n   ```\n   Can you help me extract text from this PDF?\n   ```\n\n3. **Verify activation**: Claude should use the Skill automatically\n\n4. **Check behavior**: Confirm Claude follows the instructions correctly\n\n### Step 10: Debug if needed\n\nIf Claude doesn't use the Skill:\n\n1. **Make description more specific**:\n   - Add trigger words\n   - Include file types\n   - Mention common user phrases\n\n2. **Check file location**:\n   ```bash\n   ls ~/.claude/skills/skill-name/SKILL.md\n   ls .claude/skills/skill-name/SKILL.md\n   ```\n\n3. **Validate YAML**:\n   ```bash\n   cat SKILL.md | head -n 10\n   ```\n\n4. **Run debug mode**:\n   ```bash\n   claude --debug\n   ```\n\n## Common patterns\n\n### Read-only Skill\n\n```yaml\n---\nname: code-reader\ndescription: Read and analyze code without making changes. Use for code review, understanding codebases, or documentation.\nallowed-tools: Read, Grep, Glob\n---\n```\n\n### Script-based Skill\n\n```yaml\n---\nname: data-processor\ndescription: Process CSV and JSON data files with Python scripts. Use when analyzing data files or transforming datasets.\n---\n\n# Data Processor\n\n## Instructions\n\n1. Use the processing script:\n\\`\\`\\`bash\npython scripts/process.py input.csv --output results.json\n\\`\\`\\`\n\n2. Validate output with:\n\\`\\`\\`bash\npython scripts/validate.py results.json\n\\`\\`\\`\n```\n\n### Multi-file Skill with progressive disclosure\n\n```yaml\n---\nname: api-designer\ndescription: Design REST APIs following best practices. Use when creating API endpoints, designing routes, or planning API architecture.\n---\n\n# API Designer\n\nQuick start: See [examples.md](examples.md)\n\nDetailed reference: See [reference.md](reference.md)\n\n## Instructions\n\n1. Gather requirements\n2. Design endpoints (see examples.md)\n3. Document with OpenAPI spec\n4. Review against best practices (see reference.md)\n```\n\n## Best practices for Skill authors\n\n1. **One Skill, one purpose**: Don't create mega-Skills\n2. **Specific descriptions**: Include trigger words users will say\n3. **Clear instructions**: Write for Claude, not humans\n4. **Concrete examples**: Show real code, not pseudocode\n5. **List dependencies**: Mention required packages in description\n6. **Test with teammates**: Verify activation and clarity\n7. **Version your Skills**: Document changes in content\n8. **Use progressive disclosure**: Put advanced details in separate files\n\n## Validation checklist\n\nBefore finalizing a Skill, verify:\n\n- [ ] Name is lowercase, hyphens only, max 64 chars\n- [ ] Description is specific and < 1024 chars\n- [ ] Description includes \"what\" and \"when\"\n- [ ] YAML frontmatter is valid\n- [ ] Instructions are step-by-step\n- [ ] Examples are concrete and realistic\n- [ ] Dependencies are documented\n- [ ] File paths use forward slashes\n- [ ] Skill activates on relevant queries\n- [ ] Claude follows instructions correctly\n\n## Troubleshooting\n\n**Skill doesn't activate**:\n- Make description more specific with trigger words\n- Include file types and operations in description\n- Add \"Use when...\" clause with user phrases\n\n**Multiple Skills conflict**:\n- Make descriptions more distinct\n- Use different trigger words\n- Narrow the scope of each Skill\n\n**Skill has errors**:\n- Check YAML syntax (no tabs, proper indentation)\n- Verify file paths (use forward slashes)\n- Ensure scripts have execute permissions\n- List all dependencies\n\n## Examples\n\nSee the documentation for complete examples:\n- Simple single-file Skill (commit-helper)\n- Skill with tool permissions (code-reviewer)\n- Multi-file Skill (pdf-processing)\n\n## Output format\n\nWhen creating a Skill, I will:\n\n1. Ask clarifying questions about scope and requirements\n2. Suggest a Skill name and location\n3. Create the SKILL.md file with proper frontmatter\n4. Include clear instructions and examples\n5. Add supporting files if needed\n6. Provide testing instructions\n7. Validate against all requirements\n\nThe result will be a complete, working Skill that follows all best practices and validation rules.\n"
      },
      "discovered_at": "2026-01-11T15:35:53.216645Z",
      "fetch_error": null
    },
    {
      "name": "pr-creator",
      "slug": "pr-creator",
      "source": "skillsmp_top",
      "owner": "google-gemini",
      "repo_name": "gemini-cli",
      "repository_url": "https://github.com/google-gemini/gemini-cli",
      "skill_path": ".gemini/skills/pr-creator",
      "github_metadata": {
        "stars": 90492,
        "description": "An open-source AI agent that brings the power of Gemini directly into your terminal.",
        "default_branch": "main",
        "pushed_at": "2026-01-11T15:10:57Z",
        "created_at": "2025-04-17T17:04:31Z",
        "language": "TypeScript",
        "license": "Apache-2.0",
        "open_issues": 2517,
        "forks": 10486
      },
      "skill_md": {
        "found": true,
        "path": ".gemini/skills/pr-creator/SKILL.md",
        "branch": "main",
        "content": "---\nname: pr-creator\ndescription: Use this skill when asked to create a pull request (PR). It ensures all PRs follow the repository's established templates and standards.\n---\n\n# Pull Request Creator\n\nThis skill guides the creation of high-quality Pull Requests that adhere to the repository's standards.\n\n## Workflow\n\nFollow these steps to create a Pull Request:\n\n1.  **Locate Template**: Search for a pull request template in the repository.\n    *   Check `.github/pull_request_template.md`\n    *   Check `.github/PULL_REQUEST_TEMPLATE.md`\n    *   If multiple templates exist (e.g., in `.github/PULL_REQUEST_TEMPLATE/`), ask the user which one to use or select the most appropriate one based on the context (e.g., `bug_fix.md` vs `feature.md`).\n\n2.  **Read Template**: Read the content of the identified template file.\n\n3.  **Draft Description**: Create a PR description that strictly follows the template's structure.\n    *   **Headings**: Keep all headings from the template.\n    *   **Checklists**: Review each item. Mark with `[x]` if completed. If an item is not applicable, leave it unchecked or mark as `[ ]` (depending on the template's instructions) or remove it if the template allows flexibility (but prefer keeping it unchecked for transparency).\n    *   **Content**: Fill in the sections with clear, concise summaries of your changes.\n    *   **Related Issues**: Link any issues fixed or related to this PR (e.g., \"Fixes #123\").\n\n4.  **Create PR**: Use the `gh` CLI to create the PR.\n    ```bash\n    gh pr create --title \"type(scope): succinct description\" --body \"...\"\n    ```\n    *   **Title**: Ensure the title follows the [Conventional Commits](https://www.conventionalcommits.org/) format if the repository uses it (e.g., `feat(ui): add new button`, `fix(core): resolve crash`).\n\n## Principles\n\n*   **Compliance**: Never ignore the PR template. It exists for a reason.\n*   **Completeness**: Fill out all relevant sections.\n*   **Accuracy**: Don't check boxes for tasks you haven't done.\n"
      },
      "discovered_at": "2026-01-11T15:35:53.698568Z",
      "fetch_error": null
    },
    {
      "name": "writing-dev-server-tests",
      "slug": "writing-dev-server-tests",
      "source": "skillsmp_top",
      "owner": "oven-sh",
      "repo_name": "bun",
      "repository_url": "https://github.com/oven-sh/bun",
      "skill_path": ".claude/skills/writing-dev-server-tests",
      "github_metadata": {
        "stars": 86188,
        "description": "Incredibly fast JavaScript runtime, bundler, test runner, and package manager â€“ all in one",
        "default_branch": "main",
        "pushed_at": "2026-01-11T15:11:23Z",
        "created_at": "2021-04-14T00:48:17Z",
        "language": "Zig",
        "license": "NOASSERTION",
        "open_issues": 5614,
        "forks": 3913
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/writing-dev-server-tests/SKILL.md",
        "branch": "main",
        "content": "---\nname: writing-dev-server-tests\ndescription: Guides writing HMR/Dev Server tests in test/bake/. Use when creating or modifying dev server, hot reloading, or bundling tests.\n---\n\n# Writing HMR/Dev Server Tests\n\nDev server tests validate hot-reloading robustness and reliability.\n\n## File Structure\n\n- `test/bake/bake-harness.ts` - shared utilities: `devTest`, `prodTest`, `devAndProductionTest`, `Dev` class, `Client` class\n- `test/bake/client-fixture.mjs` - subprocess for `Client` (page loading, IPC queries)\n- `test/bake/dev/*.test.ts` - dev server and hot reload tests\n- `test/bake/dev-and-prod.ts` - tests running on both dev and production mode\n\n## Test Categories\n\n- `bundle.test.ts` - DevServer-specific bundling bugs\n- `css.test.ts` - CSS bundling issues\n- `plugins.test.ts` - development mode plugins\n- `ecosystem.test.ts` - library compatibility (prefer concrete bugs over full package tests)\n- `esm.test.ts` - ESM features in development\n- `html.test.ts` - HTML file handling\n- `react-spa.test.ts` - React, react-refresh transform, server components\n- `sourcemap.test.ts` - source map correctness\n\n## devTest Basics\n\n```ts\nimport { devTest, emptyHtmlFile } from \"../bake-harness\";\n\ndevTest(\"html file is watched\", {\n  files: {\n    \"index.html\": emptyHtmlFile({\n      scripts: [\"/script.ts\"],\n      body: \"<h1>Hello</h1>\",\n    }),\n    \"script.ts\": `console.log(\"hello\");`,\n  },\n  async test(dev) {\n    await dev.fetch(\"/\").expect.toInclude(\"<h1>Hello</h1>\");\n    await dev.patch(\"index.html\", { find: \"Hello\", replace: \"World\" });\n    await dev.fetch(\"/\").expect.toInclude(\"<h1>World</h1>\");\n\n    await using c = await dev.client(\"/\");\n    await c.expectMessage(\"hello\");\n\n    await c.expectReload(async () => {\n      await dev.patch(\"index.html\", { find: \"World\", replace: \"Bar\" });\n    });\n    await c.expectMessage(\"hello\");\n  },\n});\n```\n\n## Key APIs\n\n- **`files`**: Initial filesystem state\n- **`dev.fetch()`**: HTTP requests\n- **`dev.client()`**: Opens browser instance\n- **`dev.write/patch/delete`**: Filesystem mutations (wait for hot-reload automatically)\n- **`c.expectMessage()`**: Assert console.log output\n- **`c.expectReload()`**: Wrap code that causes hard reload\n\n**Important**: Use `dev.write/patch/delete` instead of `node:fs` - they wait for hot-reload.\n\n## Testing Errors\n\n```ts\ndevTest(\"import then create\", {\n  files: {\n    \"index.html\": `<!DOCTYPE html><html><head></head><body><script type=\"module\" src=\"/script.ts\"></script></body></html>`,\n    \"script.ts\": `import data from \"./data\"; console.log(data);`,\n  },\n  async test(dev) {\n    const c = await dev.client(\"/\", {\n      errors: ['script.ts:1:18: error: Could not resolve: \"./data\"'],\n    });\n    await c.expectReload(async () => {\n      await dev.write(\"data.ts\", \"export default 'data';\");\n    });\n    await c.expectMessage(\"data\");\n  },\n});\n```\n\nSpecify expected errors with the `errors` option:\n\n```ts\nawait dev.delete(\"other.ts\", {\n  errors: ['index.ts:1:16: error: Could not resolve: \"./other\"'],\n});\n```\n"
      },
      "discovered_at": "2026-01-11T15:35:54.084126Z",
      "fetch_error": null
    },
    {
      "name": "writing-bundler-tests",
      "slug": "writing-bundler-tests",
      "source": "skillsmp_top",
      "owner": "oven-sh",
      "repo_name": "bun",
      "repository_url": "https://github.com/oven-sh/bun",
      "skill_path": ".claude/skills/writing-bundler-tests",
      "github_metadata": {
        "stars": 86188,
        "description": "Incredibly fast JavaScript runtime, bundler, test runner, and package manager â€“ all in one",
        "default_branch": "main",
        "pushed_at": "2026-01-11T15:11:23Z",
        "created_at": "2021-04-14T00:48:17Z",
        "language": "Zig",
        "license": "NOASSERTION",
        "open_issues": 5614,
        "forks": 3913
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/writing-bundler-tests/SKILL.md",
        "branch": "main",
        "content": "---\nname: writing-bundler-tests\ndescription: Guides writing bundler tests using itBundled/expectBundled in test/bundler/. Use when creating or modifying bundler, transpiler, or code transformation tests.\n---\n\n# Writing Bundler Tests\n\nBundler tests use `itBundled()` from `test/bundler/expectBundled.ts` to test Bun's bundler.\n\n## Basic Usage\n\n```typescript\nimport { describe } from \"bun:test\";\nimport { itBundled, dedent } from \"./expectBundled\";\n\ndescribe(\"bundler\", () => {\n  itBundled(\"category/TestName\", {\n    files: {\n      \"index.js\": `console.log(\"hello\");`,\n    },\n    run: {\n      stdout: \"hello\",\n    },\n  });\n});\n```\n\nTest ID format: `category/TestName` (e.g., `banner/CommentBanner`, `minify/Empty`)\n\n## File Setup\n\n```typescript\n{\n  files: {\n    \"index.js\": `console.log(\"test\");`,\n    \"lib.ts\": `export const foo = 123;`,\n    \"nested/file.js\": `export default {};`,\n  },\n  entryPoints: [\"index.js\"],  // defaults to first file\n  runtimeFiles: {             // written AFTER bundling\n    \"extra.js\": `console.log(\"added later\");`,\n  },\n}\n```\n\n## Bundler Options\n\n```typescript\n{\n  outfile: \"/out.js\",\n  outdir: \"/out\",\n  format: \"esm\" | \"cjs\" | \"iife\",\n  target: \"bun\" | \"browser\" | \"node\",\n\n  // Minification\n  minifyWhitespace: true,\n  minifyIdentifiers: true,\n  minifySyntax: true,\n\n  // Code manipulation\n  banner: \"// copyright\",\n  footer: \"// end\",\n  define: { \"PROD\": \"true\" },\n  external: [\"lodash\"],\n\n  // Advanced\n  sourceMap: \"inline\" | \"external\",\n  splitting: true,\n  treeShaking: true,\n  drop: [\"console\"],\n}\n```\n\n## Runtime Verification\n\n```typescript\n{\n  run: {\n    stdout: \"expected output\",      // exact match\n    stdout: /regex/,                // pattern match\n    partialStdout: \"contains this\", // substring\n    stderr: \"error output\",\n    exitCode: 1,\n    env: { NODE_ENV: \"production\" },\n    runtime: \"bun\" | \"node\",\n\n    // Runtime errors\n    error: \"ReferenceError: x is not defined\",\n  },\n}\n```\n\n## Bundle Errors/Warnings\n\n```typescript\n{\n  bundleErrors: {\n    \"/file.js\": [\"error message 1\", \"error message 2\"],\n  },\n  bundleWarnings: {\n    \"/file.js\": [\"warning message\"],\n  },\n}\n```\n\n## Dead Code Elimination (DCE)\n\nAdd markers in source code:\n\n```javascript\n// KEEP - this should survive\nconst used = 1;\n\n// REMOVE - this should be eliminated\nconst unused = 2;\n```\n\n```typescript\n{\n  dce: true,\n  dceKeepMarkerCount: 5,  // expected KEEP markers\n}\n```\n\n## Capture Pattern\n\nVerify exact transpilation with `capture()`:\n\n```typescript\nitBundled(\"string/Folding\", {\n  files: {\n    \"index.ts\": `capture(\\`\\${1 + 1}\\`);`,\n  },\n  capture: ['\"2\"'], // expected captured value\n  minifySyntax: true,\n});\n```\n\n## Post-Bundle Assertions\n\n```typescript\n{\n  onAfterBundle(api) {\n    api.expectFile(\"out.js\").toContain(\"console.log\");\n    api.assertFileExists(\"out.js\");\n\n    const content = api.readFile(\"out.js\");\n    expect(content).toMatchSnapshot();\n\n    const values = api.captureFile(\"out.js\");\n    expect(values).toEqual([\"2\"]);\n  },\n}\n```\n\n## Common Patterns\n\n**Simple output verification:**\n\n```typescript\nitBundled(\"banner/Comment\", {\n  banner: \"// copyright\",\n  files: { \"a.js\": `console.log(\"Hello\")` },\n  onAfterBundle(api) {\n    api.expectFile(\"out.js\").toContain(\"// copyright\");\n  },\n});\n```\n\n**Multi-file CJS/ESM interop:**\n\n```typescript\nitBundled(\"cjs/ImportSyntax\", {\n  files: {\n    \"entry.js\": `import lib from './lib.cjs'; console.log(lib);`,\n    \"lib.cjs\": `exports.foo = 'bar';`,\n  },\n  run: { stdout: '{\"foo\":\"bar\"}' },\n});\n```\n\n**Error handling:**\n\n```typescript\nitBundled(\"edgecase/InvalidLoader\", {\n  files: { \"index.js\": `...` },\n  bundleErrors: {\n    \"index.js\": [\"Unsupported loader type\"],\n  },\n});\n```\n\n## Test Organization\n\n```text\ntest/bundler/\nâ”œâ”€â”€ bundler_banner.test.ts\nâ”œâ”€â”€ bundler_string.test.ts\nâ”œâ”€â”€ bundler_minify.test.ts\nâ”œâ”€â”€ bundler_cjs.test.ts\nâ”œâ”€â”€ bundler_edgecase.test.ts\nâ”œâ”€â”€ bundler_splitting.test.ts\nâ”œâ”€â”€ css/\nâ”œâ”€â”€ transpiler/\nâ””â”€â”€ expectBundled.ts\n```\n\n## Running Tests\n\n```bash\nbun bd test test/bundler/bundler_banner.test.ts\nBUN_BUNDLER_TEST_FILTER=\"banner/Comment\" bun bd test bundler_banner.test.ts\nBUN_BUNDLER_TEST_DEBUG=1 bun bd test bundler_minify.test.ts\n```\n\n## Key Points\n\n- Use `dedent` for readable multi-line code\n- File paths are relative (e.g., `/index.js`)\n- Use `capture()` to verify exact transpilation results\n- Use `.toMatchSnapshot()` for complex outputs\n- Pass array to `run` for multiple test scenarios\n"
      },
      "discovered_at": "2026-01-11T15:35:54.576115Z",
      "fetch_error": null
    },
    {
      "name": "implementing-jsc-classes-cpp",
      "slug": "implementing-jsc-classes-cpp",
      "source": "skillsmp_top",
      "owner": "oven-sh",
      "repo_name": "bun",
      "repository_url": "https://github.com/oven-sh/bun",
      "skill_path": ".claude/skills/implementing-jsc-classes-cpp",
      "github_metadata": {
        "stars": 86188,
        "description": "Incredibly fast JavaScript runtime, bundler, test runner, and package manager â€“ all in one",
        "default_branch": "main",
        "pushed_at": "2026-01-11T15:11:23Z",
        "created_at": "2021-04-14T00:48:17Z",
        "language": "Zig",
        "license": "NOASSERTION",
        "open_issues": 5614,
        "forks": 3913
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/implementing-jsc-classes-cpp/SKILL.md",
        "branch": "main",
        "content": "---\nname: implementing-jsc-classes-cpp\ndescription: Implements JavaScript classes in C++ using JavaScriptCore. Use when creating new JS classes with C++ bindings, prototypes, or constructors.\n---\n\n# Implementing JavaScript Classes in C++\n\n## Class Structure\n\nFor publicly accessible Constructor and Prototype, create 3 classes:\n\n1. **`class Foo : public JSC::DestructibleObject`** - if C++ fields exist; otherwise use `JSC::constructEmptyObject` with `putDirectOffset`\n2. **`class FooPrototype : public JSC::JSNonFinalObject`**\n3. **`class FooConstructor : public JSC::InternalFunction`**\n\nNo public constructor? Only Prototype and class needed.\n\n## Iso Subspaces\n\nClasses with C++ fields need subspaces in:\n\n- `src/bun.js/bindings/webcore/DOMClientIsoSubspaces.h`\n- `src/bun.js/bindings/webcore/DOMIsoSubspaces.h`\n\n```cpp\ntemplate<typename MyClassT, JSC::SubspaceAccess mode>\nstatic JSC::GCClient::IsoSubspace* subspaceFor(JSC::VM& vm) {\n    if constexpr (mode == JSC::SubspaceAccess::Concurrently)\n        return nullptr;\n    return WebCore::subspaceForImpl<MyClassT, WebCore::UseCustomHeapCellType::No>(\n        vm,\n        [](auto& spaces) { return spaces.m_clientSubspaceForMyClassT.get(); },\n        [](auto& spaces, auto&& space) { spaces.m_clientSubspaceForMyClassT = std::forward<decltype(space)>(space); },\n        [](auto& spaces) { return spaces.m_subspaceForMyClassT.get(); },\n        [](auto& spaces, auto&& space) { spaces.m_subspaceForMyClassT = std::forward<decltype(space)>(space); });\n}\n```\n\n## Property Definitions\n\n```cpp\nstatic JSC_DECLARE_HOST_FUNCTION(jsFooProtoFuncMethod);\nstatic JSC_DECLARE_CUSTOM_GETTER(jsFooGetter_property);\n\nstatic const HashTableValue JSFooPrototypeTableValues[] = {\n    { \"property\"_s, static_cast<unsigned>(PropertyAttribute::ReadOnly | PropertyAttribute::CustomAccessor), NoIntrinsic, { HashTableValue::GetterSetterType, jsFooGetter_property, 0 } },\n    { \"method\"_s, static_cast<unsigned>(PropertyAttribute::Function), NoIntrinsic, { HashTableValue::NativeFunctionType, jsFooProtoFuncMethod, 1 } },\n};\n```\n\n## Prototype Class\n\n```cpp\nclass JSFooPrototype final : public JSC::JSNonFinalObject {\npublic:\n    using Base = JSC::JSNonFinalObject;\n    static constexpr unsigned StructureFlags = Base::StructureFlags;\n\n    static JSFooPrototype* create(JSC::VM& vm, JSC::JSGlobalObject* globalObject, JSC::Structure* structure) {\n        JSFooPrototype* prototype = new (NotNull, allocateCell<JSFooPrototype>(vm)) JSFooPrototype(vm, structure);\n        prototype->finishCreation(vm);\n        return prototype;\n    }\n\n    template<typename, JSC::SubspaceAccess>\n    static JSC::GCClient::IsoSubspace* subspaceFor(JSC::VM& vm) { return &vm.plainObjectSpace(); }\n\n    DECLARE_INFO;\n\n    static JSC::Structure* createStructure(JSC::VM& vm, JSC::JSGlobalObject* globalObject, JSC::JSValue prototype) {\n        auto* structure = JSC::Structure::create(vm, globalObject, prototype, JSC::TypeInfo(JSC::ObjectType, StructureFlags), info());\n        structure->setMayBePrototype(true);\n        return structure;\n    }\n\nprivate:\n    JSFooPrototype(JSC::VM& vm, JSC::Structure* structure) : Base(vm, structure) {}\n    void finishCreation(JSC::VM& vm);\n};\n\nvoid JSFooPrototype::finishCreation(VM& vm) {\n    Base::finishCreation(vm);\n    reifyStaticProperties(vm, JSFoo::info(), JSFooPrototypeTableValues, *this);\n    JSC_TO_STRING_TAG_WITHOUT_TRANSITION();\n}\n```\n\n## Getter/Setter/Function Definitions\n\n```cpp\n// Getter\nJSC_DEFINE_CUSTOM_GETTER(jsFooGetter_prop, (JSGlobalObject* globalObject, EncodedJSValue thisValue, PropertyName)) {\n    VM& vm = globalObject->vm();\n    auto scope = DECLARE_THROW_SCOPE(vm);\n    JSFoo* thisObject = jsDynamicCast<JSFoo*>(JSValue::decode(thisValue));\n    if (UNLIKELY(!thisObject)) {\n        Bun::throwThisTypeError(*globalObject, scope, \"JSFoo\"_s, \"prop\"_s);\n        return {};\n    }\n    return JSValue::encode(jsBoolean(thisObject->value()));\n}\n\n// Function\nJSC_DEFINE_HOST_FUNCTION(jsFooProtoFuncMethod, (JSGlobalObject* globalObject, CallFrame* callFrame)) {\n    VM& vm = globalObject->vm();\n    auto scope = DECLARE_THROW_SCOPE(vm);\n    auto* thisObject = jsDynamicCast<JSFoo*>(callFrame->thisValue());\n    if (UNLIKELY(!thisObject)) {\n        Bun::throwThisTypeError(*globalObject, scope, \"Foo\"_s, \"method\"_s);\n        return {};\n    }\n    return JSValue::encode(thisObject->doSomething(vm, globalObject));\n}\n```\n\n## Constructor Class\n\n```cpp\nclass JSFooConstructor final : public JSC::InternalFunction {\npublic:\n    using Base = JSC::InternalFunction;\n    static constexpr unsigned StructureFlags = Base::StructureFlags;\n\n    static JSFooConstructor* create(JSC::VM& vm, JSC::Structure* structure, JSC::JSObject* prototype) {\n        JSFooConstructor* constructor = new (NotNull, JSC::allocateCell<JSFooConstructor>(vm)) JSFooConstructor(vm, structure);\n        constructor->finishCreation(vm, prototype);\n        return constructor;\n    }\n\n    DECLARE_INFO;\n\n    template<typename CellType, JSC::SubspaceAccess>\n    static JSC::GCClient::IsoSubspace* subspaceFor(JSC::VM& vm) { return &vm.internalFunctionSpace(); }\n\n    static JSC::Structure* createStructure(JSC::VM& vm, JSC::JSGlobalObject* globalObject, JSC::JSValue prototype) {\n        return JSC::Structure::create(vm, globalObject, prototype, JSC::TypeInfo(JSC::InternalFunctionType, StructureFlags), info());\n    }\n\nprivate:\n    JSFooConstructor(JSC::VM& vm, JSC::Structure* structure) : Base(vm, structure, callFoo, constructFoo) {}\n\n    void finishCreation(JSC::VM& vm, JSC::JSObject* prototype) {\n        Base::finishCreation(vm, 0, \"Foo\"_s);\n        putDirectWithoutTransition(vm, vm.propertyNames->prototype, prototype, JSC::PropertyAttribute::DontEnum | JSC::PropertyAttribute::DontDelete | JSC::PropertyAttribute::ReadOnly);\n    }\n};\n```\n\n## Structure Caching\n\nAdd to `ZigGlobalObject.h`:\n\n```cpp\nJSC::LazyClassStructure m_JSFooClassStructure;\n```\n\nInitialize in `ZigGlobalObject.cpp`:\n\n```cpp\nm_JSFooClassStructure.initLater([](LazyClassStructure::Initializer& init) {\n    Bun::initJSFooClassStructure(init);\n});\n```\n\nVisit in `visitChildrenImpl`:\n\n```cpp\nm_JSFooClassStructure.visit(visitor);\n```\n\n## Expose to Zig\n\n```cpp\nextern \"C\" JSC::EncodedJSValue Bun__JSFooConstructor(Zig::GlobalObject* globalObject) {\n    return JSValue::encode(globalObject->m_JSFooClassStructure.constructor(globalObject));\n}\n\nextern \"C\" EncodedJSValue Bun__Foo__toJS(Zig::GlobalObject* globalObject, Foo* foo) {\n    auto* structure = globalObject->m_JSFooClassStructure.get(globalObject);\n    return JSValue::encode(JSFoo::create(globalObject->vm(), structure, globalObject, WTFMove(foo)));\n}\n```\n\nInclude `#include \"root.h\"` at the top of C++ files.\n"
      },
      "discovered_at": "2026-01-11T15:35:54.961792Z",
      "fetch_error": null
    },
    {
      "name": "zig-system-calls",
      "slug": "zig-system-calls",
      "source": "skillsmp_top",
      "owner": "oven-sh",
      "repo_name": "bun",
      "repository_url": "https://github.com/oven-sh/bun",
      "skill_path": ".claude/skills/zig-system-calls",
      "github_metadata": {
        "stars": 86188,
        "description": "Incredibly fast JavaScript runtime, bundler, test runner, and package manager â€“ all in one",
        "default_branch": "main",
        "pushed_at": "2026-01-11T15:11:23Z",
        "created_at": "2021-04-14T00:48:17Z",
        "language": "Zig",
        "license": "NOASSERTION",
        "open_issues": 5614,
        "forks": 3913
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/zig-system-calls/SKILL.md",
        "branch": "main",
        "content": "---\nname: zig-system-calls\ndescription: Guides using bun.sys for system calls and file I/O in Zig. Use when implementing file operations instead of std.fs or std.posix.\n---\n\n# System Calls & File I/O in Zig\n\nUse `bun.sys` instead of `std.fs` or `std.posix` for cross-platform syscalls with proper error handling.\n\n## bun.sys.File (Preferred)\n\nFor most file operations, use the `bun.sys.File` wrapper:\n\n```zig\nconst File = bun.sys.File;\n\nconst file = switch (File.open(path, bun.O.RDWR, 0o644)) {\n    .result => |f| f,\n    .err => |err| return .{ .err = err },\n};\ndefer file.close();\n\n// Read/write\n_ = try file.read(buffer).unwrap();\n_ = try file.writeAll(data).unwrap();\n\n// Get file info\nconst stat = try file.stat().unwrap();\nconst size = try file.getEndPos().unwrap();\n\n// std.io compatible\nconst reader = file.reader();\nconst writer = file.writer();\n```\n\n### Complete Example\n\n```zig\nconst File = bun.sys.File;\n\npub fn writeFile(path: [:0]const u8, data: []const u8) File.WriteError!void {\n    const file = switch (File.open(path, bun.O.WRONLY | bun.O.CREAT | bun.O.TRUNC, 0o664)) {\n        .result => |f| f,\n        .err => |err| return err.toError(),\n    };\n    defer file.close();\n\n    _ = switch (file.writeAll(data)) {\n        .result => {},\n        .err => |err| return err.toError(),\n    };\n}\n```\n\n## Why bun.sys?\n\n| Aspect      | bun.sys                          | std.fs/std.posix    |\n| ----------- | -------------------------------- | ------------------- |\n| Return Type | `Maybe(T)` with detailed Error   | Generic error union |\n| Windows     | Full support with libuv fallback | Limited/POSIX-only  |\n| Error Info  | errno, syscall tag, path, fd     | errno only          |\n| EINTR       | Automatic retry                  | Manual handling     |\n\n## Error Handling with Maybe(T)\n\n`bun.sys` functions return `Maybe(T)` - a tagged union:\n\n```zig\nconst sys = bun.sys;\n\n// Pattern 1: Switch on result/error\nswitch (sys.read(fd, buffer)) {\n    .result => |bytes_read| {\n        // use bytes_read\n    },\n    .err => |err| {\n        // err.errno, err.syscall, err.fd, err.path\n        if (err.getErrno() == .AGAIN) {\n            // handle EAGAIN\n        }\n    },\n}\n\n// Pattern 2: Unwrap with try (converts to Zig error)\nconst bytes = try sys.read(fd, buffer).unwrap();\n\n// Pattern 3: Unwrap with default\nconst value = sys.stat(path).unwrapOr(default_stat);\n```\n\n## Low-Level File Operations\n\nOnly use these when `bun.sys.File` doesn't meet your needs.\n\n### Opening Files\n\n```zig\nconst sys = bun.sys;\n\n// Use bun.O flags (cross-platform normalized)\nconst fd = switch (sys.open(path, bun.O.RDONLY, 0)) {\n    .result => |fd| fd,\n    .err => |err| return .{ .err = err },\n};\ndefer fd.close();\n\n// Common flags\nbun.O.RDONLY, bun.O.WRONLY, bun.O.RDWR\nbun.O.CREAT, bun.O.TRUNC, bun.O.APPEND\nbun.O.NONBLOCK, bun.O.DIRECTORY\n```\n\n### Reading & Writing\n\n```zig\n// Single read (may return less than buffer size)\nswitch (sys.read(fd, buffer)) {\n    .result => |n| { /* n bytes read */ },\n    .err => |err| { /* handle error */ },\n}\n\n// Read until EOF or buffer full\nconst total = try sys.readAll(fd, buffer).unwrap();\n\n// Position-based read/write\nsys.pread(fd, buffer, offset)\nsys.pwrite(fd, data, offset)\n\n// Vector I/O\nsys.readv(fd, iovecs)\nsys.writev(fd, iovecs)\n```\n\n### File Info\n\n```zig\nsys.stat(path)      // Follow symlinks\nsys.lstat(path)     // Don't follow symlinks\nsys.fstat(fd)       // From file descriptor\nsys.fstatat(fd, path)\n\n// Linux-only: faster selective stat\nsys.statx(path, &.{ .size, .mtime })\n```\n\n### Path Operations\n\n```zig\nsys.unlink(path)\nsys.unlinkat(dir_fd, path)\nsys.rename(from, to)\nsys.renameat(from_dir, from, to_dir, to)\nsys.readlink(path, buf)\nsys.readlinkat(fd, path, buf)\nsys.link(T, src, dest)\nsys.linkat(src_fd, src, dest_fd, dest)\nsys.symlink(target, dest)\nsys.symlinkat(target, dirfd, dest)\nsys.mkdir(path, mode)\nsys.mkdirat(dir_fd, path, mode)\nsys.rmdir(path)\n```\n\n### Permissions\n\n```zig\nsys.chmod(path, mode)\nsys.fchmod(fd, mode)\nsys.fchmodat(fd, path, mode, flags)\nsys.chown(path, uid, gid)\nsys.fchown(fd, uid, gid)\n```\n\n### Closing File Descriptors\n\nClose is on `bun.FD`:\n\n```zig\nfd.close();  // Asserts on error (use in defer)\n\n// Or if you need error info:\nif (fd.closeAllowingBadFileDescriptor(null)) |err| {\n    // handle error\n}\n```\n\n## Directory Operations\n\n```zig\nvar buf: bun.PathBuffer = undefined;\nconst cwd = try sys.getcwd(&buf).unwrap();\nconst cwdZ = try sys.getcwdZ(&buf).unwrap();  // Zero-terminated\nsys.chdir(path, destination)\n```\n\n### Directory Iteration\n\nUse `bun.DirIterator` instead of `std.fs.Dir.Iterator`:\n\n```zig\nvar iter = bun.iterateDir(dir_fd);\nwhile (true) {\n    switch (iter.next()) {\n        .result => |entry| {\n            if (entry) |e| {\n                const name = e.name.slice();\n                const kind = e.kind;  // .file, .directory, .sym_link, etc.\n            } else {\n                break;  // End of directory\n            }\n        },\n        .err => |err| return .{ .err = err },\n    }\n}\n```\n\n## Socket Operations\n\n**Important**: `bun.sys` has limited socket support. For network I/O:\n\n- **Non-blocking sockets**: Use `uws.Socket` (libuwebsockets) exclusively\n- **Pipes/blocking I/O**: Use `PipeReader.zig` and `PipeWriter.zig`\n\nAvailable in bun.sys:\n\n```zig\nsys.setsockopt(fd, level, optname, value)\nsys.socketpair(domain, socktype, protocol, nonblocking_status)\n```\n\nDo NOT use `bun.sys` for socket read/write - use `uws.Socket` instead.\n\n## Other Operations\n\n```zig\nsys.ftruncate(fd, size)\nsys.lseek(fd, offset, whence)\nsys.dup(fd)\nsys.dupWithFlags(fd, flags)\nsys.fcntl(fd, cmd, arg)\nsys.pipe()\nsys.mmap(...)\nsys.munmap(memory)\nsys.access(path, mode)\nsys.futimens(fd, atime, mtime)\nsys.utimens(path, atime, mtime)\n```\n\n## Error Type\n\n```zig\nconst err: bun.sys.Error = ...;\nerr.errno      // Raw errno value\nerr.getErrno() // As std.posix.E enum\nerr.syscall    // Which syscall failed (Tag enum)\nerr.fd         // Optional: file descriptor\nerr.path       // Optional: path string\n```\n\n## Key Points\n\n- Prefer `bun.sys.File` wrapper for most file operations\n- Use low-level `bun.sys` functions only when needed\n- Use `bun.O.*` flags instead of `std.os.O.*`\n- Handle `Maybe(T)` with switch or `.unwrap()`\n- Use `defer fd.close()` for cleanup\n- EINTR is handled automatically in most functions\n- For sockets, use `uws.Socket` not `bun.sys`\n"
      },
      "discovered_at": "2026-01-11T15:35:55.396777Z",
      "fetch_error": null
    },
    {
      "name": "implementing-jsc-classes-zig",
      "slug": "implementing-jsc-classes-zig",
      "source": "skillsmp_top",
      "owner": "oven-sh",
      "repo_name": "bun",
      "repository_url": "https://github.com/oven-sh/bun",
      "skill_path": ".claude/skills/implementing-jsc-classes-zig",
      "github_metadata": {
        "stars": 86188,
        "description": "Incredibly fast JavaScript runtime, bundler, test runner, and package manager â€“ all in one",
        "default_branch": "main",
        "pushed_at": "2026-01-11T15:11:23Z",
        "created_at": "2021-04-14T00:48:17Z",
        "language": "Zig",
        "license": "NOASSERTION",
        "open_issues": 5614,
        "forks": 3913
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/implementing-jsc-classes-zig/SKILL.md",
        "branch": "main",
        "content": "---\nname: implementing-jsc-classes-zig\ndescription: Creates JavaScript classes using Bun's Zig bindings generator (.classes.ts). Use when implementing new JS APIs in Zig with JSC integration.\n---\n\n# Bun's JavaScriptCore Class Bindings Generator\n\nBridge JavaScript and Zig through `.classes.ts` definitions and Zig implementations.\n\n## Architecture\n\n1. **Zig Implementation** (.zig files)\n2. **JavaScript Interface Definition** (.classes.ts files)\n3. **Generated Code** (C++/Zig files connecting them)\n\n## Class Definition (.classes.ts)\n\n```typescript\ndefine({\n  name: \"TextDecoder\",\n  constructor: true,\n  JSType: \"object\",\n  finalize: true,\n  proto: {\n    decode: { args: 1 },\n    encoding: { getter: true, cache: true },\n    fatal: { getter: true },\n  },\n});\n```\n\nOptions:\n\n- `name`: Class name\n- `constructor`: Has public constructor\n- `JSType`: \"object\", \"function\", etc.\n- `finalize`: Needs cleanup\n- `proto`: Properties/methods\n- `cache`: Cache property values via WriteBarrier\n\n## Zig Implementation\n\n```zig\npub const TextDecoder = struct {\n    pub const js = JSC.Codegen.JSTextDecoder;\n    pub const toJS = js.toJS;\n    pub const fromJS = js.fromJS;\n    pub const fromJSDirect = js.fromJSDirect;\n\n    encoding: []const u8,\n    fatal: bool,\n\n    pub fn constructor(\n        globalObject: *JSGlobalObject,\n        callFrame: *JSC.CallFrame,\n    ) bun.JSError!*TextDecoder {\n        return bun.new(TextDecoder, .{ .encoding = \"utf-8\", .fatal = false });\n    }\n\n    pub fn decode(\n        this: *TextDecoder,\n        globalObject: *JSGlobalObject,\n        callFrame: *JSC.CallFrame,\n    ) bun.JSError!JSC.JSValue {\n        const args = callFrame.arguments();\n        if (args.len < 1 or args.ptr[0].isUndefinedOrNull()) {\n            return globalObject.throw(\"Input cannot be null\", .{});\n        }\n        return JSC.JSValue.jsString(globalObject, \"result\");\n    }\n\n    pub fn getEncoding(this: *TextDecoder, globalObject: *JSGlobalObject) JSC.JSValue {\n        return JSC.JSValue.createStringFromUTF8(globalObject, this.encoding);\n    }\n\n    fn deinit(this: *TextDecoder) void {\n        // Release resources\n    }\n\n    pub fn finalize(this: *TextDecoder) void {\n        this.deinit();\n        bun.destroy(this);\n    }\n};\n```\n\n**Key patterns:**\n\n- Use `bun.JSError!JSValue` return type for error handling\n- Use `globalObject` not `ctx`\n- `deinit()` for cleanup, `finalize()` called by GC\n- Update `src/bun.js/bindings/generated_classes_list.zig`\n\n## CallFrame Access\n\n```zig\nconst args = callFrame.arguments();\nconst first_arg = args.ptr[0];  // Access as slice\nconst argCount = args.len;\nconst thisValue = callFrame.thisValue();\n```\n\n## Property Caching\n\nFor `cache: true` properties, generated accessors:\n\n```zig\n// Get cached value\npub fn encodingGetCached(thisValue: JSC.JSValue) ?JSC.JSValue {\n    const result = TextDecoderPrototype__encodingGetCachedValue(thisValue);\n    if (result == .zero) return null;\n    return result;\n}\n\n// Set cached value\npub fn encodingSetCached(thisValue: JSC.JSValue, globalObject: *JSC.JSGlobalObject, value: JSC.JSValue) void {\n    TextDecoderPrototype__encodingSetCachedValue(thisValue, globalObject, value);\n}\n```\n\n## Error Handling\n\n```zig\npub fn method(this: *MyClass, globalObject: *JSGlobalObject, callFrame: *JSC.CallFrame) bun.JSError!JSC.JSValue {\n    const args = callFrame.arguments();\n    if (args.len < 1) {\n        return globalObject.throw(\"Missing required argument\", .{});\n    }\n    return JSC.JSValue.jsString(globalObject, \"Success!\");\n}\n```\n\n## Memory Management\n\n```zig\npub fn deinit(this: *TextDecoder) void {\n    this._encoding.deref();\n    if (this.buffer) |buffer| {\n        bun.default_allocator.free(buffer);\n    }\n}\n\npub fn finalize(this: *TextDecoder) void {\n    JSC.markBinding(@src());\n    this.deinit();\n    bun.default_allocator.destroy(this);\n}\n```\n\n## Creating a New Binding\n\n1. Define interface in `.classes.ts`:\n\n```typescript\ndefine({\n  name: \"MyClass\",\n  constructor: true,\n  finalize: true,\n  proto: {\n    myMethod: { args: 1 },\n    myProperty: { getter: true, cache: true },\n  },\n});\n```\n\n2. Implement in `.zig`:\n\n```zig\npub const MyClass = struct {\n    pub const js = JSC.Codegen.JSMyClass;\n    pub const toJS = js.toJS;\n    pub const fromJS = js.fromJS;\n\n    value: []const u8,\n\n    pub const new = bun.TrivialNew(@This());\n\n    pub fn constructor(globalObject: *JSGlobalObject, callFrame: *JSC.CallFrame) bun.JSError!*MyClass {\n        return MyClass.new(.{ .value = \"\" });\n    }\n\n    pub fn myMethod(this: *MyClass, globalObject: *JSGlobalObject, callFrame: *JSC.CallFrame) bun.JSError!JSC.JSValue {\n        return JSC.JSValue.jsUndefined();\n    }\n\n    pub fn getMyProperty(this: *MyClass, globalObject: *JSGlobalObject) JSC.JSValue {\n        return JSC.JSValue.jsString(globalObject, this.value);\n    }\n\n    pub fn deinit(this: *MyClass) void {}\n\n    pub fn finalize(this: *MyClass) void {\n        this.deinit();\n        bun.destroy(this);\n    }\n};\n```\n\n3. Add to `src/bun.js/bindings/generated_classes_list.zig`\n\n## Generated Components\n\n- **C++ Classes**: `JSMyClass`, `JSMyClassPrototype`, `JSMyClassConstructor`\n- **Method Bindings**: `MyClassPrototype__myMethodCallback`\n- **Property Accessors**: `MyClassPrototype__myPropertyGetterWrap`\n- **Zig Bindings**: External function declarations, cached value accessors\n"
      },
      "discovered_at": "2026-01-11T15:35:55.728119Z",
      "fetch_error": null
    },
    {
      "name": "concept-workflow",
      "slug": "concept-workflow",
      "source": "skillsmp_top",
      "owner": "leonardomso",
      "repo_name": "33-js-concepts",
      "repository_url": "https://github.com/leonardomso/33-js-concepts",
      "skill_path": ".opencode/skill/concept-workflow",
      "github_metadata": {
        "stars": 66082,
        "description": "ğŸ“œ 33 JavaScript concepts every developer should know.",
        "default_branch": "master",
        "pushed_at": "2026-01-07T12:51:15Z",
        "created_at": "2018-09-04T13:27:04Z",
        "language": "JavaScript",
        "license": "MIT",
        "open_issues": 0,
        "forks": 9196
      },
      "skill_md": {
        "found": true,
        "path": ".opencode/skill/concept-workflow/SKILL.md",
        "branch": "master",
        "content": "---\nname: concept-workflow\ndescription: End-to-end workflow for creating complete JavaScript concept documentation, orchestrating all skills from research to final review\n---\n\n# Skill: Complete Concept Workflow\n\nUse this skill to create a complete, high-quality concept page from start to finish. This skill orchestrates all five specialized skills in the optimal order:\n\n1. **Resource Curation** â€” Find quality learning resources\n2. **Concept Writing** â€” Write the documentation page\n3. **Test Writing** â€” Create tests for code examples\n4. **Fact Checking** â€” Verify technical accuracy\n5. **SEO Review** â€” Optimize for search visibility\n\n## When to Use\n\n- Creating a brand new concept page from scratch\n- Completely rewriting an existing concept page\n- When you want a full end-to-end workflow with all quality checks\n\n**For partial tasks, use individual skills instead:**\n- Just adding resources? Use `resource-curator`\n- Just writing content? Use `write-concept`\n- Just adding tests? Use `test-writer`\n- Just verifying accuracy? Use `fact-check`\n- Just optimizing SEO? Use `seo-review`\n\n---\n\n## Workflow Overview\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                     COMPLETE CONCEPT WORKFLOW                                â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                                              â”‚\nâ”‚  INPUT: Concept name (e.g., \"hoisting\", \"event-loop\", \"promises\")           â”‚\nâ”‚                                                                              â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                        â”‚\nâ”‚  â”‚ PHASE 1: RESEARCH â”‚                                                       â”‚\nâ”‚  â”‚ resource-curator  â”‚  Find MDN refs, articles, videos                      â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                        â”‚\nâ”‚           â–¼                                                                  â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                        â”‚\nâ”‚  â”‚ PHASE 2: WRITE   â”‚                                                        â”‚\nâ”‚  â”‚ write-concept    â”‚  Create the documentation page                         â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                        â”‚\nâ”‚           â–¼                                                                  â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                        â”‚\nâ”‚  â”‚ PHASE 3: TEST    â”‚                                                        â”‚\nâ”‚  â”‚ test-writer      â”‚  Generate tests for all code examples                  â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                        â”‚\nâ”‚           â–¼                                                                  â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                        â”‚\nâ”‚  â”‚ PHASE 4: VERIFY  â”‚                                                        â”‚\nâ”‚  â”‚ fact-check       â”‚  Verify accuracy, run tests, check links               â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                        â”‚\nâ”‚           â–¼                                                                  â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                        â”‚\nâ”‚  â”‚ PHASE 5: OPTIMIZEâ”‚                                                        â”‚\nâ”‚  â”‚ seo-review       â”‚  SEO audit and final optimizations                     â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                        â”‚\nâ”‚           â–¼                                                                  â”‚\nâ”‚  OUTPUT: Complete, tested, verified, SEO-optimized concept page              â”‚\nâ”‚                                                                              â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n---\n\n## Phase 1: Resource Curation\n\n**Skill:** `resource-curator`\n**Goal:** Gather high-quality external resources before writing\n\n### What to Do\n\n1. **Identify the concept category** (fundamentals, async, OOP, etc.)\n2. **Search for MDN references** â€” Official documentation\n3. **Find quality articles** â€” Target 4-6 from trusted sources\n4. **Find quality videos** â€” Target 3-4 from trusted creators\n5. **Evaluate each resource** â€” Check quality criteria\n6. **Write specific descriptions** â€” 2 sentences each\n7. **Format as Card components** â€” Ready to paste into the page\n\n### Deliverables\n\n- List of 2-4 MDN/reference links with descriptions\n- List of 4-6 article links with descriptions\n- List of 3-4 video links with descriptions\n- Optional: 1-2 courses or books\n\n### Quality Gates\n\nBefore moving to Phase 2:\n- [ ] All links verified working (200 response)\n- [ ] All resources are JavaScript-focused\n- [ ] Descriptions are specific, not generic\n- [ ] Mix of beginner and advanced content\n\n---\n\n## Phase 2: Concept Writing\n\n**Skill:** `write-concept`\n**Goal:** Create the full documentation page\n\n### What to Do\n\n1. **Determine the category** for file organization\n2. **Create the frontmatter** (title, sidebarTitle, description)\n3. **Write the opening hook** â€” Question that draws readers in\n4. **Add opening code example** â€” Simple example in first 200 words\n5. **Write \"What you'll learn\" box** â€” 5-7 bullet points\n6. **Write main content sections:**\n   - What is [concept]? (with 40-60 word definition for featured snippet)\n   - Real-world analogy\n   - How it works (with diagrams)\n   - Code examples (multiple, progressive complexity)\n   - Common mistakes\n   - Edge cases\n7. **Add Key Takeaways** â€” 8-10 numbered points\n8. **Add Test Your Knowledge** â€” 5-6 Q&A accordions\n9. **Add Related Concepts** â€” 4 Cards linking to related topics\n10. **Add Resources** â€” Paste resources from Phase 1\n\n### Deliverables\n\n- Complete `.mdx` file at `/docs/concepts/{concept-name}.mdx`\n- File added to `docs.json` navigation (if new)\n\n### Quality Gates\n\nBefore moving to Phase 3:\n- [ ] Frontmatter complete (title, sidebarTitle, description)\n- [ ] Opens with question hook\n- [ ] Code example in first 200 words\n- [ ] \"What you'll learn\" Info box present\n- [ ] All required sections present\n- [ ] Resources section complete\n- [ ] 1,500+ words\n\n---\n\n## Phase 3: Test Writing\n\n**Skill:** `test-writer`\n**Goal:** Create comprehensive tests for all code examples\n\n### What to Do\n\n1. **Scan the concept page** for all code examples\n2. **Categorize examples:**\n   - Testable (console.log, return values)\n   - DOM-specific (needs jsdom)\n   - Error examples (toThrow)\n   - Conceptual (skip)\n3. **Create test file** at `tests/{category}/{concept}/{concept}.test.js`\n4. **Create DOM test file** (if needed) at `tests/{category}/{concept}/{concept}.dom.test.js`\n5. **Write tests** for each code example with source line references\n6. **Run tests** to verify all pass\n\n### Deliverables\n\n- Test file: `tests/{category}/{concept-name}/{concept-name}.test.js`\n- DOM test file (if applicable): `tests/{category}/{concept-name}/{concept-name}.dom.test.js`\n- All tests passing\n\n### Quality Gates\n\nBefore moving to Phase 4:\n- [ ] All testable code examples have tests\n- [ ] Source line references in comments\n- [ ] Tests pass: `npm test -- tests/{category}/{concept}/`\n- [ ] DOM tests in separate file with jsdom directive\n\n---\n\n## Phase 4: Fact Checking\n\n**Skill:** `fact-check`\n**Goal:** Verify technical accuracy of all content\n\n### What to Do\n\n1. **Verify code examples:**\n   - Run tests: `npm test -- tests/{category}/{concept}/`\n   - Check any untested examples manually\n   - Verify output comments match actual outputs\n\n2. **Verify MDN/spec claims:**\n   - Click all MDN links â€” verify they work\n   - Compare API descriptions to MDN\n   - Check ECMAScript spec for nuanced claims\n\n3. **Verify external resources:**\n   - Check all article/video links work\n   - Skim content for accuracy\n   - Verify descriptions match content\n\n4. **Audit technical claims:**\n   - Look for \"always/never\" statements\n   - Verify performance claims\n   - Check for common misconceptions\n\n5. **Generate fact-check report**\n\n### Deliverables\n\n- Fact-check report documenting:\n  - Code verification results\n  - Link check results\n  - Any issues found and fixes made\n\n### Quality Gates\n\nBefore moving to Phase 5:\n- [ ] All tests passing\n- [ ] All MDN links valid\n- [ ] All external resources accessible\n- [ ] No technical inaccuracies found\n- [ ] No common misconceptions\n\n---\n\n## Phase 5: SEO Review\n\n**Skill:** `seo-review`\n**Goal:** Optimize for search visibility\n\n### What to Do\n\n1. **Audit title tag:**\n   - 50-60 characters\n   - Primary keyword in first half\n   - Ends with \"in JavaScript\"\n   - Contains compelling hook\n\n2. **Audit meta description:**\n   - 150-160 characters\n   - Starts with action word (Learn, Understand, Discover)\n   - Contains primary keyword\n   - Promises specific value\n\n3. **Audit keyword placement:**\n   - Keyword in title\n   - Keyword in description\n   - Keyword in first 100 words\n   - Keyword in at least one H2\n\n4. **Audit content structure:**\n   - Question hook opening\n   - Code in first 200 words\n   - \"What you'll learn\" box\n   - Short paragraphs\n\n5. **Audit featured snippet optimization:**\n   - 40-60 word definition after \"What is\" H2\n   - Question-format H2s\n   - Numbered steps for how-to content\n\n6. **Audit internal linking:**\n   - 3-5 related concepts linked\n   - Descriptive anchor text\n   - Related Concepts section complete\n\n7. **Calculate score** and fix any issues\n\n### Deliverables\n\n- SEO audit report with score (X/27)\n- All high-priority fixes implemented\n\n### Quality Gates\n\nBefore marking complete:\n- [ ] Score 24+ out of 27 (90%+)\n- [ ] Title optimized\n- [ ] Meta description optimized\n- [ ] Keywords placed naturally\n- [ ] Featured snippet optimized\n- [ ] Internal links complete\n\n---\n\n## Complete Workflow Checklist\n\nUse this master checklist to track progress through all phases.\n\n```markdown\n# Concept Workflow: [Concept Name]\n\n**Started:** YYYY-MM-DD\n**Target Category:** {category}\n**File Path:** `/docs/concepts/{concept-name}.mdx`\n**Test Path:** `/tests/{category}/{concept-name}/`\n\n---\n\n## Phase 1: Resource Curation\n- [ ] MDN references found (2-4)\n- [ ] Articles found (4-6)\n- [ ] Videos found (3-4)\n- [ ] All links verified working\n- [ ] Descriptions written (specific, 2 sentences)\n- [ ] Resources formatted as Cards\n\n**Status:** â¬œ Not Started | ğŸŸ¡ In Progress | âœ… Complete\n\n---\n\n## Phase 2: Concept Writing\n- [ ] Frontmatter complete\n- [ ] Opening hook written\n- [ ] Opening code example added\n- [ ] \"What you'll learn\" box added\n- [ ] Main content sections written\n- [ ] Key Takeaways added\n- [ ] Test Your Knowledge added\n- [ ] Related Concepts added\n- [ ] Resources pasted from Phase 1\n- [ ] Added to docs.json (if new)\n\n**Status:** â¬œ Not Started | ğŸŸ¡ In Progress | âœ… Complete\n\n---\n\n## Phase 3: Test Writing\n- [ ] Code examples extracted and categorized\n- [ ] Test file created\n- [ ] DOM test file created (if needed)\n- [ ] All testable examples have tests\n- [ ] Source line references added\n- [ ] Tests run and passing\n\n**Test Results:** X passing, X failing\n\n**Status:** â¬œ Not Started | ğŸŸ¡ In Progress | âœ… Complete\n\n---\n\n## Phase 4: Fact Checking\n- [ ] All tests passing\n- [ ] Code examples verified accurate\n- [ ] MDN links checked (X/X valid)\n- [ ] External resources checked (X/X valid)\n- [ ] Technical claims audited\n- [ ] No misconceptions found\n- [ ] Issues fixed\n\n**Status:** â¬œ Not Started | ğŸŸ¡ In Progress | âœ… Complete\n\n---\n\n## Phase 5: SEO Review\n- [ ] Title tag optimized (50-60 chars)\n- [ ] Meta description optimized (150-160 chars)\n- [ ] Keywords placed correctly\n- [ ] Content structure verified\n- [ ] Featured snippet optimized\n- [ ] Internal links complete\n\n**SEO Score:** X/27 (X%)\n\n**Status:** â¬œ Not Started | ğŸŸ¡ In Progress | âœ… Complete\n\n---\n\n## Final Status\n\n**All Phases Complete:** â¬œ No | âœ… Yes\n**Ready to Publish:** â¬œ No | âœ… Yes\n**Completed:** YYYY-MM-DD\n```\n\n---\n\n## Execution Instructions\n\nWhen executing this workflow, follow these steps:\n\n### Step 1: Initialize\n\n```markdown\nStarting concept workflow for: [CONCEPT NAME]\n\nCategory: [fundamentals/functions-execution/web-platform/etc.]\nFile: /docs/concepts/[concept-name].mdx\nTests: /tests/[category]/[concept-name]/\n```\n\n### Step 2: Execute Each Phase\n\nFor each phase:\n\n1. **Announce the phase:**\n   ```markdown\n   ## Phase X: [Phase Name]\n   Using skill: [skill-name]\n   ```\n\n2. **Load the skill** to get detailed instructions\n\n3. **Execute the phase** following the skill's methodology\n\n4. **Report completion:**\n   ```markdown\n   Phase X complete:\n   - [Deliverable 1]\n   - [Deliverable 2]\n   - Quality gates: âœ… All passed\n   ```\n\n5. **Move to next phase** only after quality gates pass\n\n### Step 3: Final Report\n\nAfter all phases complete:\n\n```markdown\n# Workflow Complete: [Concept Name]\n\n## Summary\n- **Concept Page:** `/docs/concepts/[concept-name].mdx`\n- **Test File:** `/tests/[category]/[concept-name]/[concept-name].test.js`\n- **Word Count:** X,XXX words\n- **Code Examples:** XX (XX tested)\n- **Resources:** X MDN, X articles, X videos\n\n## Quality Metrics\n- **Tests:** XX passing\n- **Fact Check:** âœ… All verified\n- **SEO Score:** XX/27 (XX%)\n\n## Files Created/Modified\n1. `/docs/concepts/[concept-name].mdx` (created)\n2. `/docs/docs.json` (updated navigation)\n3. `/tests/[category]/[concept-name]/[concept-name].test.js` (created)\n\n## Ready to Publish: âœ… Yes\n```\n\n---\n\n## Phase Dependencies\n\nSome phases can be partially parallelized, but the general flow should be:\n\n```\nPhase 1 (Resources) â”€â”€â”\n                      â”œâ”€â”€â–º Phase 2 (Writing) â”€â”€â–º Phase 3 (Tests) â”€â”€â”\n                      â”‚                                             â”‚\n                      â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                      â”‚         â–¼\n                      â””â”€â”€â–º Phase 4 (Fact Check) â”€â”€â–º Phase 5 (SEO)\n```\n\n- **Phase 1 before Phase 2:** Resources inform what to write\n- **Phase 2 before Phase 3:** Need content before writing tests\n- **Phase 3 before Phase 4:** Tests are part of fact-checking\n- **Phase 4 before Phase 5:** Fix accuracy issues before SEO polish\n\n---\n\n## Skill Reference\n\n| Phase | Skill | Purpose |\n|-------|-------|---------|\n| 1 | `resource-curator` | Find and evaluate external resources |\n| 2 | `write-concept` | Write the documentation page |\n| 3 | `test-writer` | Generate tests for code examples |\n| 4 | `fact-check` | Verify technical accuracy |\n| 5 | `seo-review` | Optimize for search visibility |\n\nEach skill has detailed instructions in its own `SKILL.md` file. Load the appropriate skill at each phase for comprehensive guidance.\n\n---\n\n## Time Estimates\n\n| Phase | Estimated Time | Notes |\n|-------|---------------|-------|\n| Phase 1: Resources | 15-30 min | Depends on availability of quality resources |\n| Phase 2: Writing | 1-3 hours | Depends on concept complexity |\n| Phase 3: Tests | 30-60 min | Depends on number of code examples |\n| Phase 4: Fact Check | 15-30 min | Most automated via tests |\n| Phase 5: SEO | 15-30 min | Mostly checklist verification |\n| **Total** | **2-5 hours** | For a complete concept page |\n\n---\n\n## Quick Start\n\nTo start the workflow for a new concept:\n\n```\n1. Determine the concept name and category\n2. Load this skill (concept-workflow)\n3. Execute Phase 1: Load resource-curator, find resources\n4. Execute Phase 2: Load write-concept, write the page\n5. Execute Phase 3: Load test-writer, create tests\n6. Execute Phase 4: Load fact-check, verify accuracy\n7. Execute Phase 5: Load seo-review, optimize SEO\n8. Generate final report\n9. Commit changes\n```\n\n**Example prompt to start:**\n\n> \"Create a complete concept page for 'hoisting' using the concept-workflow skill\"\n\nThis will trigger the full end-to-end workflow, creating a complete, tested, verified, and SEO-optimized concept page.\n"
      },
      "discovered_at": "2026-01-11T15:35:56.024788Z",
      "fetch_error": null
    },
    {
      "name": "fact-check",
      "slug": "fact-check",
      "source": "skillsmp_top",
      "owner": "leonardomso",
      "repo_name": "33-js-concepts",
      "repository_url": "https://github.com/leonardomso/33-js-concepts",
      "skill_path": ".opencode/skill/fact-check",
      "github_metadata": {
        "stars": 66082,
        "description": "ğŸ“œ 33 JavaScript concepts every developer should know.",
        "default_branch": "master",
        "pushed_at": "2026-01-07T12:51:15Z",
        "created_at": "2018-09-04T13:27:04Z",
        "language": "JavaScript",
        "license": "MIT",
        "open_issues": 0,
        "forks": 9196
      },
      "skill_md": {
        "found": true,
        "path": ".opencode/skill/fact-check/SKILL.md",
        "branch": "master",
        "content": "---\nname: fact-check\ndescription: Verify technical accuracy of JavaScript concept pages by checking code examples, MDN/ECMAScript compliance, and external resources to prevent misinformation\n---\n\n# Skill: JavaScript Fact Checker\n\nUse this skill to verify the technical accuracy of concept documentation pages for the 33 JavaScript Concepts project. This ensures we're not spreading misinformation about JavaScript.\n\n## When to Use\n\n- Before publishing a new concept page\n- After significant edits to existing content\n- When reviewing community contributions\n- When updating pages with new JavaScript features\n- Periodic accuracy audits of existing content\n\n## What We're Protecting Against\n\n- Incorrect JavaScript behavior claims\n- Outdated information (pre-ES6 patterns presented as current)\n- Code examples that don't produce stated outputs\n- Broken or misleading external resource links\n- Common misconceptions stated as fact\n- Browser-specific behavior presented as universal\n- Inaccurate API descriptions\n\n---\n\n## Fact-Checking Methodology\n\nFollow these five phases in order for a complete fact check.\n\n### Phase 1: Code Example Verification\n\nEvery code example in the concept page must be verified for accuracy.\n\n#### Step-by-Step Process\n\n1. **Identify all code blocks** in the document\n2. **For each code block:**\n   - Read the code and any output comments (e.g., `// \"string\"`)\n   - Mentally execute the code or test in a JavaScript environment\n   - Verify the output matches what's stated in comments\n   - Check that variable names and logic are correct\n\n3. **For \"wrong\" examples (marked with âŒ):**\n   - Verify they actually produce the wrong/unexpected behavior\n   - Confirm the explanation of why it's wrong is accurate\n\n4. **For \"correct\" examples (marked with âœ“):**\n   - Verify they work as stated\n   - Confirm they follow current best practices\n\n5. **Run project tests:**\n   ```bash\n   # Run all tests\n   npm test\n   \n   # Run tests for a specific concept\n   npm test -- tests/fundamentals/call-stack/\n   npm test -- tests/fundamentals/primitive-types/\n   ```\n\n6. **Check test coverage:**\n   - Look in `/tests/{category}/{concept-name}/`\n   - Verify tests exist for major code examples\n   - Flag examples without test coverage\n\n#### Code Verification Checklist\n\n| Check | How to Verify |\n|-------|---------------|\n| `console.log` outputs match comments | Run code or trace mentally |\n| Variables are correctly named/used | Read through logic |\n| Functions return expected values | Trace execution |\n| Async code resolves in stated order | Understand event loop |\n| Error examples actually throw | Test in try/catch |\n| Array/object methods return correct types | Check MDN |\n| `typeof` results are accurate | Test common cases |\n| Strict mode behavior noted if relevant | Check if example depends on it |\n\n#### Common Output Mistakes to Catch\n\n```javascript\n// Watch for these common mistakes:\n\n// 1. typeof null\ntypeof null        // \"object\" (not \"null\"!)\n\n// 2. Array methods that return new arrays vs mutate\nconst arr = [1, 2, 3]\narr.push(4)        // Returns 4 (length), not the array!\narr.map(x => x*2)  // Returns NEW array, doesn't mutate\n\n// 3. Promise resolution order\nPromise.resolve().then(() => console.log('micro'))\nsetTimeout(() => console.log('macro'), 0)\nconsole.log('sync')\n// Output: sync, micro, macro (NOT sync, macro, micro)\n\n// 4. Comparison results\n[] == false        // true\n[] === false       // false\n![]                // false (empty array is truthy!)\n\n// 5. this binding\nconst obj = {\n  name: 'Alice',\n  greet: () => console.log(this.name)  // undefined! Arrow has no this\n}\n```\n\n---\n\n### Phase 2: MDN Documentation Verification\n\nAll claims about JavaScript APIs, methods, and behavior should align with MDN documentation.\n\n#### Step-by-Step Process\n\n1. **Check all MDN links:**\n   - Click each MDN link in the document\n   - Verify the link returns 200 (not 404)\n   - Confirm the linked page matches what's being referenced\n\n2. **Verify API descriptions:**\n   - Compare method signatures with MDN\n   - Check parameter names and types\n   - Verify return types\n   - Confirm edge case behavior\n\n3. **Check for deprecated APIs:**\n   - Look for deprecation warnings on MDN\n   - Flag any deprecated methods being taught as current\n\n4. **Verify browser compatibility claims:**\n   - Cross-reference with MDN compatibility tables\n   - Check Can I Use for broader support data\n\n#### MDN Link Patterns\n\n| Content Type | MDN URL Pattern |\n|--------------|-----------------|\n| Web APIs | `https://developer.mozilla.org/en-US/docs/Web/API/{APIName}` |\n| Global Objects | `https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/{Object}` |\n| Statements | `https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/{Statement}` |\n| Operators | `https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/{Operator}` |\n| HTTP | `https://developer.mozilla.org/en-US/docs/Web/HTTP` |\n\n#### What to Verify Against MDN\n\n| Claim Type | What to Check |\n|------------|---------------|\n| Method signature | Parameters, optional params, return type |\n| Return value | Exact type and possible values |\n| Side effects | Does it mutate? What does it affect? |\n| Exceptions | What errors can it throw? |\n| Browser support | Compatibility tables |\n| Deprecation status | Any deprecation warnings? |\n\n---\n\n### Phase 3: ECMAScript Specification Compliance\n\nFor nuanced JavaScript behavior, verify against the ECMAScript specification.\n\n#### When to Check the Spec\n\n- Edge cases and unusual behavior\n- Claims about \"how JavaScript works internally\"\n- Type coercion rules\n- Operator precedence\n- Execution order guarantees\n- Claims using words like \"always\", \"never\", \"guaranteed\"\n\n#### How to Navigate the Spec\n\nThe ECMAScript specification is at: https://tc39.es/ecma262/\n\n| Concept | Spec Section |\n|---------|--------------|\n| Type coercion | Abstract Operations (7.1) |\n| Equality | Abstract Equality Comparison (7.2.14), Strict Equality (7.2.15) |\n| typeof | The typeof Operator (13.5.3) |\n| Objects | Ordinary and Exotic Objects' Behaviours (10) |\n| Functions | ECMAScript Function Objects (10.2) |\n| this binding | ResolveThisBinding (9.4.4) |\n| Promises | Promise Objects (27.2) |\n| Iteration | Iteration (27.1) |\n\n#### Spec Verification Examples\n\n```javascript\n// Claim: \"typeof null returns 'object' due to a bug\"\n// Spec says: typeof null â†’ \"object\" (Table 41)\n// Historical context: This is a known quirk from JS 1.0\n// Verdict: âœ“ Correct, though calling it a \"bug\" is slightly informal\n\n// Claim: \"Promises always resolve asynchronously\"\n// Spec says: Promise reaction jobs are enqueued (27.2.1.3.2)\n// Verdict: âœ“ Correct - even resolved promises schedule microtasks\n\n// Claim: \"=== is faster than ==\"\n// Spec says: Nothing about performance\n// Verdict: âš ï¸ Needs nuance - this is implementation-dependent\n```\n\n---\n\n### Phase 4: External Resource Verification\n\nAll external links (articles, videos, courses) must be verified.\n\n#### Step-by-Step Process\n\n1. **Check link accessibility:**\n   - Click each external link\n   - Verify it loads (not 404, not paywalled)\n   - Note any redirects to different URLs\n\n2. **Verify content accuracy:**\n   - Skim the resource for obvious errors\n   - Check it's JavaScript-focused (not C#, Python, Java)\n   - Verify it's not teaching anti-patterns\n\n3. **Check publication date:**\n   - For time-sensitive topics (async, modules, etc.), prefer recent content\n   - Flag resources from before 2015 for ES6+ topics\n\n4. **Verify description accuracy:**\n   - Does our description match what the resource actually covers?\n   - Is the description specific (not generic)?\n\n#### External Resource Checklist\n\n| Check | Pass Criteria |\n|-------|---------------|\n| Link works | Returns 200, content loads |\n| Not paywalled | Free to access (or clearly marked) |\n| JavaScript-focused | Not primarily about other languages |\n| Not outdated | Post-2015 for modern JS topics |\n| Accurate description | Our description matches actual content |\n| No anti-patterns | Doesn't teach bad practices |\n| Reputable source | From known/trusted creators |\n\n#### Red Flags in External Resources\n\n- Uses `var` everywhere for ES6+ topics\n- Uses callbacks for content about Promises/async\n- Teaches jQuery as modern DOM manipulation\n- Contains factual errors about JavaScript\n- Video is >2 hours without timestamp links\n- Content is primarily about another language\n- Uses deprecated APIs without noting deprecation\n\n---\n\n### Phase 5: Technical Claims Audit\n\nReview all prose claims about JavaScript behavior.\n\n#### Claims That Need Verification\n\n| Claim Type | How to Verify |\n|------------|---------------|\n| Performance claims | Need benchmarks or caveats |\n| Browser behavior | Specify which browsers, check MDN |\n| Historical claims | Verify dates/versions |\n| \"Always\" or \"never\" statements | Check for exceptions |\n| Comparisons (X vs Y) | Verify both sides accurately |\n\n#### Red Flags in Technical Claims\n\n- \"Always\" or \"never\" without exceptions noted\n- Performance claims without benchmarks\n- Browser behavior claims without specifying browsers\n- Comparisons that oversimplify differences\n- Historical claims without dates\n- Claims about \"how JavaScript works\" without spec reference\n\n#### Examples of Claims to Verify\n\n```markdown\nâŒ \"async/await is always better than Promises\"\nâ†’ Verify: Not always - Promise.all() is better for parallel operations\n\nâŒ \"JavaScript is an interpreted language\"\nâ†’ Verify: Modern JS engines use JIT compilation\n\nâŒ \"Objects are passed by reference\"\nâ†’ Verify: Technically \"passed by sharing\" - the reference is passed by value\n\nâŒ \"=== is faster than ==\"\nâ†’ Verify: Implementation-dependent, not guaranteed by spec\n\nâœ“ \"JavaScript is single-threaded\"\nâ†’ Verify: Correct for the main thread (Web Workers are separate)\n\nâœ“ \"Promises always resolve asynchronously\"\nâ†’ Verify: Correct per ECMAScript spec\n```\n\n---\n\n## Common JavaScript Misconceptions\n\nWatch for these misconceptions being stated as fact.\n\n### Type System Misconceptions\n\n| Misconception | Reality | How to Verify |\n|---------------|---------|---------------|\n| `typeof null === \"object\"` is intentional | It's a bug from JS 1.0 that can't be fixed for compatibility | Historical context, TC39 discussions |\n| JavaScript has no types | JS is dynamically typed, not untyped | ECMAScript spec defines types |\n| `==` is always wrong | `== null` checks both null and undefined, has valid uses | Many style guides allow this pattern |\n| `NaN === NaN` is false \"by mistake\" | It's intentional per IEEE 754 floating point spec | IEEE 754 standard |\n\n### Function Misconceptions\n\n| Misconception | Reality | How to Verify |\n|---------------|---------|---------------|\n| Arrow functions are just shorter syntax | They have no `this`, `arguments`, `super`, or `new.target` | MDN, ECMAScript spec |\n| `var` is hoisted to function scope with its value | Only declaration is hoisted, not initialization | Code test, MDN |\n| Closures are a special opt-in feature | All functions in JS are closures | ECMAScript spec |\n| IIFEs are obsolete | Still useful for one-time initialization | Modern codebases still use them |\n\n### Async Misconceptions\n\n| Misconception | Reality | How to Verify |\n|---------------|---------|---------------|\n| Promises run in parallel | JS is single-threaded; Promises are async, not parallel | Event loop explanation |\n| `async/await` is different from Promises | It's syntactic sugar over Promises | MDN, can await any thenable |\n| `setTimeout(fn, 0)` runs immediately | Runs after current execution + microtasks | Event loop, code test |\n| `await` pauses the entire program | Only pauses the async function, not the event loop | Code test |\n\n### Object Misconceptions\n\n| Misconception | Reality | How to Verify |\n|---------------|---------|---------------|\n| Objects are \"passed by reference\" | References are passed by value (\"pass by sharing\") | Reassignment test |\n| `const` makes objects immutable | `const` prevents reassignment, not mutation | Code test |\n| Everything in JavaScript is an object | Primitives are not objects (though they have wrappers) | `typeof` tests, MDN |\n| `Object.freeze()` creates deep immutability | It's shallow - nested objects can still be mutated | Code test |\n\n### Performance Misconceptions\n\n| Misconception | Reality | How to Verify |\n|---------------|---------|---------------|\n| `===` is always faster than `==` | Implementation-dependent, not spec-guaranteed | Benchmarks vary |\n| `for` loops are faster than `forEach` | Modern engines optimize both; depends on use case | Benchmark |\n| Arrow functions are faster | No performance difference, just different behavior | Benchmark |\n| Avoiding DOM manipulation is always faster | Sometimes batch mutations are slower than individual | Depends on browser, use case |\n\n---\n\n## Test Integration\n\nRunning the project's test suite is a key part of fact-checking.\n\n### Test Commands\n\n```bash\n# Run all tests\nnpm test\n\n# Run tests in watch mode\nnpm run test:watch\n\n# Run tests with coverage\nnpm run test:coverage\n\n# Run tests for specific concept\nnpm test -- tests/fundamentals/call-stack/\nnpm test -- tests/fundamentals/primitive-types/\nnpm test -- tests/fundamentals/value-reference-types/\nnpm test -- tests/fundamentals/type-coercion/\nnpm test -- tests/fundamentals/equality-operators/\nnpm test -- tests/fundamentals/scope-and-closures/\n```\n\n### Test Directory Structure\n\n```\ntests/\nâ”œâ”€â”€ fundamentals/              # Concepts 1-6\nâ”‚   â”œâ”€â”€ call-stack/\nâ”‚   â”œâ”€â”€ primitive-types/\nâ”‚   â”œâ”€â”€ value-reference-types/\nâ”‚   â”œâ”€â”€ type-coercion/\nâ”‚   â”œâ”€â”€ equality-operators/\nâ”‚   â””â”€â”€ scope-and-closures/\nâ”œâ”€â”€ functions-execution/       # Concepts 7-8\nâ”‚   â”œâ”€â”€ event-loop/\nâ”‚   â””â”€â”€ iife-modules/\nâ””â”€â”€ web-platform/              # Concepts 9-10\n    â”œâ”€â”€ dom/\n    â””â”€â”€ http-fetch/\n```\n\n### When Tests Are Missing\n\nIf a concept doesn't have tests:\n1. Flag this in the report as \"needs test coverage\"\n2. Manually verify code examples are correct\n3. Consider adding tests as a follow-up task\n\n---\n\n## Verification Resources\n\n### Primary Sources\n\n| Resource | URL | Use For |\n|----------|-----|---------|\n| MDN Web Docs | https://developer.mozilla.org | API docs, guides, compatibility |\n| ECMAScript Spec | https://tc39.es/ecma262 | Authoritative behavior |\n| TC39 Proposals | https://github.com/tc39/proposals | New features, stages |\n| Can I Use | https://caniuse.com | Browser compatibility |\n| Node.js Docs | https://nodejs.org/docs | Node-specific APIs |\n| V8 Blog | https://v8.dev/blog | Engine internals |\n\n### Project Resources\n\n| Resource | Path | Use For |\n|----------|------|---------|\n| Test Suite | `/tests/` | Verify code examples |\n| Concept Pages | `/docs/concepts/` | Current content |\n| Run Tests | `npm test` | Execute all tests |\n\n---\n\n## Fact Check Report Template\n\nUse this template to document your findings.\n\n```markdown\n# Fact Check Report: [Concept Name]\n\n**File:** `/docs/concepts/[slug].mdx`\n**Date:** YYYY-MM-DD\n**Reviewer:** [Name/Claude]\n**Overall Status:** âœ… Verified | âš ï¸ Minor Issues | âŒ Major Issues\n\n---\n\n## Executive Summary\n\n[2-3 sentence summary of findings. State whether the page is accurate overall and highlight any critical issues.]\n\n**Tests Run:** Yes/No\n**Test Results:** X passing, Y failing\n**External Links Checked:** X/Y valid\n\n---\n\n## Phase 1: Code Example Verification\n\n| # | Description | Line | Status | Notes |\n|---|-------------|------|--------|-------|\n| 1 | [Brief description] | XX | âœ…/âš ï¸/âŒ | [Notes] |\n| 2 | [Brief description] | XX | âœ…/âš ï¸/âŒ | [Notes] |\n| 3 | [Brief description] | XX | âœ…/âš ï¸/âŒ | [Notes] |\n\n### Code Issues Found\n\n#### Issue 1: [Title]\n\n**Location:** Line XX\n**Severity:** Critical/Major/Minor\n**Current Code:**\n```javascript\n// The problematic code\n```\n**Problem:** [Explanation of what's wrong]\n**Correct Code:**\n```javascript\n// The corrected code\n```\n\n---\n\n## Phase 2: MDN/Specification Verification\n\n| Claim | Location | Source | Status | Notes |\n|-------|----------|--------|--------|-------|\n| [Claim made] | Line XX | MDN/Spec | âœ…/âš ï¸/âŒ | [Notes] |\n\n### MDN Link Status\n\n| Link Text | URL | Status |\n|-----------|-----|--------|\n| [Text] | [URL] | âœ… 200 / âŒ 404 |\n\n### Specification Discrepancies\n\n[If any claims don't match the ECMAScript spec, detail them here]\n\n---\n\n## Phase 3: External Resource Verification\n\n| Resource | Type | Link | Content | Notes |\n|----------|------|------|---------|-------|\n| [Title] | Article/Video | âœ…/âŒ | âœ…/âš ï¸/âŒ | [Notes] |\n\n### Broken Links\n\n1. **Line XX:** [URL] - 404 Not Found\n2. **Line YY:** [URL] - Domain expired\n\n### Content Concerns\n\n1. **[Resource name]:** [Concern - e.g., outdated, wrong language, anti-patterns]\n\n### Description Accuracy\n\n| Resource | Description Accurate? | Notes |\n|----------|----------------------|-------|\n| [Title] | âœ…/âŒ | [Notes] |\n\n---\n\n## Phase 4: Technical Claims Audit\n\n| Claim | Location | Verdict | Notes |\n|-------|----------|---------|-------|\n| \"[Claim]\" | Line XX | âœ…/âš ï¸/âŒ | [Notes] |\n\n### Claims Needing Revision\n\n1. **Line XX:** \"[Current claim]\"\n   - **Issue:** [What's wrong]\n   - **Suggested:** \"[Revised claim]\"\n\n---\n\n## Phase 5: Test Results\n\n**Test File:** `/tests/[category]/[concept]/[concept].test.js`\n**Tests Run:** XX\n**Passing:** XX\n**Failing:** XX\n\n### Failing Tests\n\n| Test Name | Expected | Actual | Related Doc Line |\n|-----------|----------|--------|------------------|\n| [Test] | [Expected] | [Actual] | Line XX |\n\n### Coverage Gaps\n\nExamples in documentation without corresponding tests:\n- [ ] Line XX: [Description of untested example]\n- [ ] Line YY: [Description of untested example]\n\n---\n\n## Issues Summary\n\n### Critical (Must Fix Before Publishing)\n\n1. **[Issue title]**\n   - Location: Line XX\n   - Problem: [Description]\n   - Fix: [How to fix]\n\n### Major (Should Fix)\n\n1. **[Issue title]**\n   - Location: Line XX\n   - Problem: [Description]\n   - Fix: [How to fix]\n\n### Minor (Nice to Have)\n\n1. **[Issue title]**\n   - Location: Line XX\n   - Suggestion: [Improvement]\n\n---\n\n## Recommendations\n\n1. **[Priority 1]:** [Specific actionable recommendation]\n2. **[Priority 2]:** [Specific actionable recommendation]\n3. **[Priority 3]:** [Specific actionable recommendation]\n\n---\n\n## Verification Checklist\n\n- [ ] All code examples verified for correct output\n- [ ] All MDN links checked and valid\n- [ ] API descriptions match MDN documentation\n- [ ] ECMAScript compliance verified (if applicable)\n- [ ] All external resource links accessible\n- [ ] Resource descriptions accurately represent content\n- [ ] No common JavaScript misconceptions found\n- [ ] Technical claims are accurate and nuanced\n- [ ] Project tests run and reviewed\n- [ ] Report complete and ready for handoff\n\n---\n\n## Sign-off\n\n**Verified by:** [Name/Claude]\n**Date:** YYYY-MM-DD\n**Recommendation:** âœ… Ready to publish | âš ï¸ Fix issues first | âŒ Major revision needed\n```\n\n---\n\n## Quick Reference: Verification Commands\n\n```bash\n# Run all tests\nnpm test\n\n# Run specific concept tests\nnpm test -- tests/fundamentals/call-stack/\n\n# Check for broken links (if you have a link checker)\n# Install: npm install -g broken-link-checker\n# Run: blc https://developer.mozilla.org/... -ro\n\n# Quick JavaScript REPL for testing\nnode\n> typeof null\n'object'\n> [1,2,3].map(x => x * 2)\n[ 2, 4, 6 ]\n```\n\n---\n\n## Summary\n\nWhen fact-checking a concept page:\n\n1. **Run tests first** â€” `npm test` catches code errors automatically\n2. **Verify every code example** â€” Output comments must match reality\n3. **Check all MDN links** â€” Broken links and incorrect descriptions hurt credibility\n4. **Verify external resources** â€” Must be accessible, accurate, and JavaScript-focused\n5. **Audit technical claims** â€” Watch for misconceptions and unsupported statements\n6. **Document everything** â€” Use the report template for consistent, thorough reviews\n\n**Remember:** Our readers trust us to teach them correct JavaScript. A single piece of misinformation can create confusion that takes years to unlearn. Take fact-checking seriously.\n"
      },
      "discovered_at": "2026-01-11T15:35:56.454092Z",
      "fetch_error": null
    },
    {
      "name": "write-concept",
      "slug": "write-concept",
      "source": "skillsmp_top",
      "owner": "leonardomso",
      "repo_name": "33-js-concepts",
      "repository_url": "https://github.com/leonardomso/33-js-concepts",
      "skill_path": ".opencode/skill/write-concept",
      "github_metadata": {
        "stars": 66082,
        "description": "ğŸ“œ 33 JavaScript concepts every developer should know.",
        "default_branch": "master",
        "pushed_at": "2026-01-07T12:51:15Z",
        "created_at": "2018-09-04T13:27:04Z",
        "language": "JavaScript",
        "license": "MIT",
        "open_issues": 0,
        "forks": 9196
      },
      "skill_md": {
        "found": true,
        "path": ".opencode/skill/write-concept/SKILL.md",
        "branch": "master",
        "content": "---\nname: write-concept\ndescription: Write or review JavaScript concept documentation pages for the 33 JavaScript Concepts project, following strict structure and quality guidelines\n---\n\n# Skill: Write JavaScript Concept Documentation\n\nUse this skill when writing or improving concept documentation pages for the 33 JavaScript Concepts project.\n\n## When to Use\n\n- Creating a new concept page in `/docs/concepts/`\n- Rewriting or significantly improving an existing concept page\n- Reviewing an existing concept page for quality and completeness\n- Adding explanatory content to a concept\n\n## Target Audience\n\nRemember: **the reader might be someone who has never coded before or is just learning JavaScript**. Write with empathy for beginners while still providing depth for intermediate developers. Make complex topics feel approachable and never assume prior knowledge without linking to prerequisites.\n\n## Writing Guidelines\n\n### Voice and Tone\n\n- **Conversational but authoritative**: Write like you're explaining to a smart friend\n- **Encouraging**: Make complex topics feel approachable\n- **Practical**: Focus on real-world applications and use cases\n- **Concise**: Respect the reader's time; avoid unnecessary verbosity\n- **Question-driven**: Open sections with questions the reader might have\n\n### Avoiding AI-Generated Language\n\nYour writing must sound human, not AI-generated. Here are specific patterns to avoid:\n\n#### Words and Phrases to Avoid\n\n| âŒ Avoid | âœ“ Use Instead |\n|----------|---------------|\n| \"Master [concept]\" | \"Learn [concept]\" |\n| \"dramatically easier/better\" | \"much easier\" or \"cleaner\" |\n| \"one fundamental thing\" | \"one simple thing\" |\n| \"one of the most important concepts\" | \"This is a big one\" |\n| \"essential points\" | \"key things to remember\" |\n| \"understanding X deeply improves\" | \"knowing X well makes Y easier\" |\n| \"To truly understand\" | \"Let's look at\" or \"Here's how\" |\n| \"This is crucial\" | \"This trips people up\" |\n| \"It's worth noting that\" | Just state the thing directly |\n| \"It's important to remember\" | \"Don't forget:\" or \"Remember:\" |\n| \"In order to\" | \"To\" |\n| \"Due to the fact that\" | \"Because\" |\n| \"At the end of the day\" | Remove entirely |\n| \"When it comes to\" | Remove or rephrase |\n| \"In this section, we will\" | Just start explaining |\n| \"As mentioned earlier\" | Remove or link to the section |\n\n#### Repetitive Emphasis Patterns\n\nDon't use the same lead-in pattern repeatedly. Vary your emphasis:\n\n| Instead of repeating... | Vary with... |\n|------------------------|--------------|\n| \"Key insight:\" | \"Don't forget:\", \"The pattern:\", \"Here's the thing:\" |\n| \"Best practice:\" | \"Pro tip:\", \"Quick check:\", \"A good habit:\" |\n| \"Important:\" | \"Watch out:\", \"Heads up:\", \"Note:\" |\n| \"Remember:\" | \"Keep in mind:\", \"The rule:\", \"Think of it this way:\" |\n\n#### Em Dash (â€”) Overuse\n\nAI-generated text overuses em dashes. Limit their use and prefer periods, commas, or colons:\n\n| âŒ Em Dash Overuse | âœ“ Better Alternative |\n|-------------------|---------------------|\n| \"async/await â€” syntactic sugar that...\" | \"async/await. It's syntactic sugar that...\" |\n| \"understand Promises â€” async/await is built...\" | \"understand Promises. async/await is built...\" |\n| \"doesn't throw an error â€” you just get...\" | \"doesn't throw an error. You just get...\" |\n| \"outside of async functions â€” but only in...\" | \"outside of async functions, but only in...\" |\n| \"Fails fast â€” if any Promise rejects...\" | \"Fails fast. If any Promise rejects...\" |\n| \"achieve the same thing â€” the choice...\" | \"achieve the same thing. The choice...\" |\n\n**When em dashes ARE acceptable:**\n- In Key Takeaways section (consistent formatting for the numbered list)\n- In MDN card titles (e.g., \"async function â€” MDN\")\n- In interview answer step-by-step explanations (structured formatting)\n- Sparingly when a true parenthetical aside reads naturally\n\n**Rule of thumb:** If you have more than 10-15 em dashes in a 1500-word document outside of structured sections, you're overusing them. After writing, search for \"â€”\" and evaluate each one.\n\n#### Superlatives and Filler Words\n\nAvoid vague superlatives that add no information:\n\n| âŒ Avoid | âœ“ Use Instead |\n|----------|---------------|\n| \"dramatically\" | \"much\" or remove entirely |\n| \"fundamentally\" | \"simply\" or be specific about what's fundamental |\n| \"incredibly\" | remove or be specific |\n| \"extremely\" | remove or be specific |\n| \"absolutely\" | remove |\n| \"basically\" | remove (if you need it, you're not explaining clearly) |\n| \"essentially\" | remove or just explain directly |\n| \"very\" | remove or use a stronger word |\n| \"really\" | remove |\n| \"actually\" | remove (unless correcting a misconception) |\n| \"In fact\" | remove (just state the fact) |\n| \"Interestingly\" | remove (let the reader decide if it's interesting) |\n\n#### Stiff/Formal Phrases\n\nReplace formal academic-style phrases with conversational alternatives:\n\n| âŒ Stiff | âœ“ Conversational |\n|---------|------------------|\n| \"It should be noted that\" | \"Note that\" or just state it |\n| \"One might wonder\" | \"You might wonder\" |\n| \"This enables developers to\" | \"This lets you\" |\n| \"The aforementioned\" | \"this\" or name it again |\n| \"Subsequently\" | \"Then\" or \"Next\" |\n| \"Utilize\" | \"Use\" |\n| \"Commence\" | \"Start\" |\n| \"Prior to\" | \"Before\" |\n| \"In the event that\" | \"If\" |\n| \"A considerable amount of\" | \"A lot of\" or \"Many\" |\n\n#### Playful Touches (Use Sparingly)\n\nAdd occasional human touches to make the content feel less robotic, but don't overdo it:\n\n```javascript\n// âœ“ Good: One playful comment per section\n// Callback hell - nested so deep you need a flashlight\n\n// âœ“ Good: Conversational aside  \n// forEach and async don't play well together â€” it just fires and forgets:\n\n// âœ“ Good: Relatable frustration\n// Finally, error handling that doesn't make you want to flip a table.\n\n// âŒ Bad: Trying too hard\n// Callback hell - it's like a Russian nesting doll had a baby with a spaghetti monster! ğŸ\n\n// âŒ Bad: Forced humor\n// Let's dive into the AMAZING world of Promises! ğŸ‰ğŸš€\n```\n\n**Guidelines:**\n- One or two playful touches per major section is enough\n- Humor should arise naturally from the content\n- Avoid emojis in body text (they're fine in comments occasionally)\n- Don't explain your jokes\n- If a playful line doesn't work, just be direct instead\n\n### Page Structure (Follow This Exactly)\n\nEvery concept page MUST follow this structure in this exact order:\n\n```mdx\n---\ntitle: \"Concept Name: [Hook] in JavaScript\"\nsidebarTitle: \"Concept Name: [Hook]\"\ndescription: \"SEO-friendly description in 150-160 characters starting with action word\"\n---\n\n[Opening hook - Start with engaging questions that make the reader curious]\n[Example: \"How does JavaScript get data from a server? How do you load user profiles, submit forms, or fetch the latest posts from an API?\"]\n\n[Immediately show a simple code example demonstrating the concept]\n\n```javascript\n// This is how you [do the thing] in JavaScript\nconst example = doSomething()\nconsole.log(example)  // Expected output\n```\n\n[Brief explanation connecting to what they'll learn, with **[inline MDN links](https://developer.mozilla.org/...)** for key terms]\n\n<Info>\n**What you'll learn in this guide:**\n- Key learning outcome 1\n- Key learning outcome 2\n- Key learning outcome 3\n- Key learning outcome 4 (aim for 5-7 items)\n</Info>\n\n<Warning>\n[Optional: Prerequisites or important notices - place AFTER Info box]\n**Prerequisite:** This guide assumes you understand [Related Concept](/concepts/related-concept). If you're not comfortable with that yet, read that guide first!\n</Warning>\n\n---\n\n## [First Major Section - e.g., \"What is X?\"]\n\n[Core explanation with inline MDN links for any new terms/APIs introduced]\n\n[Optional: CardGroup with MDN reference links for this section]\n\n---\n\n## [Analogy Section - e.g., \"The Restaurant Analogy\"]\n\n[Relatable real-world analogy that makes the concept click]\n\n[ASCII art diagram visualizing the concept]\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                          DIAGRAM TITLE                                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                                          â”‚\nâ”‚    [Visual representation of the concept]                                â”‚\nâ”‚                                                                          â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n---\n\n## [Core Concepts Section]\n\n[Deep dive with code examples, tables, and Mintlify components]\n\n<Steps>\n  <Step title=\"Step 1\">\n    Explanation of the first step\n  </Step>\n  <Step title=\"Step 2\">\n    Explanation of the second step\n  </Step>\n</Steps>\n\n<AccordionGroup>\n  <Accordion title=\"Subtopic 1\">\n    Detailed explanation with code examples\n  </Accordion>\n  <Accordion title=\"Subtopic 2\">\n    Detailed explanation with code examples\n  </Accordion>\n</AccordionGroup>\n\n<Tip>\n**Quick Rule of Thumb:** [Memorable summary or mnemonic]\n</Tip>\n\n---\n\n## [The API/Implementation Section]\n\n[How to actually use the concept in code]\n\n### Basic Usage\n\n```javascript\n// Basic example with step-by-step comments\n// Step 1: Do this\nconst step1 = something()\n\n// Step 2: Then this\nconst step2 = somethingElse(step1)\n\n// Step 3: Finally\nconsole.log(step2)  // Expected output\n```\n\n### [Advanced Pattern]\n\n```javascript\n// More complex real-world example\n```\n\n---\n\n## [Common Mistakes Section - e.g., \"The #1 Fetch Mistake\"]\n\n[Highlight the most common mistake developers make]\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                         VISUAL COMPARISON                                â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                                          â”‚\nâ”‚  WRONG WAY                           RIGHT WAY                           â”‚\nâ”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€                           â”€â”€â”€â”€â”€â”€â”€â”€â”€                           â”‚\nâ”‚  â€¢ Problem 1                         â€¢ Solution 1                        â”‚\nâ”‚  â€¢ Problem 2                         â€¢ Solution 2                        â”‚\nâ”‚                                                                          â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n```javascript\n// âŒ WRONG - Explanation of why this is wrong\nconst bad = wrongApproach()\n\n// âœ“ CORRECT - Explanation of the right way\nconst good = correctApproach()\n```\n\n<Warning>\n**The Trap:** [Clear explanation of what goes wrong and why]\n</Warning>\n\n---\n\n## [Advanced Patterns Section]\n\n[Real-world patterns and best practices]\n\n### Pattern Name\n\n```javascript\n// Reusable pattern with practical application\nasync function realWorldExample() {\n  // Implementation\n}\n\n// Usage\nconst result = await realWorldExample()\n```\n\n---\n\n## Key Takeaways\n\n<Info>\n**The key things to remember:**\n\n1. **First key point** â€” Brief explanation\n\n2. **Second key point** â€” Brief explanation\n\n3. **Third key point** â€” Brief explanation\n\n4. **Fourth key point** â€” Brief explanation\n\n5. **Fifth key point** â€” Brief explanation\n\n[Aim for 8-10 key takeaways that summarize everything]\n</Info>\n\n---\n\n## Test Your Knowledge\n\n<AccordionGroup>\n  <Accordion title=\"Question 1: [Specific question about the concept]\">\n    **Answer:**\n    \n    [Clear explanation]\n    \n    ```javascript\n    // Code example demonstrating the answer\n    ```\n  </Accordion>\n  \n  <Accordion title=\"Question 2: [Another question]\">\n    **Answer:**\n    \n    [Clear explanation with code if needed]\n  </Accordion>\n  \n  [Aim for 5-6 questions covering the main topics]\n</AccordionGroup>\n\n---\n\n## Related Concepts\n\n<CardGroup cols={2}>\n  <Card title=\"Related Concept 1\" icon=\"icon-name\" href=\"/concepts/slug\">\n    How it connects to this concept\n  </Card>\n  <Card title=\"Related Concept 2\" icon=\"icon-name\" href=\"/concepts/slug\">\n    How it connects to this concept\n  </Card>\n</CardGroup>\n\n---\n\n## Reference\n\n<CardGroup cols={2}>\n  <Card title=\"Main Topic â€” MDN\" icon=\"book\" href=\"https://developer.mozilla.org/...\">\n    Official MDN documentation for the main concept\n  </Card>\n  <Card title=\"Related API â€” MDN\" icon=\"book\" href=\"https://developer.mozilla.org/...\">\n    Additional MDN reference\n  </Card>\n</CardGroup>\n\n## Articles\n\n<CardGroup cols={2}>\n  <Card title=\"Article Title\" icon=\"newspaper\" href=\"https://...\">\n    Brief description of what the reader will learn from this article.\n  </Card>\n  [Aim for 4-6 high-quality articles]\n</CardGroup>\n\n## Videos\n\n<CardGroup cols={2}>\n  <Card title=\"Video Title\" icon=\"video\" href=\"https://...\">\n    Brief description of what the video covers.\n  </Card>\n  [Aim for 3-4 quality videos]\n</CardGroup>\n```\n\n---\n\n## SEO Guidelines\n\nSEO (Search Engine Optimization) is **critical** for this project. Each concept page should rank for the various ways developers search for that concept. Our goal is to appear in search results for queries like:\n\n- \"what is [concept] in JavaScript\"\n- \"how does [concept] work in JavaScript\"  \n- \"[concept] JavaScript explained\"\n- \"[concept] JavaScript tutorial\"\n- \"JavaScript [concept] example\"\n\nEvery writing decision â€” from title to structure to word choice â€” should consider search intent.\n\n---\n\n### Target Keywords for Each Concept\n\nEach concept page targets a **keyword cluster** â€” the family of related search queries. Before writing, identify these for your concept:\n\n| Keyword Type | Pattern | Example (DOM) |\n|--------------|---------|---------------|\n| **Primary** | [concept] + JavaScript | \"DOM JavaScript\", \"JavaScript DOM\" |\n| **What is** | what is [concept] in JavaScript | \"what is the DOM in JavaScript\" |\n| **How does** | how does [concept] work | \"how does the DOM work in JavaScript\" |\n| **How to** | how to [action] with [concept] | \"how to manipulate the DOM\" |\n| **Tutorial** | [concept] tutorial/guide/explained | \"DOM tutorial JavaScript\" |\n| **Comparison** | [concept] vs [related] | \"DOM vs virtual DOM\" |\n\n**More Keyword Cluster Examples:**\n\n<AccordionGroup>\n  <Accordion title=\"Closures Keyword Cluster\">\n    | Type | Keywords |\n    |------|----------|\n    | Primary | \"JavaScript closures\", \"closures in JavaScript\" |\n    | What is | \"what is a closure in JavaScript\", \"what are closures\" |\n    | How does | \"how do closures work in JavaScript\", \"how closures work\" |\n    | Why use | \"why use closures JavaScript\", \"closure use cases\" |\n    | Example | \"JavaScript closure example\", \"closure examples\" |\n    | Interview | \"closure interview questions JavaScript\" |\n  </Accordion>\n  \n  <Accordion title=\"Promises Keyword Cluster\">\n    | Type | Keywords |\n    |------|----------|\n    | Primary | \"JavaScript Promises\", \"Promises in JavaScript\" |\n    | What is | \"what is a Promise in JavaScript\", \"what are Promises\" |\n    | How does | \"how do Promises work\", \"how Promises work JavaScript\" |\n    | How to | \"how to use Promises\", \"how to chain Promises\" |\n    | Comparison | \"Promises vs callbacks\", \"Promises vs async await\" |\n    | Error | \"Promise error handling\", \"Promise catch\" |\n  </Accordion>\n  \n  <Accordion title=\"Event Loop Keyword Cluster\">\n    | Type | Keywords |\n    |------|----------|\n    | Primary | \"JavaScript event loop\", \"event loop JavaScript\" |\n    | What is | \"what is the event loop in JavaScript\" |\n    | How does | \"how does the event loop work\", \"how event loop works\" |\n    | Visual | \"event loop explained\", \"event loop visualization\" |\n    | Related | \"call stack and event loop\", \"task queue JavaScript\" |\n  </Accordion>\n  \n  <Accordion title=\"Call Stack Keyword Cluster\">\n    | Type | Keywords |\n    |------|----------|\n    | Primary | \"JavaScript call stack\", \"call stack JavaScript\" |\n    | What is | \"what is the call stack in JavaScript\" |\n    | How does | \"how does the call stack work\" |\n    | Error | \"call stack overflow JavaScript\", \"maximum call stack size exceeded\" |\n    | Visual | \"call stack explained\", \"call stack visualization\" |\n  </Accordion>\n</AccordionGroup>\n\n---\n\n### Title Tag Optimization\n\nThe frontmatter has **two title fields**:\n- `title` â€” The page's `<title>` tag (SEO, appears in search results)\n- `sidebarTitle` â€” The sidebar navigation text (cleaner, no \"JavaScript\" since we're on a JS site)\n\n**The Two-Title Pattern:**\n\n```mdx\n---\ntitle: \"Closures: How Functions Remember Their Scope in JavaScript\"\nsidebarTitle: \"Closures: How Functions Remember Their Scope\"\n---\n```\n\n- **`title`** ends with \"in JavaScript\" for SEO keyword placement\n- **`sidebarTitle`** omits \"JavaScript\" for cleaner navigation\n\n**Rules:**\n1. **50-60 characters** ideal length for `title` (Google truncates longer titles)\n2. **Concept name first** â€” lead with the topic, \"JavaScript\" comes at the end\n3. **Add a hook** â€” what will the reader understand or be able to do?\n4. **Be specific** â€” generic titles don't rank\n\n**Title Formulas That Work:**\n\n```\ntitle: \"[Concept]: [What You'll Understand] in JavaScript\"\nsidebarTitle: \"[Concept]: [What You'll Understand]\"\n\ntitle: \"[Concept]: [Benefit or Outcome] in JavaScript\"\nsidebarTitle: \"[Concept]: [Benefit or Outcome]\"\n```\n\n**Title Examples:**\n\n| âŒ Bad | âœ“ title (SEO) | âœ“ sidebarTitle (Navigation) |\n|--------|---------------|----------------------------|\n| `\"Closures\"` | `\"Closures: How Functions Remember Their Scope in JavaScript\"` | `\"Closures: How Functions Remember Their Scope\"` |\n| `\"DOM\"` | `\"DOM: How Browsers Represent Web Pages in JavaScript\"` | `\"DOM: How Browsers Represent Web Pages\"` |\n| `\"Promises\"` | `\"Promises: Handling Async Operations in JavaScript\"` | `\"Promises: Handling Async Operations\"` |\n| `\"Call Stack\"` | `\"Call Stack: How Function Execution Works in JavaScript\"` | `\"Call Stack: How Function Execution Works\"` |\n| `\"Event Loop\"` | `\"Event Loop: How Async Code Actually Runs in JavaScript\"` | `\"Event Loop: How Async Code Actually Runs\"` |\n| `\"Scope\"` | `\"Scope and Closures: Variable Visibility in JavaScript\"` | `\"Scope and Closures: Variable Visibility\"` |\n| `\"this\"` | `\"this: How Context Binding Works in JavaScript\"` | `\"this: How Context Binding Works\"` |\n| `\"Prototype\"` | `\"Prototype Chain: Understanding Inheritance in JavaScript\"` | `\"Prototype Chain: Understanding Inheritance\"` |\n\n**Character Count Check:**\nBefore finalizing, verify your `title` length:\n- Under 50 chars: Consider adding more descriptive context\n- 50-60 chars: Perfect length\n- Over 60 chars: Will be truncated in search results â€” shorten it\n\n---\n\n### Meta Description Optimization\n\nThe `description` field becomes the meta description â€” **the snippet users see in search results**. A compelling description increases click-through rate.\n\n**Rules:**\n1. **150-160 characters** maximum (Google truncates longer descriptions)\n2. **Include primary keyword** in the first half\n3. **Include secondary keywords** naturally if space allows\n4. **Start with an action word** â€” \"Learn\", \"Understand\", \"Discover\" (avoid \"Master\" â€” sounds AI-generated)\n5. **Promise specific value** â€” what will they learn?\n6. **End with a hook** â€” give them a reason to click\n\n**Description Formula:**\n\n```\n[Action word] [what the concept is] in JavaScript. [Specific things they'll learn]: [topic 1], [topic 2], and [topic 3].\n```\n\n**Description Examples:**\n\n| Concept | âŒ Too Short (Low CTR) | âœ“ SEO-Optimized (150-160 chars) |\n|---------|----------------------|--------------------------------|\n| DOM | `\"Understanding the DOM\"` | `\"Learn how the DOM works in JavaScript. Understand how browsers represent HTML as a tree, select and manipulate elements, traverse nodes, and optimize rendering.\"` |\n| Closures | `\"Functions that remember\"` | `\"Learn JavaScript closures and how functions remember their scope. Covers lexical scoping, practical use cases, memory considerations, and common closure patterns.\"` |\n| Promises | `\"Async JavaScript\"` | `\"Understand JavaScript Promises for handling asynchronous operations. Learn to create, chain, and combine Promises, handle errors properly, and write cleaner async code.\"` |\n| Event Loop | `\"How async works\"` | `\"Discover how the JavaScript event loop manages async code execution. Understand the call stack, task queue, microtasks, and why JavaScript is single-threaded but non-blocking.\"` |\n| Call Stack | `\"Function execution\"` | `\"Learn how the JavaScript call stack tracks function execution. Understand stack frames, execution context, stack overflow errors, and how recursion affects the stack.\"` |\n| this | `\"Understanding this\"` | `\"Learn the 'this' keyword in JavaScript and how context binding works. Covers the four binding rules, arrow function behavior, and how to use call, apply, and bind.\"` |\n\n**Character Count Check:**\n- Under 120 chars: You're leaving value on the table â€” add more specifics\n- 150-160 chars: Optimal length\n- Over 160 chars: Will be truncated â€” edit ruthlessly\n\n---\n\n### Keyword Placement Strategy\n\nKeywords must appear in strategic locations â€” but **always naturally**. Keyword stuffing hurts rankings.\n\n**Priority Placement Locations:**\n\n| Priority | Location | How to Include |\n|----------|----------|----------------|\n| ğŸ”´ Critical | Title | Primary keyword in first half |\n| ğŸ”´ Critical | Meta description | Primary keyword + 1-2 secondary |\n| ğŸ”´ Critical | First paragraph | Natural mention within first 100 words |\n| ğŸŸ  High | H2 headings | Question-format headings with keywords |\n| ğŸŸ  High | \"What you'll learn\" box | Topic-related phrases |\n| ğŸŸ¡ Medium | H3 subheadings | Related keywords and concepts |\n| ğŸŸ¡ Medium | Key Takeaways | Reinforce main keywords naturally |\n| ğŸŸ¢ Good | Alt text | If using images, include keywords |\n\n**Example: Keyword Placement for DOM Page**\n\n```mdx\n---\ntitle: \"DOM: How Browsers Represent Web Pages in JavaScript\"      â† ğŸ”´ Primary: \"in JavaScript\" at end\nsidebarTitle: \"DOM: How Browsers Represent Web Pages\"             â† Sidebar: no \"JavaScript\"\ndescription: \"Learn how the DOM works in JavaScript. Understand   â† ğŸ”´ Primary: \"DOM works in JavaScript\"\nhow browsers represent HTML as a tree, select and manipulate      â† ğŸ”´ Secondary: \"manipulate elements\"\nelements, traverse nodes, and optimize rendering.\"\n---\n\nHow does JavaScript change what you see on a webpage?             â† Hook question\nThe **Document Object Model (DOM)** is a programming interface    â† ğŸ”´ Primary keyword in first paragraph\nfor web documents. It represents your HTML as a **tree of \nobjects** that JavaScript can read and manipulate.\n\n<Info>\n**What you'll learn in this guide:**                              â† ğŸŸ  Topic reinforcement\n- What the DOM actually is\n- How to select elements (getElementById vs querySelector)        â† Secondary keywords\n- How to traverse the DOM tree\n- How to create, modify, and remove elements                      â† \"DOM\" implicit\n- How browsers render the DOM (Critical Rendering Path)\n</Info>\n\n## What is the DOM in JavaScript?                                 â† ğŸŸ  H2 with question keyword\n\nThe DOM (Document Object Model) is...                             â† Natural repetition\n\n## How the DOM Works                                              â† ğŸŸ  H2 with \"how\" keyword\n\n## DOM Manipulation Methods                                       â† ğŸŸ¡ H3 with related keyword\n\n## Key Takeaways                                                  â† ğŸŸ¡ Reinforce in summary\n```\n\n**Warning Signs of Keyword Stuffing:**\n- Same exact phrase appears more than 3-4 times per 1000 words\n- Sentences read awkwardly because keywords were forced in\n- Using keywords where pronouns (\"it\", \"they\", \"this\") would be natural\n\n---\n\n### Answering Search Intent\n\nGoogle ranks pages that **directly answer the user's query**. Structure your content to satisfy search intent immediately.\n\n**The First Paragraph Rule:**\n\nThe first paragraph after any H2 should directly answer the implied question. Don't build up to the answer â€” lead with it.\n\n```mdx\n<!-- âŒ BAD: Builds up to the answer -->\n## What is the Event Loop?\n\nBefore we can understand the event loop, we need to talk about JavaScript's \nsingle-threaded nature. You see, JavaScript can only do one thing at a time, \nand this creates some interesting challenges. The way JavaScript handles \nthis is through something called... the event loop.\n\n<!-- âœ“ GOOD: Answers immediately -->\n## What is the Event Loop?\n\nThe **event loop** is JavaScript's mechanism for executing code, handling events, \nand managing asynchronous operations. It continuously monitors the call stack \nand task queue, moving queued callbacks to the stack when it's empty â€” this is \nhow JavaScript handles async code despite being single-threaded.\n```\n\n**Question-Format H2 Headings:**\n\nUse H2s that match how people search:\n\n| Search Query | H2 to Use |\n|--------------|-----------|\n| \"what is the DOM\" | `## What is the DOM?` |\n| \"how closures work\" | `## How Do Closures Work?` |\n| \"why use promises\" | `## Why Use Promises?` |\n| \"when to use async await\" | `## When Should You Use async/await?` |\n\n---\n\n### Featured Snippet Optimization\n\nFeatured snippets appear at **position zero** â€” above all organic results. Structure your content to win them.\n\n**Snippet Types and How to Win Them:**\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                      FEATURED SNIPPET TYPES                              â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                                          â”‚\nâ”‚  QUERY TYPE           SNIPPET FORMAT        YOUR CONTENT STRUCTURE       â”‚\nâ”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚\nâ”‚                                                                          â”‚\nâ”‚  \"What is X\"          Paragraph             40-60 word definition        â”‚\nâ”‚                                             immediately after H2         â”‚\nâ”‚                                                                          â”‚\nâ”‚  \"How to X\"           Numbered list         <Steps> component or         â”‚\nâ”‚                                             numbered Markdown list       â”‚\nâ”‚                                                                          â”‚\nâ”‚  \"X vs Y\"             Table                 Comparison table with        â”‚\nâ”‚                                             clear column headers         â”‚\nâ”‚                                                                          â”‚\nâ”‚  \"Types of X\"         Bulleted list         Bullet list under            â”‚\nâ”‚                                             descriptive H2               â”‚\nâ”‚                                                                          â”‚\nâ”‚  \"[X] examples\"       Bulleted list or      Code examples with           â”‚\nâ”‚                       code block            brief explanations           â”‚\nâ”‚                                                                          â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n**Pattern 1: Definition Snippet (40-60 words)**\n\nFor \"what is [concept]\" queries:\n\n```mdx\n## What is a Closure in JavaScript?\n\nA **closure** is a function that retains access to variables from its outer \n(enclosing) scope, even after that outer function has finished executing. \nClosures are created every time a function is created in JavaScript, allowing \ninner functions to \"remember\" and access their lexical environment.\n```\n\n**Why this wins:**\n- H2 matches search query exactly\n- Bold keyword in first sentence\n- 40-60 word complete definition\n- Explains the \"why\" not just the \"what\"\n\n**Pattern 2: List Snippet (Steps)**\n\nFor \"how to [action]\" queries:\n\n```mdx\n## How to Make a Fetch Request in JavaScript\n\n<Steps>\n  <Step title=\"1. Call fetch() with the URL\">\n    The `fetch()` function takes a URL and returns a Promise that resolves to a Response object.\n  </Step>\n  \n  <Step title=\"2. Check if the response was successful\">\n    Always verify `response.ok` before processing â€” fetch doesn't throw on HTTP errors.\n  </Step>\n  \n  <Step title=\"3. Parse the response body\">\n    Use `response.json()` for JSON data, `response.text()` for plain text.\n  </Step>\n  \n  <Step title=\"4. Handle errors properly\">\n    Wrap everything in try/catch to handle both network and HTTP errors.\n  </Step>\n</Steps>\n```\n\n**Pattern 3: Table Snippet (Comparison)**\n\nFor \"[X] vs [Y]\" queries:\n\n```mdx\n## == vs === in JavaScript\n\n| Aspect | `==` (Loose Equality) | `===` (Strict Equality) |\n|--------|----------------------|------------------------|\n| Type coercion | Yes â€” converts types before comparing | No â€” types must match |\n| Speed | Slower (coercion overhead) | Faster (no coercion) |\n| Predictability | Can produce surprising results | Always predictable |\n| Recommendation | Avoid in most cases | Use by default |\n\n```javascript\n// Examples\n5 == \"5\"    // true (string coerced to number)\n5 === \"5\"   // false (different types)\n```\n```\n\n**Pattern 4: List Snippet (Types/Categories)**\n\nFor \"types of [concept]\" queries:\n\n```mdx\n## Types of Scope in JavaScript\n\nJavaScript has three types of scope that determine where variables are accessible:\n\n- **Global Scope** â€” Variables declared outside any function or block; accessible everywhere\n- **Function Scope** â€” Variables declared inside a function with `var`; accessible only within that function\n- **Block Scope** â€” Variables declared with `let` or `const` inside `{}`; accessible only within that block\n```\n\n---\n\n### Content Structure for SEO\n\nHow you structure content affects both rankings and user experience.\n\n**The Inverted Pyramid:**\n\nPut the most important information first. Search engines and users both prefer content that answers questions immediately.\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                        THE INVERTED PYRAMID                              â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                                          â”‚\nâ”‚                                                                          â”‚\nâ”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚\nâ”‚            â”‚       ANSWER THE QUESTION           â”‚  â† First 100 words   â”‚\nâ”‚            â”‚       Definition + Core Concept     â”‚    (most important)  â”‚\nâ”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚\nâ”‚                               â”‚                                          â”‚\nâ”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚\nâ”‚              â”‚       EXPLAIN HOW IT WORKS       â”‚  â† Next 300 words     â”‚\nâ”‚              â”‚       Mechanism + Visual Diagram â”‚    (supporting info)  â”‚\nâ”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚\nâ”‚                               â”‚                                          â”‚\nâ”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚\nâ”‚            â”‚         SHOW PRACTICAL EXAMPLES      â”‚  â† Code examples    â”‚\nâ”‚            â”‚         Code + Step-by-step          â”‚    (proof it works) â”‚\nâ”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚\nâ”‚                               â”‚                                          â”‚\nâ”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚\nâ”‚        â”‚            COVER EDGE CASES                  â”‚  â† Advanced      â”‚\nâ”‚        â”‚            Common mistakes, gotchas          â”‚    (depth)       â”‚\nâ”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚\nâ”‚                               â”‚                                          â”‚\nâ”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚\nâ”‚    â”‚               ADDITIONAL RESOURCES                   â”‚  â† External  â”‚\nâ”‚    â”‚               Related concepts, articles, videos     â”‚    (links)   â”‚\nâ”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚\nâ”‚                                                                          â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n**Scannable Content Patterns:**\n\nGoogle favors content that's easy to scan. Use these elements:\n\n| Element | SEO Benefit | When to Use |\n|---------|-------------|-------------|\n| Short paragraphs | Reduces bounce rate | Always (2-4 sentences max) |\n| Bullet lists | Often become featured snippets | Lists of 3+ items |\n| Numbered lists | \"How to\" snippet potential | Sequential steps |\n| Tables | High snippet potential | Comparisons, reference data |\n| Bold text | Highlights keywords for crawlers | First mention of key terms |\n| Headings (H2/H3) | Structure signals to Google | Every major topic shift |\n\n**Content Length Guidelines:**\n\n| Length | Assessment | Action |\n|--------|------------|--------|\n| Under 1,000 words | Too thin | Add more depth, examples, edge cases |\n| 1,000-1,500 words | Minimum viable | Acceptable for simple concepts |\n| 1,500-2,500 words | Good | Standard for most concept pages |\n| 2,500-4,000 words | Excellent | Ideal for comprehensive guides |\n| Over 4,000 words | Evaluate | Consider splitting into multiple pages |\n\n**Note:** Length alone doesn't guarantee rankings. Every section must add value â€” don't pad content.\n\n---\n\n### Internal Linking for SEO\n\nInternal links help search engines understand your site structure and distribute page authority.\n\n**Topic Cluster Strategy:**\n\nThink of concept pages as an interconnected network. Every concept should link to 3-5 related concepts:\n\n```\n                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”‚    Promises     â”‚â”€â”€â”€â”€â”€â”€â”€â”\n                      â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚\n                      â”‚                â”‚                â”‚\n                      â–¼                â–¼                â–¼\n              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n              â”‚async/awaitâ”‚â—„â”€â”€â–ºâ”‚  Event Loop   â”‚â—„â”€â”€â–ºâ”‚  Callbacks  â”‚\n              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                      â”‚                â”‚                â”‚\n                      â”‚                â–¼                â”‚\n                      â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚\n                      â””â”€â”€â”€â”€â”€â”€â–ºâ”‚  Call Stack   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”˜\n                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n**Link Placement Guidelines:**\n\n1. **In Prerequisites (Warning box):**\n```mdx\n<Warning>\n**Prerequisite:** This guide assumes you understand [Promises](/concepts/promises) and the [Event Loop](/concepts/event-loop). Read those first if you're not comfortable with asynchronous JavaScript.\n</Warning>\n```\n\n2. **In Body Content (natural context):**\n```mdx\nWhen the callback finishes, it's added to the task queue â€” which is managed by the [event loop](/concepts/event-loop).\n```\n\n3. **In Related Concepts Section:**\n```mdx\n<CardGroup cols={2}>\n  <Card title=\"Promises\" icon=\"handshake\" href=\"/concepts/promises\">\n    async/await is built on top of Promises\n  </Card>\n  <Card title=\"Event Loop\" icon=\"arrows-spin\" href=\"/concepts/event-loop\">\n    How JavaScript manages async operations\n  </Card>\n</CardGroup>\n```\n\n**Anchor Text Best Practices:**\n\n| âŒ Bad Anchor Text | âœ“ Good Anchor Text | Why |\n|-------------------|-------------------|-----|\n| \"click here\" | \"event loop guide\" | Descriptive, includes keyword |\n| \"this article\" | \"our Promises concept\" | Tells Google what page is about |\n| \"here\" | \"JavaScript closures\" | Keywords in anchor text |\n| \"read more\" | \"understanding the call stack\" | Natural, informative |\n\n---\n\n### URL and Slug Best Practices\n\nURLs (slugs) are a minor but meaningful ranking factor.\n\n**Rules:**\n1. **Use lowercase** â€” `closures` not `Closures`\n2. **Use hyphens** â€” `call-stack` not `call_stack` or `callstack`\n3. **Keep it short** â€” aim for 3-5 words maximum\n4. **Include primary keyword** â€” the concept name\n5. **Avoid stop words** â€” skip \"the\", \"and\", \"in\", \"of\" unless necessary\n\n**Slug Examples:**\n\n| Concept | âŒ Avoid | âœ“ Use |\n|---------|---------|-------|\n| The Event Loop | `the-event-loop` | `event-loop` |\n| this, call, apply and bind | `this-call-apply-and-bind` | `this-call-apply-bind` |\n| Scope and Closures | `scope-and-closures` | `scope-and-closures` (acceptable) or `scope-closures` |\n| DOM and Layout Trees | `dom-and-layout-trees` | `dom` or `dom-layout-trees` |\n\n**Note:** For this project, slugs are already set. When creating new pages, follow these conventions.\n\n---\n\n### Opening Paragraph: The SEO Power Move\n\nThe opening paragraph is prime SEO real estate. It should:\n1. Hook the reader with a question they're asking\n2. Include the primary keyword naturally\n3. Provide a brief definition or answer\n4. Set up what they'll learn\n\n**Template:**\n\n```mdx\n[Question hook that matches search intent?] [Maybe another question?]\n\nThe **[Primary Keyword]** is [brief definition that answers \"what is X\"]. \n[One sentence explaining why it matters or what it enables].\n\n```javascript\n// Immediately show a simple example\n```\n\n[Brief transition to \"What you'll learn\" box]\n```\n\n**Example (Closures):**\n\n```mdx\nWhy do some functions seem to \"remember\" variables that should have disappeared? \nHow can a callback still access variables from a function that finished running \nlong ago?\n\nThe answer is **closures** â€” one of JavaScript's most powerful (and often \nmisunderstood) features. A closure is a function that retains access to its \nouter scope's variables, even after that outer scope has finished executing.\n\n```javascript\nfunction createCounter() {\n  let count = 0  // This variable is \"enclosed\" by the returned function\n  return function() {\n    count++\n    return count\n  }\n}\n\nconst counter = createCounter()\nconsole.log(counter())  // 1\nconsole.log(counter())  // 2 â€” it remembers!\n```\n\nUnderstanding closures unlocks patterns like private variables, factory functions, \nand the module pattern that power modern JavaScript.\n```\n\n**Why this works for SEO:**\n- Question hooks match how people search (\"why do functions remember\")\n- Bold keyword in first paragraph\n- Direct definition answers \"what is a closure\"\n- Code example demonstrates immediately\n- Natural setup for learning objectives\n\n---\n\n## Inline Linking Rules (Critical!)\n\n### Always Link to MDN\n\nWhenever you introduce a new Web API, method, object, or JavaScript concept, **link to MDN immediately**. This gives readers a path to deeper learning.\n\n```mdx\n<!-- âœ“ CORRECT: Link on first mention -->\nThe **[Fetch API](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)** is JavaScript's modern way to make network requests.\n\nThe **[Response](https://developer.mozilla.org/en-US/docs/Web/API/Response)** object contains everything about the server's reply.\n\nMost modern APIs return data in **[JSON](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON)** format.\n\n<!-- âŒ WRONG: No links -->\nThe Fetch API is JavaScript's modern way to make network requests.\n```\n\n### Link to Related Concept Pages\n\nWhen mentioning concepts covered in other pages, link to them:\n\n```mdx\n<!-- âœ“ CORRECT: Internal links to related concepts -->\nIf you're not familiar with it, check out our [async/await concept](/concepts/async-await) first.\n\nThis guide assumes you understand [Promises](/concepts/promises).\n\n<!-- âŒ WRONG: No internal links -->\nIf you're not familiar with async/await, you should learn that first.\n```\n\n### Common MDN Link Patterns\n\n| Concept | MDN URL Pattern |\n|---------|-----------------|\n| Web APIs | `https://developer.mozilla.org/en-US/docs/Web/API/{APIName}` |\n| JavaScript Objects | `https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/{Object}` |\n| HTTP | `https://developer.mozilla.org/en-US/docs/Web/HTTP` |\n| HTTP Methods | `https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods/{METHOD}` |\n| HTTP Headers | `https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers` |\n\n---\n\n## Code Examples Best Practices\n\n### 1. Start with the Simplest Possible Example\n\n```javascript\n// âœ“ GOOD: Start with the absolute basics\n// This is how you fetch data in JavaScript\nconst response = await fetch('https://api.example.com/users/1')\nconst user = await response.json()\nconsole.log(user.name)  // \"Alice\"\n```\n\n### 2. Use Step-by-Step Comments\n\n```javascript\n// Step 1: fetch() returns a Promise that resolves to a Response object\nconst responsePromise = fetch('https://api.example.com/users')\n\n// Step 2: When the response arrives, we get a Response object\nresponsePromise.then(response => {\n  console.log(response.status)      // 200\n  \n  // Step 3: The body is a stream, we need to parse it\n  return response.json()\n})\n.then(data => {\n  // Step 4: Now we have the actual data\n  console.log(data)\n})\n```\n\n### 3. Show Output in Comments\n\n```javascript\nconst greeting = \"Hello\"\nconsole.log(typeof greeting)  // \"string\"\n\nconst numbers = [1, 2, 3]\nconsole.log(numbers.length)   // 3\n```\n\n### 4. Use âŒ and âœ“ for Wrong/Correct Patterns\n\n```javascript\n// âŒ WRONG - This misses HTTP errors!\ntry {\n  const response = await fetch('/api/users/999')\n  const data = await response.json()\n} catch (error) {\n  // Only catches NETWORK errors, not 404s!\n}\n\n// âœ“ CORRECT - Check response.ok\ntry {\n  const response = await fetch('/api/users/999')\n  \n  if (!response.ok) {\n    throw new Error(`HTTP error! Status: ${response.status}`)\n  }\n  \n  const data = await response.json()\n} catch (error) {\n  // Now catches both network AND HTTP errors\n}\n```\n\n### 5. Use Meaningful Variable Names\n\n```javascript\n// âŒ BAD\nconst x = [1, 2, 3]\nconst y = x.map(z => z * 2)\n\n// âœ“ GOOD\nconst numbers = [1, 2, 3]\nconst doubled = numbers.map(num => num * 2)\n```\n\n### 6. Progress from Simple to Complex\n\n```javascript\n// Level 1: Basic usage\nfetch('/api/users')\n\n// Level 2: With options\nfetch('/api/users', {\n  method: 'POST',\n  body: JSON.stringify({ name: 'Alice' })\n})\n\n// Level 3: Full real-world pattern\nasync function createUser(userData) {\n  const response = await fetch('/api/users', {\n    method: 'POST',\n    headers: { 'Content-Type': 'application/json' },\n    body: JSON.stringify(userData)\n  })\n  \n  if (!response.ok) {\n    throw new Error(`Failed to create user: ${response.status}`)\n  }\n  \n  return response.json()\n}\n```\n\n---\n\n## Resource Curation Guidelines\n\nExternal resources (articles, videos) are valuable, but must meet quality standards.\n\n### Quality Standards\n\nOnly include resources that are:\n\n1. **JavaScript-focused** â€” No resources primarily about other languages (C#, Python, Java, etc.), even if the concepts are similar\n2. **Still accessible** â€” Verify all links work before publishing\n3. **High quality** â€” From reputable sources (MDN, javascript.info, freeCodeCamp, well-known educators)\n4. **Up to date** â€” Avoid outdated resources; check publication dates for time-sensitive topics\n5. **Accurate** â€” Skim the content to verify it doesn't teach anti-patterns\n\n### Writing Resource Descriptions\n\nEach resource needs a **specific, engaging 2-sentence description** explaining what makes it unique. Generic descriptions waste the reader's time.\n\n```mdx\n<!-- âŒ Generic (bad) -->\n<Card title=\"JavaScript Promises Tutorial\" icon=\"newspaper\" href=\"...\">\n  Learn about Promises in JavaScript.\n</Card>\n\n<!-- âŒ Generic (bad) -->\n<Card title=\"Async/Await Explained\" icon=\"newspaper\" href=\"...\">\n  A comprehensive guide to async/await.\n</Card>\n\n<!-- âœ“ Specific (good) -->\n<Card title=\"JavaScript Async/Await Tutorial\" icon=\"newspaper\" href=\"https://javascript.info/async-await\">\n  The go-to reference for async/await fundamentals. Includes exercises at the end to test your understanding of rewriting promise chains.\n</Card>\n\n<!-- âœ“ Specific (good) -->\n<Card title=\"JavaScript Visualized: Promises & Async/Await\" icon=\"newspaper\" href=\"...\">\n  Animated GIFs showing the call stack, microtask queue, and event loop in action. This is how async/await finally \"clicked\" for thousands of developers.\n</Card>\n\n<!-- âœ“ Specific (good) -->\n<Card title=\"How to Escape Async/Await Hell\" icon=\"newspaper\" href=\"...\">\n  The pizza-and-drinks ordering example makes parallel vs sequential execution crystal clear. Essential reading once you know the basics.\n</Card>\n```\n\n**Description Formula:**\n1. **Sentence 1:** What makes this resource unique OR what it specifically covers\n2. **Sentence 2:** Why a reader should click (what they'll gain, who it's best for, what stands out)\n\n**Avoid in descriptions:**\n- \"Comprehensive guide to...\" (vague)\n- \"Great tutorial on...\" (vague)  \n- \"Learn all about...\" (vague)\n- \"Everything you need to know about...\" (clichÃ©)\n\n### Recommended Sources\n\n**Articles (Prioritize):**\n\n| Source | Why |\n|--------|-----|\n| javascript.info | Comprehensive, well-maintained, exercises included |\n| MDN Web Docs | Official reference, always accurate |\n| freeCodeCamp | Beginner-friendly, practical tutorials |\n| dev.to (Lydia Hallie, etc.) | Visual explanations, community favorites |\n| CSS-Tricks | DOM, browser APIs, visual topics |\n\n**Videos (Prioritize):**\n\n| Creator | Style |\n|---------|-------|\n| Web Dev Simplified | Clear, beginner-friendly, concise |\n| Fireship | Fast-paced, modern, entertaining |\n| Traversy Media | Comprehensive crash courses |\n| Fun Fun Function | Deep-dives with personality |\n| Wes Bos | Practical, real-world focused |\n\n**Avoid:**\n- Resources in other programming languages (C#, Python, Java) even if concepts overlap\n- Outdated tutorials (pre-ES6 syntax for modern concepts)\n- Paywalled content (unless there's a free tier)\n- Low-quality Medium articles (check engagement and accuracy)\n- Resources that teach anti-patterns\n- Videos over 2 hours (link to specific timestamps if valuable)\n\n### Verifying Resources\n\nBefore including any resource:\n\n1. **Click the link** â€” Verify it loads and isn't behind a paywall\n2. **Skim the content** â€” Ensure it's accurate and well-written\n3. **Check the date** â€” For time-sensitive topics, prefer recent content\n4. **Read comments/reactions** â€” Community feedback reveals quality issues\n5. **Test code examples** â€” If they include code, verify it works\n\n---\n\n## ASCII Art Diagrams\n\nUse ASCII art to visualize concepts. Make them boxed and labeled:\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                        THE REQUEST-RESPONSE CYCLE                        â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                                          â”‚\nâ”‚    YOU (Browser)                              KITCHEN (Server)           â”‚\nâ”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚\nâ”‚    â”‚          â”‚  â”€â”€â”€â”€ \"I'd like pasta\" â”€â”€â”€â”€â–º  â”‚              â”‚           â”‚\nâ”‚    â”‚    :)    â”‚         (REQUEST)             â”‚    [chef]    â”‚           â”‚\nâ”‚    â”‚          â”‚                               â”‚              â”‚           â”‚\nâ”‚    â”‚          â”‚  â—„â”€â”€â”€â”€ Here you go! â”€â”€â”€â”€â”€â”€â”€â”€  â”‚              â”‚           â”‚\nâ”‚    â”‚          â”‚         (RESPONSE)            â”‚              â”‚           â”‚\nâ”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚\nâ”‚                                                                          â”‚\nâ”‚    The waiter (HTTP) is the protocol that makes this exchange work!      â”‚\nâ”‚                                                                          â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n---\n\n## Mintlify Components Reference\n\n| Component | When to Use |\n|-----------|-------------|\n| `<Info>` | \"What you'll learn\" boxes, Key Takeaways |\n| `<Warning>` | Common mistakes, gotchas, prerequisites |\n| `<Tip>` | Pro tips, rules of thumb, best practices |\n| `<Note>` | Additional context, side notes |\n| `<AccordionGroup>` | Expandable content, Q&A sections, optional deep-dives |\n| `<Tabs>` | Comparing different approaches side-by-side |\n| `<Steps>` | Sequential processes, numbered workflows |\n| `<CardGroup>` | Resource links (articles, videos, references) |\n| `<Card>` | Individual resource with icon and link |\n\n### Card Icons Reference\n\n| Content Type | Icon |\n|--------------|------|\n| MDN/Official Docs | `book` |\n| Articles/Blog Posts | `newspaper` |\n| Videos | `video` |\n| Courses | `graduation-cap` |\n| Related Concepts | Context-appropriate (`handshake`, `hourglass`, `arrows-spin`, `sitemap`, etc.) |\n\n---\n\n## Quality Checklist\n\nBefore finalizing a concept page, verify ALL of these:\n\n### Structure\n- [ ] Opens with engaging questions that hook the reader\n- [ ] Shows a simple code example immediately after the opening\n- [ ] Has \"What you'll learn\" Info box right after the opening\n- [ ] Major sections are separated by `---` horizontal rules\n- [ ] Has a real-world analogy with ASCII art diagram\n- [ ] Has a \"Common Mistakes\" or \"The #1 Mistake\" section\n- [ ] Has a \"Key Takeaways\" section summarizing 8-10 points\n- [ ] Has a \"Test Your Knowledge\" section with 5-6 Q&As\n- [ ] Ends with Related Concepts, Reference, Articles, Videos in that order\n\n### Linking\n- [ ] All new Web APIs/methods have inline MDN links on first mention\n- [ ] All related concepts link to their concept pages (`/concepts/slug`)\n- [ ] Reference section has multiple MDN links\n- [ ] 4-6 quality articles with descriptions\n- [ ] 3-4 quality videos with descriptions\n\n### Code Examples\n- [ ] First code example is dead simple\n- [ ] Uses step-by-step comments for complex examples\n- [ ] Shows output in comments (`// \"result\"`)\n- [ ] Uses âŒ and âœ“ for wrong/correct patterns\n- [ ] Uses meaningful variable names\n- [ ] Progresses from simple to complex\n\n### Content Quality\n- [ ] Written for someone who might be new to coding\n- [ ] Prerequisites are noted with Warning component\n- [ ] No assumptions about prior knowledge without links\n- [ ] Tables used for quick reference information\n- [ ] ASCII diagrams for visual concepts\n\n### Language Quality\n- [ ] Description starts with \"Learn\" or \"Understand\" (not \"Master\")\n- [ ] No overuse of em dashes (fewer than 15 outside Key Takeaways and structured sections)\n- [ ] No AI superlatives: \"dramatically\", \"fundamentally\", \"incredibly\", \"extremely\"\n- [ ] No stiff phrases: \"one of the most important\", \"essential points\", \"It should be noted\"\n- [ ] Emphasis patterns vary (not all \"Key insight:\" or \"Best practice:\")\n- [ ] Playful touches are sparse (1-2 per major section maximum)\n- [ ] No filler words: \"basically\", \"essentially\", \"actually\", \"very\", \"really\"\n- [ ] Sentences are direct (no \"In order to\", \"Due to the fact that\")\n\n### Resource Quality\n- [ ] All article/video links are verified working\n- [ ] All resources are JavaScript-focused (no C#, Python, Java resources)\n- [ ] Each resource has a specific 2-sentence description (not generic)\n- [ ] Resource descriptions explain what makes each unique\n- [ ] No outdated resources (check dates for time-sensitive topics)\n- [ ] 4-6 articles from reputable sources\n- [ ] 3-4 videos from quality creators\n\n---\n\n## Writing Tests\n\nWhen adding code examples, create corresponding tests in `/tests/`:\n\n```javascript\n// tests/{category}/{concept-name}/{concept-name}.test.js\nimport { describe, it, expect } from 'vitest'\n\ndescribe('Concept Name', () => {\n  describe('Basic Examples', () => {\n    it('should demonstrate the core concept', () => {\n      // Convert console.log examples to expect assertions\n      expect(typeof \"hello\").toBe(\"string\")\n    })\n  })\n  \n  describe('Common Mistakes', () => {\n    it('should show the wrong behavior', () => {\n      // Test the \"wrong\" example to prove it's actually wrong\n    })\n    \n    it('should show the correct behavior', () => {\n      // Test the \"correct\" example\n    })\n  })\n})\n```\n\n---\n\n## SEO Checklist\n\nVerify these elements before publishing any concept page:\n\n### Title & Meta Description\n- [ ] **Title is 50-60 characters** â€” check with character counter\n- [ ] **Title ends with \"in JavaScript\"** â€” SEO keyword at end\n- [ ] **Title has a compelling hook** â€” tells reader what they'll understand\n- [ ] **sidebarTitle matches title but without \"in JavaScript\"** â€” cleaner navigation\n- [ ] **Description is 150-160 characters** â€” don't leave value on the table\n- [ ] **Description includes primary keyword** in first sentence\n- [ ] **Description includes 1-2 secondary keywords** naturally\n- [ ] **Description starts with action word** (Learn, Understand, Discover â€” avoid \"Master\")\n- [ ] **Description promises specific value** â€” what will they learn?\n\n### Keyword Placement\n- [ ] **Primary keyword in title**\n- [ ] **Primary keyword in description**\n- [ ] **Primary keyword in first paragraph** (within first 100 words)\n- [ ] **Primary keyword in at least one H2 heading**\n- [ ] **Secondary keywords in H2/H3 headings** where natural\n- [ ] **Keywords in \"What you'll learn\" box items**\n- [ ] **No keyword stuffing** â€” content reads naturally\n\n### Content Structure\n- [ ] **Opens with question hook** matching search intent\n- [ ] **Shows code example in first 200 words**\n- [ ] **First paragraph after H2s directly answers** the implied question\n- [ ] **Content is 1,500+ words** (comprehensive coverage)\n- [ ] **Short paragraphs** (2-4 sentences maximum)\n- [ ] **Uses bullet lists** for 3+ related items\n- [ ] **Uses numbered lists** for sequential processes\n- [ ] **Uses tables** for comparisons and reference data\n- [ ] **Key terms bolded** on first mention with MDN links\n\n### Featured Snippet Optimization\n- [ ] **\"What is X\" section has 40-60 word definition paragraph**\n- [ ] **\"How to\" sections use numbered steps or `<Steps>` component**\n- [ ] **Comparison sections use tables** with clear headers\n- [ ] **At least one H2 is phrased as a question** matching search query\n\n### Internal Linking\n- [ ] **Links to 3-5 related concept pages** in body content\n- [ ] **Uses descriptive anchor text** (not \"click here\" or \"here\")\n- [ ] **Prerequisites linked in Warning component** at start\n- [ ] **Related Concepts section has 4 cards** with relevant concepts\n- [ ] **Links appear in natural context** â€” not forced\n\n### Technical SEO\n- [ ] **Slug is lowercase with hyphens**\n- [ ] **Slug contains primary keyword**\n- [ ] **Slug is 3-5 words maximum**\n- [ ] **All external links use proper URLs** (no broken links)\n- [ ] **MDN links are current** (check they resolve)\n"
      },
      "discovered_at": "2026-01-11T15:35:56.905962Z",
      "fetch_error": null
    },
    {
      "name": "seo-review",
      "slug": "seo-review",
      "source": "skillsmp_top",
      "owner": "leonardomso",
      "repo_name": "33-js-concepts",
      "repository_url": "https://github.com/leonardomso/33-js-concepts",
      "skill_path": ".opencode/skill/seo-review",
      "github_metadata": {
        "stars": 66082,
        "description": "ğŸ“œ 33 JavaScript concepts every developer should know.",
        "default_branch": "master",
        "pushed_at": "2026-01-07T12:51:15Z",
        "created_at": "2018-09-04T13:27:04Z",
        "language": "JavaScript",
        "license": "MIT",
        "open_issues": 0,
        "forks": 9196
      },
      "skill_md": {
        "found": true,
        "path": ".opencode/skill/seo-review/SKILL.md",
        "branch": "master",
        "content": "---\nname: seo-review\ndescription: Perform a focused SEO audit on JavaScript concept pages to maximize search visibility, featured snippet optimization, and ranking potential\n---\n\n# Skill: SEO Audit for Concept Pages\n\nUse this skill to perform a focused SEO audit on concept documentation pages for the 33 JavaScript Concepts project. The goal is to maximize search visibility for JavaScript developers.\n\n## When to Use\n\n- Before publishing a new concept page\n- When optimizing underperforming pages\n- Periodic content audits\n- After major content updates\n- When targeting new keywords\n\n## Goal\n\nEach concept page should rank for searches like:\n- \"what is [concept] in JavaScript\"\n- \"how does [concept] work in JavaScript\"\n- \"[concept] JavaScript explained\"\n- \"[concept] JavaScript tutorial\"\n- \"[concept] JavaScript example\"\n\n---\n\n## SEO Audit Methodology\n\nFollow these five steps for a complete SEO audit.\n\n### Step 1: Identify Target Keywords\n\nBefore auditing, identify the keyword cluster for the concept.\n\n#### Keyword Cluster Template\n\n| Type | Pattern | Example (Closures) |\n|------|---------|-------------------|\n| **Primary** | [concept] JavaScript | closures JavaScript |\n| **What is** | what is [concept] in JavaScript | what is a closure in JavaScript |\n| **How does** | how does [concept] work | how do closures work |\n| **How to** | how to use/create [concept] | how to use closures |\n| **Why** | why use [concept] | why use closures JavaScript |\n| **Examples** | [concept] examples | closure examples JavaScript |\n| **vs** | [concept] vs [related] | closures vs scope |\n| **Interview** | [concept] interview questions | closure interview questions |\n\n### Step 2: On-Page SEO Audit\n\nCheck all on-page SEO elements systematically.\n\n### Step 3: Featured Snippet Optimization\n\nVerify content is structured to win featured snippets.\n\n### Step 4: Internal Linking Audit\n\nCheck the internal link structure.\n\n### Step 5: Generate Report\n\nDocument findings using the report template.\n\n---\n\n## Keyword Clusters by Concept\n\nUse these pre-built keyword clusters for each concept.\n\n<AccordionGroup>\n  <Accordion title=\"Call Stack\">\n    | Type | Keywords |\n    |------|----------|\n    | Primary | JavaScript call stack, call stack JavaScript |\n    | What is | what is the call stack in JavaScript |\n    | How does | how does the call stack work |\n    | Error | maximum call stack size exceeded, stack overflow JavaScript |\n    | Visual | call stack visualization, call stack explained |\n    | Interview | call stack interview questions JavaScript |\n  </Accordion>\n\n  <Accordion title=\"Primitive Types\">\n    | Type | Keywords |\n    |------|----------|\n    | Primary | JavaScript primitive types, primitives in JavaScript |\n    | What are | what are primitive types in JavaScript |\n    | List | JavaScript data types, types in JavaScript |\n    | vs | primitives vs objects JavaScript |\n    | typeof | typeof JavaScript, JavaScript typeof operator |\n    | Interview | JavaScript types interview questions |\n  </Accordion>\n\n  <Accordion title=\"Value vs Reference Types\">\n    | Type | Keywords |\n    |------|----------|\n    | Primary | JavaScript value vs reference, pass by reference JavaScript |\n    | What is | what is pass by value in JavaScript |\n    | How does | how does JavaScript pass objects |\n    | Comparison | value types vs reference types JavaScript |\n    | Copy | how to copy objects JavaScript, deep copy JavaScript |\n  </Accordion>\n\n  <Accordion title=\"Type Coercion\">\n    | Type | Keywords |\n    |------|----------|\n    | Primary | JavaScript type coercion, type conversion JavaScript |\n    | What is | what is type coercion in JavaScript |\n    | How does | how does type coercion work |\n    | Implicit | implicit type conversion JavaScript |\n    | Explicit | explicit type conversion JavaScript |\n    | Interview | type coercion interview questions |\n  </Accordion>\n\n  <Accordion title=\"Equality Operators\">\n    | Type | Keywords |\n    |------|----------|\n    | Primary | JavaScript equality, == vs === JavaScript |\n    | What is | what is the difference between == and === |\n    | Comparison | loose equality vs strict equality JavaScript |\n    | Best practice | when to use == vs === |\n    | Interview | JavaScript equality interview questions |\n  </Accordion>\n\n  <Accordion title=\"Scope and Closures\">\n    | Type | Keywords |\n    |------|----------|\n    | Primary | JavaScript closures, JavaScript scope |\n    | What is | what is a closure in JavaScript, what is scope |\n    | How does | how do closures work, how does scope work |\n    | Types | types of scope JavaScript, lexical scope |\n    | Use cases | closure use cases, why use closures |\n    | Interview | closure interview questions JavaScript |\n  </Accordion>\n\n  <Accordion title=\"Event Loop\">\n    | Type | Keywords |\n    |------|----------|\n    | Primary | JavaScript event loop, event loop JavaScript |\n    | What is | what is the event loop in JavaScript |\n    | How does | how does the event loop work |\n    | Visual | event loop visualization, event loop explained |\n    | Related | call stack event loop, task queue JavaScript |\n    | Interview | event loop interview questions |\n  </Accordion>\n\n  <Accordion title=\"Promises\">\n    | Type | Keywords |\n    |------|----------|\n    | Primary | JavaScript Promises, Promises in JavaScript |\n    | What is | what is a Promise in JavaScript |\n    | How to | how to use Promises, how to chain Promises |\n    | Methods | Promise.all, Promise.race, Promise.allSettled |\n    | Error | Promise error handling, Promise catch |\n    | vs | Promises vs callbacks, Promises vs async await |\n  </Accordion>\n\n  <Accordion title=\"async/await\">\n    | Type | Keywords |\n    |------|----------|\n    | Primary | JavaScript async await, async await JavaScript |\n    | What is | what is async await in JavaScript |\n    | How to | how to use async await, async await tutorial |\n    | Error | async await error handling, try catch async |\n    | vs | async await vs Promises |\n    | Interview | async await interview questions |\n  </Accordion>\n\n  <Accordion title=\"this Keyword\">\n    | Type | Keywords |\n    |------|----------|\n    | Primary | JavaScript this keyword, this in JavaScript |\n    | What is | what is this in JavaScript |\n    | How does | how does this work in JavaScript |\n    | Binding | call apply bind JavaScript, this binding |\n    | Arrow | this in arrow functions |\n    | Interview | this keyword interview questions |\n  </Accordion>\n\n  <Accordion title=\"Prototypes\">\n    | Type | Keywords |\n    |------|----------|\n    | Primary | JavaScript prototype, prototype chain JavaScript |\n    | What is | what is a prototype in JavaScript |\n    | How does | how does prototype inheritance work |\n    | Chain | prototype chain explained |\n    | vs | prototype vs class JavaScript |\n    | Interview | prototype interview questions JavaScript |\n  </Accordion>\n\n  <Accordion title=\"DOM\">\n    | Type | Keywords |\n    |------|----------|\n    | Primary | JavaScript DOM, DOM manipulation JavaScript |\n    | What is | what is the DOM in JavaScript |\n    | How to | how to manipulate DOM JavaScript |\n    | Methods | getElementById, querySelector JavaScript |\n    | Events | DOM events JavaScript, event listeners |\n    | Performance | DOM performance, virtual DOM vs DOM |\n  </Accordion>\n\n  <Accordion title=\"Higher-Order Functions\">\n    | Type | Keywords |\n    |------|----------|\n    | Primary | JavaScript higher order functions, higher order functions |\n    | What are | what are higher order functions |\n    | Examples | map filter reduce JavaScript |\n    | How to | how to use higher order functions |\n    | Interview | higher order functions interview |\n  </Accordion>\n\n  <Accordion title=\"Recursion\">\n    | Type | Keywords |\n    |------|----------|\n    | Primary | JavaScript recursion, recursion in JavaScript |\n    | What is | what is recursion in JavaScript |\n    | How to | how to write recursive functions |\n    | Examples | recursion examples JavaScript |\n    | vs | recursion vs iteration JavaScript |\n    | Interview | recursion interview questions |\n  </Accordion>\n</AccordionGroup>\n\n---\n\n## Audit Checklists\n\n### Title Tag Checklist (4 points)\n\n| # | Check | Points | How to Verify |\n|---|-------|--------|---------------|\n| 1 | Length 50-60 characters | 1 | Count characters in `title` frontmatter |\n| 2 | Primary keyword in first half | 1 | Concept name appears early |\n| 3 | Ends with \"in JavaScript\" | 1 | Check title ending |\n| 4 | Contains compelling hook | 1 | Promises value/benefit to reader |\n\n**Scoring:**\n- 4/4: âœ… Excellent\n- 3/4: âš ï¸ Good, minor improvements possible\n- 0-2/4: âŒ Needs significant work\n\n**Title Formula:**\n```\n[Concept]: [What You'll Understand] in JavaScript\n```\n\n**Good Examples:**\n| Concept | Title (with character count) |\n|---------|------------------------------|\n| Closures | \"Closures: How Functions Remember Their Scope in JavaScript\" (58 chars) |\n| Event Loop | \"Event Loop: How Async Code Actually Runs in JavaScript\" (54 chars) |\n| Promises | \"Promises: Handling Async Operations in JavaScript\" (49 chars) |\n| DOM | \"DOM: How Browsers Represent Web Pages in JavaScript\" (51 chars) |\n\n**Bad Examples:**\n| Issue | Bad Title | Better Title |\n|-------|-----------|--------------|\n| Too short | \"Closures\" | \"Closures: How Functions Remember Their Scope in JavaScript\" |\n| Too long | \"Understanding JavaScript Closures and How They Work with Examples\" (66 chars) | \"Closures: How Functions Remember Their Scope in JavaScript\" (58 chars) |\n| No hook | \"JavaScript Closures\" | \"Closures: How Functions Remember Their Scope in JavaScript\" |\n| Missing \"JavaScript\" | \"Understanding Closures and Scope\" | Add \"in JavaScript\" at end |\n\n---\n\n### Meta Description Checklist (4 points)\n\n| # | Check | Points | How to Verify |\n|---|-------|--------|---------------|\n| 1 | Length 150-160 characters | 1 | Count characters in `description` frontmatter |\n| 2 | Starts with action word | 1 | \"Learn\", \"Understand\", \"Discover\" (NOT \"Master\") |\n| 3 | Contains primary keyword | 1 | Concept name + \"JavaScript\" present |\n| 4 | Promises specific value | 1 | Lists what reader will learn |\n\n**Description Formula:**\n```\n[Action word] [what it is] in JavaScript. [Specific things they'll learn]: [topic 1], [topic 2], and [topic 3].\n```\n\n**Good Examples:**\n\n| Concept | Description |\n|---------|-------------|\n| Closures | \"Learn JavaScript closures and how functions remember their scope. Covers lexical scoping, practical use cases, memory considerations, and common closure patterns.\" (159 chars) |\n| Event Loop | \"Discover how the JavaScript event loop manages async code execution. Understand the call stack, task queue, microtasks, and why JavaScript is single-threaded but non-blocking.\" (176 chars - trim!) |\n| DOM | \"Learn how the DOM works in JavaScript. Understand how browsers represent HTML as a tree, select and manipulate elements, traverse nodes, and optimize rendering.\" (162 chars) |\n\n**Bad Examples:**\n\n| Issue | Bad Description | Fix |\n|-------|-----------------|-----|\n| Too short | \"Learn about closures\" | Expand to 150-160 chars with specifics |\n| Starts with \"Master\" | \"Master JavaScript closures...\" | \"Learn JavaScript closures...\" |\n| Too vague | \"A guide to closures\" | List specific topics covered |\n| Missing keyword | \"Functions can remember things\" | Include \"closures\" and \"JavaScript\" |\n\n---\n\n### Keyword Placement Checklist (5 points)\n\n| # | Check | Points | How to Verify |\n|---|-------|--------|---------------|\n| 1 | Primary keyword in title | 1 | Check frontmatter `title` |\n| 2 | Primary keyword in meta description | 1 | Check frontmatter `description` |\n| 3 | Primary keyword in first 100 words | 1 | Check opening paragraphs |\n| 4 | Keyword in at least one H2 heading | 1 | Scan all `##` headings |\n| 5 | No keyword stuffing | 1 | Content reads naturally |\n\n**Keyword Placement Map:**\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                         KEYWORD PLACEMENT                                â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                                          â”‚\nâ”‚  ğŸ”´ CRITICAL (Must have keyword)                                         â”‚\nâ”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                       â”‚\nâ”‚  â€¢ title frontmatter                                                     â”‚\nâ”‚  â€¢ description frontmatter                                               â”‚\nâ”‚  â€¢ First paragraph (within 100 words)                                    â”‚\nâ”‚  â€¢ At least one H2 heading                                               â”‚\nâ”‚                                                                          â”‚\nâ”‚  ğŸŸ¡ RECOMMENDED (Include naturally)                                      â”‚\nâ”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                      â”‚\nâ”‚  â€¢ \"What you'll learn\" Info box                                          â”‚\nâ”‚  â€¢ H3 subheadings                                                        â”‚\nâ”‚  â€¢ Key Takeaways section                                                 â”‚\nâ”‚  â€¢ First sentence after major H2s                                        â”‚\nâ”‚                                                                          â”‚\nâ”‚  âš ï¸ AVOID                                                                â”‚\nâ”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                               â”‚\nâ”‚  â€¢ Same phrase >4 times per 1000 words                                   â”‚\nâ”‚  â€¢ Forcing keywords where pronouns work better                           â”‚\nâ”‚  â€¢ Awkward sentence structures to fit keywords                           â”‚\nâ”‚                                                                          â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n---\n\n### Content Structure Checklist (6 points)\n\n| # | Check | Points | How to Verify |\n|---|-------|--------|---------------|\n| 1 | Opens with question hook | 1 | First paragraph asks engaging question |\n| 2 | Code example in first 200 words | 1 | Simple example appears early |\n| 3 | \"What you'll learn\" Info box | 1 | `<Info>` component after opening |\n| 4 | Short paragraphs (2-4 sentences) | 1 | Scan content for long blocks |\n| 5 | 1,500+ words | 1 | Word count check |\n| 6 | Key terms bolded on first mention | 1 | Important terms use `**bold**` |\n\n**Content Structure Template:**\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                       IDEAL PAGE STRUCTURE                               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                                          â”‚\nâ”‚  1. QUESTION HOOK (First 50 words)                                       â”‚\nâ”‚     \"How does JavaScript...? Why do...?\"                                 â”‚\nâ”‚                                                                          â”‚\nâ”‚  2. BRIEF ANSWER + CODE EXAMPLE (Words 50-200)                           â”‚\nâ”‚     Quick explanation + simple code demo                                 â”‚\nâ”‚                                                                          â”‚\nâ”‚  3. \"WHAT YOU'LL LEARN\" INFO BOX                                         â”‚\nâ”‚     5-7 bullet points                                                    â”‚\nâ”‚                                                                          â”‚\nâ”‚  4. PREREQUISITES WARNING (if applicable)                                â”‚\nâ”‚     Link to required prior concepts                                      â”‚\nâ”‚                                                                          â”‚\nâ”‚  5. MAIN CONTENT SECTIONS (H2s)                                          â”‚\nâ”‚     Each H2 answers a question or teaches a concept                      â”‚\nâ”‚     Include code examples, diagrams, tables                              â”‚\nâ”‚                                                                          â”‚\nâ”‚  6. COMMON MISTAKES / GOTCHAS SECTION                                    â”‚\nâ”‚     What trips people up                                                 â”‚\nâ”‚                                                                          â”‚\nâ”‚  7. KEY TAKEAWAYS                                                        â”‚\nâ”‚     8-10 numbered points summarizing everything                          â”‚\nâ”‚                                                                          â”‚\nâ”‚  8. TEST YOUR KNOWLEDGE                                                  â”‚\nâ”‚     5-6 Q&A accordions                                                   â”‚\nâ”‚                                                                          â”‚\nâ”‚  9. RELATED CONCEPTS                                                     â”‚\nâ”‚     4 cards linking to related topics                                    â”‚\nâ”‚                                                                          â”‚\nâ”‚  10. RESOURCES (Reference, Articles, Videos)                             â”‚\nâ”‚      MDN links, curated articles, videos                                 â”‚\nâ”‚                                                                          â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n---\n\n### Featured Snippet Checklist (4 points)\n\n| # | Check | Points | How to Verify |\n|---|-------|--------|---------------|\n| 1 | \"What is X\" has 40-60 word definition | 1 | Count words in first paragraph after \"What is\" H2 |\n| 2 | At least one H2 is phrased as question | 1 | Check for \"What is\", \"How does\", \"Why\" H2s |\n| 3 | Numbered steps for \"How to\" content | 1 | Uses `<Steps>` component or numbered list |\n| 4 | Comparison tables (if applicable) | 1 | Tables for \"X vs Y\" content |\n\n**Featured Snippet Patterns:**\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                     FEATURED SNIPPET FORMATS                             â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                                          â”‚\nâ”‚  QUERY TYPE             WINNING FORMAT         YOUR CONTENT              â”‚\nâ”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€            â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€              â”‚\nâ”‚                                                                          â”‚\nâ”‚  \"What is X\"            Paragraph              40-60 word definition     â”‚\nâ”‚                                                after H2, bold keyword    â”‚\nâ”‚                                                                          â”‚\nâ”‚  \"How to X\"             Numbered list          <Steps> component or      â”‚\nâ”‚                                                1. 2. 3. markdown         â”‚\nâ”‚                                                                          â”‚\nâ”‚  \"X vs Y\"               Table                  | Feature | X | Y |       â”‚\nâ”‚                                                comparison table          â”‚\nâ”‚                                                                          â”‚\nâ”‚  \"Types of X\"           Bullet list            - **Type 1** â€” desc       â”‚\nâ”‚                                                - **Type 2** â€” desc       â”‚\nâ”‚                                                                          â”‚\nâ”‚  \"[X] examples\"         Code block             ```javascript             â”‚\nâ”‚                         + explanation          // example code           â”‚\nâ”‚                                                                          â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n**Definition Paragraph Example (40-60 words):**\n\n```markdown\n## What is a Closure in JavaScript?\n\nA **closure** is a function that retains access to variables from its outer \n(enclosing) scope, even after that outer function has finished executing. \nClosures are created every time a function is created in JavaScript, allowing \ninner functions to \"remember\" and access their lexical environment.\n```\n\n(This is 52 words - perfect for a featured snippet)\n\n---\n\n### Internal Linking Checklist (4 points)\n\n| # | Check | Points | How to Verify |\n|---|-------|--------|---------------|\n| 1 | 3-5 related concepts linked in body | 1 | Count `/concepts/` links in prose |\n| 2 | Descriptive anchor text | 1 | No \"click here\", \"here\", \"this\" |\n| 3 | Prerequisites in Warning box | 1 | `<Warning>` with links at start |\n| 4 | Related Concepts section has 4 cards | 1 | `<CardGroup>` at end with 4 Cards |\n\n**Good Anchor Text:**\n\n| âŒ Bad | âœ“ Good |\n|--------|--------|\n| \"click here\" | \"event loop concept\" |\n| \"here\" | \"JavaScript closures\" |\n| \"this article\" | \"our Promises guide\" |\n| \"read more\" | \"understanding the call stack\" |\n\n**Link Placement Strategy:**\n\n```markdown\n<!-- In Prerequisites (Warning box) -->\n<Warning>\n**Prerequisite:** This guide assumes you understand [Promises](/concepts/promises) \nand the [Event Loop](/concepts/event-loop). Read those first if needed.\n</Warning>\n\n<!-- In Body Content (natural context) -->\nWhen the callback finishes, it's added to the task queue â€” managed by \nthe [event loop](/concepts/event-loop).\n\n<!-- In Related Concepts Section -->\n<CardGroup cols={2}>\n  <Card title=\"Promises\" icon=\"handshake\" href=\"/concepts/promises\">\n    async/await is built on top of Promises\n  </Card>\n</CardGroup>\n```\n\n---\n\n### Technical SEO Checklist (3 points)\n\n| # | Check | Points | How to Verify |\n|---|-------|--------|---------------|\n| 1 | Single H1 per page | 1 | Only one `#` heading (the title) |\n| 2 | URL slug contains keyword | 1 | `/concepts/closures` not `/concepts/topic-1` |\n| 3 | No orphan pages | 1 | Page is linked from at least one other page |\n\n**H1 Rule:**\n\nEvery page should have exactly ONE H1 (your main title). This is critical for SEO:\n- The H1 tells Google what the page is about\n- Multiple H1s confuse search engines about page hierarchy\n- All other headings should be H2 (`##`) and below\n- The H1 should contain your primary keyword\n\n```markdown\n# Closures in JavaScript     â† This is your H1 (only one!)\n\n## What is a Closure?        â† H2 for sections\n### Lexical Scope            â† H3 for subsections\n## How Closures Work         â† Another H2\n```\n\n**URL/Slug Best Practices:**\n\n| âœ… Good | âŒ Bad |\n|---------|--------|\n| `/concepts/closures` | `/concepts/c1` |\n| `/concepts/event-loop` | `/concepts/topic-7` |\n| `/concepts/type-coercion` | `/concepts/abc123` |\n| `/concepts/async-await` | `/concepts/async_await` |\n\nRules for slugs:\n- **Include primary keyword** â€” The concept name should be in the URL\n- **Use hyphens, not underscores** â€” `event-loop` not `event_loop`\n- **Keep slugs short and readable** â€” Under 50 characters\n- **No UUIDs, database IDs, or random strings**\n- **Lowercase only** â€” `/concepts/Event-Loop` should be `/concepts/event-loop`\n\n**Orphan Page Detection:**\n\nAn orphan page has no internal links pointing to it from other pages. This hurts SEO because:\n- Google may not discover or crawl it frequently\n- It signals the page isn't important to your site structure\n- Users can't navigate to it naturally\n- Link equity doesn't flow to the page\n\n**How to check for orphan pages:**\n1. Search the codebase for links to this concept: `grep -r \"/concepts/[slug]\" docs/`\n2. Verify it appears in at least one other concept's \"Related Concepts\" section\n3. Check that pages listing it as a prerequisite link back appropriately\n4. Ensure it's included in the navigation (`docs.json`)\n\n**Fixing orphan pages:**\n- Add the concept to related pages' \"Related Concepts\" CardGroup\n- Link to it naturally in body content of related concepts\n- Ensure bidirectional linking (if A links to B, B should link back to A where relevant)\n\n---\n\n## Scoring System\n\n### Total Points Available: 30\n\n| Category | Max Points |\n|----------|------------|\n| Title Tag | 4 |\n| Meta Description | 4 |\n| Keyword Placement | 5 |\n| Content Structure | 6 |\n| Featured Snippets | 4 |\n| Internal Linking | 4 |\n| Technical SEO | 3 |\n| **Total** | **30** |\n\n### Score Interpretation\n\n| Score | Percentage | Status | Action |\n|-------|------------|--------|--------|\n| 27-30 | 90-100% | âœ… Excellent | Ready to publish |\n| 23-26 | 75-89% | âš ï¸ Good | Minor optimizations needed |\n| 17-22 | 55-74% | âš ï¸ Fair | Several improvements needed |\n| 0-16 | <55% | âŒ Poor | Significant work required |\n\n---\n\n## Common SEO Issues and Fixes\n\n### Title Tag Issues\n\n| Issue | Current | Fix |\n|-------|---------|-----|\n| Too short (<50 chars) | \"Closures\" (8) | \"Closures: How Functions Remember Their Scope in JavaScript\" (58) |\n| Too long (>60 chars) | \"Understanding JavaScript Closures and How They Work with Examples\" (66) | \"Closures: How Functions Remember Their Scope in JavaScript\" (58) |\n| Missing keyword | \"Understanding Scope\" | Add concept name: \"Closures: Understanding Scope in JavaScript\" |\n| No hook | \"JavaScript Closures\" | Add benefit: \"Closures: How Functions Remember Their Scope in JavaScript\" |\n| Missing \"JavaScript\" | \"Closures Explained\" | Add at end: \"Closures Explained in JavaScript\" |\n\n### Meta Description Issues\n\n| Issue | Current | Fix |\n|-------|---------|-----|\n| Too short (<120 chars) | \"Learn about closures\" (20) | Expand with specifics to 150-160 chars |\n| Too long (>160 chars) | [Gets truncated] | Edit ruthlessly, keep key information |\n| Starts with \"Master\" | \"Master JavaScript closures...\" | \"Learn JavaScript closures...\" |\n| No keyword | \"Functions that remember\" | Include \"closures\" and \"JavaScript\" |\n| Too vague | \"A guide to closures\" | List specific topics: \"Covers X, Y, and Z\" |\n\n### Content Structure Issues\n\n| Issue | Fix |\n|-------|-----|\n| No question hook | Start with \"How does...?\" or \"Why...?\" |\n| Code example too late | Move simple example to first 200 words |\n| Missing Info box | Add `<Info>` with \"What you'll learn\" |\n| Long paragraphs | Break into 2-4 sentence chunks |\n| Under 1,500 words | Add more depth, examples, edge cases |\n| No bolded terms | Bold key concepts on first mention |\n\n### Featured Snippet Issues\n\n| Issue | Fix |\n|-------|-----|\n| No \"What is\" definition | Add 40-60 word definition paragraph |\n| Definition too long | Tighten to 40-60 words |\n| No question H2s | Add \"What is X?\" or \"How does X work?\" H2 |\n| Steps not numbered | Use `<Steps>` or numbered markdown |\n| No comparison tables | Add table for \"X vs Y\" sections |\n\n### Internal Linking Issues\n\n| Issue | Fix |\n|-------|-----|\n| No internal links | Add 3-5 links to related concepts |\n| Bad anchor text | Replace \"click here\" with descriptive text |\n| No prerequisites | Add `<Warning>` with prerequisite links |\n| Empty Related Concepts | Add 4 Cards linking to related topics |\n\n### Technical SEO Issues\n\n| Issue | Fix |\n|-------|-----|\n| Multiple H1 tags | Keep only one `#` heading (the title), use `##` for all sections |\n| Slug missing keyword | Rename file to include concept name (e.g., `closures.mdx`) |\n| Orphan page | Add links from related concept pages' body or Related Concepts section |\n| Underscore in slug | Use hyphens: `event-loop.mdx` not `event_loop.mdx` |\n| Uppercase in slug | Use lowercase only: `async-await.mdx` not `Async-Await.mdx` |\n| Slug too long | Shorten to primary keyword: `closures.mdx` not `understanding-javascript-closures-and-scope.mdx` |\n\n---\n\n## SEO Audit Report Template\n\nUse this template to document your findings.\n\n```markdown\n# SEO Audit Report: [Concept Name]\n\n**File:** `/docs/concepts/[slug].mdx`\n**Date:** YYYY-MM-DD\n**Auditor:** [Name/Claude]\n**Overall Score:** XX/30 (XX%)\n**Status:** âœ… Excellent | âš ï¸ Needs Work | âŒ Poor\n\n---\n\n## Score Summary\n\n| Category | Score | Status |\n|----------|-------|--------|\n| Title Tag | X/4 | âœ…/âš ï¸/âŒ |\n| Meta Description | X/4 | âœ…/âš ï¸/âŒ |\n| Keyword Placement | X/5 | âœ…/âš ï¸/âŒ |\n| Content Structure | X/6 | âœ…/âš ï¸/âŒ |\n| Featured Snippets | X/4 | âœ…/âš ï¸/âŒ |\n| Internal Linking | X/4 | âœ…/âš ï¸/âŒ |\n| Technical SEO | X/3 | âœ…/âš ï¸/âŒ |\n| **Total** | **X/30** | **STATUS** |\n\n---\n\n## Target Keywords\n\n**Primary Keyword:** [e.g., \"JavaScript closures\"]\n**Secondary Keywords:**\n- [keyword 1]\n- [keyword 2]\n- [keyword 3]\n\n**Search Intent:** Informational / How-to / Comparison\n\n---\n\n## Title Tag Analysis\n\n**Current Title:** \"[current title from frontmatter]\"\n**Character Count:** XX characters\n**Score:** X/4\n\n| Check | Status | Notes |\n|-------|--------|-------|\n| Length 50-60 chars | âœ…/âŒ | XX characters |\n| Primary keyword in first half | âœ…/âŒ | [notes] |\n| Ends with \"in JavaScript\" | âœ…/âŒ | [notes] |\n| Contains compelling hook | âœ…/âŒ | [notes] |\n\n**Issues Found:** [if any]\n\n**Recommended Title:** \"[suggested title]\" (XX chars)\n\n---\n\n## Meta Description Analysis\n\n**Current Description:** \"[current description from frontmatter]\"\n**Character Count:** XX characters\n**Score:** X/4\n\n| Check | Status | Notes |\n|-------|--------|-------|\n| Length 150-160 chars | âœ…/âŒ | XX characters |\n| Starts with action word | âœ…/âŒ | Starts with \"[word]\" |\n| Contains primary keyword | âœ…/âŒ | [notes] |\n| Promises specific value | âœ…/âŒ | [notes] |\n\n**Issues Found:** [if any]\n\n**Recommended Description:** \"[suggested description]\" (XX chars)\n\n---\n\n## Keyword Placement Analysis\n\n**Score:** X/5\n\n| Location | Present | Notes |\n|----------|---------|-------|\n| Title | âœ…/âŒ | [notes] |\n| Meta description | âœ…/âŒ | [notes] |\n| First 100 words | âœ…/âŒ | Found at word XX |\n| H2 heading | âœ…/âŒ | Found in: \"[H2 text]\" |\n| Natural reading | âœ…/âŒ | [no stuffing / stuffing detected] |\n\n**Missing Keyword Placements:**\n- [ ] [Location where keyword should be added]\n\n---\n\n## Content Structure Analysis\n\n**Word Count:** X,XXX words\n**Score:** X/6\n\n| Check | Status | Notes |\n|-------|--------|-------|\n| Question hook opening | âœ…/âŒ | [notes] |\n| Code in first 200 words | âœ…/âŒ | Code appears at word XX |\n| \"What you'll learn\" box | âœ…/âŒ | [present/missing] |\n| Short paragraphs | âœ…/âŒ | [notes on paragraph length] |\n| 1,500+ words | âœ…/âŒ | X,XXX words |\n| Bolded key terms | âœ…/âŒ | [notes] |\n\n**Structure Issues:**\n- [ ] [Issue and recommendation]\n\n---\n\n## Featured Snippet Analysis\n\n**Score:** X/4\n\n| Check | Status | Notes |\n|-------|--------|-------|\n| 40-60 word definition | âœ…/âŒ | Currently XX words |\n| Question-format H2 | âœ…/âŒ | Found: \"[H2]\" / Not found |\n| Numbered steps | âœ…/âŒ | [notes] |\n| Comparison tables | âœ…/âŒ/N/A | [notes] |\n\n**Snippet Opportunities:**\n\n1. **\"What is [concept]\" snippet:**\n   - Current definition: XX words\n   - Action: [Expand to/Trim to] 40-60 words\n\n2. **\"How to [action]\" snippet:**\n   - Action: [Add Steps component / Already present]\n\n---\n\n## Internal Linking Analysis\n\n**Score:** X/4\n\n| Check | Status | Notes |\n|-------|--------|-------|\n| 3-5 internal links in body | âœ…/âŒ | Found X links |\n| Descriptive anchor text | âœ…/âŒ | [notes] |\n| Prerequisites in Warning | âœ…/âŒ | [present/missing] |\n| Related Concepts section | âœ…/âŒ | X cards present |\n\n**Current Internal Links:**\n1. [Anchor text] â†’ `/concepts/[slug]`\n2. [Anchor text] â†’ `/concepts/[slug]`\n\n**Recommended Links to Add:**\n- Link to [concept] in [section/context]\n- Link to [concept] in [section/context]\n\n**Bad Anchor Text Found:**\n- Line XX: \"click here\" â†’ change to \"[descriptive text]\"\n\n---\n\n## Technical SEO Analysis\n\n**Score:** X/3\n\n| Check | Status | Notes |\n|-------|--------|-------|\n| Single H1 per page | âœ…/âŒ | [Found X H1 tags] |\n| URL slug contains keyword | âœ…/âŒ | Current: `/concepts/[slug]` |\n| Not an orphan page | âœ…/âŒ | Linked from X other pages |\n\n**H1 Tags Found:**\n- Line XX: `# [H1 text]` â† Should be the only one\n- [List any additional H1s that need to be changed to H2]\n\n**Slug Analysis:**\n- Current slug: `[slug].mdx`\n- Contains keyword: âœ…/âŒ\n- Format correct: âœ…/âŒ (lowercase, hyphens, no special chars)\n\n**Incoming Links Found:**\n1. `/concepts/[other-concept]` â†’ Links to this page in [section]\n2. `/concepts/[other-concept]` â†’ Links in Related Concepts\n\n**If orphan page, add links from:**\n- [Suggested concept page] in [section]\n- [Suggested concept page] in Related Concepts\n\n---\n\n## Priority Fixes\n\n### High Priority (Do First)\n\n1. **[Issue]**\n   - Current: [what it is now]\n   - Recommended: [what it should be]\n   - Impact: [why this matters]\n\n2. **[Issue]**\n   - Current: [what it is now]\n   - Recommended: [what it should be]\n   - Impact: [why this matters]\n\n### Medium Priority\n\n1. **[Issue]**\n   - Recommendation: [fix]\n\n### Low Priority (Nice to Have)\n\n1. **[Issue]**\n   - Recommendation: [fix]\n\n---\n\n## Competitive Analysis (Optional)\n\n**Top-Ranking Pages for \"[primary keyword]\":**\n\n1. **[Competitor 1 - URL]**\n   - What they do well: [observation]\n   - Word count: ~X,XXX\n\n2. **[Competitor 2 - URL]**\n   - What they do well: [observation]\n   - Word count: ~X,XXX\n\n**Our Advantages:**\n- [What we do better]\n\n**Gaps to Fill:**\n- [What we're missing that competitors have]\n\n---\n\n## Implementation Checklist\n\nAfter making fixes, verify:\n\n- [ ] Title is 50-60 characters with keyword and hook\n- [ ] Description is 150-160 characters with action word and value\n- [ ] Primary keyword in title, description, first 100 words, and H2\n- [ ] Opens with question hook\n- [ ] Code example in first 200 words\n- [ ] \"What you'll learn\" Info box present\n- [ ] Paragraphs are 2-4 sentences\n- [ ] 1,500+ words total\n- [ ] Key terms bolded on first mention\n- [ ] 40-60 word definition for featured snippet\n- [ ] At least one question-format H2\n- [ ] 3-5 internal links with descriptive anchor text\n- [ ] Prerequisites in Warning box (if applicable)\n- [ ] Related Concepts section has 4 cards\n- [ ] Single H1 per page (title only)\n- [ ] URL slug contains primary keyword\n- [ ] Page linked from at least one other concept page\n- [ ] All fixes implemented and verified\n\n---\n\n## Final Recommendation\n\n**Ready to Publish:** âœ… Yes / âŒ No - [reason]\n\n**Next Review Date:** [When to re-audit, e.g., \"3 months\" or \"after major update\"]\n```\n\n---\n\n## Quick Reference\n\n### Character Counts\n\n| Element | Ideal Length |\n|---------|--------------|\n| Title | 50-60 characters |\n| Meta Description | 150-160 characters |\n| Definition paragraph | 40-60 words |\n\n### Keyword Density\n\n- Don't exceed 3-4 mentions of exact phrase per 1,000 words\n- Use variations naturally (e.g., \"closures\", \"closure\", \"JavaScript closures\")\n\n### Content Length\n\n| Length | Assessment |\n|--------|------------|\n| <1,000 words | Too thin - add depth |\n| 1,000-1,500 | Minimum viable |\n| 1,500-2,500 | Good |\n| 2,500-4,000 | Excellent |\n| >4,000 | Consider splitting |\n\n---\n\n## Summary\n\nWhen auditing a concept page for SEO:\n\n1. **Identify target keywords** using the keyword cluster for that concept\n2. **Check title tag** â€” 50-60 chars, keyword first, hook, ends with \"JavaScript\"\n3. **Check meta description** â€” 150-160 chars, action word, keyword, specific value\n4. **Verify keyword placement** â€” Title, description, first 100 words, H2\n5. **Audit content structure** â€” Question hook, early code, Info box, short paragraphs\n6. **Optimize for featured snippets** â€” 40-60 word definitions, numbered steps, tables\n7. **Check internal linking** â€” 3-5 links, good anchors, Related Concepts section\n8. **Generate report** â€” Document score, issues, and prioritized fixes\n\n**Remember:** SEO isn't about gaming search engines â€” it's about making content easy to find for developers who need it. Every optimization should also improve the reader experience.\n"
      },
      "discovered_at": "2026-01-11T15:35:57.354099Z",
      "fetch_error": null
    },
    {
      "name": "test-writer",
      "slug": "test-writer",
      "source": "skillsmp_top",
      "owner": "leonardomso",
      "repo_name": "33-js-concepts",
      "repository_url": "https://github.com/leonardomso/33-js-concepts",
      "skill_path": ".opencode/skill/test-writer",
      "github_metadata": {
        "stars": 66082,
        "description": "ğŸ“œ 33 JavaScript concepts every developer should know.",
        "default_branch": "master",
        "pushed_at": "2026-01-07T12:51:15Z",
        "created_at": "2018-09-04T13:27:04Z",
        "language": "JavaScript",
        "license": "MIT",
        "open_issues": 0,
        "forks": 9196
      },
      "skill_md": {
        "found": true,
        "path": ".opencode/skill/test-writer/SKILL.md",
        "branch": "master",
        "content": "---\nname: test-writer\ndescription: Generate comprehensive Vitest tests for code examples in JavaScript concept documentation pages, following project conventions and referencing source lines\n---\n\n# Skill: Test Writer for Concept Pages\n\nUse this skill to generate comprehensive Vitest tests for all code examples in a concept documentation page. Tests verify that code examples in the documentation are accurate and work as described.\n\n## When to Use\n\n- After writing a new concept page\n- When adding new code examples to existing pages\n- When updating existing code examples\n- To verify documentation accuracy through automated tests\n- Before publishing to ensure all examples work correctly\n\n## Test Writing Methodology\n\nFollow these four phases to create comprehensive tests for a concept page.\n\n### Phase 1: Code Example Extraction\n\nScan the concept page for all code examples and categorize them:\n\n| Category | Characteristics | Action |\n|----------|-----------------|--------|\n| **Testable** | Has `console.log` with output comments, returns values | Write tests |\n| **DOM-specific** | Uses `document`, `window`, DOM APIs, event handlers | Write DOM tests (separate file) |\n| **Error examples** | Intentionally throws errors, demonstrates failures | Write tests with `toThrow` |\n| **Conceptual** | ASCII diagrams, pseudo-code, incomplete snippets | Skip (document why) |\n| **Browser-only** | Uses browser APIs not available in jsdom | Skip or mock |\n\n### Phase 2: Determine Test File Structure\n\n```\ntests/\nâ”œâ”€â”€ fundamentals/              # Concepts 1-6\nâ”œâ”€â”€ functions-execution/       # Concepts 7-8\nâ”œâ”€â”€ web-platform/             # Concepts 9-10\nâ”œâ”€â”€ object-oriented/          # Concepts 11-15\nâ”œâ”€â”€ functional-programming/   # Concepts 16-19\nâ”œâ”€â”€ async-javascript/         # Concepts 20-22\nâ”œâ”€â”€ advanced-topics/          # Concepts 23-31\nâ””â”€â”€ beyond/                   # Extended concepts\n    â””â”€â”€ {subcategory}/\n```\n\n**File naming:**\n- Standard tests: `{concept-name}.test.js`\n- DOM tests: `{concept-name}.dom.test.js`\n\n### Phase 3: Convert Examples to Tests\n\nFor each testable code example:\n\n1. Identify the expected output (from `console.log` comments or documented behavior)\n2. Convert to `expect` assertions\n3. Add source line reference in comments\n4. Group related tests in `describe` blocks matching documentation sections\n\n### Phase 4: Handle Special Cases\n\n| Case | Solution |\n|------|----------|\n| Browser-only APIs | Use jsdom environment or skip with note |\n| Timing-dependent code | Use `vi.useFakeTimers()` or test the logic, not timing |\n| Side effects | Capture output or test mutations |\n| Intentional errors | Use `expect(() => {...}).toThrow()` |\n| Async code | Use `async/await` with proper assertions |\n\n---\n\n## Project Test Conventions\n\n### Import Pattern\n\n```javascript\nimport { describe, it, expect } from 'vitest'\n```\n\nFor DOM tests or tests needing mocks:\n\n```javascript\nimport { describe, it, expect, vi, beforeEach, afterEach } from 'vitest'\n```\n\n### DOM Test File Header\n\n```javascript\n/**\n * @vitest-environment jsdom\n */\nimport { describe, it, expect, vi, beforeEach, afterEach } from 'vitest'\n```\n\n### Describe Block Organization\n\nMatch the structure of the documentation:\n\n```javascript\ndescribe('Concept Name', () => {\n  describe('Section from Documentation', () => {\n    describe('Subsection if needed', () => {\n      it('should [specific behavior]', () => {\n        // Test\n      })\n    })\n  })\n})\n```\n\n### Test Naming Convention\n\n- Start with \"should\"\n- Be descriptive and specific\n- Match the documented behavior\n\n```javascript\n// Good\nit('should return \"object\" for typeof null', () => {})\nit('should throw TypeError when accessing property of undefined', () => {})\nit('should resolve promises in order they were created', () => {})\n\n// Bad\nit('test typeof', () => {})\nit('works correctly', () => {})\nit('null test', () => {})\n```\n\n### Source Line References\n\nAlways reference the documentation source:\n\n```javascript\n// ============================================================\n// SECTION NAME FROM DOCUMENTATION\n// From {concept}.mdx lines XX-YY\n// ============================================================\n\ndescribe('Section Name', () => {\n  // From lines 45-52: Basic typeof examples\n  it('should return correct type strings', () => {\n    // Test\n  })\n})\n```\n\n---\n\n## Test Patterns Reference\n\n### Pattern 1: Basic Value Assertion\n\n**Documentation:**\n```javascript\nconsole.log(typeof \"hello\")  // \"string\"\nconsole.log(typeof 42)       // \"number\"\n```\n\n**Test:**\n```javascript\n// From lines XX-YY: typeof examples\nit('should return correct type for primitives', () => {\n  expect(typeof \"hello\").toBe(\"string\")\n  expect(typeof 42).toBe(\"number\")\n})\n```\n\n---\n\n### Pattern 2: Multiple Related Assertions\n\n**Documentation:**\n```javascript\nlet a = \"hello\"\nlet b = \"hello\"\nconsole.log(a === b)  // true\n\nlet obj1 = { x: 1 }\nlet obj2 = { x: 1 }\nconsole.log(obj1 === obj2)  // false\n```\n\n**Test:**\n```javascript\n// From lines XX-YY: Primitive vs object comparison\nit('should compare primitives by value', () => {\n  let a = \"hello\"\n  let b = \"hello\"\n  expect(a === b).toBe(true)\n})\n\nit('should compare objects by reference', () => {\n  let obj1 = { x: 1 }\n  let obj2 = { x: 1 }\n  expect(obj1 === obj2).toBe(false)\n})\n```\n\n---\n\n### Pattern 3: Function Return Values\n\n**Documentation:**\n```javascript\nfunction greet(name) {\n  return \"Hello, \" + name + \"!\"\n}\n\nconsole.log(greet(\"Alice\"))  // \"Hello, Alice!\"\n```\n\n**Test:**\n```javascript\n// From lines XX-YY: greet function example\nit('should return greeting with name', () => {\n  function greet(name) {\n    return \"Hello, \" + name + \"!\"\n  }\n  \n  expect(greet(\"Alice\")).toBe(\"Hello, Alice!\")\n})\n```\n\n---\n\n### Pattern 4: Error Testing\n\n**Documentation:**\n```javascript\n// This throws an error!\nconst obj = null\nconsole.log(obj.property)  // TypeError: Cannot read property of null\n```\n\n**Test:**\n```javascript\n// From lines XX-YY: Accessing property of null\nit('should throw TypeError when accessing property of null', () => {\n  const obj = null\n  \n  expect(() => {\n    obj.property\n  }).toThrow(TypeError)\n})\n```\n\n---\n\n### Pattern 5: Specific Error Messages\n\n**Documentation:**\n```javascript\nfunction divide(a, b) {\n  if (b === 0) throw new Error(\"Cannot divide by zero\")\n  return a / b\n}\n```\n\n**Test:**\n```javascript\n// From lines XX-YY: divide function with error\nit('should throw error when dividing by zero', () => {\n  function divide(a, b) {\n    if (b === 0) throw new Error(\"Cannot divide by zero\")\n    return a / b\n  }\n  \n  expect(() => divide(10, 0)).toThrow(\"Cannot divide by zero\")\n  expect(divide(10, 2)).toBe(5)\n})\n```\n\n---\n\n### Pattern 6: Async/Await Testing\n\n**Documentation:**\n```javascript\nasync function fetchUser(id) {\n  const response = await fetch(`/api/users/${id}`)\n  return response.json()\n}\n```\n\n**Test:**\n```javascript\n// From lines XX-YY: async fetchUser function\nit('should fetch user data asynchronously', async () => {\n  // Mock fetch for testing\n  global.fetch = vi.fn(() =>\n    Promise.resolve({\n      json: () => Promise.resolve({ id: 1, name: 'Alice' })\n    })\n  )\n  \n  async function fetchUser(id) {\n    const response = await fetch(`/api/users/${id}`)\n    return response.json()\n  }\n  \n  const user = await fetchUser(1)\n  expect(user).toEqual({ id: 1, name: 'Alice' })\n})\n```\n\n---\n\n### Pattern 7: Promise Testing\n\n**Documentation:**\n```javascript\nconst promise = new Promise((resolve) => {\n  resolve(\"done\")\n})\n\npromise.then(result => console.log(result))  // \"done\"\n```\n\n**Test:**\n```javascript\n// From lines XX-YY: Basic Promise resolution\nit('should resolve with correct value', async () => {\n  const promise = new Promise((resolve) => {\n    resolve(\"done\")\n  })\n  \n  await expect(promise).resolves.toBe(\"done\")\n})\n```\n\n---\n\n### Pattern 8: Promise Rejection\n\n**Documentation:**\n```javascript\nconst promise = new Promise((resolve, reject) => {\n  reject(new Error(\"Something went wrong\"))\n})\n```\n\n**Test:**\n```javascript\n// From lines XX-YY: Promise rejection\nit('should reject with error', async () => {\n  const promise = new Promise((resolve, reject) => {\n    reject(new Error(\"Something went wrong\"))\n  })\n  \n  await expect(promise).rejects.toThrow(\"Something went wrong\")\n})\n```\n\n---\n\n### Pattern 9: Floating Point Comparison\n\n**Documentation:**\n```javascript\nconsole.log(0.1 + 0.2)         // 0.30000000000000004\nconsole.log(0.1 + 0.2 === 0.3) // false\n```\n\n**Test:**\n```javascript\n// From lines XX-YY: Floating point precision\nit('should demonstrate floating point imprecision', () => {\n  expect(0.1 + 0.2).not.toBe(0.3)\n  expect(0.1 + 0.2).toBeCloseTo(0.3)\n  expect(0.1 + 0.2 === 0.3).toBe(false)\n})\n```\n\n---\n\n### Pattern 10: Array Method Testing\n\n**Documentation:**\n```javascript\nconst numbers = [1, 2, 3, 4, 5]\nconst doubled = numbers.map(n => n * 2)\nconsole.log(doubled)  // [2, 4, 6, 8, 10]\n```\n\n**Test:**\n```javascript\n// From lines XX-YY: Array map example\nit('should double all numbers in array', () => {\n  const numbers = [1, 2, 3, 4, 5]\n  const doubled = numbers.map(n => n * 2)\n  \n  expect(doubled).toEqual([2, 4, 6, 8, 10])\n  expect(numbers).toEqual([1, 2, 3, 4, 5]) // Original unchanged\n})\n```\n\n---\n\n### Pattern 11: Object Mutation Testing\n\n**Documentation:**\n```javascript\nconst obj = { a: 1 }\nobj.b = 2\nconsole.log(obj)  // { a: 1, b: 2 }\n```\n\n**Test:**\n```javascript\n// From lines XX-YY: Object mutation\nit('should allow adding properties to objects', () => {\n  const obj = { a: 1 }\n  obj.b = 2\n  \n  expect(obj).toEqual({ a: 1, b: 2 })\n})\n```\n\n---\n\n### Pattern 12: Closure Testing\n\n**Documentation:**\n```javascript\nfunction counter() {\n  let count = 0\n  return function() {\n    count++\n    return count\n  }\n}\n\nconst increment = counter()\nconsole.log(increment())  // 1\nconsole.log(increment())  // 2\nconsole.log(increment())  // 3\n```\n\n**Test:**\n```javascript\n// From lines XX-YY: Closure counter example\nit('should maintain state across calls via closure', () => {\n  function counter() {\n    let count = 0\n    return function() {\n      count++\n      return count\n    }\n  }\n  \n  const increment = counter()\n  expect(increment()).toBe(1)\n  expect(increment()).toBe(2)\n  expect(increment()).toBe(3)\n})\n\nit('should create independent counters', () => {\n  function counter() {\n    let count = 0\n    return function() {\n      count++\n      return count\n    }\n  }\n  \n  const counter1 = counter()\n  const counter2 = counter()\n  \n  expect(counter1()).toBe(1)\n  expect(counter1()).toBe(2)\n  expect(counter2()).toBe(1) // Independent\n})\n```\n\n---\n\n### Pattern 13: DOM Event Testing\n\n**Documentation:**\n```javascript\nconst button = document.getElementById('myButton')\nbutton.addEventListener('click', function(event) {\n  console.log('Button clicked!')\n  console.log(event.type)  // \"click\"\n})\n```\n\n**Test (in .dom.test.js file):**\n```javascript\n/**\n * @vitest-environment jsdom\n */\nimport { describe, it, expect, beforeEach, afterEach } from 'vitest'\n\ndescribe('DOM Event Handlers', () => {\n  let button\n  \n  beforeEach(() => {\n    button = document.createElement('button')\n    button.id = 'myButton'\n    document.body.appendChild(button)\n  })\n  \n  afterEach(() => {\n    document.body.innerHTML = ''\n  })\n  \n  // From lines XX-YY: Button click event\n  it('should fire click event handler', () => {\n    const output = []\n    \n    button.addEventListener('click', function(event) {\n      output.push('Button clicked!')\n      output.push(event.type)\n    })\n    \n    button.click()\n    \n    expect(output).toEqual(['Button clicked!', 'click'])\n  })\n})\n```\n\n---\n\n### Pattern 14: DOM Manipulation Testing\n\n**Documentation:**\n```javascript\nconst div = document.createElement('div')\ndiv.textContent = 'Hello'\ndiv.classList.add('greeting')\ndocument.body.appendChild(div)\n```\n\n**Test:**\n```javascript\n// From lines XX-YY: Creating and appending elements\nit('should create element with text and class', () => {\n  const div = document.createElement('div')\n  div.textContent = 'Hello'\n  div.classList.add('greeting')\n  document.body.appendChild(div)\n  \n  const element = document.querySelector('.greeting')\n  expect(element).not.toBeNull()\n  expect(element.textContent).toBe('Hello')\n  expect(element.classList.contains('greeting')).toBe(true)\n})\n```\n\n---\n\n### Pattern 15: Timer Testing\n\n**Documentation:**\n```javascript\nconsole.log('First')\nsetTimeout(() => console.log('Second'), 0)\nconsole.log('Third')\n// Output: First, Third, Second\n```\n\n**Test:**\n```javascript\n// From lines XX-YY: setTimeout execution order\nit('should execute setTimeout callback after synchronous code', async () => {\n  const output = []\n  \n  output.push('First')\n  setTimeout(() => output.push('Second'), 0)\n  output.push('Third')\n  \n  // Wait for setTimeout to execute\n  await new Promise(resolve => setTimeout(resolve, 10))\n  \n  expect(output).toEqual(['First', 'Third', 'Second'])\n})\n```\n\n---\n\n### Pattern 16: Strict Mode Behavior\n\n**Documentation:**\n```javascript\n// In strict mode, this throws\n\"use strict\"\nx = 10  // ReferenceError: x is not defined\n```\n\n**Test:**\n```javascript\n// From lines XX-YY: Strict mode variable declaration\nit('should throw ReferenceError in strict mode for undeclared variables', () => {\n  // Vitest runs in strict mode by default\n  expect(() => {\n    // Using eval to test strict mode behavior\n    \"use strict\"\n    eval('undeclaredVar = 10')\n  }).toThrow()\n})\n```\n\n---\n\n## Complete Test File Template\n\n```javascript\nimport { describe, it, expect } from 'vitest'\n\ndescribe('[Concept Name]', () => {\n  // ============================================================\n  // [FIRST SECTION NAME FROM DOCUMENTATION]\n  // From [concept].mdx lines XX-YY\n  // ============================================================\n  \n  describe('[First Section]', () => {\n    // From lines XX-YY: [Brief description of example]\n    it('should [expected behavior]', () => {\n      // Code from documentation\n      \n      expect(result).toBe(expected)\n    })\n    \n    // From lines XX-YY: [Brief description of next example]\n    it('should [another expected behavior]', () => {\n      // Code from documentation\n      \n      expect(result).toEqual(expected)\n    })\n  })\n  \n  // ============================================================\n  // [SECOND SECTION NAME FROM DOCUMENTATION]\n  // From [concept].mdx lines XX-YY\n  // ============================================================\n  \n  describe('[Second Section]', () => {\n    // From lines XX-YY: [Description]\n    it('should [behavior]', () => {\n      // Test\n    })\n  })\n  \n  // ============================================================\n  // EDGE CASES AND COMMON MISTAKES\n  // From [concept].mdx lines XX-YY\n  // ============================================================\n  \n  describe('Edge Cases', () => {\n    // From lines XX-YY: [Edge case description]\n    it('should handle [edge case]', () => {\n      // Test\n    })\n  })\n  \n  describe('Common Mistakes', () => {\n    // From lines XX-YY: Wrong way example\n    it('should demonstrate the incorrect behavior', () => {\n      // Test showing why the \"wrong\" way fails\n    })\n    \n    // From lines XX-YY: Correct way example\n    it('should demonstrate the correct behavior', () => {\n      // Test showing the right approach\n    })\n  })\n})\n```\n\n---\n\n## Complete DOM Test File Template\n\n```javascript\n/**\n * @vitest-environment jsdom\n */\nimport { describe, it, expect, vi, beforeEach, afterEach } from 'vitest'\n\n// ============================================================\n// DOM EXAMPLES FROM [CONCEPT NAME]\n// From [concept].mdx lines XX-YY\n// ============================================================\n\ndescribe('[Concept Name] - DOM', () => {\n  // Shared setup\n  let container\n  \n  beforeEach(() => {\n    // Create a fresh container for each test\n    container = document.createElement('div')\n    container.id = 'test-container'\n    document.body.appendChild(container)\n  })\n  \n  afterEach(() => {\n    // Clean up after each test\n    document.body.innerHTML = ''\n    vi.restoreAllMocks()\n  })\n  \n  // ============================================================\n  // [SECTION NAME]\n  // From lines XX-YY\n  // ============================================================\n  \n  describe('[Section Name]', () => {\n    // From lines XX-YY: [Example description]\n    it('should [expected DOM behavior]', () => {\n      // Setup\n      const element = document.createElement('div')\n      container.appendChild(element)\n      \n      // Action\n      element.textContent = 'Hello'\n      \n      // Assert\n      expect(element.textContent).toBe('Hello')\n    })\n  })\n  \n  // ============================================================\n  // EVENT HANDLING\n  // From lines XX-YY\n  // ============================================================\n  \n  describe('Event Handling', () => {\n    // From lines XX-YY: Click event example\n    it('should handle click events', () => {\n      const button = document.createElement('button')\n      container.appendChild(button)\n      \n      let clicked = false\n      button.addEventListener('click', () => {\n        clicked = true\n      })\n      \n      button.click()\n      \n      expect(clicked).toBe(true)\n    })\n  })\n})\n```\n\n---\n\n## Running Tests\n\n```bash\n# Run all tests\nnpm test\n\n# Run tests for specific concept\nnpm test -- tests/fundamentals/primitive-types/\n\n# Run tests for specific file\nnpm test -- tests/fundamentals/primitive-types/primitive-types.test.js\n\n# Run DOM tests only\nnpm test -- tests/fundamentals/primitive-types/primitive-types.dom.test.js\n\n# Run with watch mode\nnpm run test:watch\n\n# Run with coverage\nnpm run test:coverage\n\n# Run with verbose output\nnpm test -- --reporter=verbose\n```\n\n---\n\n## Quality Checklist\n\n### Completeness\n- [ ] All testable code examples have corresponding tests\n- [ ] Tests organized by documentation sections\n- [ ] Source line references included in comments (From lines XX-YY)\n- [ ] DOM tests in separate `.dom.test.js` file\n- [ ] Edge cases and error examples tested\n\n### Correctness\n- [ ] Tests verify the actual documented behavior\n- [ ] Output comments in docs match test expectations\n- [ ] Async tests properly use async/await\n- [ ] Error tests use correct `toThrow` pattern\n- [ ] Floating point comparisons use `toBeCloseTo`\n- [ ] Object comparisons use `toEqual` (not `toBe`)\n\n### Convention\n- [ ] Uses explicit imports from vitest\n- [ ] Follows describe/it nesting pattern\n- [ ] Test names start with \"should\"\n- [ ] Proper file naming (`{concept}.test.js`)\n- [ ] DOM tests have jsdom environment directive\n\n### Verification\n- [ ] All tests pass: `npm test -- tests/{category}/{concept}/`\n- [ ] No skipped tests without documented reason\n- [ ] No false positives (tests that pass for wrong reasons)\n\n---\n\n## Test Report Template\n\nUse this template to document test coverage for a concept page.\n\n```markdown\n# Test Coverage Report: [Concept Name]\n\n**Concept Page:** `/docs/concepts/[slug].mdx`\n**Test File:** `/tests/{category}/{concept}/{concept}.test.js`\n**DOM Test File:** `/tests/{category}/{concept}/{concept}.dom.test.js` (if applicable)\n**Date:** YYYY-MM-DD\n**Author:** [Name/Claude]\n\n## Summary\n\n| Metric | Count |\n|--------|-------|\n| Total Code Examples in Doc | XX |\n| Testable Examples | XX |\n| Tests Written | XX |\n| DOM Tests Written | XX |\n| Skipped (with reason) | XX |\n\n## Tests by Section\n\n| Section | Line Range | Examples | Tests | Status |\n|---------|------------|----------|-------|--------|\n| [Section 1] | XX-YY | X | X | âœ… |\n| [Section 2] | XX-YY | X | X | âœ… |\n| [Section 3] | XX-YY | X | X | âš ï¸ (1 skipped) |\n\n## Skipped Examples\n\n| Line | Example Description | Reason |\n|------|---------------------|--------|\n| XX | ASCII diagram of call stack | Conceptual, not executable |\n| YY | Browser fetch example | Requires network, mocked instead |\n\n## Test Execution\n\n```bash\nnpm test -- tests/{category}/{concept}/\n```\n\n**Result:** âœ… XX passing | âŒ X failing | â­ï¸ X skipped\n\n## Notes\n\n[Any special considerations, mock requirements, or issues encountered]\n```\n\n---\n\n## Common Issues and Solutions\n\n### Issue: Test passes but shouldn't\n\n**Problem:** Test expectations don't match documentation output\n\n**Solution:** Double-check the expected value matches the `console.log` comment exactly\n\n```javascript\n// Documentation says: console.log(result)  // [1, 2, 3]\n// Make sure test uses:\nexpect(result).toEqual([1, 2, 3])  // NOT toBe for arrays\n```\n\n### Issue: Async test times out\n\n**Problem:** Async test never resolves\n\n**Solution:** Ensure all promises are awaited and async function is marked\n\n```javascript\n// Bad\nit('should fetch data', () => {\n  const data = fetchData()  // Missing await!\n  expect(data).toBeDefined()\n})\n\n// Good\nit('should fetch data', async () => {\n  const data = await fetchData()\n  expect(data).toBeDefined()\n})\n```\n\n### Issue: DOM test fails with \"document is not defined\"\n\n**Problem:** Missing jsdom environment\n\n**Solution:** Add environment directive at top of file\n\n```javascript\n/**\n * @vitest-environment jsdom\n */\n```\n\n### Issue: Test isolation problems\n\n**Problem:** Tests affect each other\n\n**Solution:** Use beforeEach/afterEach for cleanup\n\n```javascript\nafterEach(() => {\n  document.body.innerHTML = ''\n  vi.restoreAllMocks()\n})\n```\n\n---\n\n## Summary\n\nWhen writing tests for a concept page:\n\n1. **Extract all code examples** from the documentation\n2. **Categorize** as testable, DOM, error, or conceptual\n3. **Create test file** in correct location with proper naming\n4. **Convert each example** to test using appropriate pattern\n5. **Reference source lines** in comments for traceability\n6. **Run tests** to verify all pass\n7. **Document coverage** using the report template\n\n**Remember:** Tests serve two purposes:\n1. Verify documentation is accurate\n2. Catch regressions if code examples are updated\n\nEvery testable code example in the documentation should have a corresponding test. If an example can't be tested, document why.\n"
      },
      "discovered_at": "2026-01-11T15:35:57.917976Z",
      "fetch_error": null
    },
    {
      "name": "resource-curator",
      "slug": "resource-curator",
      "source": "skillsmp_top",
      "owner": "leonardomso",
      "repo_name": "33-js-concepts",
      "repository_url": "https://github.com/leonardomso/33-js-concepts",
      "skill_path": ".opencode/skill/resource-curator",
      "github_metadata": {
        "stars": 66082,
        "description": "ğŸ“œ 33 JavaScript concepts every developer should know.",
        "default_branch": "master",
        "pushed_at": "2026-01-07T12:51:15Z",
        "created_at": "2018-09-04T13:27:04Z",
        "language": "JavaScript",
        "license": "MIT",
        "open_issues": 0,
        "forks": 9196
      },
      "skill_md": {
        "found": true,
        "path": ".opencode/skill/resource-curator/SKILL.md",
        "branch": "master",
        "content": "---\nname: resource-curator\ndescription: Find, evaluate, and maintain high-quality external resources for JavaScript concept documentation, including auditing for broken and outdated links\n---\n\n# Skill: Resource Curator for Concept Pages\n\nUse this skill to find, evaluate, add, and maintain high-quality external resources (articles, videos, courses) for concept documentation pages. This includes auditing existing resources for broken links and outdated content.\n\n## When to Use\n\n- Adding resources to a new concept page\n- Refreshing resources on existing pages\n- Auditing for broken or outdated links\n- Reviewing community-contributed resources\n- Periodic link maintenance\n\n## Resource Curation Methodology\n\nFollow these five phases for comprehensive resource curation.\n\n### Phase 1: Audit Existing Resources\n\nBefore adding new resources, audit what's already there:\n\n1. **Check link accessibility** â€” Does each link return 200?\n2. **Verify content accuracy** â€” Is the content still correct?\n3. **Check publication dates** â€” Is it too old for the topic?\n4. **Identify outdated content** â€” Does it use old syntax/patterns?\n5. **Review descriptions** â€” Are they specific or generic?\n\n### Phase 2: Identify Resource Gaps\n\nCompare current resources against targets:\n\n| Section | Target Count | Icon |\n|---------|--------------|------|\n| Reference | 2-4 MDN links | `book` |\n| Articles | 4-6 articles | `newspaper` |\n| Videos | 3-4 videos | `video` |\n| Courses | 1-3 (optional) | `graduation-cap` |\n| Books | 1-2 (optional) | `book` |\n\nAsk:\n- Are there enough resources for beginners AND advanced learners?\n- Is there visual content (diagrams, animations)?\n- Are official references (MDN) included?\n- Is there diversity in teaching styles?\n\n### Phase 3: Find New Resources\n\nSearch trusted sources using targeted queries:\n\n**For Articles:**\n```\n[concept] javascript tutorial site:javascript.info\n[concept] javascript explained site:freecodecamp.org\n[concept] javascript site:dev.to\n[concept] javascript deep dive site:2ality.com\n[concept] javascript guide site:css-tricks.com\n```\n\n**For Videos:**\n```\nYouTube: [concept] javascript explained\nYouTube: [concept] javascript tutorial\nYouTube: jsconf [concept]\nYouTube: [concept] javascript fireship\nYouTube: [concept] javascript web dev simplified\n```\n\n**For MDN:**\n```\n[concept] site:developer.mozilla.org\n[API name] MDN\n```\n\n### Phase 4: Write Descriptions\n\nEvery resource needs a specific, valuable description:\n\n**Formula:**\n```\nSentence 1: What makes this resource unique OR what it specifically covers\nSentence 2: Why reader should click (what they'll gain, who it's best for)\n```\n\n### Phase 5: Format and Organize\n\n- Use correct Card syntax with proper icons\n- Order resources logically (foundational first, advanced later)\n- Ensure consistent formatting\n\n---\n\n## Trusted Sources\n\n### Reference Sources (Priority Order)\n\n| Priority | Source | URL | Best For |\n|----------|--------|-----|----------|\n| 1 | MDN Web Docs | developer.mozilla.org | API docs, guides, compatibility |\n| 2 | ECMAScript Spec | tc39.es/ecma262 | Authoritative behavior |\n| 3 | Node.js Docs | nodejs.org/docs | Node-specific APIs |\n| 4 | Web.dev | web.dev | Performance, best practices |\n| 5 | Can I Use | caniuse.com | Browser compatibility |\n\n### Article Sources (Priority Order)\n\n| Priority | Source | Why Trusted |\n|----------|--------|-------------|\n| 1 | javascript.info | Comprehensive, exercises, well-maintained |\n| 2 | MDN Guides | Official, accurate, regularly updated |\n| 3 | freeCodeCamp | Beginner-friendly, practical |\n| 4 | 2ality (Dr. Axel) | Deep technical dives, spec-focused |\n| 5 | CSS-Tricks | DOM, visual topics, well-written |\n| 6 | dev.to (Lydia Hallie) | Visual explanations, animations |\n| 7 | LogRocket Blog | Practical tutorials, real-world |\n| 8 | Smashing Magazine | In-depth, well-researched |\n| 9 | Digital Ocean | Clear tutorials, examples |\n| 10 | Kent C. Dodds | Testing, React, best practices |\n\n### Video Creators (Priority Order)\n\n| Priority | Creator | Style | Best For |\n|----------|---------|-------|----------|\n| 1 | Fireship | Fast, modern, entertaining | Quick overviews, modern JS |\n| 2 | Web Dev Simplified | Clear, beginner-friendly | Beginners, fundamentals |\n| 3 | Fun Fun Function | Deep-dives, personality | Understanding \"why\" |\n| 4 | Traversy Media | Comprehensive crash courses | Full topic coverage |\n| 5 | JSConf/dotJS | Expert conference talks | Advanced, in-depth |\n| 6 | Academind | Thorough explanations | Complete understanding |\n| 7 | The Coding Train | Creative, visual | Visual learners |\n| 8 | Wes Bos | Practical, real-world | Applied learning |\n| 9 | The Net Ninja | Step-by-step tutorials | Following along |\n| 10 | Programming with Mosh | Professional, clear | Career-focused |\n\n### Course Sources\n\n| Source | Type | Notes |\n|--------|------|-------|\n| javascript.info | Free | Comprehensive, exercises |\n| Piccalilli | Free | Well-written, modern |\n| freeCodeCamp | Free | Project-based |\n| Frontend Masters | Paid | Expert instructors |\n| Egghead.io | Paid | Short, focused lessons |\n| Udemy (top-rated) | Paid | Check reviews carefully |\n| Codecademy | Freemium | Interactive |\n\n---\n\n## Quality Criteria\n\n### Must Have (Required)\n\n- [ ] **Link works** â€” Returns 200 (not 404, 301, 5xx)\n- [ ] **JavaScript-focused** â€” Not primarily about C#, Python, Java, etc.\n- [ ] **Technically accurate** â€” No factual errors or anti-patterns\n- [ ] **Accessible** â€” Free or has meaningful free preview\n\n### Should Have (Preferred)\n\n- [ ] **Recent enough** â€” See publication date guidelines below\n- [ ] **Reputable source** â€” From trusted sources list or well-known creator\n- [ ] **Unique perspective** â€” Not duplicate of existing resources\n- [ ] **Appropriate depth** â€” Matches concept complexity\n- [ ] **Good engagement** â€” Positive comments, high views (for videos)\n\n### Red Flags (Reject)\n\n| Red Flag | Why It Matters |\n|----------|----------------|\n| Uses `var` everywhere | Outdated for ES6+ topics |\n| Teaches anti-patterns | Harmful to learners |\n| Primarily other languages | Wrong focus |\n| Hard paywall (no preview) | Inaccessible |\n| Pre-2015 for modern topics | Likely outdated |\n| Low quality comments | Often indicates issues |\n| Factual errors | Spreads misinformation |\n| Clickbait title, thin content | Wastes reader time |\n\n---\n\n## Publication Date Guidelines\n\n| Topic Category | Minimum Year | Reasoning |\n|----------------|--------------|-----------|\n| **ES6+ Features** | 2015+ | ES6 released June 2015 |\n| **Promises** | 2015+ | Native Promises in ES6 |\n| **async/await** | 2017+ | ES2017 feature |\n| **ES Modules** | 2018+ | Stable browser support |\n| **Optional chaining (?.)** | 2020+ | ES2020 feature |\n| **Nullish coalescing (??)** | 2020+ | ES2020 feature |\n| **Top-level await** | 2022+ | ES2022 feature |\n| **Fundamentals** (closures, scope, this) | Any | Core concepts don't change |\n| **DOM manipulation** | 2018+ | Modern APIs preferred |\n| **Fetch API** | 2017+ | Widespread support |\n\n**Rule of thumb:** For time-sensitive topics, prefer content from the last 3-5 years. For fundamentals, older classic content is often excellent.\n\n---\n\n## Description Writing Guide\n\n### The Formula\n\n```\nSentence 1: What makes this resource unique OR what it specifically covers\nSentence 2: Why reader should click (what they'll gain, who it's best for)\n```\n\n### Good Examples\n\n```markdown\n<Card title=\"JavaScript Visualized: Promises & Async/Await â€” Lydia Hallie\" icon=\"newspaper\" href=\"https://dev.to/lydiahallie/javascript-visualized-promises-async-await-5gke\">\n  Animated GIFs showing the call stack, microtask queue, and event loop in action. \n  The visuals make Promise execution order finally click for visual learners.\n</Card>\n\n<Card title=\"What the heck is the event loop anyway? â€” Philip Roberts\" icon=\"video\" href=\"https://www.youtube.com/watch?v=8aGhZQkoFbQ\">\n  The legendary JSConf talk that made the event loop click for millions of developers. \n  Philip Roberts' live visualizations are the gold standard â€” a must-watch.\n</Card>\n\n<Card title=\"You Don't Know JS: Scope & Closures â€” Kyle Simpson\" icon=\"book\" href=\"https://github.com/getify/You-Dont-Know-JS/blob/2nd-ed/scope-closures/README.md\">\n  Kyle Simpson's deep dive into JavaScript's scope mechanics and closure behavior. \n  Goes beyond the basics into edge cases and mental models for truly understanding scope.\n</Card>\n\n<Card title=\"JavaScript Promises in 10 Minutes â€” Web Dev Simplified\" icon=\"video\" href=\"https://www.youtube.com/watch?v=DHvZLI7Db8E\">\n  Quick, clear explanation covering Promise creation, chaining, and error handling. \n  Perfect starting point if you're new to async JavaScript.\n</Card>\n\n<Card title=\"How to Escape Async/Await Hell â€” Aditya Agarwal\" icon=\"newspaper\" href=\"https://medium.com/free-code-camp/avoiding-the-async-await-hell-c77a0fb71c4c\">\n  The pizza-and-drinks ordering analogy makes parallel vs sequential execution crystal clear. \n  Essential reading once you know async/await basics but want to write faster code.\n</Card>\n```\n\n### Bad Examples (Avoid)\n\n```markdown\n<!-- TOO GENERIC -->\n<Card title=\"Promises Tutorial\" icon=\"newspaper\" href=\"...\">\n  A comprehensive guide to Promises in JavaScript.\n</Card>\n\n<!-- NO VALUE PROPOSITION -->\n<Card title=\"Learn Closures\" icon=\"video\" href=\"...\">\n  This video explains closures in JavaScript.\n</Card>\n\n<!-- VAGUE, NO SPECIFICS -->\n<Card title=\"JavaScript Guide\" icon=\"newspaper\" href=\"...\">\n  Everything you need to know about JavaScript.\n</Card>\n\n<!-- JUST RESTATING THE TITLE -->\n<Card title=\"Understanding the Event Loop\" icon=\"video\" href=\"...\">\n  A video about understanding the event loop.\n</Card>\n```\n\n### Words and Phrases to Avoid\n\n| Avoid | Why | Use Instead |\n|-------|-----|-------------|\n| \"comprehensive guide to...\" | Vague, overused | Specify what's covered |\n| \"learn all about...\" | Generic | What specifically will they learn? |\n| \"everything you need to know...\" | Hyperbolic | Be specific |\n| \"great tutorial on...\" | Subjective filler | Why is it great? |\n| \"explains X\" | Too basic | How does it explain? What's unique? |\n| \"in-depth look at...\" | Vague | What depth? What aspect? |\n\n### Words and Phrases That Work\n\n| Good Phrase | Example |\n|-------------|---------|\n| \"step-by-step walkthrough\" | \"Step-by-step walkthrough of building a Promise from scratch\" |\n| \"visual explanation\" | \"Visual explanation with animated diagrams\" |\n| \"deep dive into\" | \"Deep dive into V8's optimization strategies\" |\n| \"practical examples of\" | \"Practical examples of closures in React hooks\" |\n| \"the go-to reference for\" | \"The go-to reference for array method signatures\" |\n| \"finally makes X click\" | \"Finally makes prototype chains click\" |\n| \"perfect for beginners\" | \"Perfect for beginners new to async code\" |\n| \"covers X, Y, and Z\" | \"Covers creation, chaining, and error handling\" |\n\n---\n\n## Link Audit Process\n\n### Step 1: Check Each Link\n\nFor each resource in the concept page:\n\n1. **Click the link** â€” Does it load?\n2. **Note the HTTP status:**\n\n| Status | Meaning | Action |\n|--------|---------|--------|\n| 200 | OK | Keep, continue to content check |\n| 301/302 | Redirect | Update to final URL |\n| 404 | Not Found | Remove or find replacement |\n| 403 | Forbidden | Check manually, may be geo-blocked |\n| 5xx | Server Error | Retry later, may be temporary |\n\n### Step 2: Content Verification\n\nFor each accessible link:\n\n1. **Skim the content** â€” Is it still accurate?\n2. **Check the date** â€” When was it published/updated?\n3. **Verify JavaScript focus** â€” Is it primarily about JS?\n4. **Look for red flags** â€” Anti-patterns, errors, outdated syntax\n\n### Step 3: Description Review\n\nFor each resource:\n\n1. **Read current description** â€” Is it specific?\n2. **Compare to actual content** â€” Does it match?\n3. **Check for generic phrases** â€” \"comprehensive guide\", etc.\n4. **Identify improvements** â€” How can it be more specific?\n\n### Step 4: Gap Analysis\n\nAfter auditing all resources:\n\n1. **Count by section** â€” Do we meet targets?\n2. **Check diversity** â€” Beginner AND advanced? Visual AND text?\n3. **Identify missing types** â€” No MDN? No videos?\n4. **Note recommendations** â€” What should we add?\n\n---\n\n## Resource Section Templates\n\n### Reference Section\n\n```markdown\n## Reference\n\n<CardGroup cols={2}>\n  <Card title=\"[Main Topic] â€” MDN\" icon=\"book\" href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/...\">\n    Official MDN documentation covering [specific aspects]. \n    The authoritative reference for [what it's best for].\n  </Card>\n  <Card title=\"[Related API/Concept] â€” MDN\" icon=\"book\" href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/...\">\n    [What this reference covers]. \n    Essential reading for understanding [specific aspect].\n  </Card>\n</CardGroup>\n```\n\n### Articles Section\n\n```markdown\n## Articles\n\n<CardGroup cols={2}>\n  <Card title=\"[Article Title]\" icon=\"newspaper\" href=\"...\">\n    [What makes it unique/what it covers]. \n    [Why read this one/who it's for].\n  </Card>\n  <Card title=\"[Article Title]\" icon=\"newspaper\" href=\"...\">\n    [Specific coverage]. \n    [Value proposition].\n  </Card>\n  <Card title=\"[Article Title]\" icon=\"newspaper\" href=\"...\">\n    [Unique angle]. \n    [Why it's worth reading].\n  </Card>\n  <Card title=\"[Article Title]\" icon=\"newspaper\" href=\"...\">\n    [What it covers]. \n    [Best for whom].\n  </Card>\n</CardGroup>\n```\n\n### Videos Section\n\n```markdown\n## Videos\n\n<CardGroup cols={2}>\n  <Card title=\"[Video Title] â€” [Creator]\" icon=\"video\" href=\"https://www.youtube.com/watch?v=...\">\n    [What it covers/unique approach]. \n    [Why watch/who it's for].\n  </Card>\n  <Card title=\"[Video Title] â€” [Creator]\" icon=\"video\" href=\"https://www.youtube.com/watch?v=...\">\n    [Specific focus]. \n    [What makes it stand out].\n  </Card>\n  <Card title=\"[Video Title] â€” [Creator]\" icon=\"video\" href=\"https://www.youtube.com/watch?v=...\">\n    [Coverage]. \n    [Value].\n  </Card>\n</CardGroup>\n```\n\n### Books Section (Optional)\n\n```markdown\n<Card title=\"[Book Title] â€” [Author]\" icon=\"book\" href=\"...\">\n  [What the book covers and its approach]. \n  [Who should read it and what they'll gain].\n</Card>\n```\n\n### Courses Section (Optional)\n\n```markdown\n<CardGroup cols={2}>\n  <Card title=\"[Course Title] â€” [Platform]\" icon=\"graduation-cap\" href=\"...\">\n    [What the course covers]. \n    [Format and who it's best for].\n  </Card>\n</CardGroup>\n```\n\n---\n\n## Resource Audit Report Template\n\nUse this template to document audit findings.\n\n```markdown\n# Resource Audit Report: [Concept Name]\n\n**File:** `/docs/concepts/[slug].mdx`\n**Date:** YYYY-MM-DD\n**Auditor:** [Name/Claude]\n\n---\n\n## Summary\n\n| Metric | Count |\n|--------|-------|\n| Total Resources | XX |\n| Working Links (200) | XX |\n| Broken Links (404) | XX |\n| Redirects (301/302) | XX |\n| Outdated Content | XX |\n| Generic Descriptions | XX |\n\n## Resource Count vs Targets\n\n| Section | Current | Target | Status |\n|---------|---------|--------|--------|\n| Reference (MDN) | X | 2-4 | âœ…/âš ï¸/âŒ |\n| Articles | X | 4-6 | âœ…/âš ï¸/âŒ |\n| Videos | X | 3-4 | âœ…/âš ï¸/âŒ |\n| Courses | X | 0-3 | âœ…/âš ï¸/âŒ |\n\n---\n\n## Broken Links (Remove or Replace)\n\n| Resource | Line | URL | Status | Action |\n|----------|------|-----|--------|--------|\n| [Title] | XX | [URL] | 404 | Remove |\n| [Title] | XX | [URL] | 404 | Replace with [alternative] |\n\n---\n\n## Redirects (Update URLs)\n\n| Resource | Line | Old URL | New URL |\n|----------|------|---------|---------|\n| [Title] | XX | [old] | [new] |\n\n---\n\n## Outdated Resources (Consider Replacing)\n\n| Resource | Line | Issue | Recommendation |\n|----------|------|-------|----------------|\n| [Title] | XX | Published 2014, uses var throughout | Replace with [modern alternative] |\n| [Title] | XX | Pre-ES6, no mention of let/const | Find updated version or replace |\n\n---\n\n## Description Improvements Needed\n\n| Resource | Line | Current | Suggested |\n|----------|------|---------|-----------|\n| [Title] | XX | \"A guide to closures\" | \"[Specific description with value prop]\" |\n| [Title] | XX | \"Learn about promises\" | \"[What makes it unique]. [Why read it].\" |\n\n---\n\n## Missing Resources (Recommendations)\n\n| Type | Gap | Suggested Resource | URL |\n|------|-----|-------------------|-----|\n| Reference | No main MDN link | [Topic] â€” MDN | [URL] |\n| Article | No beginner guide | [Title] â€” javascript.info | [URL] |\n| Video | No visual explanation | [Title] â€” [Creator] | [URL] |\n| Article | No advanced deep-dive | [Title] â€” 2ality | [URL] |\n\n---\n\n## Non-JavaScript Resources (Remove)\n\n| Resource | Line | Issue |\n|----------|------|-------|\n| [Title] | XX | Primarily about C#, not JavaScript |\n\n---\n\n## Action Items\n\n### High Priority (Do First)\n1. **Remove broken link:** [Title] (line XX)\n2. **Add missing MDN reference:** [Topic]\n3. **Replace outdated resource:** [Title] with [alternative]\n\n### Medium Priority\n1. **Update redirect URL:** [Title] (line XX)\n2. **Improve description:** [Title] (line XX)\n3. **Add beginner-friendly article**\n\n### Low Priority\n1. **Add additional video resource**\n2. **Consider adding course section**\n\n---\n\n## Verification Checklist\n\nAfter making changes:\n\n- [ ] All broken links removed or replaced\n- [ ] All redirect URLs updated\n- [ ] Outdated resources replaced\n- [ ] Generic descriptions rewritten\n- [ ] Missing resource types added\n- [ ] Resource counts meet targets\n- [ ] All new links verified working\n- [ ] All descriptions are specific and valuable\n```\n\n---\n\n## Quick Reference\n\n### Icon Reference\n\n| Content Type | Icon Value |\n|--------------|------------|\n| MDN/Official docs | `book` |\n| Articles/Blog posts | `newspaper` |\n| Videos | `video` |\n| Courses | `graduation-cap` |\n| Books | `book` |\n| Related concepts | Context-appropriate |\n\n### Character Guidelines\n\n| Element | Guideline |\n|---------|-----------|\n| Card title | Keep concise, include creator for videos |\n| Description sentence 1 | What it covers / what's unique |\n| Description sentence 2 | Why read/watch / who it's for |\n\n### Resource Ordering\n\nWithin each section, order resources:\n1. **Most foundational/beginner-friendly first**\n2. **Official references before community content**\n3. **Most highly recommended prominently placed**\n4. **Advanced/niche content last**\n\n---\n\n## Quality Checklist\n\n### Link Verification\n- [ ] All links return 200 (not 404, 301)\n- [ ] No redirect chains\n- [ ] No hard paywalls without notice\n- [ ] All URLs are HTTPS where available\n\n### Content Quality\n- [ ] All resources are JavaScript-focused\n- [ ] No resources teaching anti-patterns\n- [ ] Publication dates appropriate for topic\n- [ ] Mix of beginner and advanced content\n- [ ] Visual and text resources included\n\n### Description Quality\n- [ ] All descriptions are specific (not generic)\n- [ ] Descriptions explain unique value\n- [ ] No \"comprehensive guide to...\" phrases\n- [ ] Each description is 2 sentences\n- [ ] Descriptions match actual content\n\n### Completeness\n- [ ] 2-4 MDN/official references\n- [ ] 4-6 quality articles\n- [ ] 3-4 quality videos\n- [ ] Resources ordered logically\n- [ ] Diversity in teaching styles\n\n---\n\n## Summary\n\nWhen curating resources for a concept page:\n\n1. **Audit first** â€” Check all existing links and content\n2. **Identify gaps** â€” Compare against targets (2-4 refs, 4-6 articles, 3-4 videos)\n3. **Find quality resources** â€” Search trusted sources\n4. **Write specific descriptions** â€” What's unique + why read/watch\n5. **Format correctly** â€” Proper Card syntax, icons, ordering\n6. **Document changes** â€” Use the audit report template\n\n**Remember:** Resources should enhance learning, not pad the page. Every link should offer genuine value. Quality over quantity â€” a few excellent resources beat many mediocre ones.\n"
      },
      "discovered_at": "2026-01-11T15:35:58.364753Z",
      "fetch_error": null
    },
    {
      "name": "skill-creator",
      "slug": "skill-creator",
      "source": "skillsmp_top",
      "owner": "openai",
      "repo_name": "codex",
      "repository_url": "https://github.com/openai/codex",
      "skill_path": "codex-rs/core/src/skills/assets/samples/skill-creator",
      "github_metadata": {
        "stars": 55828,
        "description": "Lightweight coding agent that runs in your terminal",
        "default_branch": "main",
        "pushed_at": "2026-01-11T09:16:21Z",
        "created_at": "2025-04-13T05:37:54Z",
        "language": "Rust",
        "license": "Apache-2.0",
        "open_issues": 890,
        "forks": 7181
      },
      "skill_md": {
        "found": true,
        "path": "codex-rs/core/src/skills/assets/samples/skill-creator/SKILL.md",
        "branch": "main",
        "content": "---\nname: skill-creator\ndescription: Guide for creating effective skills. This skill should be used when users want to create a new skill (or update an existing skill) that extends Codex's capabilities with specialized knowledge, workflows, or tool integrations.\nmetadata:\n  short-description: Create or update a skill\n---\n\n# Skill Creator\n\nThis skill provides guidance for creating effective skills.\n\n## About Skills\n\nSkills are modular, self-contained packages that extend Codex's capabilities by providing\nspecialized knowledge, workflows, and tools. Think of them as \"onboarding guides\" for specific\ndomains or tasksâ€”they transform Codex from a general-purpose agent into a specialized agent\nequipped with procedural knowledge that no model can fully possess.\n\n### What Skills Provide\n\n1. Specialized workflows - Multi-step procedures for specific domains\n2. Tool integrations - Instructions for working with specific file formats or APIs\n3. Domain expertise - Company-specific knowledge, schemas, business logic\n4. Bundled resources - Scripts, references, and assets for complex and repetitive tasks\n\n## Core Principles\n\n### Concise is Key\n\nThe context window is a public good. Skills share the context window with everything else Codex needs: system prompt, conversation history, other Skills' metadata, and the actual user request.\n\n**Default assumption: Codex is already very smart.** Only add context Codex doesn't already have. Challenge each piece of information: \"Does Codex really need this explanation?\" and \"Does this paragraph justify its token cost?\"\n\nPrefer concise examples over verbose explanations.\n\n### Set Appropriate Degrees of Freedom\n\nMatch the level of specificity to the task's fragility and variability:\n\n**High freedom (text-based instructions)**: Use when multiple approaches are valid, decisions depend on context, or heuristics guide the approach.\n\n**Medium freedom (pseudocode or scripts with parameters)**: Use when a preferred pattern exists, some variation is acceptable, or configuration affects behavior.\n\n**Low freedom (specific scripts, few parameters)**: Use when operations are fragile and error-prone, consistency is critical, or a specific sequence must be followed.\n\nThink of Codex as exploring a path: a narrow bridge with cliffs needs specific guardrails (low freedom), while an open field allows many routes (high freedom).\n\n### Anatomy of a Skill\n\nEvery skill consists of a required SKILL.md file and optional bundled resources:\n\n```\nskill-name/\nâ”œâ”€â”€ SKILL.md (required)\nâ”‚   â”œâ”€â”€ YAML frontmatter metadata (required)\nâ”‚   â”‚   â”œâ”€â”€ name: (required)\nâ”‚   â”‚   â””â”€â”€ description: (required)\nâ”‚   â””â”€â”€ Markdown instructions (required)\nâ””â”€â”€ Bundled Resources (optional)\n    â”œâ”€â”€ scripts/          - Executable code (Python/Bash/etc.)\n    â”œâ”€â”€ references/       - Documentation intended to be loaded into context as needed\n    â””â”€â”€ assets/           - Files used in output (templates, icons, fonts, etc.)\n```\n\n#### SKILL.md (required)\n\nEvery SKILL.md consists of:\n\n- **Frontmatter** (YAML): Contains `name` and `description` fields. These are the only fields that Codex reads to determine when the skill gets used, thus it is very important to be clear and comprehensive in describing what the skill is, and when it should be used.\n- **Body** (Markdown): Instructions and guidance for using the skill. Only loaded AFTER the skill triggers (if at all).\n\n#### Bundled Resources (optional)\n\n##### Scripts (`scripts/`)\n\nExecutable code (Python/Bash/etc.) for tasks that require deterministic reliability or are repeatedly rewritten.\n\n- **When to include**: When the same code is being rewritten repeatedly or deterministic reliability is needed\n- **Example**: `scripts/rotate_pdf.py` for PDF rotation tasks\n- **Benefits**: Token efficient, deterministic, may be executed without loading into context\n- **Note**: Scripts may still need to be read by Codex for patching or environment-specific adjustments\n\n##### References (`references/`)\n\nDocumentation and reference material intended to be loaded as needed into context to inform Codex's process and thinking.\n\n- **When to include**: For documentation that Codex should reference while working\n- **Examples**: `references/finance.md` for financial schemas, `references/mnda.md` for company NDA template, `references/policies.md` for company policies, `references/api_docs.md` for API specifications\n- **Use cases**: Database schemas, API documentation, domain knowledge, company policies, detailed workflow guides\n- **Benefits**: Keeps SKILL.md lean, loaded only when Codex determines it's needed\n- **Best practice**: If files are large (>10k words), include grep search patterns in SKILL.md\n- **Avoid duplication**: Information should live in either SKILL.md or references files, not both. Prefer references files for detailed information unless it's truly core to the skillâ€”this keeps SKILL.md lean while making information discoverable without hogging the context window. Keep only essential procedural instructions and workflow guidance in SKILL.md; move detailed reference material, schemas, and examples to references files.\n\n##### Assets (`assets/`)\n\nFiles not intended to be loaded into context, but rather used within the output Codex produces.\n\n- **When to include**: When the skill needs files that will be used in the final output\n- **Examples**: `assets/logo.png` for brand assets, `assets/slides.pptx` for PowerPoint templates, `assets/frontend-template/` for HTML/React boilerplate, `assets/font.ttf` for typography\n- **Use cases**: Templates, images, icons, boilerplate code, fonts, sample documents that get copied or modified\n- **Benefits**: Separates output resources from documentation, enables Codex to use files without loading them into context\n\n#### What to Not Include in a Skill\n\nA skill should only contain essential files that directly support its functionality. Do NOT create extraneous documentation or auxiliary files, including:\n\n- README.md\n- INSTALLATION_GUIDE.md\n- QUICK_REFERENCE.md\n- CHANGELOG.md\n- etc.\n\nThe skill should only contain the information needed for an AI agent to do the job at hand. It should not contain auxiliary context about the process that went into creating it, setup and testing procedures, user-facing documentation, etc. Creating additional documentation files just adds clutter and confusion.\n\n### Progressive Disclosure Design Principle\n\nSkills use a three-level loading system to manage context efficiently:\n\n1. **Metadata (name + description)** - Always in context (~100 words)\n2. **SKILL.md body** - When skill triggers (<5k words)\n3. **Bundled resources** - As needed by Codex (Unlimited because scripts can be executed without reading into context window)\n\n#### Progressive Disclosure Patterns\n\nKeep SKILL.md body to the essentials and under 500 lines to minimize context bloat. Split content into separate files when approaching this limit. When splitting out content into other files, it is very important to reference them from SKILL.md and describe clearly when to read them, to ensure the reader of the skill knows they exist and when to use them.\n\n**Key principle:** When a skill supports multiple variations, frameworks, or options, keep only the core workflow and selection guidance in SKILL.md. Move variant-specific details (patterns, examples, configuration) into separate reference files.\n\n**Pattern 1: High-level guide with references**\n\n```markdown\n# PDF Processing\n\n## Quick start\n\nExtract text with pdfplumber:\n[code example]\n\n## Advanced features\n\n- **Form filling**: See [FORMS.md](FORMS.md) for complete guide\n- **API reference**: See [REFERENCE.md](REFERENCE.md) for all methods\n- **Examples**: See [EXAMPLES.md](EXAMPLES.md) for common patterns\n```\n\nCodex loads FORMS.md, REFERENCE.md, or EXAMPLES.md only when needed.\n\n**Pattern 2: Domain-specific organization**\n\nFor Skills with multiple domains, organize content by domain to avoid loading irrelevant context:\n\n```\nbigquery-skill/\nâ”œâ”€â”€ SKILL.md (overview and navigation)\nâ””â”€â”€ reference/\n    â”œâ”€â”€ finance.md (revenue, billing metrics)\n    â”œâ”€â”€ sales.md (opportunities, pipeline)\n    â”œâ”€â”€ product.md (API usage, features)\n    â””â”€â”€ marketing.md (campaigns, attribution)\n```\n\nWhen a user asks about sales metrics, Codex only reads sales.md.\n\nSimilarly, for skills supporting multiple frameworks or variants, organize by variant:\n\n```\ncloud-deploy/\nâ”œâ”€â”€ SKILL.md (workflow + provider selection)\nâ””â”€â”€ references/\n    â”œâ”€â”€ aws.md (AWS deployment patterns)\n    â”œâ”€â”€ gcp.md (GCP deployment patterns)\n    â””â”€â”€ azure.md (Azure deployment patterns)\n```\n\nWhen the user chooses AWS, Codex only reads aws.md.\n\n**Pattern 3: Conditional details**\n\nShow basic content, link to advanced content:\n\n```markdown\n# DOCX Processing\n\n## Creating documents\n\nUse docx-js for new documents. See [DOCX-JS.md](DOCX-JS.md).\n\n## Editing documents\n\nFor simple edits, modify the XML directly.\n\n**For tracked changes**: See [REDLINING.md](REDLINING.md)\n**For OOXML details**: See [OOXML.md](OOXML.md)\n```\n\nCodex reads REDLINING.md or OOXML.md only when the user needs those features.\n\n**Important guidelines:**\n\n- **Avoid deeply nested references** - Keep references one level deep from SKILL.md. All reference files should link directly from SKILL.md.\n- **Structure longer reference files** - For files longer than 100 lines, include a table of contents at the top so Codex can see the full scope when previewing.\n\n## Skill Creation Process\n\nSkill creation involves these steps:\n\n1. Understand the skill with concrete examples\n2. Plan reusable skill contents (scripts, references, assets)\n3. Initialize the skill (run init_skill.py)\n4. Edit the skill (implement resources and write SKILL.md)\n5. Package the skill (run package_skill.py)\n6. Iterate based on real usage\n\nFollow these steps in order, skipping only if there is a clear reason why they are not applicable.\n\n### Skill Naming\n\n- Use lowercase letters, digits, and hyphens only; normalize user-provided titles to hyphen-case (e.g., \"Plan Mode\" -> `plan-mode`).\n- When generating names, generate a name under 64 characters (letters, digits, hyphens).\n- Prefer short, verb-led phrases that describe the action.\n- Namespace by tool when it improves clarity or triggering (e.g., `gh-address-comments`, `linear-address-issue`).\n- Name the skill folder exactly after the skill name.\n\n### Step 1: Understanding the Skill with Concrete Examples\n\nSkip this step only when the skill's usage patterns are already clearly understood. It remains valuable even when working with an existing skill.\n\nTo create an effective skill, clearly understand concrete examples of how the skill will be used. This understanding can come from either direct user examples or generated examples that are validated with user feedback.\n\nFor example, when building an image-editor skill, relevant questions include:\n\n- \"What functionality should the image-editor skill support? Editing, rotating, anything else?\"\n- \"Can you give some examples of how this skill would be used?\"\n- \"I can imagine users asking for things like 'Remove the red-eye from this image' or 'Rotate this image'. Are there other ways you imagine this skill being used?\"\n- \"What would a user say that should trigger this skill?\"\n\nTo avoid overwhelming users, avoid asking too many questions in a single message. Start with the most important questions and follow up as needed for better effectiveness.\n\nConclude this step when there is a clear sense of the functionality the skill should support.\n\n### Step 2: Planning the Reusable Skill Contents\n\nTo turn concrete examples into an effective skill, analyze each example by:\n\n1. Considering how to execute on the example from scratch\n2. Identifying what scripts, references, and assets would be helpful when executing these workflows repeatedly\n\nExample: When building a `pdf-editor` skill to handle queries like \"Help me rotate this PDF,\" the analysis shows:\n\n1. Rotating a PDF requires re-writing the same code each time\n2. A `scripts/rotate_pdf.py` script would be helpful to store in the skill\n\nExample: When designing a `frontend-webapp-builder` skill for queries like \"Build me a todo app\" or \"Build me a dashboard to track my steps,\" the analysis shows:\n\n1. Writing a frontend webapp requires the same boilerplate HTML/React each time\n2. An `assets/hello-world/` template containing the boilerplate HTML/React project files would be helpful to store in the skill\n\nExample: When building a `big-query` skill to handle queries like \"How many users have logged in today?\" the analysis shows:\n\n1. Querying BigQuery requires re-discovering the table schemas and relationships each time\n2. A `references/schema.md` file documenting the table schemas would be helpful to store in the skill\n\nTo establish the skill's contents, analyze each concrete example to create a list of the reusable resources to include: scripts, references, and assets.\n\n### Step 3: Initializing the Skill\n\nAt this point, it is time to actually create the skill.\n\nSkip this step only if the skill being developed already exists, and iteration or packaging is needed. In this case, continue to the next step.\n\nWhen creating a new skill from scratch, always run the `init_skill.py` script. The script conveniently generates a new template skill directory that automatically includes everything a skill requires, making the skill creation process much more efficient and reliable.\n\nUsage:\n\n```bash\nscripts/init_skill.py <skill-name> --path <output-directory> [--resources scripts,references,assets] [--examples]\n```\n\nExamples:\n\n```bash\nscripts/init_skill.py my-skill --path skills/public\nscripts/init_skill.py my-skill --path skills/public --resources scripts,references\nscripts/init_skill.py my-skill --path skills/public --resources scripts --examples\n```\n\nThe script:\n\n- Creates the skill directory at the specified path\n- Generates a SKILL.md template with proper frontmatter and TODO placeholders\n- Optionally creates resource directories based on `--resources`\n- Optionally adds example files when `--examples` is set\n\nAfter initialization, customize the SKILL.md and add resources as needed. If you used `--examples`, replace or delete placeholder files.\n\n### Step 4: Edit the Skill\n\nWhen editing the (newly-generated or existing) skill, remember that the skill is being created for another instance of Codex to use. Include information that would be beneficial and non-obvious to Codex. Consider what procedural knowledge, domain-specific details, or reusable assets would help another Codex instance execute these tasks more effectively.\n\n#### Learn Proven Design Patterns\n\nConsult these helpful guides based on your skill's needs:\n\n- **Multi-step processes**: See references/workflows.md for sequential workflows and conditional logic\n- **Specific output formats or quality standards**: See references/output-patterns.md for template and example patterns\n\nThese files contain established best practices for effective skill design.\n\n#### Start with Reusable Skill Contents\n\nTo begin implementation, start with the reusable resources identified above: `scripts/`, `references/`, and `assets/` files. Note that this step may require user input. For example, when implementing a `brand-guidelines` skill, the user may need to provide brand assets or templates to store in `assets/`, or documentation to store in `references/`.\n\nAdded scripts must be tested by actually running them to ensure there are no bugs and that the output matches what is expected. If there are many similar scripts, only a representative sample needs to be tested to ensure confidence that they all work while balancing time to completion.\n\nIf you used `--examples`, delete any placeholder files that are not needed for the skill. Only create resource directories that are actually required.\n\n#### Update SKILL.md\n\n**Writing Guidelines:** Always use imperative/infinitive form.\n\n##### Frontmatter\n\nWrite the YAML frontmatter with `name` and `description`:\n\n- `name`: The skill name\n- `description`: This is the primary triggering mechanism for your skill, and helps Codex understand when to use the skill.\n  - Include both what the Skill does and specific triggers/contexts for when to use it.\n  - Include all \"when to use\" information here - Not in the body. The body is only loaded after triggering, so \"When to Use This Skill\" sections in the body are not helpful to Codex.\n  - Example description for a `docx` skill: \"Comprehensive document creation, editing, and analysis with support for tracked changes, comments, formatting preservation, and text extraction. Use when Codex needs to work with professional documents (.docx files) for: (1) Creating new documents, (2) Modifying or editing content, (3) Working with tracked changes, (4) Adding comments, or any other document tasks\"\n\nEnsure the frontmatter is valid YAML. Keep `name` and `description` as single-line scalars. If either could be interpreted as YAML syntax, wrap it in quotes.\n\nDo not include any other fields in YAML frontmatter.\n\n##### Body\n\nWrite instructions for using the skill and its bundled resources.\n\n### Step 5: Packaging a Skill\n\nOnce development of the skill is complete, it must be packaged into a distributable .skill file that gets shared with the user. The packaging process automatically validates the skill first to ensure it meets all requirements:\n\n```bash\nscripts/package_skill.py <path/to/skill-folder>\n```\n\nOptional output directory specification:\n\n```bash\nscripts/package_skill.py <path/to/skill-folder> ./dist\n```\n\nThe packaging script will:\n\n1. **Validate** the skill automatically, checking:\n\n   - YAML frontmatter format and required fields\n   - Skill naming conventions and directory structure\n   - Description completeness and quality\n   - File organization and resource references\n\n2. **Package** the skill if validation passes, creating a .skill file named after the skill (e.g., `my-skill.skill`) that includes all files and maintains the proper directory structure for distribution. The .skill file is a zip file with a .skill extension.\n\nIf validation fails, the script will report the errors and exit without creating a package. Fix any validation errors and run the packaging command again.\n\n### Step 6: Iterate\n\nAfter testing the skill, users may request improvements. Often this happens right after using the skill, with fresh context of how the skill performed.\n\n**Iteration workflow:**\n\n1. Use the skill on real tasks\n2. Notice struggles or inefficiencies\n3. Identify how SKILL.md or bundled resources should be updated\n4. Implement changes and test again\n"
      },
      "discovered_at": "2026-01-11T15:35:58.879920Z",
      "fetch_error": null
    },
    {
      "name": "skill-installer",
      "slug": "skill-installer",
      "source": "skillsmp_top",
      "owner": "openai",
      "repo_name": "codex",
      "repository_url": "https://github.com/openai/codex",
      "skill_path": "codex-rs/core/src/skills/assets/samples/skill-installer",
      "github_metadata": {
        "stars": 55828,
        "description": "Lightweight coding agent that runs in your terminal",
        "default_branch": "main",
        "pushed_at": "2026-01-11T09:16:21Z",
        "created_at": "2025-04-13T05:37:54Z",
        "language": "Rust",
        "license": "Apache-2.0",
        "open_issues": 890,
        "forks": 7181
      },
      "skill_md": {
        "found": true,
        "path": "codex-rs/core/src/skills/assets/samples/skill-installer/SKILL.md",
        "branch": "main",
        "content": "---\nname: skill-installer\ndescription: Install Codex skills into $CODEX_HOME/skills from a curated list or a GitHub repo path. Use when a user asks to list installable skills, install a curated skill, or install a skill from another repo (including private repos).\nmetadata:\n  short-description: Install curated skills from openai/skills or other repos\n---\n\n# Skill Installer\n\nHelps install skills. By default these are from https://github.com/openai/skills/tree/main/skills/.curated, but users can also provide other locations.\n\nUse the helper scripts based on the task:\n- List curated skills when the user asks what is available, or if the user uses this skill without specifying what to do.\n- Install from the curated list when the user provides a skill name.\n- Install from another repo when the user provides a GitHub repo/path (including private repos).\n\nInstall skills with the helper scripts.\n\n## Communication\n\nWhen listing curated skills, output approximately as follows, depending on the context of the user's request:\n\"\"\"\nSkills from {repo}:\n1. skill-1\n2. skill-2 (already installed)\n3. ...\nWhich ones would you like installed?\n\"\"\"\n\nAfter installing a skill, tell the user: \"Restart Codex to pick up new skills.\"\n\n## Scripts\n\nAll of these scripts use network, so when running in the sandbox, request escalation when running them.\n\n- `scripts/list-curated-skills.py` (prints curated list with installed annotations)\n- `scripts/list-curated-skills.py --format json`\n- `scripts/install-skill-from-github.py --repo <owner>/<repo> --path <path/to/skill> [<path/to/skill> ...]`\n- `scripts/install-skill-from-github.py --url https://github.com/<owner>/<repo>/tree/<ref>/<path>`\n\n## Behavior and Options\n\n- Defaults to direct download for public GitHub repos.\n- If download fails with auth/permission errors, falls back to git sparse checkout.\n- Aborts if the destination skill directory already exists.\n- Installs into `$CODEX_HOME/skills/<skill-name>` (defaults to `~/.codex/skills`).\n- Multiple `--path` values install multiple skills in one run, each named from the path basename unless `--name` is supplied.\n- Options: `--ref <ref>` (default `main`), `--dest <path>`, `--method auto|download|git`.\n\n## Notes\n\n- Curated listing is fetched from `https://github.com/openai/skills/tree/main/skills/.curated` via the GitHub API. If it is unavailable, explain the error and exit.\n- Private GitHub repos can be accessed via existing git credentials or optional `GITHUB_TOKEN`/`GH_TOKEN` for download.\n- Git fallback tries HTTPS first, then SSH.\n- The skills at https://github.com/openai/skills/tree/main/skills/.system are preinstalled, so no need to help users install those. If they ask, just explain this. If they insist, you can download and overwrite.\n- Installed annotations come from `$CODEX_HOME/skills`.\n"
      },
      "discovered_at": "2026-01-11T15:35:59.382726Z",
      "fetch_error": null
    },
    {
      "name": "claude-opus-4-5-migration",
      "slug": "claude-opus-4-5-migration",
      "source": "skillsmp_top",
      "owner": "anthropics",
      "repo_name": "claude-code",
      "repository_url": "https://github.com/anthropics/claude-code",
      "skill_path": "plugins/claude-opus-4-5-migration/skills/claude-opus-4-5-migration",
      "github_metadata": {
        "stars": 55095,
        "description": "Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands.",
        "default_branch": "main",
        "pushed_at": "2026-01-11T00:28:28Z",
        "created_at": "2025-02-22T17:41:21Z",
        "language": "Shell",
        "license": null,
        "open_issues": 4495,
        "forks": 3984
      },
      "skill_md": {
        "found": true,
        "path": "plugins/claude-opus-4-5-migration/skills/claude-opus-4-5-migration/SKILL.md",
        "branch": "main",
        "content": "---\nname: claude-opus-4-5-migration\ndescription: Migrate prompts and code from Claude Sonnet 4.0, Sonnet 4.5, or Opus 4.1 to Opus 4.5. Use when the user wants to update their codebase, prompts, or API calls to use Opus 4.5. Handles model string updates and prompt adjustments for known Opus 4.5 behavioral differences. Does NOT migrate Haiku 4.5.\n---\n\n# Opus 4.5 Migration Guide\n\nOne-shot migration from Sonnet 4.0, Sonnet 4.5, or Opus 4.1 to Opus 4.5.\n\n## Migration Workflow\n\n1. Search codebase for model strings and API calls\n2. Update model strings to Opus 4.5 (see platform-specific strings below)\n3. Remove unsupported beta headers\n4. Add effort parameter set to `\"high\"` (see `references/effort.md`)\n5. Summarize all changes made\n6. Tell the user: \"If you encounter any issues with Opus 4.5, let me know and I can help adjust your prompts.\"\n\n## Model String Updates\n\nIdentify which platform the codebase uses, then replace model strings accordingly.\n\n### Unsupported Beta Headers\n\nRemove the `context-1m-2025-08-07` beta header if presentâ€”it is not yet supported with Opus 4.5. Leave a comment noting this:\n\n```python\n# Note: 1M context beta (context-1m-2025-08-07) not yet supported with Opus 4.5\n```\n\n### Target Model Strings (Opus 4.5)\n\n| Platform | Opus 4.5 Model String |\n|----------|----------------------|\n| Anthropic API (1P) | `claude-opus-4-5-20251101` |\n| AWS Bedrock | `anthropic.claude-opus-4-5-20251101-v1:0` |\n| Google Vertex AI | `claude-opus-4-5@20251101` |\n| Azure AI Foundry | `claude-opus-4-5-20251101` |\n\n### Source Model Strings to Replace\n\n| Source Model | Anthropic API (1P) | AWS Bedrock | Google Vertex AI |\n|--------------|-------------------|-------------|------------------|\n| Sonnet 4.0 | `claude-sonnet-4-20250514` | `anthropic.claude-sonnet-4-20250514-v1:0` | `claude-sonnet-4@20250514` |\n| Sonnet 4.5 | `claude-sonnet-4-5-20250929` | `anthropic.claude-sonnet-4-5-20250929-v1:0` | `claude-sonnet-4-5@20250929` |\n| Opus 4.1 | `claude-opus-4-1-20250422` | `anthropic.claude-opus-4-1-20250422-v1:0` | `claude-opus-4-1@20250422` |\n\n**Do NOT migrate**: Any Haiku models (e.g., `claude-haiku-4-5-20251001`).\n\n## Prompt Adjustments\n\nOpus 4.5 has known behavioral differences from previous models. **Only apply these fixes if the user explicitly requests them or reports a specific issue.** By default, just update model strings.\n\n**Integration guidelines**: When adding snippets, don't just append them to prompts. Integrate them thoughtfully:\n- Use XML tags (e.g., `<code_guidelines>`, `<tool_usage>`) to organize additions\n- Match the style and structure of the existing prompt\n- Place snippets in logical locations (e.g., coding guidelines near other coding instructions)\n- If the prompt already uses XML tags, add new content within appropriate existing tags or create consistent new ones\n\n### 1. Tool Overtriggering\n\nOpus 4.5 is more responsive to system prompts. Aggressive language that prevented undertriggering on previous models may now cause overtriggering.\n\n**Apply if**: User reports tools being called too frequently or unnecessarily.\n\n**Find and soften**:\n- `CRITICAL:` â†’ remove or soften\n- `You MUST...` â†’ `You should...`\n- `ALWAYS do X` â†’ `Do X`\n- `NEVER skip...` â†’ `Don't skip...`\n- `REQUIRED` â†’ remove or soften\n\nOnly apply to tool-triggering instructions. Leave other uses of emphasis alone.\n\n### 2. Over-Engineering Prevention\n\nOpus 4.5 tends to create extra files, add unnecessary abstractions, or build unrequested flexibility.\n\n**Apply if**: User reports unwanted files, excessive abstraction, or unrequested features. Add the snippet from `references/prompt-snippets.md`.\n\n### 3. Code Exploration\n\nOpus 4.5 can be overly conservative about exploring code, proposing solutions without reading files.\n\n**Apply if**: User reports the model proposing fixes without inspecting relevant code. Add the snippet from `references/prompt-snippets.md`.\n\n### 4. Frontend Design\n\n**Apply if**: User requests improved frontend design quality or reports generic-looking outputs.\n\nAdd the frontend aesthetics snippet from `references/prompt-snippets.md`.\n\n### 5. Thinking Sensitivity\n\nWhen extended thinking is not enabled (the default), Opus 4.5 is particularly sensitive to the word \"think\" and its variants. Extended thinking is enabled only if the API request contains a `thinking` parameter.\n\n**Apply if**: User reports issues related to \"thinking\" while extended thinking is not enabled (no `thinking` parameter in request).\n\nReplace \"think\" with alternatives like \"consider,\" \"believe,\" or \"evaluate.\"\n\n## Reference\n\nSee `references/prompt-snippets.md` for the full text of each snippet to add.\n\nSee `references/effort.md` for configuring the effort parameter (only if user requests it).\n"
      },
      "discovered_at": "2026-01-11T15:35:59.840594Z",
      "fetch_error": null
    },
    {
      "name": "frontend-design",
      "slug": "frontend-design",
      "source": "skillsmp_top",
      "owner": "anthropics",
      "repo_name": "claude-code",
      "repository_url": "https://github.com/anthropics/claude-code",
      "skill_path": "plugins/frontend-design/skills/frontend-design",
      "github_metadata": {
        "stars": 55095,
        "description": "Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands.",
        "default_branch": "main",
        "pushed_at": "2026-01-11T00:28:28Z",
        "created_at": "2025-02-22T17:41:21Z",
        "language": "Shell",
        "license": null,
        "open_issues": 4495,
        "forks": 3984
      },
      "skill_md": {
        "found": true,
        "path": "plugins/frontend-design/skills/frontend-design/SKILL.md",
        "branch": "main",
        "content": "---\nname: frontend-design\ndescription: Create distinctive, production-grade frontend interfaces with high design quality. Use this skill when the user asks to build web components, pages, or applications. Generates creative, polished code that avoids generic AI aesthetics.\nlicense: Complete terms in LICENSE.txt\n---\n\nThis skill guides creation of distinctive, production-grade frontend interfaces that avoid generic \"AI slop\" aesthetics. Implement real working code with exceptional attention to aesthetic details and creative choices.\n\nThe user provides frontend requirements: a component, page, application, or interface to build. They may include context about the purpose, audience, or technical constraints.\n\n## Design Thinking\n\nBefore coding, understand the context and commit to a BOLD aesthetic direction:\n- **Purpose**: What problem does this interface solve? Who uses it?\n- **Tone**: Pick an extreme: brutally minimal, maximalist chaos, retro-futuristic, organic/natural, luxury/refined, playful/toy-like, editorial/magazine, brutalist/raw, art deco/geometric, soft/pastel, industrial/utilitarian, etc. There are so many flavors to choose from. Use these for inspiration but design one that is true to the aesthetic direction.\n- **Constraints**: Technical requirements (framework, performance, accessibility).\n- **Differentiation**: What makes this UNFORGETTABLE? What's the one thing someone will remember?\n\n**CRITICAL**: Choose a clear conceptual direction and execute it with precision. Bold maximalism and refined minimalism both work - the key is intentionality, not intensity.\n\nThen implement working code (HTML/CSS/JS, React, Vue, etc.) that is:\n- Production-grade and functional\n- Visually striking and memorable\n- Cohesive with a clear aesthetic point-of-view\n- Meticulously refined in every detail\n\n## Frontend Aesthetics Guidelines\n\nFocus on:\n- **Typography**: Choose fonts that are beautiful, unique, and interesting. Avoid generic fonts like Arial and Inter; opt instead for distinctive choices that elevate the frontend's aesthetics; unexpected, characterful font choices. Pair a distinctive display font with a refined body font.\n- **Color & Theme**: Commit to a cohesive aesthetic. Use CSS variables for consistency. Dominant colors with sharp accents outperform timid, evenly-distributed palettes.\n- **Motion**: Use animations for effects and micro-interactions. Prioritize CSS-only solutions for HTML. Use Motion library for React when available. Focus on high-impact moments: one well-orchestrated page load with staggered reveals (animation-delay) creates more delight than scattered micro-interactions. Use scroll-triggering and hover states that surprise.\n- **Spatial Composition**: Unexpected layouts. Asymmetry. Overlap. Diagonal flow. Grid-breaking elements. Generous negative space OR controlled density.\n- **Backgrounds & Visual Details**: Create atmosphere and depth rather than defaulting to solid colors. Add contextual effects and textures that match the overall aesthetic. Apply creative forms like gradient meshes, noise textures, geometric patterns, layered transparencies, dramatic shadows, decorative borders, custom cursors, and grain overlays.\n\nNEVER use generic AI-generated aesthetics like overused font families (Inter, Roboto, Arial, system fonts), cliched color schemes (particularly purple gradients on white backgrounds), predictable layouts and component patterns, and cookie-cutter design that lacks context-specific character.\n\nInterpret creatively and make unexpected choices that feel genuinely designed for the context. No design should be the same. Vary between light and dark themes, different fonts, different aesthetics. NEVER converge on common choices (Space Grotesk, for example) across generations.\n\n**IMPORTANT**: Match implementation complexity to the aesthetic vision. Maximalist designs need elaborate code with extensive animations and effects. Minimalist or refined designs need restraint, precision, and careful attention to spacing, typography, and subtle details. Elegance comes from executing the vision well.\n\nRemember: Claude is capable of extraordinary creative work. Don't hold back, show what can truly be created when thinking outside the box and committing fully to a distinctive vision."
      },
      "discovered_at": "2026-01-11T15:36:00.249620Z",
      "fetch_error": null
    },
    {
      "name": "rule-identifier",
      "slug": "rule-identifier",
      "source": "skillsmp_top",
      "owner": "anthropics",
      "repo_name": "claude-code",
      "repository_url": "https://github.com/anthropics/claude-code",
      "skill_path": "plugins/hookify/skills/writing-rules",
      "github_metadata": {
        "stars": 55095,
        "description": "Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands.",
        "default_branch": "main",
        "pushed_at": "2026-01-11T00:28:28Z",
        "created_at": "2025-02-22T17:41:21Z",
        "language": "Shell",
        "license": null,
        "open_issues": 4495,
        "forks": 3984
      },
      "skill_md": {
        "found": true,
        "path": "plugins/hookify/skills/writing-rules/SKILL.md",
        "branch": "main",
        "content": "---\nname: Writing Hookify Rules\ndescription: This skill should be used when the user asks to \"create a hookify rule\", \"write a hook rule\", \"configure hookify\", \"add a hookify rule\", or needs guidance on hookify rule syntax and patterns.\nversion: 0.1.0\n---\n\n# Writing Hookify Rules\n\n## Overview\n\nHookify rules are markdown files with YAML frontmatter that define patterns to watch for and messages to show when those patterns match. Rules are stored in `.claude/hookify.{rule-name}.local.md` files.\n\n## Rule File Format\n\n### Basic Structure\n\n```markdown\n---\nname: rule-identifier\nenabled: true\nevent: bash|file|stop|prompt|all\npattern: regex-pattern-here\n---\n\nMessage to show Claude when this rule triggers.\nCan include markdown formatting, warnings, suggestions, etc.\n```\n\n### Frontmatter Fields\n\n**name** (required): Unique identifier for the rule\n- Use kebab-case: `warn-dangerous-rm`, `block-console-log`\n- Be descriptive and action-oriented\n- Start with verb: warn, prevent, block, require, check\n\n**enabled** (required): Boolean to activate/deactivate\n- `true`: Rule is active\n- `false`: Rule is disabled (won't trigger)\n- Can toggle without deleting rule\n\n**event** (required): Which hook event to trigger on\n- `bash`: Bash tool commands\n- `file`: Edit, Write, MultiEdit tools\n- `stop`: When agent wants to stop\n- `prompt`: When user submits a prompt\n- `all`: All events\n\n**action** (optional): What to do when rule matches\n- `warn`: Show message but allow operation (default)\n- `block`: Prevent operation (PreToolUse) or stop session (Stop events)\n- If omitted, defaults to `warn`\n\n**pattern** (simple format): Regex pattern to match\n- Used for simple single-condition rules\n- Matches against command (bash) or new_text (file)\n- Python regex syntax\n\n**Example:**\n```yaml\nevent: bash\npattern: rm\\s+-rf\n```\n\n### Advanced Format (Multiple Conditions)\n\nFor complex rules with multiple conditions:\n\n```markdown\n---\nname: warn-env-file-edits\nenabled: true\nevent: file\nconditions:\n  - field: file_path\n    operator: regex_match\n    pattern: \\.env$\n  - field: new_text\n    operator: contains\n    pattern: API_KEY\n---\n\nYou're adding an API key to a .env file. Ensure this file is in .gitignore!\n```\n\n**Condition fields:**\n- `field`: Which field to check\n  - For bash: `command`\n  - For file: `file_path`, `new_text`, `old_text`, `content`\n- `operator`: How to match\n  - `regex_match`: Regex pattern matching\n  - `contains`: Substring check\n  - `equals`: Exact match\n  - `not_contains`: Substring must NOT be present\n  - `starts_with`: Prefix check\n  - `ends_with`: Suffix check\n- `pattern`: Pattern or string to match\n\n**All conditions must match for rule to trigger.**\n\n## Message Body\n\nThe markdown content after frontmatter is shown to Claude when the rule triggers.\n\n**Good messages:**\n- Explain what was detected\n- Explain why it's problematic\n- Suggest alternatives or best practices\n- Use formatting for clarity (bold, lists, etc.)\n\n**Example:**\n```markdown\nâš ï¸ **Console.log detected!**\n\nYou're adding console.log to production code.\n\n**Why this matters:**\n- Debug logs shouldn't ship to production\n- Console.log can expose sensitive data\n- Impacts browser performance\n\n**Alternatives:**\n- Use a proper logging library\n- Remove before committing\n- Use conditional debug builds\n```\n\n## Event Type Guide\n\n### bash Events\n\nMatch Bash command patterns:\n\n```markdown\n---\nevent: bash\npattern: sudo\\s+|rm\\s+-rf|chmod\\s+777\n---\n\nDangerous command detected!\n```\n\n**Common patterns:**\n- Dangerous commands: `rm\\s+-rf`, `dd\\s+if=`, `mkfs`\n- Privilege escalation: `sudo\\s+`, `su\\s+`\n- Permission issues: `chmod\\s+777`, `chown\\s+root`\n\n### file Events\n\nMatch Edit/Write/MultiEdit operations:\n\n```markdown\n---\nevent: file\npattern: console\\.log\\(|eval\\(|innerHTML\\s*=\n---\n\nPotentially problematic code pattern detected!\n```\n\n**Match on different fields:**\n```markdown\n---\nevent: file\nconditions:\n  - field: file_path\n    operator: regex_match\n    pattern: \\.tsx?$\n  - field: new_text\n    operator: regex_match\n    pattern: console\\.log\\(\n---\n\nConsole.log in TypeScript file!\n```\n\n**Common patterns:**\n- Debug code: `console\\.log\\(`, `debugger`, `print\\(`\n- Security risks: `eval\\(`, `innerHTML\\s*=`, `dangerouslySetInnerHTML`\n- Sensitive files: `\\.env$`, `credentials`, `\\.pem$`\n- Generated files: `node_modules/`, `dist/`, `build/`\n\n### stop Events\n\nMatch when agent wants to stop (completion checks):\n\n```markdown\n---\nevent: stop\npattern: .*\n---\n\nBefore stopping, verify:\n- [ ] Tests were run\n- [ ] Build succeeded\n- [ ] Documentation updated\n```\n\n**Use for:**\n- Reminders about required steps\n- Completion checklists\n- Process enforcement\n\n### prompt Events\n\nMatch user prompt content (advanced):\n\n```markdown\n---\nevent: prompt\nconditions:\n  - field: user_prompt\n    operator: contains\n    pattern: deploy to production\n---\n\nProduction deployment checklist:\n- [ ] Tests passing?\n- [ ] Reviewed by team?\n- [ ] Monitoring ready?\n```\n\n## Pattern Writing Tips\n\n### Regex Basics\n\n**Literal characters:** Most characters match themselves\n- `rm` matches \"rm\"\n- `console.log` matches \"console.log\"\n\n**Special characters need escaping:**\n- `.` (any char) â†’ `\\.` (literal dot)\n- `(` `)` â†’ `\\(` `\\)` (literal parens)\n- `[` `]` â†’ `\\[` `\\]` (literal brackets)\n\n**Common metacharacters:**\n- `\\s` - whitespace (space, tab, newline)\n- `\\d` - digit (0-9)\n- `\\w` - word character (a-z, A-Z, 0-9, _)\n- `.` - any character\n- `+` - one or more\n- `*` - zero or more\n- `?` - zero or one\n- `|` - OR\n\n**Examples:**\n```\nrm\\s+-rf         Matches: rm -rf, rm  -rf\nconsole\\.log\\(   Matches: console.log(\n(eval|exec)\\(    Matches: eval( or exec(\nchmod\\s+777      Matches: chmod 777, chmod  777\nAPI_KEY\\s*=      Matches: API_KEY=, API_KEY =\n```\n\n### Testing Patterns\n\nTest regex patterns before using:\n\n```bash\npython3 -c \"import re; print(re.search(r'your_pattern', 'test text'))\"\n```\n\nOr use online regex testers (regex101.com with Python flavor).\n\n### Common Pitfalls\n\n**Too broad:**\n```yaml\npattern: log    # Matches \"log\", \"login\", \"dialog\", \"catalog\"\n```\nBetter: `console\\.log\\(|logger\\.`\n\n**Too specific:**\n```yaml\npattern: rm -rf /tmp  # Only matches exact path\n```\nBetter: `rm\\s+-rf`\n\n**Escaping issues:**\n- YAML quoted strings: `\"pattern\"` requires double backslashes `\\\\s`\n- YAML unquoted: `pattern: \\s` works as-is\n- **Recommendation**: Use unquoted patterns in YAML\n\n## File Organization\n\n**Location:** All rules in `.claude/` directory\n**Naming:** `.claude/hookify.{descriptive-name}.local.md`\n**Gitignore:** Add `.claude/*.local.md` to `.gitignore`\n\n**Good names:**\n- `hookify.dangerous-rm.local.md`\n- `hookify.console-log.local.md`\n- `hookify.require-tests.local.md`\n- `hookify.sensitive-files.local.md`\n\n**Bad names:**\n- `hookify.rule1.local.md` (not descriptive)\n- `hookify.md` (missing .local)\n- `danger.local.md` (missing hookify prefix)\n\n## Workflow\n\n### Creating a Rule\n\n1. Identify unwanted behavior\n2. Determine which tool is involved (Bash, Edit, etc.)\n3. Choose event type (bash, file, stop, etc.)\n4. Write regex pattern\n5. Create `.claude/hookify.{name}.local.md` file in project root\n6. Test immediately - rules are read dynamically on next tool use\n\n### Refining a Rule\n\n1. Edit the `.local.md` file\n2. Adjust pattern or message\n3. Test immediately - changes take effect on next tool use\n\n### Disabling a Rule\n\n**Temporary:** Set `enabled: false` in frontmatter\n**Permanent:** Delete the `.local.md` file\n\n## Examples\n\nSee `${CLAUDE_PLUGIN_ROOT}/examples/` for complete examples:\n- `dangerous-rm.local.md` - Block dangerous rm commands\n- `console-log-warning.local.md` - Warn about console.log\n- `sensitive-files-warning.local.md` - Warn about editing .env files\n\n## Quick Reference\n\n**Minimum viable rule:**\n```markdown\n---\nname: my-rule\nenabled: true\nevent: bash\npattern: dangerous_command\n---\n\nWarning message here\n```\n\n**Rule with conditions:**\n```markdown\n---\nname: my-rule\nenabled: true\nevent: file\nconditions:\n  - field: file_path\n    operator: regex_match\n    pattern: \\.ts$\n  - field: new_text\n    operator: contains\n    pattern: any\n---\n\nWarning message\n```\n\n**Event types:**\n- `bash` - Bash commands\n- `file` - File edits\n- `stop` - Completion checks\n- `prompt` - User input\n- `all` - All events\n\n**Field options:**\n- Bash: `command`\n- File: `file_path`, `new_text`, `old_text`, `content`\n- Prompt: `user_prompt`\n\n**Operators:**\n- `regex_match`, `contains`, `equals`, `not_contains`, `starts_with`, `ends_with`\n"
      },
      "discovered_at": "2026-01-11T15:36:00.734404Z",
      "fetch_error": null
    },
    {
      "name": "agent-identifier",
      "slug": "agent-identifier",
      "source": "skillsmp_top",
      "owner": "anthropics",
      "repo_name": "claude-code",
      "repository_url": "https://github.com/anthropics/claude-code",
      "skill_path": "plugins/plugin-dev/skills/agent-development",
      "github_metadata": {
        "stars": 55095,
        "description": "Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands.",
        "default_branch": "main",
        "pushed_at": "2026-01-11T00:28:28Z",
        "created_at": "2025-02-22T17:41:21Z",
        "language": "Shell",
        "license": null,
        "open_issues": 4495,
        "forks": 3984
      },
      "skill_md": {
        "found": true,
        "path": "plugins/plugin-dev/skills/agent-development/SKILL.md",
        "branch": "main",
        "content": "---\nname: Agent Development\ndescription: This skill should be used when the user asks to \"create an agent\", \"add an agent\", \"write a subagent\", \"agent frontmatter\", \"when to use description\", \"agent examples\", \"agent tools\", \"agent colors\", \"autonomous agent\", or needs guidance on agent structure, system prompts, triggering conditions, or agent development best practices for Claude Code plugins.\nversion: 0.1.0\n---\n\n# Agent Development for Claude Code Plugins\n\n## Overview\n\nAgents are autonomous subprocesses that handle complex, multi-step tasks independently. Understanding agent structure, triggering conditions, and system prompt design enables creating powerful autonomous capabilities.\n\n**Key concepts:**\n- Agents are FOR autonomous work, commands are FOR user-initiated actions\n- Markdown file format with YAML frontmatter\n- Triggering via description field with examples\n- System prompt defines agent behavior\n- Model and color customization\n\n## Agent File Structure\n\n### Complete Format\n\n```markdown\n---\nname: agent-identifier\ndescription: Use this agent when [triggering conditions]. Examples:\n\n<example>\nContext: [Situation description]\nuser: \"[User request]\"\nassistant: \"[How assistant should respond and use this agent]\"\n<commentary>\n[Why this agent should be triggered]\n</commentary>\n</example>\n\n<example>\n[Additional example...]\n</example>\n\nmodel: inherit\ncolor: blue\ntools: [\"Read\", \"Write\", \"Grep\"]\n---\n\nYou are [agent role description]...\n\n**Your Core Responsibilities:**\n1. [Responsibility 1]\n2. [Responsibility 2]\n\n**Analysis Process:**\n[Step-by-step workflow]\n\n**Output Format:**\n[What to return]\n```\n\n## Frontmatter Fields\n\n### name (required)\n\nAgent identifier used for namespacing and invocation.\n\n**Format:** lowercase, numbers, hyphens only\n**Length:** 3-50 characters\n**Pattern:** Must start and end with alphanumeric\n\n**Good examples:**\n- `code-reviewer`\n- `test-generator`\n- `api-docs-writer`\n- `security-analyzer`\n\n**Bad examples:**\n- `helper` (too generic)\n- `-agent-` (starts/ends with hyphen)\n- `my_agent` (underscores not allowed)\n- `ag` (too short, < 3 chars)\n\n### description (required)\n\nDefines when Claude should trigger this agent. **This is the most critical field.**\n\n**Must include:**\n1. Triggering conditions (\"Use this agent when...\")\n2. Multiple `<example>` blocks showing usage\n3. Context, user request, and assistant response in each example\n4. `<commentary>` explaining why agent triggers\n\n**Format:**\n```\nUse this agent when [conditions]. Examples:\n\n<example>\nContext: [Scenario description]\nuser: \"[What user says]\"\nassistant: \"[How Claude should respond]\"\n<commentary>\n[Why this agent is appropriate]\n</commentary>\n</example>\n\n[More examples...]\n```\n\n**Best practices:**\n- Include 2-4 concrete examples\n- Show proactive and reactive triggering\n- Cover different phrasings of same intent\n- Explain reasoning in commentary\n- Be specific about when NOT to use the agent\n\n### model (required)\n\nWhich model the agent should use.\n\n**Options:**\n- `inherit` - Use same model as parent (recommended)\n- `sonnet` - Claude Sonnet (balanced)\n- `opus` - Claude Opus (most capable, expensive)\n- `haiku` - Claude Haiku (fast, cheap)\n\n**Recommendation:** Use `inherit` unless agent needs specific model capabilities.\n\n### color (required)\n\nVisual identifier for agent in UI.\n\n**Options:** `blue`, `cyan`, `green`, `yellow`, `magenta`, `red`\n\n**Guidelines:**\n- Choose distinct colors for different agents in same plugin\n- Use consistent colors for similar agent types\n- Blue/cyan: Analysis, review\n- Green: Success-oriented tasks\n- Yellow: Caution, validation\n- Red: Critical, security\n- Magenta: Creative, generation\n\n### tools (optional)\n\nRestrict agent to specific tools.\n\n**Format:** Array of tool names\n\n```yaml\ntools: [\"Read\", \"Write\", \"Grep\", \"Bash\"]\n```\n\n**Default:** If omitted, agent has access to all tools\n\n**Best practice:** Limit tools to minimum needed (principle of least privilege)\n\n**Common tool sets:**\n- Read-only analysis: `[\"Read\", \"Grep\", \"Glob\"]`\n- Code generation: `[\"Read\", \"Write\", \"Grep\"]`\n- Testing: `[\"Read\", \"Bash\", \"Grep\"]`\n- Full access: Omit field or use `[\"*\"]`\n\n## System Prompt Design\n\nThe markdown body becomes the agent's system prompt. Write in second person, addressing the agent directly.\n\n### Structure\n\n**Standard template:**\n```markdown\nYou are [role] specializing in [domain].\n\n**Your Core Responsibilities:**\n1. [Primary responsibility]\n2. [Secondary responsibility]\n3. [Additional responsibilities...]\n\n**Analysis Process:**\n1. [Step one]\n2. [Step two]\n3. [Step three]\n[...]\n\n**Quality Standards:**\n- [Standard 1]\n- [Standard 2]\n\n**Output Format:**\nProvide results in this format:\n- [What to include]\n- [How to structure]\n\n**Edge Cases:**\nHandle these situations:\n- [Edge case 1]: [How to handle]\n- [Edge case 2]: [How to handle]\n```\n\n### Best Practices\n\nâœ… **DO:**\n- Write in second person (\"You are...\", \"You will...\")\n- Be specific about responsibilities\n- Provide step-by-step process\n- Define output format\n- Include quality standards\n- Address edge cases\n- Keep under 10,000 characters\n\nâŒ **DON'T:**\n- Write in first person (\"I am...\", \"I will...\")\n- Be vague or generic\n- Omit process steps\n- Leave output format undefined\n- Skip quality guidance\n- Ignore error cases\n\n## Creating Agents\n\n### Method 1: AI-Assisted Generation\n\nUse this prompt pattern (extracted from Claude Code):\n\n```\nCreate an agent configuration based on this request: \"[YOUR DESCRIPTION]\"\n\nRequirements:\n1. Extract core intent and responsibilities\n2. Design expert persona for the domain\n3. Create comprehensive system prompt with:\n   - Clear behavioral boundaries\n   - Specific methodologies\n   - Edge case handling\n   - Output format\n4. Create identifier (lowercase, hyphens, 3-50 chars)\n5. Write description with triggering conditions\n6. Include 2-3 <example> blocks showing when to use\n\nReturn JSON with:\n{\n  \"identifier\": \"agent-name\",\n  \"whenToUse\": \"Use this agent when... Examples: <example>...</example>\",\n  \"systemPrompt\": \"You are...\"\n}\n```\n\nThen convert to agent file format with frontmatter.\n\nSee `examples/agent-creation-prompt.md` for complete template.\n\n### Method 2: Manual Creation\n\n1. Choose agent identifier (3-50 chars, lowercase, hyphens)\n2. Write description with examples\n3. Select model (usually `inherit`)\n4. Choose color for visual identification\n5. Define tools (if restricting access)\n6. Write system prompt with structure above\n7. Save as `agents/agent-name.md`\n\n## Validation Rules\n\n### Identifier Validation\n\n```\nâœ… Valid: code-reviewer, test-gen, api-analyzer-v2\nâŒ Invalid: ag (too short), -start (starts with hyphen), my_agent (underscore)\n```\n\n**Rules:**\n- 3-50 characters\n- Lowercase letters, numbers, hyphens only\n- Must start and end with alphanumeric\n- No underscores, spaces, or special characters\n\n### Description Validation\n\n**Length:** 10-5,000 characters\n**Must include:** Triggering conditions and examples\n**Best:** 200-1,000 characters with 2-4 examples\n\n### System Prompt Validation\n\n**Length:** 20-10,000 characters\n**Best:** 500-3,000 characters\n**Structure:** Clear responsibilities, process, output format\n\n## Agent Organization\n\n### Plugin Agents Directory\n\n```\nplugin-name/\nâ””â”€â”€ agents/\n    â”œâ”€â”€ analyzer.md\n    â”œâ”€â”€ reviewer.md\n    â””â”€â”€ generator.md\n```\n\nAll `.md` files in `agents/` are auto-discovered.\n\n### Namespacing\n\nAgents are namespaced automatically:\n- Single plugin: `agent-name`\n- With subdirectories: `plugin:subdir:agent-name`\n\n## Testing Agents\n\n### Test Triggering\n\nCreate test scenarios to verify agent triggers correctly:\n\n1. Write agent with specific triggering examples\n2. Use similar phrasing to examples in test\n3. Check Claude loads the agent\n4. Verify agent provides expected functionality\n\n### Test System Prompt\n\nEnsure system prompt is complete:\n\n1. Give agent typical task\n2. Check it follows process steps\n3. Verify output format is correct\n4. Test edge cases mentioned in prompt\n5. Confirm quality standards are met\n\n## Quick Reference\n\n### Minimal Agent\n\n```markdown\n---\nname: simple-agent\ndescription: Use this agent when... Examples: <example>...</example>\nmodel: inherit\ncolor: blue\n---\n\nYou are an agent that [does X].\n\nProcess:\n1. [Step 1]\n2. [Step 2]\n\nOutput: [What to provide]\n```\n\n### Frontmatter Fields Summary\n\n| Field | Required | Format | Example |\n|-------|----------|--------|---------|\n| name | Yes | lowercase-hyphens | code-reviewer |\n| description | Yes | Text + examples | Use when... <example>... |\n| model | Yes | inherit/sonnet/opus/haiku | inherit |\n| color | Yes | Color name | blue |\n| tools | No | Array of tool names | [\"Read\", \"Grep\"] |\n\n### Best Practices\n\n**DO:**\n- âœ… Include 2-4 concrete examples in description\n- âœ… Write specific triggering conditions\n- âœ… Use `inherit` for model unless specific need\n- âœ… Choose appropriate tools (least privilege)\n- âœ… Write clear, structured system prompts\n- âœ… Test agent triggering thoroughly\n\n**DON'T:**\n- âŒ Use generic descriptions without examples\n- âŒ Omit triggering conditions\n- âŒ Give all agents same color\n- âŒ Grant unnecessary tool access\n- âŒ Write vague system prompts\n- âŒ Skip testing\n\n## Additional Resources\n\n### Reference Files\n\nFor detailed guidance, consult:\n\n- **`references/system-prompt-design.md`** - Complete system prompt patterns\n- **`references/triggering-examples.md`** - Example formats and best practices\n- **`references/agent-creation-system-prompt.md`** - The exact prompt from Claude Code\n\n### Example Files\n\nWorking examples in `examples/`:\n\n- **`agent-creation-prompt.md`** - AI-assisted agent generation template\n- **`complete-agent-examples.md`** - Full agent examples for different use cases\n\n### Utility Scripts\n\nDevelopment tools in `scripts/`:\n\n- **`validate-agent.sh`** - Validate agent file structure\n- **`test-agent-trigger.sh`** - Test if agent triggers correctly\n\n## Implementation Workflow\n\nTo create an agent for a plugin:\n\n1. Define agent purpose and triggering conditions\n2. Choose creation method (AI-assisted or manual)\n3. Create `agents/agent-name.md` file\n4. Write frontmatter with all required fields\n5. Write system prompt following best practices\n6. Include 2-4 triggering examples in description\n7. Validate with `scripts/validate-agent.sh`\n8. Test triggering with real scenarios\n9. Document agent in plugin README\n\nFocus on clear triggering conditions and comprehensive system prompts for autonomous operation.\n"
      },
      "discovered_at": "2026-01-11T15:36:01.264337Z",
      "fetch_error": null
    },
    {
      "name": "command-development",
      "slug": "command-development",
      "source": "skillsmp_top",
      "owner": "anthropics",
      "repo_name": "claude-code",
      "repository_url": "https://github.com/anthropics/claude-code",
      "skill_path": "plugins/plugin-dev/skills/command-development",
      "github_metadata": {
        "stars": 55095,
        "description": "Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands.",
        "default_branch": "main",
        "pushed_at": "2026-01-11T00:28:28Z",
        "created_at": "2025-02-22T17:41:21Z",
        "language": "Shell",
        "license": null,
        "open_issues": 4495,
        "forks": 3984
      },
      "skill_md": {
        "found": true,
        "path": "plugins/plugin-dev/skills/command-development/SKILL.md",
        "branch": "main",
        "content": "---\nname: Command Development\ndescription: This skill should be used when the user asks to \"create a slash command\", \"add a command\", \"write a custom command\", \"define command arguments\", \"use command frontmatter\", \"organize commands\", \"create command with file references\", \"interactive command\", \"use AskUserQuestion in command\", or needs guidance on slash command structure, YAML frontmatter fields, dynamic arguments, bash execution in commands, user interaction patterns, or command development best practices for Claude Code.\nversion: 0.2.0\n---\n\n# Command Development for Claude Code\n\n## Overview\n\nSlash commands are frequently-used prompts defined as Markdown files that Claude executes during interactive sessions. Understanding command structure, frontmatter options, and dynamic features enables creating powerful, reusable workflows.\n\n**Key concepts:**\n- Markdown file format for commands\n- YAML frontmatter for configuration\n- Dynamic arguments and file references\n- Bash execution for context\n- Command organization and namespacing\n\n## Command Basics\n\n### What is a Slash Command?\n\nA slash command is a Markdown file containing a prompt that Claude executes when invoked. Commands provide:\n- **Reusability**: Define once, use repeatedly\n- **Consistency**: Standardize common workflows\n- **Sharing**: Distribute across team or projects\n- **Efficiency**: Quick access to complex prompts\n\n### Critical: Commands are Instructions FOR Claude\n\n**Commands are written for agent consumption, not human consumption.**\n\nWhen a user invokes `/command-name`, the command content becomes Claude's instructions. Write commands as directives TO Claude about what to do, not as messages TO the user.\n\n**Correct approach (instructions for Claude):**\n```markdown\nReview this code for security vulnerabilities including:\n- SQL injection\n- XSS attacks\n- Authentication issues\n\nProvide specific line numbers and severity ratings.\n```\n\n**Incorrect approach (messages to user):**\n```markdown\nThis command will review your code for security issues.\nYou'll receive a report with vulnerability details.\n```\n\nThe first example tells Claude what to do. The second tells the user what will happen but doesn't instruct Claude. Always use the first approach.\n\n### Command Locations\n\n**Project commands** (shared with team):\n- Location: `.claude/commands/`\n- Scope: Available in specific project\n- Label: Shown as \"(project)\" in `/help`\n- Use for: Team workflows, project-specific tasks\n\n**Personal commands** (available everywhere):\n- Location: `~/.claude/commands/`\n- Scope: Available in all projects\n- Label: Shown as \"(user)\" in `/help`\n- Use for: Personal workflows, cross-project utilities\n\n**Plugin commands** (bundled with plugins):\n- Location: `plugin-name/commands/`\n- Scope: Available when plugin installed\n- Label: Shown as \"(plugin-name)\" in `/help`\n- Use for: Plugin-specific functionality\n\n## File Format\n\n### Basic Structure\n\nCommands are Markdown files with `.md` extension:\n\n```\n.claude/commands/\nâ”œâ”€â”€ review.md           # /review command\nâ”œâ”€â”€ test.md             # /test command\nâ””â”€â”€ deploy.md           # /deploy command\n```\n\n**Simple command:**\n```markdown\nReview this code for security vulnerabilities including:\n- SQL injection\n- XSS attacks\n- Authentication bypass\n- Insecure data handling\n```\n\nNo frontmatter needed for basic commands.\n\n### With YAML Frontmatter\n\nAdd configuration using YAML frontmatter:\n\n```markdown\n---\ndescription: Review code for security issues\nallowed-tools: Read, Grep, Bash(git:*)\nmodel: sonnet\n---\n\nReview this code for security vulnerabilities...\n```\n\n## YAML Frontmatter Fields\n\n### description\n\n**Purpose:** Brief description shown in `/help`\n**Type:** String\n**Default:** First line of command prompt\n\n```yaml\n---\ndescription: Review pull request for code quality\n---\n```\n\n**Best practice:** Clear, actionable description (under 60 characters)\n\n### allowed-tools\n\n**Purpose:** Specify which tools command can use\n**Type:** String or Array\n**Default:** Inherits from conversation\n\n```yaml\n---\nallowed-tools: Read, Write, Edit, Bash(git:*)\n---\n```\n\n**Patterns:**\n- `Read, Write, Edit` - Specific tools\n- `Bash(git:*)` - Bash with git commands only\n- `*` - All tools (rarely needed)\n\n**Use when:** Command requires specific tool access\n\n### model\n\n**Purpose:** Specify model for command execution\n**Type:** String (sonnet, opus, haiku)\n**Default:** Inherits from conversation\n\n```yaml\n---\nmodel: haiku\n---\n```\n\n**Use cases:**\n- `haiku` - Fast, simple commands\n- `sonnet` - Standard workflows\n- `opus` - Complex analysis\n\n### argument-hint\n\n**Purpose:** Document expected arguments for autocomplete\n**Type:** String\n**Default:** None\n\n```yaml\n---\nargument-hint: [pr-number] [priority] [assignee]\n---\n```\n\n**Benefits:**\n- Helps users understand command arguments\n- Improves command discovery\n- Documents command interface\n\n### disable-model-invocation\n\n**Purpose:** Prevent SlashCommand tool from programmatically calling command\n**Type:** Boolean\n**Default:** false\n\n```yaml\n---\ndisable-model-invocation: true\n---\n```\n\n**Use when:** Command should only be manually invoked\n\n## Dynamic Arguments\n\n### Using $ARGUMENTS\n\nCapture all arguments as single string:\n\n```markdown\n---\ndescription: Fix issue by number\nargument-hint: [issue-number]\n---\n\nFix issue #$ARGUMENTS following our coding standards and best practices.\n```\n\n**Usage:**\n```\n> /fix-issue 123\n> /fix-issue 456\n```\n\n**Expands to:**\n```\nFix issue #123 following our coding standards...\nFix issue #456 following our coding standards...\n```\n\n### Using Positional Arguments\n\nCapture individual arguments with `$1`, `$2`, `$3`, etc.:\n\n```markdown\n---\ndescription: Review PR with priority and assignee\nargument-hint: [pr-number] [priority] [assignee]\n---\n\nReview pull request #$1 with priority level $2.\nAfter review, assign to $3 for follow-up.\n```\n\n**Usage:**\n```\n> /review-pr 123 high alice\n```\n\n**Expands to:**\n```\nReview pull request #123 with priority level high.\nAfter review, assign to alice for follow-up.\n```\n\n### Combining Arguments\n\nMix positional and remaining arguments:\n\n```markdown\nDeploy $1 to $2 environment with options: $3\n```\n\n**Usage:**\n```\n> /deploy api staging --force --skip-tests\n```\n\n**Expands to:**\n```\nDeploy api to staging environment with options: --force --skip-tests\n```\n\n## File References\n\n### Using @ Syntax\n\nInclude file contents in command:\n\n```markdown\n---\ndescription: Review specific file\nargument-hint: [file-path]\n---\n\nReview @$1 for:\n- Code quality\n- Best practices\n- Potential bugs\n```\n\n**Usage:**\n```\n> /review-file src/api/users.ts\n```\n\n**Effect:** Claude reads `src/api/users.ts` before processing command\n\n### Multiple File References\n\nReference multiple files:\n\n```markdown\nCompare @src/old-version.js with @src/new-version.js\n\nIdentify:\n- Breaking changes\n- New features\n- Bug fixes\n```\n\n### Static File References\n\nReference known files without arguments:\n\n```markdown\nReview @package.json and @tsconfig.json for consistency\n\nEnsure:\n- TypeScript version matches\n- Dependencies are aligned\n- Build configuration is correct\n```\n\n## Bash Execution in Commands\n\nCommands can execute bash commands inline to dynamically gather context before Claude processes the command. This is useful for including repository state, environment information, or project-specific context.\n\n**When to use:**\n- Include dynamic context (git status, environment vars, etc.)\n- Gather project/repository state\n- Build context-aware workflows\n\n**Implementation details:**\nFor complete syntax, examples, and best practices, see `references/plugin-features-reference.md` section on bash execution. The reference includes the exact syntax and multiple working examples to avoid execution issues\n\n## Command Organization\n\n### Flat Structure\n\nSimple organization for small command sets:\n\n```\n.claude/commands/\nâ”œâ”€â”€ build.md\nâ”œâ”€â”€ test.md\nâ”œâ”€â”€ deploy.md\nâ”œâ”€â”€ review.md\nâ””â”€â”€ docs.md\n```\n\n**Use when:** 5-15 commands, no clear categories\n\n### Namespaced Structure\n\nOrganize commands in subdirectories:\n\n```\n.claude/commands/\nâ”œâ”€â”€ ci/\nâ”‚   â”œâ”€â”€ build.md        # /build (project:ci)\nâ”‚   â”œâ”€â”€ test.md         # /test (project:ci)\nâ”‚   â””â”€â”€ lint.md         # /lint (project:ci)\nâ”œâ”€â”€ git/\nâ”‚   â”œâ”€â”€ commit.md       # /commit (project:git)\nâ”‚   â””â”€â”€ pr.md           # /pr (project:git)\nâ””â”€â”€ docs/\n    â”œâ”€â”€ generate.md     # /generate (project:docs)\n    â””â”€â”€ publish.md      # /publish (project:docs)\n```\n\n**Benefits:**\n- Logical grouping by category\n- Namespace shown in `/help`\n- Easier to find related commands\n\n**Use when:** 15+ commands, clear categories\n\n## Best Practices\n\n### Command Design\n\n1. **Single responsibility:** One command, one task\n2. **Clear descriptions:** Self-explanatory in `/help`\n3. **Explicit dependencies:** Use `allowed-tools` when needed\n4. **Document arguments:** Always provide `argument-hint`\n5. **Consistent naming:** Use verb-noun pattern (review-pr, fix-issue)\n\n### Argument Handling\n\n1. **Validate arguments:** Check for required arguments in prompt\n2. **Provide defaults:** Suggest defaults when arguments missing\n3. **Document format:** Explain expected argument format\n4. **Handle edge cases:** Consider missing or invalid arguments\n\n```markdown\n---\nargument-hint: [pr-number]\n---\n\n$IF($1,\n  Review PR #$1,\n  Please provide a PR number. Usage: /review-pr [number]\n)\n```\n\n### File References\n\n1. **Explicit paths:** Use clear file paths\n2. **Check existence:** Handle missing files gracefully\n3. **Relative paths:** Use project-relative paths\n4. **Glob support:** Consider using Glob tool for patterns\n\n### Bash Commands\n\n1. **Limit scope:** Use `Bash(git:*)` not `Bash(*)`\n2. **Safe commands:** Avoid destructive operations\n3. **Handle errors:** Consider command failures\n4. **Keep fast:** Long-running commands slow invocation\n\n### Documentation\n\n1. **Add comments:** Explain complex logic\n2. **Provide examples:** Show usage in comments\n3. **List requirements:** Document dependencies\n4. **Version commands:** Note breaking changes\n\n```markdown\n---\ndescription: Deploy application to environment\nargument-hint: [environment] [version]\n---\n\n<!--\nUsage: /deploy [staging|production] [version]\nRequires: AWS credentials configured\nExample: /deploy staging v1.2.3\n-->\n\nDeploy application to $1 environment using version $2...\n```\n\n## Common Patterns\n\n### Review Pattern\n\n```markdown\n---\ndescription: Review code changes\nallowed-tools: Read, Bash(git:*)\n---\n\nFiles changed: !`git diff --name-only`\n\nReview each file for:\n1. Code quality and style\n2. Potential bugs or issues\n3. Test coverage\n4. Documentation needs\n\nProvide specific feedback for each file.\n```\n\n### Testing Pattern\n\n```markdown\n---\ndescription: Run tests for specific file\nargument-hint: [test-file]\nallowed-tools: Bash(npm:*)\n---\n\nRun tests: !`npm test $1`\n\nAnalyze results and suggest fixes for failures.\n```\n\n### Documentation Pattern\n\n```markdown\n---\ndescription: Generate documentation for file\nargument-hint: [source-file]\n---\n\nGenerate comprehensive documentation for @$1 including:\n- Function/class descriptions\n- Parameter documentation\n- Return value descriptions\n- Usage examples\n- Edge cases and errors\n```\n\n### Workflow Pattern\n\n```markdown\n---\ndescription: Complete PR workflow\nargument-hint: [pr-number]\nallowed-tools: Bash(gh:*), Read\n---\n\nPR #$1 Workflow:\n\n1. Fetch PR: !`gh pr view $1`\n2. Review changes\n3. Run checks\n4. Approve or request changes\n```\n\n## Troubleshooting\n\n**Command not appearing:**\n- Check file is in correct directory\n- Verify `.md` extension present\n- Ensure valid Markdown format\n- Restart Claude Code\n\n**Arguments not working:**\n- Verify `$1`, `$2` syntax correct\n- Check `argument-hint` matches usage\n- Ensure no extra spaces\n\n**Bash execution failing:**\n- Check `allowed-tools` includes Bash\n- Verify command syntax in backticks\n- Test command in terminal first\n- Check for required permissions\n\n**File references not working:**\n- Verify `@` syntax correct\n- Check file path is valid\n- Ensure Read tool allowed\n- Use absolute or project-relative paths\n\n## Plugin-Specific Features\n\n### CLAUDE_PLUGIN_ROOT Variable\n\nPlugin commands have access to `${CLAUDE_PLUGIN_ROOT}`, an environment variable that resolves to the plugin's absolute path.\n\n**Purpose:**\n- Reference plugin files portably\n- Execute plugin scripts\n- Load plugin configuration\n- Access plugin templates\n\n**Basic usage:**\n\n```markdown\n---\ndescription: Analyze using plugin script\nallowed-tools: Bash(node:*)\n---\n\nRun analysis: !`node ${CLAUDE_PLUGIN_ROOT}/scripts/analyze.js $1`\n\nReview results and report findings.\n```\n\n**Common patterns:**\n\n```markdown\n# Execute plugin script\n!`bash ${CLAUDE_PLUGIN_ROOT}/scripts/script.sh`\n\n# Load plugin configuration\n@${CLAUDE_PLUGIN_ROOT}/config/settings.json\n\n# Use plugin template\n@${CLAUDE_PLUGIN_ROOT}/templates/report.md\n\n# Access plugin resources\n@${CLAUDE_PLUGIN_ROOT}/docs/reference.md\n```\n\n**Why use it:**\n- Works across all installations\n- Portable between systems\n- No hardcoded paths needed\n- Essential for multi-file plugins\n\n### Plugin Command Organization\n\nPlugin commands discovered automatically from `commands/` directory:\n\n```\nplugin-name/\nâ”œâ”€â”€ commands/\nâ”‚   â”œâ”€â”€ foo.md              # /foo (plugin:plugin-name)\nâ”‚   â”œâ”€â”€ bar.md              # /bar (plugin:plugin-name)\nâ”‚   â””â”€â”€ utils/\nâ”‚       â””â”€â”€ helper.md       # /helper (plugin:plugin-name:utils)\nâ””â”€â”€ plugin.json\n```\n\n**Namespace benefits:**\n- Logical command grouping\n- Shown in `/help` output\n- Avoid name conflicts\n- Organize related commands\n\n**Naming conventions:**\n- Use descriptive action names\n- Avoid generic names (test, run)\n- Consider plugin-specific prefix\n- Use hyphens for multi-word names\n\n### Plugin Command Patterns\n\n**Configuration-based pattern:**\n\n```markdown\n---\ndescription: Deploy using plugin configuration\nargument-hint: [environment]\nallowed-tools: Read, Bash(*)\n---\n\nLoad configuration: @${CLAUDE_PLUGIN_ROOT}/config/$1-deploy.json\n\nDeploy to $1 using configuration settings.\nMonitor deployment and report status.\n```\n\n**Template-based pattern:**\n\n```markdown\n---\ndescription: Generate docs from template\nargument-hint: [component]\n---\n\nTemplate: @${CLAUDE_PLUGIN_ROOT}/templates/docs.md\n\nGenerate documentation for $1 following template structure.\n```\n\n**Multi-script pattern:**\n\n```markdown\n---\ndescription: Complete build workflow\nallowed-tools: Bash(*)\n---\n\nBuild: !`bash ${CLAUDE_PLUGIN_ROOT}/scripts/build.sh`\nTest: !`bash ${CLAUDE_PLUGIN_ROOT}/scripts/test.sh`\nPackage: !`bash ${CLAUDE_PLUGIN_ROOT}/scripts/package.sh`\n\nReview outputs and report workflow status.\n```\n\n**See `references/plugin-features-reference.md` for detailed patterns.**\n\n## Integration with Plugin Components\n\nCommands can integrate with other plugin components for powerful workflows.\n\n### Agent Integration\n\nLaunch plugin agents for complex tasks:\n\n```markdown\n---\ndescription: Deep code review\nargument-hint: [file-path]\n---\n\nInitiate comprehensive review of @$1 using the code-reviewer agent.\n\nThe agent will analyze:\n- Code structure\n- Security issues\n- Performance\n- Best practices\n\nAgent uses plugin resources:\n- ${CLAUDE_PLUGIN_ROOT}/config/rules.json\n- ${CLAUDE_PLUGIN_ROOT}/checklists/review.md\n```\n\n**Key points:**\n- Agent must exist in `plugin/agents/` directory\n- Claude uses Task tool to launch agent\n- Document agent capabilities\n- Reference plugin resources agent uses\n\n### Skill Integration\n\nLeverage plugin skills for specialized knowledge:\n\n```markdown\n---\ndescription: Document API with standards\nargument-hint: [api-file]\n---\n\nDocument API in @$1 following plugin standards.\n\nUse the api-docs-standards skill to ensure:\n- Complete endpoint documentation\n- Consistent formatting\n- Example quality\n- Error documentation\n\nGenerate production-ready API docs.\n```\n\n**Key points:**\n- Skill must exist in `plugin/skills/` directory\n- Mention skill name to trigger invocation\n- Document skill purpose\n- Explain what skill provides\n\n### Hook Coordination\n\nDesign commands that work with plugin hooks:\n- Commands can prepare state for hooks to process\n- Hooks execute automatically on tool events\n- Commands should document expected hook behavior\n- Guide Claude on interpreting hook output\n\nSee `references/plugin-features-reference.md` for examples of commands that coordinate with hooks\n\n### Multi-Component Workflows\n\nCombine agents, skills, and scripts:\n\n```markdown\n---\ndescription: Comprehensive review workflow\nargument-hint: [file]\nallowed-tools: Bash(node:*), Read\n---\n\nTarget: @$1\n\nPhase 1 - Static Analysis:\n!`node ${CLAUDE_PLUGIN_ROOT}/scripts/lint.js $1`\n\nPhase 2 - Deep Review:\nLaunch code-reviewer agent for detailed analysis.\n\nPhase 3 - Standards Check:\nUse coding-standards skill for validation.\n\nPhase 4 - Report:\nTemplate: @${CLAUDE_PLUGIN_ROOT}/templates/review.md\n\nCompile findings into report following template.\n```\n\n**When to use:**\n- Complex multi-step workflows\n- Leverage multiple plugin capabilities\n- Require specialized analysis\n- Need structured outputs\n\n## Validation Patterns\n\nCommands should validate inputs and resources before processing.\n\n### Argument Validation\n\n```markdown\n---\ndescription: Deploy with validation\nargument-hint: [environment]\n---\n\nValidate environment: !`echo \"$1\" | grep -E \"^(dev|staging|prod)$\" || echo \"INVALID\"`\n\nIf $1 is valid environment:\n  Deploy to $1\nOtherwise:\n  Explain valid environments: dev, staging, prod\n  Show usage: /deploy [environment]\n```\n\n### File Existence Checks\n\n```markdown\n---\ndescription: Process configuration\nargument-hint: [config-file]\n---\n\nCheck file exists: !`test -f $1 && echo \"EXISTS\" || echo \"MISSING\"`\n\nIf file exists:\n  Process configuration: @$1\nOtherwise:\n  Explain where to place config file\n  Show expected format\n  Provide example configuration\n```\n\n### Plugin Resource Validation\n\n```markdown\n---\ndescription: Run plugin analyzer\nallowed-tools: Bash(test:*)\n---\n\nValidate plugin setup:\n- Script: !`test -x ${CLAUDE_PLUGIN_ROOT}/bin/analyze && echo \"âœ“\" || echo \"âœ—\"`\n- Config: !`test -f ${CLAUDE_PLUGIN_ROOT}/config.json && echo \"âœ“\" || echo \"âœ—\"`\n\nIf all checks pass, run analysis.\nOtherwise, report missing components.\n```\n\n### Error Handling\n\n```markdown\n---\ndescription: Build with error handling\nallowed-tools: Bash(*)\n---\n\nExecute build: !`bash ${CLAUDE_PLUGIN_ROOT}/scripts/build.sh 2>&1 || echo \"BUILD_FAILED\"`\n\nIf build succeeded:\n  Report success and output location\nIf build failed:\n  Analyze error output\n  Suggest likely causes\n  Provide troubleshooting steps\n```\n\n**Best practices:**\n- Validate early in command\n- Provide helpful error messages\n- Suggest corrective actions\n- Handle edge cases gracefully\n\n---\n\nFor detailed frontmatter field specifications, see `references/frontmatter-reference.md`.\nFor plugin-specific features and patterns, see `references/plugin-features-reference.md`.\nFor command pattern examples, see `examples/` directory.\n"
      },
      "discovered_at": "2026-01-11T15:36:01.656751Z",
      "fetch_error": null
    },
    {
      "name": "hook-development",
      "slug": "hook-development",
      "source": "skillsmp_top",
      "owner": "anthropics",
      "repo_name": "claude-code",
      "repository_url": "https://github.com/anthropics/claude-code",
      "skill_path": "plugins/plugin-dev/skills/hook-development",
      "github_metadata": {
        "stars": 55095,
        "description": "Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands.",
        "default_branch": "main",
        "pushed_at": "2026-01-11T00:28:28Z",
        "created_at": "2025-02-22T17:41:21Z",
        "language": "Shell",
        "license": null,
        "open_issues": 4495,
        "forks": 3984
      },
      "skill_md": {
        "found": true,
        "path": "plugins/plugin-dev/skills/hook-development/SKILL.md",
        "branch": "main",
        "content": "---\nname: Hook Development\ndescription: This skill should be used when the user asks to \"create a hook\", \"add a PreToolUse/PostToolUse/Stop hook\", \"validate tool use\", \"implement prompt-based hooks\", \"use ${CLAUDE_PLUGIN_ROOT}\", \"set up event-driven automation\", \"block dangerous commands\", or mentions hook events (PreToolUse, PostToolUse, Stop, SubagentStop, SessionStart, SessionEnd, UserPromptSubmit, PreCompact, Notification). Provides comprehensive guidance for creating and implementing Claude Code plugin hooks with focus on advanced prompt-based hooks API.\nversion: 0.1.0\n---\n\n# Hook Development for Claude Code Plugins\n\n## Overview\n\nHooks are event-driven automation scripts that execute in response to Claude Code events. Use hooks to validate operations, enforce policies, add context, and integrate external tools into workflows.\n\n**Key capabilities:**\n- Validate tool calls before execution (PreToolUse)\n- React to tool results (PostToolUse)\n- Enforce completion standards (Stop, SubagentStop)\n- Load project context (SessionStart)\n- Automate workflows across the development lifecycle\n\n## Hook Types\n\n### Prompt-Based Hooks (Recommended)\n\nUse LLM-driven decision making for context-aware validation:\n\n```json\n{\n  \"type\": \"prompt\",\n  \"prompt\": \"Evaluate if this tool use is appropriate: $TOOL_INPUT\",\n  \"timeout\": 30\n}\n```\n\n**Supported events:** Stop, SubagentStop, UserPromptSubmit, PreToolUse\n\n**Benefits:**\n- Context-aware decisions based on natural language reasoning\n- Flexible evaluation logic without bash scripting\n- Better edge case handling\n- Easier to maintain and extend\n\n### Command Hooks\n\nExecute bash commands for deterministic checks:\n\n```json\n{\n  \"type\": \"command\",\n  \"command\": \"bash ${CLAUDE_PLUGIN_ROOT}/scripts/validate.sh\",\n  \"timeout\": 60\n}\n```\n\n**Use for:**\n- Fast deterministic validations\n- File system operations\n- External tool integrations\n- Performance-critical checks\n\n## Hook Configuration Formats\n\n### Plugin hooks.json Format\n\n**For plugin hooks** in `hooks/hooks.json`, use wrapper format:\n\n```json\n{\n  \"description\": \"Brief explanation of hooks (optional)\",\n  \"hooks\": {\n    \"PreToolUse\": [...],\n    \"Stop\": [...],\n    \"SessionStart\": [...]\n  }\n}\n```\n\n**Key points:**\n- `description` field is optional\n- `hooks` field is required wrapper containing actual hook events\n- This is the **plugin-specific format**\n\n**Example:**\n```json\n{\n  \"description\": \"Validation hooks for code quality\",\n  \"hooks\": {\n    \"PreToolUse\": [\n      {\n        \"matcher\": \"Write\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"${CLAUDE_PLUGIN_ROOT}/hooks/validate.sh\"\n          }\n        ]\n      }\n    ]\n  }\n}\n```\n\n### Settings Format (Direct)\n\n**For user settings** in `.claude/settings.json`, use direct format:\n\n```json\n{\n  \"PreToolUse\": [...],\n  \"Stop\": [...],\n  \"SessionStart\": [...]\n}\n```\n\n**Key points:**\n- No wrapper - events directly at top level\n- No description field\n- This is the **settings format**\n\n**Important:** The examples below show the hook event structure that goes inside either format. For plugin hooks.json, wrap these in `{\"hooks\": {...}}`.\n\n## Hook Events\n\n### PreToolUse\n\nExecute before any tool runs. Use to approve, deny, or modify tool calls.\n\n**Example (prompt-based):**\n```json\n{\n  \"PreToolUse\": [\n    {\n      \"matcher\": \"Write|Edit\",\n      \"hooks\": [\n        {\n          \"type\": \"prompt\",\n          \"prompt\": \"Validate file write safety. Check: system paths, credentials, path traversal, sensitive content. Return 'approve' or 'deny'.\"\n        }\n      ]\n    }\n  ]\n}\n```\n\n**Output for PreToolUse:**\n```json\n{\n  \"hookSpecificOutput\": {\n    \"permissionDecision\": \"allow|deny|ask\",\n    \"updatedInput\": {\"field\": \"modified_value\"}\n  },\n  \"systemMessage\": \"Explanation for Claude\"\n}\n```\n\n### PostToolUse\n\nExecute after tool completes. Use to react to results, provide feedback, or log.\n\n**Example:**\n```json\n{\n  \"PostToolUse\": [\n    {\n      \"matcher\": \"Edit\",\n      \"hooks\": [\n        {\n          \"type\": \"prompt\",\n          \"prompt\": \"Analyze edit result for potential issues: syntax errors, security vulnerabilities, breaking changes. Provide feedback.\"\n        }\n      ]\n    }\n  ]\n}\n```\n\n**Output behavior:**\n- Exit 0: stdout shown in transcript\n- Exit 2: stderr fed back to Claude\n- systemMessage included in context\n\n### Stop\n\nExecute when main agent considers stopping. Use to validate completeness.\n\n**Example:**\n```json\n{\n  \"Stop\": [\n    {\n      \"matcher\": \"*\",\n      \"hooks\": [\n        {\n          \"type\": \"prompt\",\n          \"prompt\": \"Verify task completion: tests run, build succeeded, questions answered. Return 'approve' to stop or 'block' with reason to continue.\"\n        }\n      ]\n    }\n  ]\n}\n```\n\n**Decision output:**\n```json\n{\n  \"decision\": \"approve|block\",\n  \"reason\": \"Explanation\",\n  \"systemMessage\": \"Additional context\"\n}\n```\n\n### SubagentStop\n\nExecute when subagent considers stopping. Use to ensure subagent completed its task.\n\nSimilar to Stop hook, but for subagents.\n\n### UserPromptSubmit\n\nExecute when user submits a prompt. Use to add context, validate, or block prompts.\n\n**Example:**\n```json\n{\n  \"UserPromptSubmit\": [\n    {\n      \"matcher\": \"*\",\n      \"hooks\": [\n        {\n          \"type\": \"prompt\",\n          \"prompt\": \"Check if prompt requires security guidance. If discussing auth, permissions, or API security, return relevant warnings.\"\n        }\n      ]\n    }\n  ]\n}\n```\n\n### SessionStart\n\nExecute when Claude Code session begins. Use to load context and set environment.\n\n**Example:**\n```json\n{\n  \"SessionStart\": [\n    {\n      \"matcher\": \"*\",\n      \"hooks\": [\n        {\n          \"type\": \"command\",\n          \"command\": \"bash ${CLAUDE_PLUGIN_ROOT}/scripts/load-context.sh\"\n        }\n      ]\n    }\n  ]\n}\n```\n\n**Special capability:** Persist environment variables using `$CLAUDE_ENV_FILE`:\n```bash\necho \"export PROJECT_TYPE=nodejs\" >> \"$CLAUDE_ENV_FILE\"\n```\n\nSee `examples/load-context.sh` for complete example.\n\n### SessionEnd\n\nExecute when session ends. Use for cleanup, logging, and state preservation.\n\n### PreCompact\n\nExecute before context compaction. Use to add critical information to preserve.\n\n### Notification\n\nExecute when Claude sends notifications. Use to react to user notifications.\n\n## Hook Output Format\n\n### Standard Output (All Hooks)\n\n```json\n{\n  \"continue\": true,\n  \"suppressOutput\": false,\n  \"systemMessage\": \"Message for Claude\"\n}\n```\n\n- `continue`: If false, halt processing (default true)\n- `suppressOutput`: Hide output from transcript (default false)\n- `systemMessage`: Message shown to Claude\n\n### Exit Codes\n\n- `0` - Success (stdout shown in transcript)\n- `2` - Blocking error (stderr fed back to Claude)\n- Other - Non-blocking error\n\n## Hook Input Format\n\nAll hooks receive JSON via stdin with common fields:\n\n```json\n{\n  \"session_id\": \"abc123\",\n  \"transcript_path\": \"/path/to/transcript.txt\",\n  \"cwd\": \"/current/working/dir\",\n  \"permission_mode\": \"ask|allow\",\n  \"hook_event_name\": \"PreToolUse\"\n}\n```\n\n**Event-specific fields:**\n\n- **PreToolUse/PostToolUse:** `tool_name`, `tool_input`, `tool_result`\n- **UserPromptSubmit:** `user_prompt`\n- **Stop/SubagentStop:** `reason`\n\nAccess fields in prompts using `$TOOL_INPUT`, `$TOOL_RESULT`, `$USER_PROMPT`, etc.\n\n## Environment Variables\n\nAvailable in all command hooks:\n\n- `$CLAUDE_PROJECT_DIR` - Project root path\n- `$CLAUDE_PLUGIN_ROOT` - Plugin directory (use for portable paths)\n- `$CLAUDE_ENV_FILE` - SessionStart only: persist env vars here\n- `$CLAUDE_CODE_REMOTE` - Set if running in remote context\n\n**Always use ${CLAUDE_PLUGIN_ROOT} in hook commands for portability:**\n\n```json\n{\n  \"type\": \"command\",\n  \"command\": \"bash ${CLAUDE_PLUGIN_ROOT}/scripts/validate.sh\"\n}\n```\n\n## Plugin Hook Configuration\n\nIn plugins, define hooks in `hooks/hooks.json`:\n\n```json\n{\n  \"PreToolUse\": [\n    {\n      \"matcher\": \"Write|Edit\",\n      \"hooks\": [\n        {\n          \"type\": \"prompt\",\n          \"prompt\": \"Validate file write safety\"\n        }\n      ]\n    }\n  ],\n  \"Stop\": [\n    {\n      \"matcher\": \"*\",\n      \"hooks\": [\n        {\n          \"type\": \"prompt\",\n          \"prompt\": \"Verify task completion\"\n        }\n      ]\n    }\n  ],\n  \"SessionStart\": [\n    {\n      \"matcher\": \"*\",\n      \"hooks\": [\n        {\n          \"type\": \"command\",\n          \"command\": \"bash ${CLAUDE_PLUGIN_ROOT}/scripts/load-context.sh\",\n          \"timeout\": 10\n        }\n      ]\n    }\n  ]\n}\n```\n\nPlugin hooks merge with user's hooks and run in parallel.\n\n## Matchers\n\n### Tool Name Matching\n\n**Exact match:**\n```json\n\"matcher\": \"Write\"\n```\n\n**Multiple tools:**\n```json\n\"matcher\": \"Read|Write|Edit\"\n```\n\n**Wildcard (all tools):**\n```json\n\"matcher\": \"*\"\n```\n\n**Regex patterns:**\n```json\n\"matcher\": \"mcp__.*__delete.*\"  // All MCP delete tools\n```\n\n**Note:** Matchers are case-sensitive.\n\n### Common Patterns\n\n```json\n// All MCP tools\n\"matcher\": \"mcp__.*\"\n\n// Specific plugin's MCP tools\n\"matcher\": \"mcp__plugin_asana_.*\"\n\n// All file operations\n\"matcher\": \"Read|Write|Edit\"\n\n// Bash commands only\n\"matcher\": \"Bash\"\n```\n\n## Security Best Practices\n\n### Input Validation\n\nAlways validate inputs in command hooks:\n\n```bash\n#!/bin/bash\nset -euo pipefail\n\ninput=$(cat)\ntool_name=$(echo \"$input\" | jq -r '.tool_name')\n\n# Validate tool name format\nif [[ ! \"$tool_name\" =~ ^[a-zA-Z0-9_]+$ ]]; then\n  echo '{\"decision\": \"deny\", \"reason\": \"Invalid tool name\"}' >&2\n  exit 2\nfi\n```\n\n### Path Safety\n\nCheck for path traversal and sensitive files:\n\n```bash\nfile_path=$(echo \"$input\" | jq -r '.tool_input.file_path')\n\n# Deny path traversal\nif [[ \"$file_path\" == *\"..\"* ]]; then\n  echo '{\"decision\": \"deny\", \"reason\": \"Path traversal detected\"}' >&2\n  exit 2\nfi\n\n# Deny sensitive files\nif [[ \"$file_path\" == *\".env\"* ]]; then\n  echo '{\"decision\": \"deny\", \"reason\": \"Sensitive file\"}' >&2\n  exit 2\nfi\n```\n\nSee `examples/validate-write.sh` and `examples/validate-bash.sh` for complete examples.\n\n### Quote All Variables\n\n```bash\n# GOOD: Quoted\necho \"$file_path\"\ncd \"$CLAUDE_PROJECT_DIR\"\n\n# BAD: Unquoted (injection risk)\necho $file_path\ncd $CLAUDE_PROJECT_DIR\n```\n\n### Set Appropriate Timeouts\n\n```json\n{\n  \"type\": \"command\",\n  \"command\": \"bash script.sh\",\n  \"timeout\": 10\n}\n```\n\n**Defaults:** Command hooks (60s), Prompt hooks (30s)\n\n## Performance Considerations\n\n### Parallel Execution\n\nAll matching hooks run **in parallel**:\n\n```json\n{\n  \"PreToolUse\": [\n    {\n      \"matcher\": \"Write\",\n      \"hooks\": [\n        {\"type\": \"command\", \"command\": \"check1.sh\"},  // Parallel\n        {\"type\": \"command\", \"command\": \"check2.sh\"},  // Parallel\n        {\"type\": \"prompt\", \"prompt\": \"Validate...\"}   // Parallel\n      ]\n    }\n  ]\n}\n```\n\n**Design implications:**\n- Hooks don't see each other's output\n- Non-deterministic ordering\n- Design for independence\n\n### Optimization\n\n1. Use command hooks for quick deterministic checks\n2. Use prompt hooks for complex reasoning\n3. Cache validation results in temp files\n4. Minimize I/O in hot paths\n\n## Temporarily Active Hooks\n\nCreate hooks that activate conditionally by checking for a flag file or configuration:\n\n**Pattern: Flag file activation**\n```bash\n#!/bin/bash\n# Only active when flag file exists\nFLAG_FILE=\"$CLAUDE_PROJECT_DIR/.enable-strict-validation\"\n\nif [ ! -f \"$FLAG_FILE\" ]; then\n  # Flag not present, skip validation\n  exit 0\nfi\n\n# Flag present, run validation\ninput=$(cat)\n# ... validation logic ...\n```\n\n**Pattern: Configuration-based activation**\n```bash\n#!/bin/bash\n# Check configuration for activation\nCONFIG_FILE=\"$CLAUDE_PROJECT_DIR/.claude/plugin-config.json\"\n\nif [ -f \"$CONFIG_FILE\" ]; then\n  enabled=$(jq -r '.strictMode // false' \"$CONFIG_FILE\")\n  if [ \"$enabled\" != \"true\" ]; then\n    exit 0  # Not enabled, skip\n  fi\nfi\n\n# Enabled, run hook logic\ninput=$(cat)\n# ... hook logic ...\n```\n\n**Use cases:**\n- Enable strict validation only when needed\n- Temporary debugging hooks\n- Project-specific hook behavior\n- Feature flags for hooks\n\n**Best practice:** Document activation mechanism in plugin README so users know how to enable/disable temporary hooks.\n\n## Hook Lifecycle and Limitations\n\n### Hooks Load at Session Start\n\n**Important:** Hooks are loaded when Claude Code session starts. Changes to hook configuration require restarting Claude Code.\n\n**Cannot hot-swap hooks:**\n- Editing `hooks/hooks.json` won't affect current session\n- Adding new hook scripts won't be recognized\n- Changing hook commands/prompts won't update\n- Must restart Claude Code: exit and run `claude` again\n\n**To test hook changes:**\n1. Edit hook configuration or scripts\n2. Exit Claude Code session\n3. Restart: `claude` or `cc`\n4. New hook configuration loads\n5. Test hooks with `claude --debug`\n\n### Hook Validation at Startup\n\nHooks are validated when Claude Code starts:\n- Invalid JSON in hooks.json causes loading failure\n- Missing scripts cause warnings\n- Syntax errors reported in debug mode\n\nUse `/hooks` command to review loaded hooks in current session.\n\n## Debugging Hooks\n\n### Enable Debug Mode\n\n```bash\nclaude --debug\n```\n\nLook for hook registration, execution logs, input/output JSON, and timing information.\n\n### Test Hook Scripts\n\nTest command hooks directly:\n\n```bash\necho '{\"tool_name\": \"Write\", \"tool_input\": {\"file_path\": \"/test\"}}' | \\\n  bash ${CLAUDE_PLUGIN_ROOT}/scripts/validate.sh\n\necho \"Exit code: $?\"\n```\n\n### Validate JSON Output\n\nEnsure hooks output valid JSON:\n\n```bash\noutput=$(./your-hook.sh < test-input.json)\necho \"$output\" | jq .\n```\n\n## Quick Reference\n\n### Hook Events Summary\n\n| Event | When | Use For |\n|-------|------|---------|\n| PreToolUse | Before tool | Validation, modification |\n| PostToolUse | After tool | Feedback, logging |\n| UserPromptSubmit | User input | Context, validation |\n| Stop | Agent stopping | Completeness check |\n| SubagentStop | Subagent done | Task validation |\n| SessionStart | Session begins | Context loading |\n| SessionEnd | Session ends | Cleanup, logging |\n| PreCompact | Before compact | Preserve context |\n| Notification | User notified | Logging, reactions |\n\n### Best Practices\n\n**DO:**\n- âœ… Use prompt-based hooks for complex logic\n- âœ… Use ${CLAUDE_PLUGIN_ROOT} for portability\n- âœ… Validate all inputs in command hooks\n- âœ… Quote all bash variables\n- âœ… Set appropriate timeouts\n- âœ… Return structured JSON output\n- âœ… Test hooks thoroughly\n\n**DON'T:**\n- âŒ Use hardcoded paths\n- âŒ Trust user input without validation\n- âŒ Create long-running hooks\n- âŒ Rely on hook execution order\n- âŒ Modify global state unpredictably\n- âŒ Log sensitive information\n\n## Additional Resources\n\n### Reference Files\n\nFor detailed patterns and advanced techniques, consult:\n\n- **`references/patterns.md`** - Common hook patterns (8+ proven patterns)\n- **`references/migration.md`** - Migrating from basic to advanced hooks\n- **`references/advanced.md`** - Advanced use cases and techniques\n\n### Example Hook Scripts\n\nWorking examples in `examples/`:\n\n- **`validate-write.sh`** - File write validation example\n- **`validate-bash.sh`** - Bash command validation example\n- **`load-context.sh`** - SessionStart context loading example\n\n### Utility Scripts\n\nDevelopment tools in `scripts/`:\n\n- **`validate-hook-schema.sh`** - Validate hooks.json structure and syntax\n- **`test-hook.sh`** - Test hooks with sample input before deployment\n- **`hook-linter.sh`** - Check hook scripts for common issues and best practices\n\n### External Resources\n\n- **Official Docs**: https://docs.claude.com/en/docs/claude-code/hooks\n- **Examples**: See security-guidance plugin in marketplace\n- **Testing**: Use `claude --debug` for detailed logs\n- **Validation**: Use `jq` to validate hook JSON output\n\n## Implementation Workflow\n\nTo implement hooks in a plugin:\n\n1. Identify events to hook into (PreToolUse, Stop, SessionStart, etc.)\n2. Decide between prompt-based (flexible) or command (deterministic) hooks\n3. Write hook configuration in `hooks/hooks.json`\n4. For command hooks, create hook scripts\n5. Use ${CLAUDE_PLUGIN_ROOT} for all file references\n6. Validate configuration with `scripts/validate-hook-schema.sh hooks/hooks.json`\n7. Test hooks with `scripts/test-hook.sh` before deployment\n8. Test in Claude Code with `claude --debug`\n9. Document hooks in plugin README\n\nFocus on prompt-based hooks for most use cases. Reserve command hooks for performance-critical or deterministic checks.\n"
      },
      "discovered_at": "2026-01-11T15:36:02.159124Z",
      "fetch_error": null
    },
    {
      "name": "mcp-integration",
      "slug": "mcp-integration",
      "source": "skillsmp_top",
      "owner": "anthropics",
      "repo_name": "claude-code",
      "repository_url": "https://github.com/anthropics/claude-code",
      "skill_path": "plugins/plugin-dev/skills/mcp-integration",
      "github_metadata": {
        "stars": 55095,
        "description": "Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands.",
        "default_branch": "main",
        "pushed_at": "2026-01-11T00:28:28Z",
        "created_at": "2025-02-22T17:41:21Z",
        "language": "Shell",
        "license": null,
        "open_issues": 4495,
        "forks": 3984
      },
      "skill_md": {
        "found": true,
        "path": "plugins/plugin-dev/skills/mcp-integration/SKILL.md",
        "branch": "main",
        "content": "---\nname: MCP Integration\ndescription: This skill should be used when the user asks to \"add MCP server\", \"integrate MCP\", \"configure MCP in plugin\", \"use .mcp.json\", \"set up Model Context Protocol\", \"connect external service\", mentions \"${CLAUDE_PLUGIN_ROOT} with MCP\", or discusses MCP server types (SSE, stdio, HTTP, WebSocket). Provides comprehensive guidance for integrating Model Context Protocol servers into Claude Code plugins for external tool and service integration.\nversion: 0.1.0\n---\n\n# MCP Integration for Claude Code Plugins\n\n## Overview\n\nModel Context Protocol (MCP) enables Claude Code plugins to integrate with external services and APIs by providing structured tool access. Use MCP integration to expose external service capabilities as tools within Claude Code.\n\n**Key capabilities:**\n- Connect to external services (databases, APIs, file systems)\n- Provide 10+ related tools from a single service\n- Handle OAuth and complex authentication flows\n- Bundle MCP servers with plugins for automatic setup\n\n## MCP Server Configuration Methods\n\nPlugins can bundle MCP servers in two ways:\n\n### Method 1: Dedicated .mcp.json (Recommended)\n\nCreate `.mcp.json` at plugin root:\n\n```json\n{\n  \"database-tools\": {\n    \"command\": \"${CLAUDE_PLUGIN_ROOT}/servers/db-server\",\n    \"args\": [\"--config\", \"${CLAUDE_PLUGIN_ROOT}/config.json\"],\n    \"env\": {\n      \"DB_URL\": \"${DB_URL}\"\n    }\n  }\n}\n```\n\n**Benefits:**\n- Clear separation of concerns\n- Easier to maintain\n- Better for multiple servers\n\n### Method 2: Inline in plugin.json\n\nAdd `mcpServers` field to plugin.json:\n\n```json\n{\n  \"name\": \"my-plugin\",\n  \"version\": \"1.0.0\",\n  \"mcpServers\": {\n    \"plugin-api\": {\n      \"command\": \"${CLAUDE_PLUGIN_ROOT}/servers/api-server\",\n      \"args\": [\"--port\", \"8080\"]\n    }\n  }\n}\n```\n\n**Benefits:**\n- Single configuration file\n- Good for simple single-server plugins\n\n## MCP Server Types\n\n### stdio (Local Process)\n\nExecute local MCP servers as child processes. Best for local tools and custom servers.\n\n**Configuration:**\n```json\n{\n  \"filesystem\": {\n    \"command\": \"npx\",\n    \"args\": [\"-y\", \"@modelcontextprotocol/server-filesystem\", \"/allowed/path\"],\n    \"env\": {\n      \"LOG_LEVEL\": \"debug\"\n    }\n  }\n}\n```\n\n**Use cases:**\n- File system access\n- Local database connections\n- Custom MCP servers\n- NPM-packaged MCP servers\n\n**Process management:**\n- Claude Code spawns and manages the process\n- Communicates via stdin/stdout\n- Terminates when Claude Code exits\n\n### SSE (Server-Sent Events)\n\nConnect to hosted MCP servers with OAuth support. Best for cloud services.\n\n**Configuration:**\n```json\n{\n  \"asana\": {\n    \"type\": \"sse\",\n    \"url\": \"https://mcp.asana.com/sse\"\n  }\n}\n```\n\n**Use cases:**\n- Official hosted MCP servers (Asana, GitHub, etc.)\n- Cloud services with MCP endpoints\n- OAuth-based authentication\n- No local installation needed\n\n**Authentication:**\n- OAuth flows handled automatically\n- User prompted on first use\n- Tokens managed by Claude Code\n\n### HTTP (REST API)\n\nConnect to RESTful MCP servers with token authentication.\n\n**Configuration:**\n```json\n{\n  \"api-service\": {\n    \"type\": \"http\",\n    \"url\": \"https://api.example.com/mcp\",\n    \"headers\": {\n      \"Authorization\": \"Bearer ${API_TOKEN}\",\n      \"X-Custom-Header\": \"value\"\n    }\n  }\n}\n```\n\n**Use cases:**\n- REST API-based MCP servers\n- Token-based authentication\n- Custom API backends\n- Stateless interactions\n\n### WebSocket (Real-time)\n\nConnect to WebSocket MCP servers for real-time bidirectional communication.\n\n**Configuration:**\n```json\n{\n  \"realtime-service\": {\n    \"type\": \"ws\",\n    \"url\": \"wss://mcp.example.com/ws\",\n    \"headers\": {\n      \"Authorization\": \"Bearer ${TOKEN}\"\n    }\n  }\n}\n```\n\n**Use cases:**\n- Real-time data streaming\n- Persistent connections\n- Push notifications from server\n- Low-latency requirements\n\n## Environment Variable Expansion\n\nAll MCP configurations support environment variable substitution:\n\n**${CLAUDE_PLUGIN_ROOT}** - Plugin directory (always use for portability):\n```json\n{\n  \"command\": \"${CLAUDE_PLUGIN_ROOT}/servers/my-server\"\n}\n```\n\n**User environment variables** - From user's shell:\n```json\n{\n  \"env\": {\n    \"API_KEY\": \"${MY_API_KEY}\",\n    \"DATABASE_URL\": \"${DB_URL}\"\n  }\n}\n```\n\n**Best practice:** Document all required environment variables in plugin README.\n\n## MCP Tool Naming\n\nWhen MCP servers provide tools, they're automatically prefixed:\n\n**Format:** `mcp__plugin_<plugin-name>_<server-name>__<tool-name>`\n\n**Example:**\n- Plugin: `asana`\n- Server: `asana`\n- Tool: `create_task`\n- **Full name:** `mcp__plugin_asana_asana__asana_create_task`\n\n### Using MCP Tools in Commands\n\nPre-allow specific MCP tools in command frontmatter:\n\n```markdown\n---\nallowed-tools: [\n  \"mcp__plugin_asana_asana__asana_create_task\",\n  \"mcp__plugin_asana_asana__asana_search_tasks\"\n]\n---\n```\n\n**Wildcard (use sparingly):**\n```markdown\n---\nallowed-tools: [\"mcp__plugin_asana_asana__*\"]\n---\n```\n\n**Best practice:** Pre-allow specific tools, not wildcards, for security.\n\n## Lifecycle Management\n\n**Automatic startup:**\n- MCP servers start when plugin enables\n- Connection established before first tool use\n- Restart required for configuration changes\n\n**Lifecycle:**\n1. Plugin loads\n2. MCP configuration parsed\n3. Server process started (stdio) or connection established (SSE/HTTP/WS)\n4. Tools discovered and registered\n5. Tools available as `mcp__plugin_...__...`\n\n**Viewing servers:**\nUse `/mcp` command to see all servers including plugin-provided ones.\n\n## Authentication Patterns\n\n### OAuth (SSE/HTTP)\n\nOAuth handled automatically by Claude Code:\n\n```json\n{\n  \"type\": \"sse\",\n  \"url\": \"https://mcp.example.com/sse\"\n}\n```\n\nUser authenticates in browser on first use. No additional configuration needed.\n\n### Token-Based (Headers)\n\nStatic or environment variable tokens:\n\n```json\n{\n  \"type\": \"http\",\n  \"url\": \"https://api.example.com\",\n  \"headers\": {\n    \"Authorization\": \"Bearer ${API_TOKEN}\"\n  }\n}\n```\n\nDocument required environment variables in README.\n\n### Environment Variables (stdio)\n\nPass configuration to MCP server:\n\n```json\n{\n  \"command\": \"python\",\n  \"args\": [\"-m\", \"my_mcp_server\"],\n  \"env\": {\n    \"DATABASE_URL\": \"${DB_URL}\",\n    \"API_KEY\": \"${API_KEY}\",\n    \"LOG_LEVEL\": \"info\"\n  }\n}\n```\n\n## Integration Patterns\n\n### Pattern 1: Simple Tool Wrapper\n\nCommands use MCP tools with user interaction:\n\n```markdown\n# Command: create-item.md\n---\nallowed-tools: [\"mcp__plugin_name_server__create_item\"]\n---\n\nSteps:\n1. Gather item details from user\n2. Use mcp__plugin_name_server__create_item\n3. Confirm creation\n```\n\n**Use for:** Adding validation or preprocessing before MCP calls.\n\n### Pattern 2: Autonomous Agent\n\nAgents use MCP tools autonomously:\n\n```markdown\n# Agent: data-analyzer.md\n\nAnalysis Process:\n1. Query data via mcp__plugin_db_server__query\n2. Process and analyze results\n3. Generate insights report\n```\n\n**Use for:** Multi-step MCP workflows without user interaction.\n\n### Pattern 3: Multi-Server Plugin\n\nIntegrate multiple MCP servers:\n\n```json\n{\n  \"github\": {\n    \"type\": \"sse\",\n    \"url\": \"https://mcp.github.com/sse\"\n  },\n  \"jira\": {\n    \"type\": \"sse\",\n    \"url\": \"https://mcp.jira.com/sse\"\n  }\n}\n```\n\n**Use for:** Workflows spanning multiple services.\n\n## Security Best Practices\n\n### Use HTTPS/WSS\n\nAlways use secure connections:\n\n```json\nâœ… \"url\": \"https://mcp.example.com/sse\"\nâŒ \"url\": \"http://mcp.example.com/sse\"\n```\n\n### Token Management\n\n**DO:**\n- âœ… Use environment variables for tokens\n- âœ… Document required env vars in README\n- âœ… Let OAuth flow handle authentication\n\n**DON'T:**\n- âŒ Hardcode tokens in configuration\n- âŒ Commit tokens to git\n- âŒ Share tokens in documentation\n\n### Permission Scoping\n\nPre-allow only necessary MCP tools:\n\n```markdown\nâœ… allowed-tools: [\n  \"mcp__plugin_api_server__read_data\",\n  \"mcp__plugin_api_server__create_item\"\n]\n\nâŒ allowed-tools: [\"mcp__plugin_api_server__*\"]\n```\n\n## Error Handling\n\n### Connection Failures\n\nHandle MCP server unavailability:\n- Provide fallback behavior in commands\n- Inform user of connection issues\n- Check server URL and configuration\n\n### Tool Call Errors\n\nHandle failed MCP operations:\n- Validate inputs before calling MCP tools\n- Provide clear error messages\n- Check rate limiting and quotas\n\n### Configuration Errors\n\nValidate MCP configuration:\n- Test server connectivity during development\n- Validate JSON syntax\n- Check required environment variables\n\n## Performance Considerations\n\n### Lazy Loading\n\nMCP servers connect on-demand:\n- Not all servers connect at startup\n- First tool use triggers connection\n- Connection pooling managed automatically\n\n### Batching\n\nBatch similar requests when possible:\n\n```\n# Good: Single query with filters\ntasks = search_tasks(project=\"X\", assignee=\"me\", limit=50)\n\n# Avoid: Many individual queries\nfor id in task_ids:\n    task = get_task(id)\n```\n\n## Testing MCP Integration\n\n### Local Testing\n\n1. Configure MCP server in `.mcp.json`\n2. Install plugin locally (`.claude-plugin/`)\n3. Run `/mcp` to verify server appears\n4. Test tool calls in commands\n5. Check `claude --debug` logs for connection issues\n\n### Validation Checklist\n\n- [ ] MCP configuration is valid JSON\n- [ ] Server URL is correct and accessible\n- [ ] Required environment variables documented\n- [ ] Tools appear in `/mcp` output\n- [ ] Authentication works (OAuth or tokens)\n- [ ] Tool calls succeed from commands\n- [ ] Error cases handled gracefully\n\n## Debugging\n\n### Enable Debug Logging\n\n```bash\nclaude --debug\n```\n\nLook for:\n- MCP server connection attempts\n- Tool discovery logs\n- Authentication flows\n- Tool call errors\n\n### Common Issues\n\n**Server not connecting:**\n- Check URL is correct\n- Verify server is running (stdio)\n- Check network connectivity\n- Review authentication configuration\n\n**Tools not available:**\n- Verify server connected successfully\n- Check tool names match exactly\n- Run `/mcp` to see available tools\n- Restart Claude Code after config changes\n\n**Authentication failing:**\n- Clear cached auth tokens\n- Re-authenticate\n- Check token scopes and permissions\n- Verify environment variables set\n\n## Quick Reference\n\n### MCP Server Types\n\n| Type | Transport | Best For | Auth |\n|------|-----------|----------|------|\n| stdio | Process | Local tools, custom servers | Env vars |\n| SSE | HTTP | Hosted services, cloud APIs | OAuth |\n| HTTP | REST | API backends, token auth | Tokens |\n| ws | WebSocket | Real-time, streaming | Tokens |\n\n### Configuration Checklist\n\n- [ ] Server type specified (stdio/SSE/HTTP/ws)\n- [ ] Type-specific fields complete (command or url)\n- [ ] Authentication configured\n- [ ] Environment variables documented\n- [ ] HTTPS/WSS used (not HTTP/WS)\n- [ ] ${CLAUDE_PLUGIN_ROOT} used for paths\n\n### Best Practices\n\n**DO:**\n- âœ… Use ${CLAUDE_PLUGIN_ROOT} for portable paths\n- âœ… Document required environment variables\n- âœ… Use secure connections (HTTPS/WSS)\n- âœ… Pre-allow specific MCP tools in commands\n- âœ… Test MCP integration before publishing\n- âœ… Handle connection and tool errors gracefully\n\n**DON'T:**\n- âŒ Hardcode absolute paths\n- âŒ Commit credentials to git\n- âŒ Use HTTP instead of HTTPS\n- âŒ Pre-allow all tools with wildcards\n- âŒ Skip error handling\n- âŒ Forget to document setup\n\n## Additional Resources\n\n### Reference Files\n\nFor detailed information, consult:\n\n- **`references/server-types.md`** - Deep dive on each server type\n- **`references/authentication.md`** - Authentication patterns and OAuth\n- **`references/tool-usage.md`** - Using MCP tools in commands and agents\n\n### Example Configurations\n\nWorking examples in `examples/`:\n\n- **`stdio-server.json`** - Local stdio MCP server\n- **`sse-server.json`** - Hosted SSE server with OAuth\n- **`http-server.json`** - REST API with token auth\n\n### External Resources\n\n- **Official MCP Docs**: https://modelcontextprotocol.io/\n- **Claude Code MCP Docs**: https://docs.claude.com/en/docs/claude-code/mcp\n- **MCP SDK**: @modelcontextprotocol/sdk\n- **Testing**: Use `claude --debug` and `/mcp` command\n\n## Implementation Workflow\n\nTo add MCP integration to a plugin:\n\n1. Choose MCP server type (stdio, SSE, HTTP, ws)\n2. Create `.mcp.json` at plugin root with configuration\n3. Use ${CLAUDE_PLUGIN_ROOT} for all file references\n4. Document required environment variables in README\n5. Test locally with `/mcp` command\n6. Pre-allow MCP tools in relevant commands\n7. Handle authentication (OAuth or tokens)\n8. Test error cases (connection failures, auth errors)\n9. Document MCP integration in plugin README\n\nFocus on stdio for custom/local servers, SSE for hosted services with OAuth.\n"
      },
      "discovered_at": "2026-01-11T15:36:02.551134Z",
      "fetch_error": null
    },
    {
      "name": "configured-agent",
      "slug": "configured-agent",
      "source": "skillsmp_top",
      "owner": "anthropics",
      "repo_name": "claude-code",
      "repository_url": "https://github.com/anthropics/claude-code",
      "skill_path": "plugins/plugin-dev/skills/plugin-settings",
      "github_metadata": {
        "stars": 55095,
        "description": "Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands.",
        "default_branch": "main",
        "pushed_at": "2026-01-11T00:28:28Z",
        "created_at": "2025-02-22T17:41:21Z",
        "language": "Shell",
        "license": null,
        "open_issues": 4495,
        "forks": 3984
      },
      "skill_md": {
        "found": true,
        "path": "plugins/plugin-dev/skills/plugin-settings/SKILL.md",
        "branch": "main",
        "content": "---\nname: Plugin Settings\ndescription: This skill should be used when the user asks about \"plugin settings\", \"store plugin configuration\", \"user-configurable plugin\", \".local.md files\", \"plugin state files\", \"read YAML frontmatter\", \"per-project plugin settings\", or wants to make plugin behavior configurable. Documents the .claude/plugin-name.local.md pattern for storing plugin-specific configuration with YAML frontmatter and markdown content.\nversion: 0.1.0\n---\n\n# Plugin Settings Pattern for Claude Code Plugins\n\n## Overview\n\nPlugins can store user-configurable settings and state in `.claude/plugin-name.local.md` files within the project directory. This pattern uses YAML frontmatter for structured configuration and markdown content for prompts or additional context.\n\n**Key characteristics:**\n- File location: `.claude/plugin-name.local.md` in project root\n- Structure: YAML frontmatter + markdown body\n- Purpose: Per-project plugin configuration and state\n- Usage: Read from hooks, commands, and agents\n- Lifecycle: User-managed (not in git, should be in `.gitignore`)\n\n## File Structure\n\n### Basic Template\n\n```markdown\n---\nenabled: true\nsetting1: value1\nsetting2: value2\nnumeric_setting: 42\nlist_setting: [\"item1\", \"item2\"]\n---\n\n# Additional Context\n\nThis markdown body can contain:\n- Task descriptions\n- Additional instructions\n- Prompts to feed back to Claude\n- Documentation or notes\n```\n\n### Example: Plugin State File\n\n**.claude/my-plugin.local.md:**\n```markdown\n---\nenabled: true\nstrict_mode: false\nmax_retries: 3\nnotification_level: info\ncoordinator_session: team-leader\n---\n\n# Plugin Configuration\n\nThis plugin is configured for standard validation mode.\nContact @team-lead with questions.\n```\n\n## Reading Settings Files\n\n### From Hooks (Bash Scripts)\n\n**Pattern: Check existence and parse frontmatter**\n\n```bash\n#!/bin/bash\nset -euo pipefail\n\n# Define state file path\nSTATE_FILE=\".claude/my-plugin.local.md\"\n\n# Quick exit if file doesn't exist\nif [[ ! -f \"$STATE_FILE\" ]]; then\n  exit 0  # Plugin not configured, skip\nfi\n\n# Parse YAML frontmatter (between --- markers)\nFRONTMATTER=$(sed -n '/^---$/,/^---$/{ /^---$/d; p; }' \"$STATE_FILE\")\n\n# Extract individual fields\nENABLED=$(echo \"$FRONTMATTER\" | grep '^enabled:' | sed 's/enabled: *//' | sed 's/^\"\\(.*\\)\"$/\\1/')\nSTRICT_MODE=$(echo \"$FRONTMATTER\" | grep '^strict_mode:' | sed 's/strict_mode: *//' | sed 's/^\"\\(.*\\)\"$/\\1/')\n\n# Check if enabled\nif [[ \"$ENABLED\" != \"true\" ]]; then\n  exit 0  # Disabled\nfi\n\n# Use configuration in hook logic\nif [[ \"$STRICT_MODE\" == \"true\" ]]; then\n  # Apply strict validation\n  # ...\nfi\n```\n\nSee `examples/read-settings-hook.sh` for complete working example.\n\n### From Commands\n\nCommands can read settings files to customize behavior:\n\n```markdown\n---\ndescription: Process data with plugin\nallowed-tools: [\"Read\", \"Bash\"]\n---\n\n# Process Command\n\nSteps:\n1. Check if settings exist at `.claude/my-plugin.local.md`\n2. Read configuration using Read tool\n3. Parse YAML frontmatter to extract settings\n4. Apply settings to processing logic\n5. Execute with configured behavior\n```\n\n### From Agents\n\nAgents can reference settings in their instructions:\n\n```markdown\n---\nname: configured-agent\ndescription: Agent that adapts to project settings\n---\n\nCheck for plugin settings at `.claude/my-plugin.local.md`.\nIf present, parse YAML frontmatter and adapt behavior according to:\n- enabled: Whether plugin is active\n- mode: Processing mode (strict, standard, lenient)\n- Additional configuration fields\n```\n\n## Parsing Techniques\n\n### Extract Frontmatter\n\n```bash\n# Extract everything between --- markers\nFRONTMATTER=$(sed -n '/^---$/,/^---$/{ /^---$/d; p; }' \"$FILE\")\n```\n\n### Read Individual Fields\n\n**String fields:**\n```bash\nVALUE=$(echo \"$FRONTMATTER\" | grep '^field_name:' | sed 's/field_name: *//' | sed 's/^\"\\(.*\\)\"$/\\1/')\n```\n\n**Boolean fields:**\n```bash\nENABLED=$(echo \"$FRONTMATTER\" | grep '^enabled:' | sed 's/enabled: *//')\n# Compare: if [[ \"$ENABLED\" == \"true\" ]]; then\n```\n\n**Numeric fields:**\n```bash\nMAX=$(echo \"$FRONTMATTER\" | grep '^max_value:' | sed 's/max_value: *//')\n# Use: if [[ $MAX -gt 100 ]]; then\n```\n\n### Read Markdown Body\n\nExtract content after second `---`:\n\n```bash\n# Get everything after closing ---\nBODY=$(awk '/^---$/{i++; next} i>=2' \"$FILE\")\n```\n\n## Common Patterns\n\n### Pattern 1: Temporarily Active Hooks\n\nUse settings file to control hook activation:\n\n```bash\n#!/bin/bash\nSTATE_FILE=\".claude/security-scan.local.md\"\n\n# Quick exit if not configured\nif [[ ! -f \"$STATE_FILE\" ]]; then\n  exit 0\nfi\n\n# Read enabled flag\nFRONTMATTER=$(sed -n '/^---$/,/^---$/{ /^---$/d; p; }' \"$STATE_FILE\")\nENABLED=$(echo \"$FRONTMATTER\" | grep '^enabled:' | sed 's/enabled: *//')\n\nif [[ \"$ENABLED\" != \"true\" ]]; then\n  exit 0  # Disabled\nfi\n\n# Run hook logic\n# ...\n```\n\n**Use case:** Enable/disable hooks without editing hooks.json (requires restart).\n\n### Pattern 2: Agent State Management\n\nStore agent-specific state and configuration:\n\n**.claude/multi-agent-swarm.local.md:**\n```markdown\n---\nagent_name: auth-agent\ntask_number: 3.5\npr_number: 1234\ncoordinator_session: team-leader\nenabled: true\ndependencies: [\"Task 3.4\"]\n---\n\n# Task Assignment\n\nImplement JWT authentication for the API.\n\n**Success Criteria:**\n- Authentication endpoints created\n- Tests passing\n- PR created and CI green\n```\n\nRead from hooks to coordinate agents:\n\n```bash\nAGENT_NAME=$(echo \"$FRONTMATTER\" | grep '^agent_name:' | sed 's/agent_name: *//')\nCOORDINATOR=$(echo \"$FRONTMATTER\" | grep '^coordinator_session:' | sed 's/coordinator_session: *//')\n\n# Send notification to coordinator\ntmux send-keys -t \"$COORDINATOR\" \"Agent $AGENT_NAME completed task\" Enter\n```\n\n### Pattern 3: Configuration-Driven Behavior\n\n**.claude/my-plugin.local.md:**\n```markdown\n---\nvalidation_level: strict\nmax_file_size: 1000000\nallowed_extensions: [\".js\", \".ts\", \".tsx\"]\nenable_logging: true\n---\n\n# Validation Configuration\n\nStrict mode enabled for this project.\nAll writes validated against security policies.\n```\n\nUse in hooks or commands:\n\n```bash\nLEVEL=$(echo \"$FRONTMATTER\" | grep '^validation_level:' | sed 's/validation_level: *//')\n\ncase \"$LEVEL\" in\n  strict)\n    # Apply strict validation\n    ;;\n  standard)\n    # Apply standard validation\n    ;;\n  lenient)\n    # Apply lenient validation\n    ;;\nesac\n```\n\n## Creating Settings Files\n\n### From Commands\n\nCommands can create settings files:\n\n```markdown\n# Setup Command\n\nSteps:\n1. Ask user for configuration preferences\n2. Create `.claude/my-plugin.local.md` with YAML frontmatter\n3. Set appropriate values based on user input\n4. Inform user that settings are saved\n5. Remind user to restart Claude Code for hooks to recognize changes\n```\n\n### Template Generation\n\nProvide template in plugin README:\n\n```markdown\n## Configuration\n\nCreate `.claude/my-plugin.local.md` in your project:\n\n\\`\\`\\`markdown\n---\nenabled: true\nmode: standard\nmax_retries: 3\n---\n\n# Plugin Configuration\n\nYour settings are active.\n\\`\\`\\`\n\nAfter creating or editing, restart Claude Code for changes to take effect.\n```\n\n## Best Practices\n\n### File Naming\n\nâœ… **DO:**\n- Use `.claude/plugin-name.local.md` format\n- Match plugin name exactly\n- Use `.local.md` suffix for user-local files\n\nâŒ **DON'T:**\n- Use different directory (not `.claude/`)\n- Use inconsistent naming\n- Use `.md` without `.local` (might be committed)\n\n### Gitignore\n\nAlways add to `.gitignore`:\n\n```gitignore\n.claude/*.local.md\n.claude/*.local.json\n```\n\nDocument this in plugin README.\n\n### Defaults\n\nProvide sensible defaults when settings file doesn't exist:\n\n```bash\nif [[ ! -f \"$STATE_FILE\" ]]; then\n  # Use defaults\n  ENABLED=true\n  MODE=standard\nelse\n  # Read from file\n  # ...\nfi\n```\n\n### Validation\n\nValidate settings values:\n\n```bash\nMAX=$(echo \"$FRONTMATTER\" | grep '^max_value:' | sed 's/max_value: *//')\n\n# Validate numeric range\nif ! [[ \"$MAX\" =~ ^[0-9]+$ ]] || [[ $MAX -lt 1 ]] || [[ $MAX -gt 100 ]]; then\n  echo \"âš ï¸  Invalid max_value in settings (must be 1-100)\" >&2\n  MAX=10  # Use default\nfi\n```\n\n### Restart Requirement\n\n**Important:** Settings changes require Claude Code restart.\n\nDocument in your README:\n\n```markdown\n## Changing Settings\n\nAfter editing `.claude/my-plugin.local.md`:\n1. Save the file\n2. Exit Claude Code\n3. Restart: `claude` or `cc`\n4. New settings will be loaded\n```\n\nHooks cannot be hot-swapped within a session.\n\n## Security Considerations\n\n### Sanitize User Input\n\nWhen writing settings files from user input:\n\n```bash\n# Escape quotes in user input\nSAFE_VALUE=$(echo \"$USER_INPUT\" | sed 's/\"/\\\\\"/g')\n\n# Write to file\ncat > \"$STATE_FILE\" <<EOF\n---\nuser_setting: \"$SAFE_VALUE\"\n---\nEOF\n```\n\n### Validate File Paths\n\nIf settings contain file paths:\n\n```bash\nFILE_PATH=$(echo \"$FRONTMATTER\" | grep '^data_file:' | sed 's/data_file: *//')\n\n# Check for path traversal\nif [[ \"$FILE_PATH\" == *\"..\"* ]]; then\n  echo \"âš ï¸  Invalid path in settings (path traversal)\" >&2\n  exit 2\nfi\n```\n\n### Permissions\n\nSettings files should be:\n- Readable by user only (`chmod 600`)\n- Not committed to git\n- Not shared between users\n\n## Real-World Examples\n\n### multi-agent-swarm Plugin\n\n**.claude/multi-agent-swarm.local.md:**\n```markdown\n---\nagent_name: auth-implementation\ntask_number: 3.5\npr_number: 1234\ncoordinator_session: team-leader\nenabled: true\ndependencies: [\"Task 3.4\"]\nadditional_instructions: Use JWT tokens, not sessions\n---\n\n# Task: Implement Authentication\n\nBuild JWT-based authentication for the REST API.\nCoordinate with auth-agent on shared types.\n```\n\n**Hook usage (agent-stop-notification.sh):**\n- Checks if file exists (line 15-18: quick exit if not)\n- Parses frontmatter to get coordinator_session, agent_name, enabled\n- Sends notifications to coordinator if enabled\n- Allows quick activation/deactivation via `enabled: true/false`\n\n### ralph-wiggum Plugin\n\n**.claude/ralph-loop.local.md:**\n```markdown\n---\niteration: 1\nmax_iterations: 10\ncompletion_promise: \"All tests passing and build successful\"\n---\n\nFix all the linting errors in the project.\nMake sure tests pass after each fix.\n```\n\n**Hook usage (stop-hook.sh):**\n- Checks if file exists (line 15-18: quick exit if not active)\n- Reads iteration count and max_iterations\n- Extracts completion_promise for loop termination\n- Reads body as the prompt to feed back\n- Updates iteration count on each loop\n\n## Quick Reference\n\n### File Location\n\n```\nproject-root/\nâ””â”€â”€ .claude/\n    â””â”€â”€ plugin-name.local.md\n```\n\n### Frontmatter Parsing\n\n```bash\n# Extract frontmatter\nFRONTMATTER=$(sed -n '/^---$/,/^---$/{ /^---$/d; p; }' \"$FILE\")\n\n# Read field\nVALUE=$(echo \"$FRONTMATTER\" | grep '^field:' | sed 's/field: *//' | sed 's/^\"\\(.*\\)\"$/\\1/')\n```\n\n### Body Parsing\n\n```bash\n# Extract body (after second ---)\nBODY=$(awk '/^---$/{i++; next} i>=2' \"$FILE\")\n```\n\n### Quick Exit Pattern\n\n```bash\nif [[ ! -f \".claude/my-plugin.local.md\" ]]; then\n  exit 0  # Not configured\nfi\n```\n\n## Additional Resources\n\n### Reference Files\n\nFor detailed implementation patterns:\n\n- **`references/parsing-techniques.md`** - Complete guide to parsing YAML frontmatter and markdown bodies\n- **`references/real-world-examples.md`** - Deep dive into multi-agent-swarm and ralph-wiggum implementations\n\n### Example Files\n\nWorking examples in `examples/`:\n\n- **`read-settings-hook.sh`** - Hook that reads and uses settings\n- **`create-settings-command.md`** - Command that creates settings file\n- **`example-settings.md`** - Template settings file\n\n### Utility Scripts\n\nDevelopment tools in `scripts/`:\n\n- **`validate-settings.sh`** - Validate settings file structure\n- **`parse-frontmatter.sh`** - Extract frontmatter fields\n\n## Implementation Workflow\n\nTo add settings to a plugin:\n\n1. Design settings schema (which fields, types, defaults)\n2. Create template file in plugin documentation\n3. Add gitignore entry for `.claude/*.local.md`\n4. Implement settings parsing in hooks/commands\n5. Use quick-exit pattern (check file exists, check enabled field)\n6. Document settings in plugin README with template\n7. Remind users that changes require Claude Code restart\n\nFocus on keeping settings simple and providing good defaults when settings file doesn't exist.\n"
      },
      "discovered_at": "2026-01-11T15:36:03.016822Z",
      "fetch_error": null
    },
    {
      "name": "command-name",
      "slug": "command-name",
      "source": "skillsmp_top",
      "owner": "anthropics",
      "repo_name": "claude-code",
      "repository_url": "https://github.com/anthropics/claude-code",
      "skill_path": "plugins/plugin-dev/skills/plugin-structure",
      "github_metadata": {
        "stars": 55095,
        "description": "Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands.",
        "default_branch": "main",
        "pushed_at": "2026-01-11T00:28:28Z",
        "created_at": "2025-02-22T17:41:21Z",
        "language": "Shell",
        "license": null,
        "open_issues": 4495,
        "forks": 3984
      },
      "skill_md": {
        "found": true,
        "path": "plugins/plugin-dev/skills/plugin-structure/SKILL.md",
        "branch": "main",
        "content": "---\nname: Plugin Structure\ndescription: This skill should be used when the user asks to \"create a plugin\", \"scaffold a plugin\", \"understand plugin structure\", \"organize plugin components\", \"set up plugin.json\", \"use ${CLAUDE_PLUGIN_ROOT}\", \"add commands/agents/skills/hooks\", \"configure auto-discovery\", or needs guidance on plugin directory layout, manifest configuration, component organization, file naming conventions, or Claude Code plugin architecture best practices.\nversion: 0.1.0\n---\n\n# Plugin Structure for Claude Code\n\n## Overview\n\nClaude Code plugins follow a standardized directory structure with automatic component discovery. Understanding this structure enables creating well-organized, maintainable plugins that integrate seamlessly with Claude Code.\n\n**Key concepts:**\n- Conventional directory layout for automatic discovery\n- Manifest-driven configuration in `.claude-plugin/plugin.json`\n- Component-based organization (commands, agents, skills, hooks)\n- Portable path references using `${CLAUDE_PLUGIN_ROOT}`\n- Explicit vs. auto-discovered component loading\n\n## Directory Structure\n\nEvery Claude Code plugin follows this organizational pattern:\n\n```\nplugin-name/\nâ”œâ”€â”€ .claude-plugin/\nâ”‚   â””â”€â”€ plugin.json          # Required: Plugin manifest\nâ”œâ”€â”€ commands/                 # Slash commands (.md files)\nâ”œâ”€â”€ agents/                   # Subagent definitions (.md files)\nâ”œâ”€â”€ skills/                   # Agent skills (subdirectories)\nâ”‚   â””â”€â”€ skill-name/\nâ”‚       â””â”€â”€ SKILL.md         # Required for each skill\nâ”œâ”€â”€ hooks/\nâ”‚   â””â”€â”€ hooks.json           # Event handler configuration\nâ”œâ”€â”€ .mcp.json                # MCP server definitions\nâ””â”€â”€ scripts/                 # Helper scripts and utilities\n```\n\n**Critical rules:**\n\n1. **Manifest location**: The `plugin.json` manifest MUST be in `.claude-plugin/` directory\n2. **Component locations**: All component directories (commands, agents, skills, hooks) MUST be at plugin root level, NOT nested inside `.claude-plugin/`\n3. **Optional components**: Only create directories for components the plugin actually uses\n4. **Naming convention**: Use kebab-case for all directory and file names\n\n## Plugin Manifest (plugin.json)\n\nThe manifest defines plugin metadata and configuration. Located at `.claude-plugin/plugin.json`:\n\n### Required Fields\n\n```json\n{\n  \"name\": \"plugin-name\"\n}\n```\n\n**Name requirements:**\n- Use kebab-case format (lowercase with hyphens)\n- Must be unique across installed plugins\n- No spaces or special characters\n- Example: `code-review-assistant`, `test-runner`, `api-docs`\n\n### Recommended Metadata\n\n```json\n{\n  \"name\": \"plugin-name\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Brief explanation of plugin purpose\",\n  \"author\": {\n    \"name\": \"Author Name\",\n    \"email\": \"author@example.com\",\n    \"url\": \"https://example.com\"\n  },\n  \"homepage\": \"https://docs.example.com\",\n  \"repository\": \"https://github.com/user/plugin-name\",\n  \"license\": \"MIT\",\n  \"keywords\": [\"testing\", \"automation\", \"ci-cd\"]\n}\n```\n\n**Version format**: Follow semantic versioning (MAJOR.MINOR.PATCH)\n**Keywords**: Use for plugin discovery and categorization\n\n### Component Path Configuration\n\nSpecify custom paths for components (supplements default directories):\n\n```json\n{\n  \"name\": \"plugin-name\",\n  \"commands\": \"./custom-commands\",\n  \"agents\": [\"./agents\", \"./specialized-agents\"],\n  \"hooks\": \"./config/hooks.json\",\n  \"mcpServers\": \"./.mcp.json\"\n}\n```\n\n**Important**: Custom paths supplement defaultsâ€”they don't replace them. Components in both default directories and custom paths will load.\n\n**Path rules:**\n- Must be relative to plugin root\n- Must start with `./`\n- Cannot use absolute paths\n- Support arrays for multiple locations\n\n## Component Organization\n\n### Commands\n\n**Location**: `commands/` directory\n**Format**: Markdown files with YAML frontmatter\n**Auto-discovery**: All `.md` files in `commands/` load automatically\n\n**Example structure**:\n```\ncommands/\nâ”œâ”€â”€ review.md        # /review command\nâ”œâ”€â”€ test.md          # /test command\nâ””â”€â”€ deploy.md        # /deploy command\n```\n\n**File format**:\n```markdown\n---\nname: command-name\ndescription: Command description\n---\n\nCommand implementation instructions...\n```\n\n**Usage**: Commands integrate as native slash commands in Claude Code\n\n### Agents\n\n**Location**: `agents/` directory\n**Format**: Markdown files with YAML frontmatter\n**Auto-discovery**: All `.md` files in `agents/` load automatically\n\n**Example structure**:\n```\nagents/\nâ”œâ”€â”€ code-reviewer.md\nâ”œâ”€â”€ test-generator.md\nâ””â”€â”€ refactorer.md\n```\n\n**File format**:\n```markdown\n---\ndescription: Agent role and expertise\ncapabilities:\n  - Specific task 1\n  - Specific task 2\n---\n\nDetailed agent instructions and knowledge...\n```\n\n**Usage**: Users can invoke agents manually, or Claude Code selects them automatically based on task context\n\n### Skills\n\n**Location**: `skills/` directory with subdirectories per skill\n**Format**: Each skill in its own directory with `SKILL.md` file\n**Auto-discovery**: All `SKILL.md` files in skill subdirectories load automatically\n\n**Example structure**:\n```\nskills/\nâ”œâ”€â”€ api-testing/\nâ”‚   â”œâ”€â”€ SKILL.md\nâ”‚   â”œâ”€â”€ scripts/\nâ”‚   â”‚   â””â”€â”€ test-runner.py\nâ”‚   â””â”€â”€ references/\nâ”‚       â””â”€â”€ api-spec.md\nâ””â”€â”€ database-migrations/\n    â”œâ”€â”€ SKILL.md\n    â””â”€â”€ examples/\n        â””â”€â”€ migration-template.sql\n```\n\n**SKILL.md format**:\n```markdown\n---\nname: Skill Name\ndescription: When to use this skill\nversion: 1.0.0\n---\n\nSkill instructions and guidance...\n```\n\n**Supporting files**: Skills can include scripts, references, examples, or assets in subdirectories\n\n**Usage**: Claude Code autonomously activates skills based on task context matching the description\n\n### Hooks\n\n**Location**: `hooks/hooks.json` or inline in `plugin.json`\n**Format**: JSON configuration defining event handlers\n**Registration**: Hooks register automatically when plugin enables\n\n**Example structure**:\n```\nhooks/\nâ”œâ”€â”€ hooks.json           # Hook configuration\nâ””â”€â”€ scripts/\n    â”œâ”€â”€ validate.sh      # Hook script\n    â””â”€â”€ check-style.sh   # Hook script\n```\n\n**Configuration format**:\n```json\n{\n  \"PreToolUse\": [{\n    \"matcher\": \"Write|Edit\",\n    \"hooks\": [{\n      \"type\": \"command\",\n      \"command\": \"bash ${CLAUDE_PLUGIN_ROOT}/hooks/scripts/validate.sh\",\n      \"timeout\": 30\n    }]\n  }]\n}\n```\n\n**Available events**: PreToolUse, PostToolUse, Stop, SubagentStop, SessionStart, SessionEnd, UserPromptSubmit, PreCompact, Notification\n\n**Usage**: Hooks execute automatically in response to Claude Code events\n\n### MCP Servers\n\n**Location**: `.mcp.json` at plugin root or inline in `plugin.json`\n**Format**: JSON configuration for MCP server definitions\n**Auto-start**: Servers start automatically when plugin enables\n\n**Example format**:\n```json\n{\n  \"mcpServers\": {\n    \"server-name\": {\n      \"command\": \"node\",\n      \"args\": [\"${CLAUDE_PLUGIN_ROOT}/servers/server.js\"],\n      \"env\": {\n        \"API_KEY\": \"${API_KEY}\"\n      }\n    }\n  }\n}\n```\n\n**Usage**: MCP servers integrate seamlessly with Claude Code's tool system\n\n## Portable Path References\n\n### ${CLAUDE_PLUGIN_ROOT}\n\nUse `${CLAUDE_PLUGIN_ROOT}` environment variable for all intra-plugin path references:\n\n```json\n{\n  \"command\": \"bash ${CLAUDE_PLUGIN_ROOT}/scripts/run.sh\"\n}\n```\n\n**Why it matters**: Plugins install in different locations depending on:\n- User installation method (marketplace, local, npm)\n- Operating system conventions\n- User preferences\n\n**Where to use it**:\n- Hook command paths\n- MCP server command arguments\n- Script execution references\n- Resource file paths\n\n**Never use**:\n- Hardcoded absolute paths (`/Users/name/plugins/...`)\n- Relative paths from working directory (`./scripts/...` in commands)\n- Home directory shortcuts (`~/plugins/...`)\n\n### Path Resolution Rules\n\n**In manifest JSON fields** (hooks, MCP servers):\n```json\n\"command\": \"${CLAUDE_PLUGIN_ROOT}/scripts/tool.sh\"\n```\n\n**In component files** (commands, agents, skills):\n```markdown\nReference scripts at: ${CLAUDE_PLUGIN_ROOT}/scripts/helper.py\n```\n\n**In executed scripts**:\n```bash\n#!/bin/bash\n# ${CLAUDE_PLUGIN_ROOT} available as environment variable\nsource \"${CLAUDE_PLUGIN_ROOT}/lib/common.sh\"\n```\n\n## File Naming Conventions\n\n### Component Files\n\n**Commands**: Use kebab-case `.md` files\n- `code-review.md` â†’ `/code-review`\n- `run-tests.md` â†’ `/run-tests`\n- `api-docs.md` â†’ `/api-docs`\n\n**Agents**: Use kebab-case `.md` files describing role\n- `test-generator.md`\n- `code-reviewer.md`\n- `performance-analyzer.md`\n\n**Skills**: Use kebab-case directory names\n- `api-testing/`\n- `database-migrations/`\n- `error-handling/`\n\n### Supporting Files\n\n**Scripts**: Use descriptive kebab-case names with appropriate extensions\n- `validate-input.sh`\n- `generate-report.py`\n- `process-data.js`\n\n**Documentation**: Use kebab-case markdown files\n- `api-reference.md`\n- `migration-guide.md`\n- `best-practices.md`\n\n**Configuration**: Use standard names\n- `hooks.json`\n- `.mcp.json`\n- `plugin.json`\n\n## Auto-Discovery Mechanism\n\nClaude Code automatically discovers and loads components:\n\n1. **Plugin manifest**: Reads `.claude-plugin/plugin.json` when plugin enables\n2. **Commands**: Scans `commands/` directory for `.md` files\n3. **Agents**: Scans `agents/` directory for `.md` files\n4. **Skills**: Scans `skills/` for subdirectories containing `SKILL.md`\n5. **Hooks**: Loads configuration from `hooks/hooks.json` or manifest\n6. **MCP servers**: Loads configuration from `.mcp.json` or manifest\n\n**Discovery timing**:\n- Plugin installation: Components register with Claude Code\n- Plugin enable: Components become available for use\n- No restart required: Changes take effect on next Claude Code session\n\n**Override behavior**: Custom paths in `plugin.json` supplement (not replace) default directories\n\n## Best Practices\n\n### Organization\n\n1. **Logical grouping**: Group related components together\n   - Put test-related commands, agents, and skills together\n   - Create subdirectories in `scripts/` for different purposes\n\n2. **Minimal manifest**: Keep `plugin.json` lean\n   - Only specify custom paths when necessary\n   - Rely on auto-discovery for standard layouts\n   - Use inline configuration only for simple cases\n\n3. **Documentation**: Include README files\n   - Plugin root: Overall purpose and usage\n   - Component directories: Specific guidance\n   - Script directories: Usage and requirements\n\n### Naming\n\n1. **Consistency**: Use consistent naming across components\n   - If command is `test-runner`, name related agent `test-runner-agent`\n   - Match skill directory names to their purpose\n\n2. **Clarity**: Use descriptive names that indicate purpose\n   - Good: `api-integration-testing/`, `code-quality-checker.md`\n   - Avoid: `utils/`, `misc.md`, `temp.sh`\n\n3. **Length**: Balance brevity with clarity\n   - Commands: 2-3 words (`review-pr`, `run-ci`)\n   - Agents: Describe role clearly (`code-reviewer`, `test-generator`)\n   - Skills: Topic-focused (`error-handling`, `api-design`)\n\n### Portability\n\n1. **Always use ${CLAUDE_PLUGIN_ROOT}**: Never hardcode paths\n2. **Test on multiple systems**: Verify on macOS, Linux, Windows\n3. **Document dependencies**: List required tools and versions\n4. **Avoid system-specific features**: Use portable bash/Python constructs\n\n### Maintenance\n\n1. **Version consistently**: Update version in plugin.json for releases\n2. **Deprecate gracefully**: Mark old components clearly before removal\n3. **Document breaking changes**: Note changes affecting existing users\n4. **Test thoroughly**: Verify all components work after changes\n\n## Common Patterns\n\n### Minimal Plugin\n\nSingle command with no dependencies:\n```\nmy-plugin/\nâ”œâ”€â”€ .claude-plugin/\nâ”‚   â””â”€â”€ plugin.json    # Just name field\nâ””â”€â”€ commands/\n    â””â”€â”€ hello.md       # Single command\n```\n\n### Full-Featured Plugin\n\nComplete plugin with all component types:\n```\nmy-plugin/\nâ”œâ”€â”€ .claude-plugin/\nâ”‚   â””â”€â”€ plugin.json\nâ”œâ”€â”€ commands/          # User-facing commands\nâ”œâ”€â”€ agents/            # Specialized subagents\nâ”œâ”€â”€ skills/            # Auto-activating skills\nâ”œâ”€â”€ hooks/             # Event handlers\nâ”‚   â”œâ”€â”€ hooks.json\nâ”‚   â””â”€â”€ scripts/\nâ”œâ”€â”€ .mcp.json          # External integrations\nâ””â”€â”€ scripts/           # Shared utilities\n```\n\n### Skill-Focused Plugin\n\nPlugin providing only skills:\n```\nmy-plugin/\nâ”œâ”€â”€ .claude-plugin/\nâ”‚   â””â”€â”€ plugin.json\nâ””â”€â”€ skills/\n    â”œâ”€â”€ skill-one/\n    â”‚   â””â”€â”€ SKILL.md\n    â””â”€â”€ skill-two/\n        â””â”€â”€ SKILL.md\n```\n\n## Troubleshooting\n\n**Component not loading**:\n- Verify file is in correct directory with correct extension\n- Check YAML frontmatter syntax (commands, agents, skills)\n- Ensure skill has `SKILL.md` (not `README.md` or other name)\n- Confirm plugin is enabled in Claude Code settings\n\n**Path resolution errors**:\n- Replace all hardcoded paths with `${CLAUDE_PLUGIN_ROOT}`\n- Verify paths are relative and start with `./` in manifest\n- Check that referenced files exist at specified paths\n- Test with `echo $CLAUDE_PLUGIN_ROOT` in hook scripts\n\n**Auto-discovery not working**:\n- Confirm directories are at plugin root (not in `.claude-plugin/`)\n- Check file naming follows conventions (kebab-case, correct extensions)\n- Verify custom paths in manifest are correct\n- Restart Claude Code to reload plugin configuration\n\n**Conflicts between plugins**:\n- Use unique, descriptive component names\n- Namespace commands with plugin name if needed\n- Document potential conflicts in plugin README\n- Consider command prefixes for related functionality\n\n---\n\nFor detailed examples and advanced patterns, see files in `references/` and `examples/` directories.\n"
      },
      "discovered_at": "2026-01-11T15:36:03.456629Z",
      "fetch_error": null
    },
    {
      "name": "skill-development",
      "slug": "skill-development",
      "source": "skillsmp_top",
      "owner": "anthropics",
      "repo_name": "claude-code",
      "repository_url": "https://github.com/anthropics/claude-code",
      "skill_path": "plugins/plugin-dev/skills/skill-development",
      "github_metadata": {
        "stars": 55095,
        "description": "Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands.",
        "default_branch": "main",
        "pushed_at": "2026-01-11T00:28:28Z",
        "created_at": "2025-02-22T17:41:21Z",
        "language": "Shell",
        "license": null,
        "open_issues": 4495,
        "forks": 3984
      },
      "skill_md": {
        "found": true,
        "path": "plugins/plugin-dev/skills/skill-development/SKILL.md",
        "branch": "main",
        "content": "---\nname: Skill Development\ndescription: This skill should be used when the user wants to \"create a skill\", \"add a skill to plugin\", \"write a new skill\", \"improve skill description\", \"organize skill content\", or needs guidance on skill structure, progressive disclosure, or skill development best practices for Claude Code plugins.\nversion: 0.1.0\n---\n\n# Skill Development for Claude Code Plugins\n\nThis skill provides guidance for creating effective skills for Claude Code plugins.\n\n## About Skills\n\nSkills are modular, self-contained packages that extend Claude's capabilities by providing\nspecialized knowledge, workflows, and tools. Think of them as \"onboarding guides\" for specific\ndomains or tasksâ€”they transform Claude from a general-purpose agent into a specialized agent\nequipped with procedural knowledge that no model can fully possess.\n\n### What Skills Provide\n\n1. Specialized workflows - Multi-step procedures for specific domains\n2. Tool integrations - Instructions for working with specific file formats or APIs\n3. Domain expertise - Company-specific knowledge, schemas, business logic\n4. Bundled resources - Scripts, references, and assets for complex and repetitive tasks\n\n### Anatomy of a Skill\n\nEvery skill consists of a required SKILL.md file and optional bundled resources:\n\n```\nskill-name/\nâ”œâ”€â”€ SKILL.md (required)\nâ”‚   â”œâ”€â”€ YAML frontmatter metadata (required)\nâ”‚   â”‚   â”œâ”€â”€ name: (required)\nâ”‚   â”‚   â””â”€â”€ description: (required)\nâ”‚   â””â”€â”€ Markdown instructions (required)\nâ””â”€â”€ Bundled Resources (optional)\n    â”œâ”€â”€ scripts/          - Executable code (Python/Bash/etc.)\n    â”œâ”€â”€ references/       - Documentation intended to be loaded into context as needed\n    â””â”€â”€ assets/           - Files used in output (templates, icons, fonts, etc.)\n```\n\n#### SKILL.md (required)\n\n**Metadata Quality:** The `name` and `description` in YAML frontmatter determine when Claude will use the skill. Be specific about what the skill does and when to use it. Use the third-person (e.g. \"This skill should be used when...\" instead of \"Use this skill when...\").\n\n#### Bundled Resources (optional)\n\n##### Scripts (`scripts/`)\n\nExecutable code (Python/Bash/etc.) for tasks that require deterministic reliability or are repeatedly rewritten.\n\n- **When to include**: When the same code is being rewritten repeatedly or deterministic reliability is needed\n- **Example**: `scripts/rotate_pdf.py` for PDF rotation tasks\n- **Benefits**: Token efficient, deterministic, may be executed without loading into context\n- **Note**: Scripts may still need to be read by Claude for patching or environment-specific adjustments\n\n##### References (`references/`)\n\nDocumentation and reference material intended to be loaded as needed into context to inform Claude's process and thinking.\n\n- **When to include**: For documentation that Claude should reference while working\n- **Examples**: `references/finance.md` for financial schemas, `references/mnda.md` for company NDA template, `references/policies.md` for company policies, `references/api_docs.md` for API specifications\n- **Use cases**: Database schemas, API documentation, domain knowledge, company policies, detailed workflow guides\n- **Benefits**: Keeps SKILL.md lean, loaded only when Claude determines it's needed\n- **Best practice**: If files are large (>10k words), include grep search patterns in SKILL.md\n- **Avoid duplication**: Information should live in either SKILL.md or references files, not both. Prefer references files for detailed information unless it's truly core to the skillâ€”this keeps SKILL.md lean while making information discoverable without hogging the context window. Keep only essential procedural instructions and workflow guidance in SKILL.md; move detailed reference material, schemas, and examples to references files.\n\n##### Assets (`assets/`)\n\nFiles not intended to be loaded into context, but rather used within the output Claude produces.\n\n- **When to include**: When the skill needs files that will be used in the final output\n- **Examples**: `assets/logo.png` for brand assets, `assets/slides.pptx` for PowerPoint templates, `assets/frontend-template/` for HTML/React boilerplate, `assets/font.ttf` for typography\n- **Use cases**: Templates, images, icons, boilerplate code, fonts, sample documents that get copied or modified\n- **Benefits**: Separates output resources from documentation, enables Claude to use files without loading them into context\n\n### Progressive Disclosure Design Principle\n\nSkills use a three-level loading system to manage context efficiently:\n\n1. **Metadata (name + description)** - Always in context (~100 words)\n2. **SKILL.md body** - When skill triggers (<5k words)\n3. **Bundled resources** - As needed by Claude (Unlimited*)\n\n*Unlimited because scripts can be executed without reading into context window.\n\n## Skill Creation Process\n\nTo create a skill, follow the \"Skill Creation Process\" in order, skipping steps only if there is a clear reason why they are not applicable.\n\n### Step 1: Understanding the Skill with Concrete Examples\n\nSkip this step only when the skill's usage patterns are already clearly understood. It remains valuable even when working with an existing skill.\n\nTo create an effective skill, clearly understand concrete examples of how the skill will be used. This understanding can come from either direct user examples or generated examples that are validated with user feedback.\n\nFor example, when building an image-editor skill, relevant questions include:\n\n- \"What functionality should the image-editor skill support? Editing, rotating, anything else?\"\n- \"Can you give some examples of how this skill would be used?\"\n- \"I can imagine users asking for things like 'Remove the red-eye from this image' or 'Rotate this image'. Are there other ways you imagine this skill being used?\"\n- \"What would a user say that should trigger this skill?\"\n\nTo avoid overwhelming users, avoid asking too many questions in a single message. Start with the most important questions and follow up as needed for better effectiveness.\n\nConclude this step when there is a clear sense of the functionality the skill should support.\n\n### Step 2: Planning the Reusable Skill Contents\n\nTo turn concrete examples into an effective skill, analyze each example by:\n\n1. Considering how to execute on the example from scratch\n2. Identifying what scripts, references, and assets would be helpful when executing these workflows repeatedly\n\nExample: When building a `pdf-editor` skill to handle queries like \"Help me rotate this PDF,\" the analysis shows:\n\n1. Rotating a PDF requires re-writing the same code each time\n2. A `scripts/rotate_pdf.py` script would be helpful to store in the skill\n\nExample: When designing a `frontend-webapp-builder` skill for queries like \"Build me a todo app\" or \"Build me a dashboard to track my steps,\" the analysis shows:\n\n1. Writing a frontend webapp requires the same boilerplate HTML/React each time\n2. An `assets/hello-world/` template containing the boilerplate HTML/React project files would be helpful to store in the skill\n\nExample: When building a `big-query` skill to handle queries like \"How many users have logged in today?\" the analysis shows:\n\n1. Querying BigQuery requires re-discovering the table schemas and relationships each time\n2. A `references/schema.md` file documenting the table schemas would be helpful to store in the skill\n\n**For Claude Code plugins:** When building a hooks skill, the analysis shows:\n1. Developers repeatedly need to validate hooks.json and test hook scripts\n2. `scripts/validate-hook-schema.sh` and `scripts/test-hook.sh` utilities would be helpful\n3. `references/patterns.md` for detailed hook patterns to avoid bloating SKILL.md\n\nTo establish the skill's contents, analyze each concrete example to create a list of the reusable resources to include: scripts, references, and assets.\n\n### Step 3: Create Skill Structure\n\nFor Claude Code plugins, create the skill directory structure:\n\n```bash\nmkdir -p plugin-name/skills/skill-name/{references,examples,scripts}\ntouch plugin-name/skills/skill-name/SKILL.md\n```\n\n**Note:** Unlike the generic skill-creator which uses `init_skill.py`, plugin skills are created directly in the plugin's `skills/` directory with a simpler manual structure.\n\n### Step 4: Edit the Skill\n\nWhen editing the (newly-created or existing) skill, remember that the skill is being created for another instance of Claude to use. Focus on including information that would be beneficial and non-obvious to Claude. Consider what procedural knowledge, domain-specific details, or reusable assets would help another Claude instance execute these tasks more effectively.\n\n#### Start with Reusable Skill Contents\n\nTo begin implementation, start with the reusable resources identified above: `scripts/`, `references/`, and `assets/` files. Note that this step may require user input. For example, when implementing a `brand-guidelines` skill, the user may need to provide brand assets or templates to store in `assets/`, or documentation to store in `references/`.\n\nAlso, delete any example files and directories not needed for the skill. Create only the directories you actually need (references/, examples/, scripts/).\n\n#### Update SKILL.md\n\n**Writing Style:** Write the entire skill using **imperative/infinitive form** (verb-first instructions), not second person. Use objective, instructional language (e.g., \"To accomplish X, do Y\" rather than \"You should do X\" or \"If you need to do X\"). This maintains consistency and clarity for AI consumption.\n\n**Description (Frontmatter):** Use third-person format with specific trigger phrases:\n\n```yaml\n---\nname: Skill Name\ndescription: This skill should be used when the user asks to \"specific phrase 1\", \"specific phrase 2\", \"specific phrase 3\". Include exact phrases users would say that should trigger this skill. Be concrete and specific.\nversion: 0.1.0\n---\n```\n\n**Good description examples:**\n```yaml\ndescription: This skill should be used when the user asks to \"create a hook\", \"add a PreToolUse hook\", \"validate tool use\", \"implement prompt-based hooks\", or mentions hook events (PreToolUse, PostToolUse, Stop).\n```\n\n**Bad description examples:**\n```yaml\ndescription: Use this skill when working with hooks.  # Wrong person, vague\ndescription: Load when user needs hook help.  # Not third person\ndescription: Provides hook guidance.  # No trigger phrases\n```\n\nTo complete SKILL.md body, answer the following questions:\n\n1. What is the purpose of the skill, in a few sentences?\n2. When should the skill be used? (Include this in frontmatter description with specific triggers)\n3. In practice, how should Claude use the skill? All reusable skill contents developed above should be referenced so that Claude knows how to use them.\n\n**Keep SKILL.md lean:** Target 1,500-2,000 words for the body. Move detailed content to references/:\n- Detailed patterns â†’ `references/patterns.md`\n- Advanced techniques â†’ `references/advanced.md`\n- Migration guides â†’ `references/migration.md`\n- API references â†’ `references/api-reference.md`\n\n**Reference resources in SKILL.md:**\n```markdown\n## Additional Resources\n\n### Reference Files\n\nFor detailed patterns and techniques, consult:\n- **`references/patterns.md`** - Common patterns\n- **`references/advanced.md`** - Advanced use cases\n\n### Example Files\n\nWorking examples in `examples/`:\n- **`example-script.sh`** - Working example\n```\n\n### Step 5: Validate and Test\n\n**For plugin skills, validation is different from generic skills:**\n\n1. **Check structure**: Skill directory in `plugin-name/skills/skill-name/`\n2. **Validate SKILL.md**: Has frontmatter with name and description\n3. **Check trigger phrases**: Description includes specific user queries\n4. **Verify writing style**: Body uses imperative/infinitive form, not second person\n5. **Test progressive disclosure**: SKILL.md is lean (~1,500-2,000 words), detailed content in references/\n6. **Check references**: All referenced files exist\n7. **Validate examples**: Examples are complete and correct\n8. **Test scripts**: Scripts are executable and work correctly\n\n**Use the skill-reviewer agent:**\n```\nAsk: \"Review my skill and check if it follows best practices\"\n```\n\nThe skill-reviewer agent will check description quality, content organization, and progressive disclosure.\n\n### Step 6: Iterate\n\nAfter testing the skill, users may request improvements. Often this happens right after using the skill, with fresh context of how the skill performed.\n\n**Iteration workflow:**\n1. Use the skill on real tasks\n2. Notice struggles or inefficiencies\n3. Identify how SKILL.md or bundled resources should be updated\n4. Implement changes and test again\n\n**Common improvements:**\n- Strengthen trigger phrases in description\n- Move long sections from SKILL.md to references/\n- Add missing examples or scripts\n- Clarify ambiguous instructions\n- Add edge case handling\n\n## Plugin-Specific Considerations\n\n### Skill Location in Plugins\n\nPlugin skills live in the plugin's `skills/` directory:\n\n```\nmy-plugin/\nâ”œâ”€â”€ .claude-plugin/\nâ”‚   â””â”€â”€ plugin.json\nâ”œâ”€â”€ commands/\nâ”œâ”€â”€ agents/\nâ””â”€â”€ skills/\n    â””â”€â”€ my-skill/\n        â”œâ”€â”€ SKILL.md\n        â”œâ”€â”€ references/\n        â”œâ”€â”€ examples/\n        â””â”€â”€ scripts/\n```\n\n### Auto-Discovery\n\nClaude Code automatically discovers skills:\n- Scans `skills/` directory\n- Finds subdirectories containing `SKILL.md`\n- Loads skill metadata (name + description) always\n- Loads SKILL.md body when skill triggers\n- Loads references/examples when needed\n\n### No Packaging Needed\n\nPlugin skills are distributed as part of the plugin, not as separate ZIP files. Users get skills when they install the plugin.\n\n### Testing in Plugins\n\nTest skills by installing plugin locally:\n\n```bash\n# Test with --plugin-dir\ncc --plugin-dir /path/to/plugin\n\n# Ask questions that should trigger the skill\n# Verify skill loads correctly\n```\n\n## Examples from Plugin-Dev\n\nStudy the skills in this plugin as examples of best practices:\n\n**hook-development skill:**\n- Excellent trigger phrases: \"create a hook\", \"add a PreToolUse hook\", etc.\n- Lean SKILL.md (1,651 words)\n- 3 references/ files for detailed content\n- 3 examples/ of working hooks\n- 3 scripts/ utilities\n\n**agent-development skill:**\n- Strong triggers: \"create an agent\", \"agent frontmatter\", etc.\n- Focused SKILL.md (1,438 words)\n- References include the AI generation prompt from Claude Code\n- Complete agent examples\n\n**plugin-settings skill:**\n- Specific triggers: \"plugin settings\", \".local.md files\", \"YAML frontmatter\"\n- References show real implementations (multi-agent-swarm, ralph-wiggum)\n- Working parsing scripts\n\nEach demonstrates progressive disclosure and strong triggering.\n\n## Progressive Disclosure in Practice\n\n### What Goes in SKILL.md\n\n**Include (always loaded when skill triggers):**\n- Core concepts and overview\n- Essential procedures and workflows\n- Quick reference tables\n- Pointers to references/examples/scripts\n- Most common use cases\n\n**Keep under 3,000 words, ideally 1,500-2,000 words**\n\n### What Goes in references/\n\n**Move to references/ (loaded as needed):**\n- Detailed patterns and advanced techniques\n- Comprehensive API documentation\n- Migration guides\n- Edge cases and troubleshooting\n- Extensive examples and walkthroughs\n\n**Each reference file can be large (2,000-5,000+ words)**\n\n### What Goes in examples/\n\n**Working code examples:**\n- Complete, runnable scripts\n- Configuration files\n- Template files\n- Real-world usage examples\n\n**Users can copy and adapt these directly**\n\n### What Goes in scripts/\n\n**Utility scripts:**\n- Validation tools\n- Testing helpers\n- Parsing utilities\n- Automation scripts\n\n**Should be executable and documented**\n\n## Writing Style Requirements\n\n### Imperative/Infinitive Form\n\nWrite using verb-first instructions, not second person:\n\n**Correct (imperative):**\n```\nTo create a hook, define the event type.\nConfigure the MCP server with authentication.\nValidate settings before use.\n```\n\n**Incorrect (second person):**\n```\nYou should create a hook by defining the event type.\nYou need to configure the MCP server.\nYou must validate settings before use.\n```\n\n### Third-Person in Description\n\nThe frontmatter description must use third person:\n\n**Correct:**\n```yaml\ndescription: This skill should be used when the user asks to \"create X\", \"configure Y\"...\n```\n\n**Incorrect:**\n```yaml\ndescription: Use this skill when you want to create X...\ndescription: Load this skill when user asks...\n```\n\n### Objective, Instructional Language\n\nFocus on what to do, not who should do it:\n\n**Correct:**\n```\nParse the frontmatter using sed.\nExtract fields with grep.\nValidate values before use.\n```\n\n**Incorrect:**\n```\nYou can parse the frontmatter...\nClaude should extract fields...\nThe user might validate values...\n```\n\n## Validation Checklist\n\nBefore finalizing a skill:\n\n**Structure:**\n- [ ] SKILL.md file exists with valid YAML frontmatter\n- [ ] Frontmatter has `name` and `description` fields\n- [ ] Markdown body is present and substantial\n- [ ] Referenced files actually exist\n\n**Description Quality:**\n- [ ] Uses third person (\"This skill should be used when...\")\n- [ ] Includes specific trigger phrases users would say\n- [ ] Lists concrete scenarios (\"create X\", \"configure Y\")\n- [ ] Not vague or generic\n\n**Content Quality:**\n- [ ] SKILL.md body uses imperative/infinitive form\n- [ ] Body is focused and lean (1,500-2,000 words ideal, <5k max)\n- [ ] Detailed content moved to references/\n- [ ] Examples are complete and working\n- [ ] Scripts are executable and documented\n\n**Progressive Disclosure:**\n- [ ] Core concepts in SKILL.md\n- [ ] Detailed docs in references/\n- [ ] Working code in examples/\n- [ ] Utilities in scripts/\n- [ ] SKILL.md references these resources\n\n**Testing:**\n- [ ] Skill triggers on expected user queries\n- [ ] Content is helpful for intended tasks\n- [ ] No duplicated information across files\n- [ ] References load when needed\n\n## Common Mistakes to Avoid\n\n### Mistake 1: Weak Trigger Description\n\nâŒ **Bad:**\n```yaml\ndescription: Provides guidance for working with hooks.\n```\n\n**Why bad:** Vague, no specific trigger phrases, not third person\n\nâœ… **Good:**\n```yaml\ndescription: This skill should be used when the user asks to \"create a hook\", \"add a PreToolUse hook\", \"validate tool use\", or mentions hook events. Provides comprehensive hooks API guidance.\n```\n\n**Why good:** Third person, specific phrases, concrete scenarios\n\n### Mistake 2: Too Much in SKILL.md\n\nâŒ **Bad:**\n```\nskill-name/\nâ””â”€â”€ SKILL.md  (8,000 words - everything in one file)\n```\n\n**Why bad:** Bloats context when skill loads, detailed content always loaded\n\nâœ… **Good:**\n```\nskill-name/\nâ”œâ”€â”€ SKILL.md  (1,800 words - core essentials)\nâ””â”€â”€ references/\n    â”œâ”€â”€ patterns.md (2,500 words)\n    â””â”€â”€ advanced.md (3,700 words)\n```\n\n**Why good:** Progressive disclosure, detailed content loaded only when needed\n\n### Mistake 3: Second Person Writing\n\nâŒ **Bad:**\n```markdown\nYou should start by reading the configuration file.\nYou need to validate the input.\nYou can use the grep tool to search.\n```\n\n**Why bad:** Second person, not imperative form\n\nâœ… **Good:**\n```markdown\nStart by reading the configuration file.\nValidate the input before processing.\nUse the grep tool to search for patterns.\n```\n\n**Why good:** Imperative form, direct instructions\n\n### Mistake 4: Missing Resource References\n\nâŒ **Bad:**\n```markdown\n# SKILL.md\n\n[Core content]\n\n[No mention of references/ or examples/]\n```\n\n**Why bad:** Claude doesn't know references exist\n\nâœ… **Good:**\n```markdown\n# SKILL.md\n\n[Core content]\n\n## Additional Resources\n\n### Reference Files\n- **`references/patterns.md`** - Detailed patterns\n- **`references/advanced.md`** - Advanced techniques\n\n### Examples\n- **`examples/script.sh`** - Working example\n```\n\n**Why good:** Claude knows where to find additional information\n\n## Quick Reference\n\n### Minimal Skill\n\n```\nskill-name/\nâ””â”€â”€ SKILL.md\n```\n\nGood for: Simple knowledge, no complex resources needed\n\n### Standard Skill (Recommended)\n\n```\nskill-name/\nâ”œâ”€â”€ SKILL.md\nâ”œâ”€â”€ references/\nâ”‚   â””â”€â”€ detailed-guide.md\nâ””â”€â”€ examples/\n    â””â”€â”€ working-example.sh\n```\n\nGood for: Most plugin skills with detailed documentation\n\n### Complete Skill\n\n```\nskill-name/\nâ”œâ”€â”€ SKILL.md\nâ”œâ”€â”€ references/\nâ”‚   â”œâ”€â”€ patterns.md\nâ”‚   â””â”€â”€ advanced.md\nâ”œâ”€â”€ examples/\nâ”‚   â”œâ”€â”€ example1.sh\nâ”‚   â””â”€â”€ example2.json\nâ””â”€â”€ scripts/\n    â””â”€â”€ validate.sh\n```\n\nGood for: Complex domains with validation utilities\n\n## Best Practices Summary\n\nâœ… **DO:**\n- Use third-person in description (\"This skill should be used when...\")\n- Include specific trigger phrases (\"create X\", \"configure Y\")\n- Keep SKILL.md lean (1,500-2,000 words)\n- Use progressive disclosure (move details to references/)\n- Write in imperative/infinitive form\n- Reference supporting files clearly\n- Provide working examples\n- Create utility scripts for common operations\n- Study plugin-dev's skills as templates\n\nâŒ **DON'T:**\n- Use second person anywhere\n- Have vague trigger conditions\n- Put everything in SKILL.md (>3,000 words without references/)\n- Write in second person (\"You should...\")\n- Leave resources unreferenced\n- Include broken or incomplete examples\n- Skip validation\n\n## Additional Resources\n\n### Study These Skills\n\nPlugin-dev's skills demonstrate best practices:\n- `../hook-development/` - Progressive disclosure, utilities\n- `../agent-development/` - AI-assisted creation, references\n- `../mcp-integration/` - Comprehensive references\n- `../plugin-settings/` - Real-world examples\n- `../command-development/` - Clear critical concepts\n- `../plugin-structure/` - Good organization\n\n### Reference Files\n\nFor complete skill-creator methodology:\n- **`references/skill-creator-original.md`** - Full original skill-creator content\n\n## Implementation Workflow\n\nTo create a skill for your plugin:\n\n1. **Understand use cases**: Identify concrete examples of skill usage\n2. **Plan resources**: Determine what scripts/references/examples needed\n3. **Create structure**: `mkdir -p skills/skill-name/{references,examples,scripts}`\n4. **Write SKILL.md**:\n   - Frontmatter with third-person description and trigger phrases\n   - Lean body (1,500-2,000 words) in imperative form\n   - Reference supporting files\n5. **Add resources**: Create references/, examples/, scripts/ as needed\n6. **Validate**: Check description, writing style, organization\n7. **Test**: Verify skill loads on expected triggers\n8. **Iterate**: Improve based on usage\n\nFocus on strong trigger descriptions, progressive disclosure, and imperative writing style for effective skills that load when needed and provide targeted guidance.\n"
      },
      "discovered_at": "2026-01-11T15:36:03.936960Z",
      "fetch_error": null
    },
    {
      "name": "add-admin-api-endpoint",
      "slug": "add-admin-api-endpoint",
      "source": "skillsmp_top",
      "owner": "TryGhost",
      "repo_name": "Ghost",
      "repository_url": "https://github.com/TryGhost/Ghost",
      "skill_path": ".claude/skills/add-admin-api-endpoint",
      "github_metadata": {
        "stars": 51564,
        "description": "Independent technology for modern publishing, memberships, subscriptions and newsletters.",
        "default_branch": "main",
        "pushed_at": "2026-01-10T18:16:46Z",
        "created_at": "2013-05-04T11:09:13Z",
        "language": "JavaScript",
        "license": "MIT",
        "open_issues": 258,
        "forks": 11255
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/add-admin-api-endpoint/SKILL.md",
        "branch": "main",
        "content": "---\nname: Add Admin API Endpoint\ndescription: Add a new endpoint or endpoints to Ghost's Admin API at `ghost/api/admin/**`.\n---\n\n# Create Admin API Endpoint\n\n## Instructions\n\n1. If creating an endpoint for an entirely new resource, create a new endpoint file in `ghost/core/core/server/api/endpoints/`. Otherwise, locate the existing endpoint file in the same directory.\n2. The endpoint file should create a controller object using the JSDoc type from (@tryghost/api-framework).Controller, including at minimum a `docName` and a single endpoint definition, i.e. `browse`. \n3. Add routes for each endpoint to `ghost/core/core/server/web/api/endpoints/admin/routes.js`.\n4. Add basic `e2e-api` tests for the endpoint in `ghost/core/test/e2e-api/admin` to ensure the new endpoints function as expected.\n5. Run the tests and iterate until they pass: `cd ghost/core && yarn test:single test/e2e-api/admin/{test-file-name}`.\n\n## Reference\nFor a detailed reference on Ghost's API framework and how to create API controllers, see [reference.md](reference.md)."
      },
      "discovered_at": "2026-01-11T15:36:04.564131Z",
      "fetch_error": null
    },
    {
      "name": "create-database-migration",
      "slug": "create-database-migration",
      "source": "skillsmp_top",
      "owner": "TryGhost",
      "repo_name": "Ghost",
      "repository_url": "https://github.com/TryGhost/Ghost",
      "skill_path": ".claude/skills/create-database-migration",
      "github_metadata": {
        "stars": 51564,
        "description": "Independent technology for modern publishing, memberships, subscriptions and newsletters.",
        "default_branch": "main",
        "pushed_at": "2026-01-10T18:16:46Z",
        "created_at": "2013-05-04T11:09:13Z",
        "language": "JavaScript",
        "license": "MIT",
        "open_issues": 258,
        "forks": 11255
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/create-database-migration/SKILL.md",
        "branch": "main",
        "content": "---\nname: Create database migration\ndescription: Create a database migration to add a table, add columns to an existing table, add a setting, or otherwise change the schema of Ghost's MySQL database.\n---\n\n# Create Database Migration\n\n## Instructions\n\n1. Change directories into `ghost/core`: `cd ghost/core`\n2. Create a new, empty migration file using slimer: `slimer migration <name-of-database-migration>`. IMPORTANT: do not create the migration file manually; always use slimer to create the initial empty migration file.\n3. The above command will create a new directory in `ghost/core/core/server/data/migrations/versions` if needed, and create the empty migration file with the appropriate name.\n4. Update the migration file with the changes you want to make in the database, following the existing patterns in the codebase. Where appropriate, prefer to use the utility functions in `ghost/core/core/server/data/migrations/utils/*`.\n5. Update the schema definition file in `ghost/core/core/server/data/schema/schema.js`, and make sure it aligns with the latest changes from the migration.\n6. Test the migration manually: `yarn knex-migrator migrate --v {version directory} --force`\n7. If adding or dropping a table, update `ghost/core/core/server/data/exporter/table-lists.js` as appropriate.\n8. Run the schema integrity test, and update the hash: `yarn test:single test/unit/server/data/schema/integrity.test.js`\n9. Run unit tests in Ghost core, and iterate until they pass: `cd ghost/core && yarn test:unit`\n\n## Examples\nSee [examples.md](examples.md) for example migrations.\n\n## Rules\nSee [rules.md](rules.md) for rules that should always be followed when creating database migrations."
      },
      "discovered_at": "2026-01-11T15:36:05.222247Z",
      "fetch_error": null
    },
    {
      "name": "clojure-review",
      "slug": "clojure-review",
      "source": "skillsmp_top",
      "owner": "metabase",
      "repo_name": "metabase",
      "repository_url": "https://github.com/metabase/metabase",
      "skill_path": ".claude/skills/clojure-review",
      "github_metadata": {
        "stars": 45538,
        "description": "The easy-to-use open source Business Intelligence and Embedded Analytics tool that lets everyone work with data :bar_chart:",
        "default_branch": "master",
        "pushed_at": "2026-01-11T13:53:34Z",
        "created_at": "2015-02-02T19:25:47Z",
        "language": "Clojure",
        "license": "NOASSERTION",
        "open_issues": 3883,
        "forks": 6167
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/clojure-review/SKILL.md",
        "branch": "master",
        "content": "---\nname: clojure-review\ndescription: Review Clojure and ClojureScript code changes for compliance with Metabase coding standards, style violations, and code quality issues. Use when reviewing pull requests or diffs containing Clojure/ClojureScript code.\nallowed-tools: Read, Grep, Bash, Glob\n---\n\n# Clojure Code Review Skill\n\n@./../_shared/clojure-style-guide.md\n@./../_shared/clojure-commands.md\n\n## Review guidelines\n\n**What to flag:**\n\n- Check compliance with the Metabase Clojure style guide (included above)\n- If `CLOJURE_STYLE_GUIDE.adoc` exists in the working directory, also check compliance with the community Clojure style guide\n- Flag all style guide violations\n\n**What NOT to post:**\n\n- Do not post comments congratulating someone for trivial changes or for following style guidelines\n- Do not post comments confirming things \"look good\" or telling them they did something correctly\n- Only post comments about style violations or potential issues\n\nExample bad code review comments to avoid:\n\n> This TODO comment is properly formatted with author and date - nice work!\n\n> Good addition of limit 1 to the query - this makes the test more efficient without changing its behavior.\n\n> The kondo ignore comment is appropriately placed here\n\n> Test name properly ends with -test as required by the style guide.\n\n**Special cases:**\n\n- Do not post comments about missing parentheses (these will be caught by the linter)\n\n## Quick review checklist\n\nUse this to scan through changes efficiently:\n\n### Naming\n\n- [ ] Descriptive names (no `tbl`, `zs'`)\n- [ ] Pure functions named as nouns describing their return value\n- [ ] `kebab-case` for all variables and functions\n- [ ] Side-effect functions end with `!`\n- [ ] No namespace-alias repetition in function names\n\n### Documentation\n\n- [ ] Public vars in `src` or `enterprise/backend/src` have useful docstrings\n- [ ] Docstrings use Markdown conventions\n- [ ] References use `[[other-var]]` not backticks\n- [ ] `TODO` comments include author and date: `;; TODO (Name 1/1/25) -- description`\n\n### Code Organization\n\n- [ ] Everything `^:private` unless used elsewhere\n- [ ] No `declare` when avoidable (public functions near end)\n- [ ] Functions under 20 lines when possible\n- [ ] No blank lines within definition forms (except pairwise constructs in `let`/`cond`)\n- [ ] Lines â‰¤ 120 characters\n\n### Tests\n\n- [ ] Separate `deftest` forms for distinct test cases\n- [ ] Pure tests marked `^:parallel`\n- [ ] Test names end in `-test` or `-test-<number>`\n\n### Modules\n\n- [ ] Correct module patterns (OSS: `metabase.<module>.*`, EE: `metabase-enterprise.<module>.*`)\n- [ ] API endpoints in `<module>.api` namespaces\n- [ ] Public API in `<module>.core` with Potemkin\n- [ ] No cheating module linters with `:clj-kondo/ignore [:metabase/modules]`\n\n### REST API\n\n- [ ] Response schemas present (`:- <schema>`)\n- [ ] Query params use kebab-case, bodies use `snake_case`\n- [ ] Routes use singular nouns (e.g., `/api/dashboard/:id`)\n- [ ] `GET` has no side effects (except analytics)\n- [ ] Malli schemas detailed and complete\n- [ ] All new endpoints have tests\n\n### MBQL\n\n- [ ] No raw MBQL manipulation outside `lib`, `lib-be`, or `query-processor` modules\n- [ ] Uses Lib and MBQL 5, not legacy MBQL\n\n### Database\n\n- [ ] Model and table names are singular nouns\n- [ ] Uses `t2/select-one-fn` instead of selecting full rows for one column\n- [ ] Logic in Toucan methods, not helper functions\n\n### Drivers\n\n- [ ] New multimethods documented in `docs/developers-guide/driver-changelog.md`\n- [ ] Passes `driver` argument to other driver methods (no hardcoded driver names)\n- [ ] Minimal logic in `read-column-thunk`\n\n### Miscellaneous\n\n- [ ] Example data is bird-themed when possible\n- [ ] Kondo linter suppressions use proper format (not `#_:clj-kondo/ignore` keyword form)\n\n## Pattern matching table\n\nQuick scan for common issues:\n\n| Pattern                                      | Issue                                                       |\n| -------------------------------------------- | ----------------------------------------------------------- |\n| `calculate-age`, `get-user`                  | Pure functions should be nouns: `age`, `user`               |\n| `update-db`, `save-model`                    | Missing `!` for side effects: `update-db!`, `save-model!`   |\n| `snake_case_var`                             | Should use kebab-case                                       |\n| Public var without docstring                 | Add docstring explaining purpose                            |\n| `;; TODO fix this`                           | Missing author/date: `;; TODO (Name 1/1/25) -- description` |\n| `(defn foo ...)` in namespace used elsewhere | Should be `(defn ^:private foo ...)`                        |\n| Function > 20 lines                          | Consider breaking up into smaller functions                 |\n| `/api/dashboards/:id`                        | Use singular: `/api/dashboard/:id`                          |\n| Query params with `snake_case`               | Use kebab-case for query params                             |\n| New API endpoint without tests               | Add tests for the endpoint                                  |\n\n## Feedback format examples\n\n**For style violations:**\n\n> This pure function should be named as a noun describing its return value. Consider `user` instead of `get-user`.\n\n**For missing documentation:**\n\n> This public var needs a docstring explaining its purpose, inputs, and outputs.\n\n**For organization issues:**\n\n> This function is only used in this namespace, so it should be marked `^:private`.\n\n**For API conventions:**\n\n> Query parameters should use kebab-case. Change `user_id` to `user-id`.\n"
      },
      "discovered_at": "2026-01-11T15:36:05.675585Z",
      "fetch_error": null
    },
    {
      "name": "clojure-write",
      "slug": "clojure-write",
      "source": "skillsmp_top",
      "owner": "metabase",
      "repo_name": "metabase",
      "repository_url": "https://github.com/metabase/metabase",
      "skill_path": ".claude/skills/clojure-write",
      "github_metadata": {
        "stars": 45538,
        "description": "The easy-to-use open source Business Intelligence and Embedded Analytics tool that lets everyone work with data :bar_chart:",
        "default_branch": "master",
        "pushed_at": "2026-01-11T13:53:34Z",
        "created_at": "2015-02-02T19:25:47Z",
        "language": "Clojure",
        "license": "NOASSERTION",
        "open_issues": 3883,
        "forks": 6167
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/clojure-write/SKILL.md",
        "branch": "master",
        "content": "---\nname: clojure-write\ndescription: Guide Clojure and ClojureScript development using REPL-driven workflow, coding conventions, and best practices. Use when writing, developing, or refactoring Clojure/ClojureScript code.\n---\n\n# Clojure Development Skill\n\n## Tool Preference\n\nWhen `clojure-mcp` tools are available (e.g., `clojure_eval`, `clojure_edit`), **always use them**\ninstead of shell commands like `./bin/mage -repl`. The MCP tools provide:\n- Direct REPL integration without shell escaping issues\n- Better error messages and feedback\n- Structural Clojure editing that prevents syntax errors\n\nOnly fall back to `./bin/mage` commands when clojure-mcp is not available.\n\n@./../_shared/development-workflow.md\n@./../_shared/clojure-style-guide.md\n@./../_shared/clojure-commands.md\n\n## REPL-Driven Development Workflow\n\n- Start with small, fundamental functions:\n- Identify the core features or functionalities required for your task.\n- Break each feature down into the smallest, most basic functions that can be developed and tested independently.\n- Write and test in the REPL:\n  - Write the code for each small function directly in the REPL (Read-Eval-Print Loop).\n  - Test it thoroughly with a variety of inputs, including typical use cases and relevant edge cases, to ensure it\n    behaves as expected.\n- Integrate into source code:\n  - Once a function works correctly in the REPL, move it from the REPL environment into your source code files (e.g.,\n    within appropriate namespaces).\n- Gradually increase complexity:\n  - Build upon tested, basic functions to create more complex functions or components.\n  - Compose smaller functions together, testing each new composition in the REPL to verify correctness step by step.\n- Ensure dependency testing:\n  - Make sure every function is fully tested in the REPL before it is depended upon by other functions.\n  - This ensures that each layer of your application is reliable before you build on it.\n- Use the REPL fully:\n  - Use the REPL as your primary tool to experiment with different approaches, iterate quickly, and get immediate\n    feedback on your code.\n- Follow functional programming principles:\n  - Keep functions small, focused, and composable.\n  - Use Clojure's functional programming featuresâ€”like immutability, higher-order functions, and the standard\n    libraryâ€”to write concise, effective code.\n\n## How to Evaluate Code\n\n### Bottom-up Dev Loop\n\n1. Write code into a file.\n2. Evaluate the file's namespace and make sure it loads correctly with:\n\n```\n./bin/mage -repl --namespace metabase.app-db.connection\n```\n\n3. Call functions in the namespace with test inputs, and observe that the outputs are correct\n   Feel free to copy these REPL session trials into actual test cases using `deftest` and `is`.\n4. Once you know these functions are good, return to 1, and compose them into the task that you need to build.\n\n## Critical Rules for Editing\n\n- Be careful with parentheses counts when editing Clojure code\n- After EVERY change to Clojure code, verify readability with `-check-readable`\n- End all files with a newline\n- When editing tabular code, where the columns line up, try to keep them aligned\n- Spaces on a line with nothing after it is not allowed\n"
      },
      "discovered_at": "2026-01-11T15:36:06.162946Z",
      "fetch_error": null
    },
    {
      "name": "docs-review",
      "slug": "docs-review",
      "source": "skillsmp_top",
      "owner": "metabase",
      "repo_name": "metabase",
      "repository_url": "https://github.com/metabase/metabase",
      "skill_path": ".claude/skills/docs-review",
      "github_metadata": {
        "stars": 45538,
        "description": "The easy-to-use open source Business Intelligence and Embedded Analytics tool that lets everyone work with data :bar_chart:",
        "default_branch": "master",
        "pushed_at": "2026-01-11T13:53:34Z",
        "created_at": "2015-02-02T19:25:47Z",
        "language": "Clojure",
        "license": "NOASSERTION",
        "open_issues": 3883,
        "forks": 6167
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/docs-review/SKILL.md",
        "branch": "master",
        "content": "---\nname: docs-review\ndescription: Review documentation changes for compliance with the Metabase writing style guide. Use when reviewing pull requests, files, or diffs containing documentation markdown files.\nallowed-tools: Read, Grep, Bash, Glob\n---\n\n# Documentation Review Skill\n\n@./../_shared/metabase-style-guide.md\n\n## Review mode detection\n\n**IMPORTANT: Before starting the review, determine which mode to use:**\n\n1. **PR review mode**: If the `mcp__github__create_pending_pull_request_review` tool is available, you are reviewing a GitHub PR\n   - Use the pending review workflow to post all issues as one cohesive review\n   - Follow the workflow steps in \"PR review mode format\" below\n\n2. **Local review mode**: If the MCP tool is NOT available, output issues in the conversation\n   - Format all issues in a numbered markdown list (as described in \"Feedback format\" below)\n\n## Review process\n\n1. **Detect review mode** - Check if `mcp__github__create_pending_pull_request_review` is available\n2. Read the changes through once to understand intent\n3. Check all issues that violate style guide or significantly impact readability\n4. Only flag issues worth mentioning - if it won't make a material difference to the reader, skip it\n5. **REQUIRED: Number ALL feedback sequentially** - Start from Issue 1 and increment for each issue found\n\n## Review checklist\n\nRun through the diff looking for these issues:\n\n**Tone and voice:**\n\n- [ ] Formal/corporate language (\"utilize\" not \"use\", \"offerings\", etc.)\n- [ ] \"Users\" instead of \"people\" or \"companies\"\n- [ ] Excessive exclamation points or overly peppy tone\n- [ ] Telling readers something is cool instead of showing them\n\n**Structure and clarity:**\n\n- [ ] Important information buried instead of leading\n- [ ] Verbose text that adds little value\n- [ ] Paragraphs without clear purpose\n- [ ] Vague headings that don't convey the point\n- [ ] Instructions explain \"why\" before telling \"what to do\"\n- [ ] Tasks described as \"easy\" or \"simple\"\n\n**Links and references:**\n\n- [ ] Linking the word \"here\" instead of descriptive text\n- [ ] Links in headings (unless entire heading is a link)\n\n**Formatting:**\n\n- [ ] Ampersands as \"and\" substitute (except proper nouns)\n- [ ] Inconsistent list formatting\n\n**Code and examples:**\n\n- [ ] Code examples that don't work or would error\n- [ ] Commands not in execution order\n- [ ] Full-width screenshots instead of scoped UI elements\n- [ ] Excessive or unnecessary images\n\n**Sentence construction:**\n\n- [ ] Overuse of pronouns when introducing new terms\n\n## Quick scan table\n\n| Pattern                       | Issue                                         |\n| ----------------------------- | --------------------------------------------- |\n| we can do X, our feature      | Should be \"Metabase\" or \"it\"                  |\n| click here, read more here    | Need descriptive link text                    |\n| easy, simple, just            | Remove condescending qualifiers               |\n| users                         | Should be \"people\" or \"companies\" if possible |\n\n## Feedback format\n\n**MANDATORY REQUIREMENT: Every single issue MUST be numbered sequentially starting from Issue 1.**\n\nThis numbered format is NON-NEGOTIABLE. It allows users to efficiently reference specific issues (e.g., \"fix issues 1, 3, and 5\") and track which feedback has been addressed.\n\n### Local review mode format\n\nWhen outputting issues in the conversation (local mode), use this format:\n\n```markdown\n## Issues\n\n**Issue 1: [Brief title]**\nLine X: Succinct description of the issue\n[code or example]\nSuggested fix or succinct explanation\n\n**Issue 2: [Brief title]**\nLine Y: Description of the issue\nSuggested fix or explanation\n\n**Issue 3: [Brief title]**\n...\n```\n\n**Examples:**\n\n> **Issue 1: Formal tone**\n> Line 15: This could be more conversational. Consider: \"You can't...\" instead of \"You cannot...\"\n\n> **Issue 2: Vague heading**\n> Line 8: The heading could be more specific. Try stating the point directly: \"Run migrations before upgrading\" vs \"Upgrade process\"\n\n### PR review mode format\n\nWhen posting to GitHub (PR mode), use the **pending review workflow**:\n\n**Workflow steps:**\n\n1. **Start a review**: Use `mcp__github__create_pending_pull_request_review` to begin a pending review\n   - This creates a draft review that won't be visible until submitted\n\n2. **Get diff information**: Use `mcp__github__get_pull_request_diff` to understand the code changes and line numbers\n   - This helps you determine the correct file paths and line numbers for comments\n\n3. **Identify ALL issues**: Read through all changes and identify every issue worth mentioning\n   - Collect all issues before posting any comments\n   - Number them sequentially (Issue 1, Issue 2, Issue 3, etc.)\n\n4. **Add review comments**: Use `mcp__github__add_pull_request_review_comment_to_pending_review` for each issue\n   - **CRITICAL**: Post ALL comments in a SINGLE response using multiple tool calls in parallel\n   - Each comment should reference a specific file path and line number from the diff\n   - Start each comment body with `**Issue N: [Brief title]**`\n   - Include the description and suggested fix\n\n5. **Submit the review**: Use `mcp__github__submit_pending_pull_request_review` to publish all comments at once\n   - Use event type `\"COMMENT\"` (NOT \"REQUEST_CHANGES\") to make it non-blocking\n   - **Do NOT include a body message** - Leave the body empty or omit it entirely\n   - All comments will appear together as one cohesive review\n\n**Comment format example:**\n\n```\n**Issue 1: Formal tone**\n\nThis could be more conversational. Consider: \"You can't...\" instead of \"You cannot...\"\n```\n\n**IMPORTANT**:\n- Each issue gets its own review comment attached to the pending review\n- Number ALL comments sequentially (Issue 1, Issue 2, Issue 3, etc.)\n- Always start the comment body with `**Issue N: [Brief title]**`\n- **MUST add all comments in parallel in a single response** - Do NOT add them one after another in separate responses\n- Do NOT output a summary message to the conversation - only post GitHub review comments\n- When submitting the review, do NOT include a body parameter (or leave it empty) to avoid cluttering the PR with summary text\n- The review will appear as a single review with multiple comments when submitted\n\n## Final check\n\n1. Remove any issues from your assessment that won't make a material difference to the reader if addressed. Only flag issues worth the author's time to fix.\n2. **Verify all issues are numbered sequentially** starting from Issue 1 with no gaps in numbering.\n3. Confirm the format exactly matches: `**Issue N: [Brief title]**` where N is the issue number.\n4. **In PR mode**: Verify each issue was posted as a separate GitHub comment (not output to conversation).\n"
      },
      "discovered_at": "2026-01-11T15:36:06.607529Z",
      "fetch_error": null
    },
    {
      "name": "docs-write",
      "slug": "docs-write",
      "source": "skillsmp_top",
      "owner": "metabase",
      "repo_name": "metabase",
      "repository_url": "https://github.com/metabase/metabase",
      "skill_path": ".claude/skills/docs-write",
      "github_metadata": {
        "stars": 45538,
        "description": "The easy-to-use open source Business Intelligence and Embedded Analytics tool that lets everyone work with data :bar_chart:",
        "default_branch": "master",
        "pushed_at": "2026-01-11T13:53:34Z",
        "created_at": "2015-02-02T19:25:47Z",
        "language": "Clojure",
        "license": "NOASSERTION",
        "open_issues": 3883,
        "forks": 6167
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/docs-write/SKILL.md",
        "branch": "master",
        "content": "---\nname: docs-write\ndescription: Write documentation following Metabase's conversational, clear, and user-focused style. Use when creating or editing documentation files (markdown, MDX, etc.).\nallowed-tools: Read, Write, Grep, Bash, Glob\n---\n\n# Documentation Writing Skill\n\n@./../_shared/metabase-style-guide.md\n\n## When writing documentation\n\n### Start here\n\n1. **Who is this for?** Match complexity to audience. Don't oversimplify hard things or overcomplicate simple ones.\n2. **What do they need?** Get them to the answer fast. Nobody wants to be in docs longer than necessary.\n3. **What did you struggle with?** Those common questions you had when learning? Answer them (without literally including the question).\n\n### Writing process\n\n**Draft:**\n\n- Write out the steps/explanation as you'd tell a colleague\n- Lead with what to do, then explain why\n- Use headings that state your point: \"Set SAML before adding users\" not \"SAML configuration timing\"\n\n**Edit:**\n\n- Read aloud. Does it sound like you talking? If it's too formal, simplify.\n- Cut anything that doesn't directly help the reader\n- Check each paragraph has one clear purpose\n- Verify examples actually work (don't give examples that error)\n\n**Polish:**\n\n- Make links descriptive (never \"here\")\n- Backticks only for code/variables, **bold** for UI elements\n- American spelling, serial commas\n- Keep images minimal and scoped tight\n\n**Format:**\n\n- Run prettier on the file after making edits: `yarn prettier --write <file-path>`\n- This ensures consistent formatting across all documentation\n\n### Common patterns\n\n**Instructions:**\n\n```markdown\nRun:\n\\`\\`\\`\ncommand-to-run\n\\`\\`\\`\n\nThen:\n\\`\\`\\`\nnext-command\n\\`\\`\\`\n\nThis ensures you're getting the latest changes.\n```\n\nNot: \"(remember to run X before Y...)\" buried in a paragraph.\n\n**Headings:**\n\n- \"Use environment variables for configuration\" âœ…\n- \"Environment variables\" âŒ (too vague)\n- \"How to use environment variables for configuration\" âŒ (too wordy)\n\n**Links:**\n\n- \"Check out the [SAML documentation](link)\" âœ…\n- \"Read the docs [here](link)\" âŒ\n\n### Watch out for\n\n- Describing tasks as \"easy\" (you don't know the reader's context)\n- Using \"we\" when talking about Metabase features (use \"Metabase\" or \"it\")\n- Formal language: \"utilize\", \"reference\", \"offerings\"\n- Too peppy: multiple exclamation points\n- Burying the action in explanation\n- Code examples that don't work\n- Numbers that will become outdated\n\n### Quick reference\n\n| Write This                 | Not This           |\n| -------------------------- | ------------------ |\n| people, companies          | users              |\n| summarize                  | aggregate          |\n| take a look at             | reference          |\n| can't, don't               | cannot, do not     |\n| **Filter** button          | \\`Filter\\` button  |\n| Check out [the docs](link) | Click [here](link) |\n"
      },
      "discovered_at": "2026-01-11T15:36:07.103698Z",
      "fetch_error": null
    },
    {
      "name": "typescript-review",
      "slug": "typescript-review",
      "source": "skillsmp_top",
      "owner": "metabase",
      "repo_name": "metabase",
      "repository_url": "https://github.com/metabase/metabase",
      "skill_path": ".claude/skills/typescript-review",
      "github_metadata": {
        "stars": 45538,
        "description": "The easy-to-use open source Business Intelligence and Embedded Analytics tool that lets everyone work with data :bar_chart:",
        "default_branch": "master",
        "pushed_at": "2026-01-11T13:53:34Z",
        "created_at": "2015-02-02T19:25:47Z",
        "language": "Clojure",
        "license": "NOASSERTION",
        "open_issues": 3883,
        "forks": 6167
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/typescript-review/SKILL.md",
        "branch": "master",
        "content": "---\nname: typescript-review\ndescription: Review TypeScript and JavaScript code changes for compliance with Metabase coding standards, style violations, and code quality issues. Use when reviewing pull requests or diffs containing TypeScript/JavaScript code.\nallowed-tools: Read, Grep, Bash, Glob\n---\n\n# TypeScript/JavaScript Code Review Skill\n\n@./../_shared/typescript-commands.md\n\n## Code Review Guidelines\n\nReview pull requests with a focus on:\n\n- Compliance with project coding standards and conventions\n- Code quality and best practices\n- Clear and correct JSDoc comments\n- Type safety and proper TypeScript usage\n- React best practices (when applicable)"
      },
      "discovered_at": "2026-01-11T15:36:07.454535Z",
      "fetch_error": null
    },
    {
      "name": "typescript-write",
      "slug": "typescript-write",
      "source": "skillsmp_top",
      "owner": "metabase",
      "repo_name": "metabase",
      "repository_url": "https://github.com/metabase/metabase",
      "skill_path": ".claude/skills/typescript-write",
      "github_metadata": {
        "stars": 45538,
        "description": "The easy-to-use open source Business Intelligence and Embedded Analytics tool that lets everyone work with data :bar_chart:",
        "default_branch": "master",
        "pushed_at": "2026-01-11T13:53:34Z",
        "created_at": "2015-02-02T19:25:47Z",
        "language": "Clojure",
        "license": "NOASSERTION",
        "open_issues": 3883,
        "forks": 6167
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/typescript-write/SKILL.md",
        "branch": "master",
        "content": "---\nname: typescript-write\ndescription: Write TypeScript and JavaScript code following Metabase coding standards and best practices. Use when developing or refactoring TypeScript/JavaScript code.\n---\n\n# TypeScript/JavaScript Development Skill\n\n@./../_shared/development-workflow.md\n@./../_shared/typescript-commands.md\n"
      },
      "discovered_at": "2026-01-11T15:36:07.873735Z",
      "fetch_error": null
    },
    {
      "name": "add-malli-schemas",
      "slug": "add-malli-schemas",
      "source": "skillsmp_top",
      "owner": "metabase",
      "repo_name": "metabase",
      "repository_url": "https://github.com/metabase/metabase",
      "skill_path": ".claude/skills/add-malli-schemas",
      "github_metadata": {
        "stars": 45538,
        "description": "The easy-to-use open source Business Intelligence and Embedded Analytics tool that lets everyone work with data :bar_chart:",
        "default_branch": "master",
        "pushed_at": "2026-01-11T13:53:34Z",
        "created_at": "2015-02-02T19:25:47Z",
        "language": "Clojure",
        "license": "NOASSERTION",
        "open_issues": 3883,
        "forks": 6167
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/add-malli-schemas/SKILL.md",
        "branch": "master",
        "content": "---\nname: add-malli-schemas\ndescription: Efficiently add Malli schemas to API endpoints in the Metabase codebase with proper patterns, validation timing, and error handling\n---\n\n# Add Malli Schemas to API Endpoints\n\nThis skill helps you efficiently and uniformly add Malli schemas to API endpoints in the Metabase codebase.\n\n## Reference Files (Best Examples)\n\n- `src/metabase/warehouses/api.clj` - Most comprehensive schemas, custom error messages\n- `src/metabase/api_keys/api.clj` - Excellent response schemas\n- `src/metabase/collections/api.clj` - Great named schema patterns\n- `src/metabase/timeline/api/timeline.clj` - Clean, simple examples\n\n## Quick Checklist\n\nWhen adding Malli schemas to an endpoint:\n\n- [ ] Route params have schemas\n- [ ] Query params have schemas with `:optional true` and `:default` where appropriate\n- [ ] Request body has a schema (for POST/PUT)\n- [ ] Response schema is defined (using `:-` after route string)\n- [ ] Use existing schema types from `ms` namespace when possible\n- [ ] Consider creating named schemas for reusable or complex types\n- [ ] Add contextual error messages for validation failures\n\n## Basic Structure\n\n### Complete Endpoint Example\n\n```clojure\n(mr/def ::Color [:enum \"red\" \"blue\" \"green\"])\n\n(mr/def ::ResponseSchema\n  [:map\n   [:id pos-int?]\n   [:name string?]\n   [:color ::Color]\n   [:created_at ms/TemporalString]])\n\n(api.macros/defendpoint :post \"/:name\" :- ::ResponseSchema\n  \"Create a resource with a given name.\"\n  [;; Route Params:\n   {:keys [name]} :- [:map [:name ms/NonBlankString]]\n   ;; Query Params:\n   {:keys [include archived]} :- [:map\n                                   [:include  {:optional true} [:maybe [:= \"details\"]]]\n                                   [:archived {:default false} [:maybe ms/BooleanValue]]]\n   ;; Body Params:\n   {:keys [color]} :- [:map [:color ::Color]]\n   ]\n  ;; endpoint implementation, ex:\n  {:id 99\n   :name (str \"mr or mrs \" name)\n   :color ({\"red\" \"blue\" \"blue\" \"green\" \"green\" \"red\"} color)\n   :created_at (t/format (t/formatter \"yyyy-MM-dd'T'HH:mm:ssXXX\") (t/zoned-date-time))}\n  )\n```\n\n## Common Schema Patterns\n\n1. Route Params (the 5 in `api/user/id/5`)\n2. Query Params (the sort+asc pair in `api/users?sort=asc`)\n3. Body Params (the contents of a request body. Almost always decoded from json into edn)\n4. The Raw Request map\n\nOf the 4 arguments, deprioritize usage of the raw request unless necessary.\n\n### Route Params\n\nAlways required, typically just a map with an ID:\n\n```clojure\n[{:keys [id]} :- [:map [:id ms/PositiveInt]]]\n```\n\nFor multiple route params:\n\n```clojure\n[{:keys [id field-id]} :- [:map\n                           [:id ms/PositiveInt]\n                           [:field-id ms/PositiveInt]]]\n```\n\n### Query Params\n\nAdd properties for `{:optional true ...}` and `:default` values:\n\n```clojure\n{:keys [archived include limit offset]} :- [:map\n                                            [:archived {:default false} [:maybe ms/BooleanValue]]\n                                            [:include  {:optional true}   [:maybe [:= \"tables\"]]]\n                                            [:limit    {:optional true} [:maybe ms/PositiveInt]]\n                                            [:offset   {:optional true} [:maybe ms/PositiveInt]]]\n```\n\n### Request Body (POST/PUT)\n\n```clojure\n{:keys [name description parent_id]} :- [:map\n                                         [:name        ms/NonBlankString]\n                                         [:description {:optional true} [:maybe ms/NonBlankString]]\n                                         [:parent_id   {:optional true} [:maybe ms/PositiveInt]]]\n```\n\n### Response Schemas\n\n#### Simple inline response:\n\n```clojure\n(api.macros/defendpoint :get \"/:id\" :- [:map\n                                        [:id pos-int?]\n                                        [:name string?]]\n  \"Get a thing\"\n  ...)\n```\n\n#### Named schema for reuse:\n\n```clojure\n(mr/def ::Thing\n  [:map\n   [:id pos-int?]\n   [:name string?]\n   [:description [:maybe string?]]])\n\n(api.macros/defendpoint :get \"/:id\" :- ::Thing\n  \"Get a thing\"\n  ...)\n\n(api.macros/defendpoint :get \"/\" :- [:sequential ::Thing]\n  \"Get all things\"\n  ...)\n```\n\n## Common Schema Types\n\n### From `metabase.util.malli.schema` (aliased as `ms`)\n\nPrefer the schemas in the ms/* namespace, since they work better with our api infrastructure. \n\nFor example use `ms/PositiveInt` instead of `pos-int?`.\n\n```clojure\nms/PositiveInt                  ;; Positive integer\nms/NonBlankString               ;; Non-empty string\nms/BooleanValue                 ;; String \"true\"/\"false\" or boolean\nms/MaybeBooleanValue            ;; BooleanValue or nil\nms/TemporalString               ;; ISO-8601 date/time string (for REQUEST params only!)\nms/Map                          ;; Any map\nms/JSONString                   ;; JSON-encoded string\nms/PositiveNum                  ;; Positive number\nms/IntGreaterThanOrEqualToZero  ;; 0 or positive\n```\n\n**IMPORTANT:** For response schemas, use `:any` for temporal fields, not `ms/TemporalString`!\nResponse schemas validate BEFORE JSON serialization, so they see Java Time objects.\n\n### Built-in Malli Types\n\n```clojure\n:string                     ;; Any string\n:boolean                    ;; true/false\n:int                        ;; Any integer\n:keyword                    ;; Clojure keyword\npos-int?                    ;; Positive integer predicate\n[:maybe X]                  ;; X or nil\n[:enum \"a\" \"b\" \"c\"]         ;; One of these values\n[:or X Y]                   ;; Schema that satisfies X or Y\n[:and X Y]                  ;; Schema that satisfies X and Y\n[:sequential X]             ;; Sequential of Xs\n[:set X]                    ;; Set of Xs\n[:map-of K V]               ;; Map with keys w/ schema K and values w/ schema V\n[:tuple X Y Z]              ;; Fixed-length tuple of schemas X Y Z\n```\n\nAvoid using sequence schemas unless completely necessary.\n\n## Step-by-Step: Adding Schemas to an Endpoint\n\n### Example: Adding return schema to `GET /api/field/:id/related`\n\n**Before:**\n```clojure\n(api.macros/defendpoint :get \"/:id/related\"\n  \"Return related entities.\"\n  [{:keys [id]} :- [:map [:id ms/PositiveInt]]]\n  (-> (t2/select-one :model/Field :id id) api/read-check xrays/related))\n```\n\n**Step 1:** Check what the function returns (look at `xrays/related`)\n\n**Step 2:** Define response schema based on return type:\n\n```clojure\n(mr/def ::RelatedEntity\n  [:map\n   [:tables [:sequential [:map [:id pos-int?] [:name string?]]]]\n   [:fields [:sequential [:map [:id pos-int?] [:name string?]]]]])\n```\n\n**Step 3:** Add response schema to endpoint:\n\n```clojure\n(api.macros/defendpoint :get \"/:id/related\" :- ::RelatedEntity\n  \"Return related entities.\"\n  [{:keys [id]} :- [:map [:id ms/PositiveInt]]]\n  (-> (t2/select-one :model/Field :id id) api/read-check xrays/related))\n```\n\n## Advanced Patterns\n\n### Custom Error Messages\n\n```clojure\n(def DBEngineString\n  \"Schema for a valid database engine name.\"\n  (mu/with-api-error-message\n   [:and\n    ms/NonBlankString\n    [:fn\n     {:error/message \"Valid database engine\"}\n     #(u/ignore-exceptions (driver/the-driver %))]]\n   (deferred-tru \"value must be a valid database engine.\")))\n```\n\n### Enum with Documentation\n\n```clojure\n(def PinnedState\n  (into [:enum {:error/message \"pinned state must be 'all', 'is_pinned', or 'is_not_pinned'\"}]\n        #{\"all\" \"is_pinned\" \"is_not_pinned\"}))\n```\n\n### Complex Nested Response\n\n```clojure\n(mr/def ::DashboardQuestionCandidate\n  [:map\n   [:id ms/PositiveInt]\n   [:name ms/NonBlankString]\n   [:description [:maybe string?]]\n   [:sole_dashboard_info\n    [:map\n     [:id ms/PositiveInt]\n     [:name ms/NonBlankString]\n     [:description [:maybe string?]]]]])\n\n(mr/def ::DashboardQuestionCandidatesResponse\n  [:map\n   [:data [:sequential ::DashboardQuestionCandidate]]\n   [:total ms/PositiveInt]])\n```\n\n### Paginated Response Pattern\n\n```clojure\n(mr/def ::PaginatedResponse\n  [:map\n   [:data [:sequential ::Item]]\n   [:total integer?]\n   [:limit {:optional true} [:maybe integer?]]\n   [:offset {:optional true} [:maybe integer?]]])\n```\n\n## Common Pitfalls\n\n### Don't: Forget `:maybe` for nullable fields\n\n```clojure\n[:description ms/NonBlankString]  ;; WRONG - fails if nil\n[:description [:maybe ms/NonBlankString]]  ;; RIGHT - allows nil\n```\n\n### Don't: Forget `:optional true` for optional query params\n\n```clojure\n[:limit ms/PositiveInt]  ;; WRONG - required but shouldn't be\n[:limit {:optional true} [:maybe ms/PositiveInt]]  ;; RIGHT\n```\n\n### Don't: Forget `:default` values for known params\n\n```clojure\n[:limit ms/PositiveInt]  ;; WRONG - required but shouldn't be\n[:limit {:optional true :default 0} [:maybe ms/PositiveInt]]  ;; RIGHT\n```\n\n\n### Don't: Mix up route params, query params, and body\n\n```clojure\n;; WRONG - all in one map\n[{:keys [id name archived]} :- [:map ...]]\n\n;; RIGHT - separate destructuring\n[{:keys [id]} :- [:map [:id ms/PositiveInt]]\n {:keys [archived]} :- [:map [:archived {:default false} ms/BooleanValue]]\n {:keys [name]} :- [:map [:name ms/NonBlankString]]]\n```\n\n### Don't: Use `ms/TemporalString` for Java Time objects in response schemas\n\n```clojure\n;; WRONG - Java Time objects aren't strings yet\n[:date_joined ms/TemporalString]\n\n;; RIGHT - schemas validate BEFORE JSON serialization\n[:date_joined :any]  ;; Java Time object, serialized to string by middleware\n[:last_login [:maybe :any]]  ;; Java Time object or nil\n```\n\n**Why:** Response schemas validate the internal Clojure data structures BEFORE they are serialized to JSON. Java Time objects like `OffsetDateTime` get converted to ISO-8601 strings by the JSON middleware, so the schema needs to accept the raw Java objects.\n\n### Don't: Use `[:sequential X]` when the data is actually a set\n\n```clojure\n;; WRONG - group_ids is actually a set\n[:group_ids {:optional true} [:sequential pos-int?]]\n\n;; RIGHT - matches the actual data structure\n[:group_ids {:optional true} [:maybe [:set pos-int?]]]\n```\n\n**Why:** Toucan hydration methods often return sets. The JSON middleware will serialize sets to arrays, but the schema validates before serialization.\n\n### Don't: Create anonymous schemas for reused structures\n\nUse `mr/def` for schemas used in multiple places:\n\n```clojure\n(mr/def ::User\n  [:map\n   [:id pos-int?]\n   [:email string?]\n   [:name string?]])\n```\n\n## Finding Return Types\n\n1. **Look at the function being called**\n\n```clojure\n(api.macros/defendpoint :get \"/:id\"\n  [{:keys [id]}]\n  (t2/select-one :model/Field :id id))  ;; Returns a Field instance\n```\n\n2. **Check Toucan models for structure**\n\nLook in `src/metabase/*/models/*.clj` for model definitions.\n\n3. **Use clojure-mcp or REPL to inspect**\n\n```bash\n./bin/mage -repl '(require '\\''metabase.xrays.core) (doc metabase.xrays.core/related)'\n```\n\n4. **Check tests**\n\nTests often show the expected response structure.\n\n## Understanding Schema Validation Timing\n\n**CRITICAL CONCEPT:** Schemas validate at different points in the request/response lifecycle:\n\n### Request Parameter Schemas (Query/Body/Route)\n- Validate AFTER JSON parsing\n- Data is already deserialized (strings, numbers, booleans)\n- Use `ms/TemporalString` for date/time inputs\n- Use `ms/BooleanValue` for boolean query params\n\n### Response Schemas\n- Validate BEFORE JSON serialization\n- Data is still in Clojure format (Java Time objects, sets, keywords)\n- Use `:any` for Java Time objects\n- Use `[:set X]` for sets\n- Use `[:enum :keyword]` for keyword enums\n\n### Serialization Flow\n\n```\nRequest:  JSON string â†’ Parse â†’ Coerce â†’ Handler\nResponse: Handler â†’ Schema Check â†’ Encode â†’ Serialize â†’ JSON string\n```\n\n## Workflow Summary\n\n1. **Read the endpoint** - understand what it does\n2. **Identify params** - route, query, body\n3. **Add parameter schemas** - use existing types from `ms`\n4. **Determine return type** - check the implementation\n5. **Define response schema** - inline or named with `mr/def`\n6. **Test** - ensure the endpoint works and validates correctly\n\n## Testing Your Schemas\n\nAfter adding schemas, verify:\n\n1. **Valid requests work** - test with correct data\n2. **Invalid requests fail gracefully** - test with wrong types\n3. **Optional params work** - test with/without optional params\n4. **Error messages are clear** - check validation error responses\n\n## Tips\n\n- **Start simple** - begin with basic types, refine later\n- **Reuse schemas** - if you see the same structure twice, make it a named schema\n- **Be specific** - use `ms/PositiveInt` instead of `pos-int?`\n- **Document intent** - add docstrings to named schemas\n- **Follow conventions** - look at similar endpoints in the same namespace\n- **Check the actual data** - use REPL to inspect what's actually returned before serialization\n\n## Additional Resources\n\n- [Malli Documentation](https://github.com/metosin/malli)\n- Metabase Malli utilities: `src/metabase/util/malli/schema.clj`\n- Metabase schema registry: `src/metabase/util/malli/registry.clj`\n"
      },
      "discovered_at": "2026-01-11T15:36:08.250075Z",
      "fetch_error": null
    },
    {
      "name": "skill-creator",
      "slug": "skill-creator",
      "source": "skillsmp_top",
      "owner": "tldraw",
      "repo_name": "tldraw",
      "repository_url": "https://github.com/tldraw/tldraw",
      "skill_path": ".claude/skills/skill-creator",
      "github_metadata": {
        "stars": 44522,
        "description": "very good whiteboard infinite canvas SDK",
        "default_branch": "main",
        "pushed_at": "2026-01-10T14:48:37Z",
        "created_at": "2021-05-09T11:48:37Z",
        "language": "TypeScript",
        "license": "NOASSERTION",
        "open_issues": 335,
        "forks": 2926
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/skill-creator/SKILL.md",
        "branch": "main",
        "content": "---\nname: skill-creator\ndescription: Guide for creating effective skills. This skill should be used when users want to create a new skill (or update an existing skill) that extends Claude's capabilities with specialized knowledge, workflows, or tool integrations.\nlicense: Complete terms in LICENSE.txt\n---\n\n# Skill Creator\n\nThis skill provides guidance for creating effective skills.\n\n## About Skills\n\nSkills are modular, self-contained packages that extend Claude's capabilities by providing\nspecialized knowledge, workflows, and tools. Think of them as \"onboarding guides\" for specific\ndomains or tasksâ€”they transform Claude from a general-purpose agent into a specialized agent\nequipped with procedural knowledge that no model can fully possess.\n\n### What Skills Provide\n\n1. Specialized workflows - Multi-step procedures for specific domains\n2. Tool integrations - Instructions for working with specific file formats or APIs\n3. Domain expertise - Company-specific knowledge, schemas, business logic\n4. Bundled resources - Scripts, references, and assets for complex and repetitive tasks\n\n## Core Principles\n\n### Concise is Key\n\nThe context window is a public good. Skills share the context window with everything else Claude needs: system prompt, conversation history, other Skills' metadata, and the actual user request.\n\n**Default assumption: Claude is already very smart.** Only add context Claude doesn't already have. Challenge each piece of information: \"Does Claude really need this explanation?\" and \"Does this paragraph justify its token cost?\"\n\nPrefer concise examples over verbose explanations.\n\n### Set Appropriate Degrees of Freedom\n\nMatch the level of specificity to the task's fragility and variability:\n\n**High freedom (text-based instructions)**: Use when multiple approaches are valid, decisions depend on context, or heuristics guide the approach.\n\n**Medium freedom (pseudocode or scripts with parameters)**: Use when a preferred pattern exists, some variation is acceptable, or configuration affects behavior.\n\n**Low freedom (specific scripts, few parameters)**: Use when operations are fragile and error-prone, consistency is critical, or a specific sequence must be followed.\n\nThink of Claude as exploring a path: a narrow bridge with cliffs needs specific guardrails (low freedom), while an open field allows many routes (high freedom).\n\n### Anatomy of a Skill\n\nEvery skill consists of a required SKILL.md file and optional bundled resources:\n\n```\nskill-name/\nâ”œâ”€â”€ SKILL.md (required)\nâ”‚   â”œâ”€â”€ YAML frontmatter metadata (required)\nâ”‚   â”‚   â”œâ”€â”€ name: (required)\nâ”‚   â”‚   â””â”€â”€ description: (required)\nâ”‚   â””â”€â”€ Markdown instructions (required)\nâ””â”€â”€ Bundled Resources (optional)\n    â”œâ”€â”€ scripts/          - Executable code (TypeScript/Python/Bash/etc.)\n    â”œâ”€â”€ references/       - Documentation intended to be loaded into context as needed\n    â””â”€â”€ assets/           - Files used in output (templates, icons, fonts, etc.)\n```\n\n#### SKILL.md (required)\n\nEvery SKILL.md consists of:\n\n- **Frontmatter** (YAML): Contains `name` and `description` fields. These are the only fields that Claude reads to determine when the skill gets used, thus it is very important to be clear and comprehensive in describing what the skill is, and when it should be used.\n- **Body** (Markdown): Instructions and guidance for using the skill. Only loaded AFTER the skill triggers (if at all).\n\n#### Bundled Resources (optional)\n\n##### Scripts (`scripts/`)\n\nExecutable code (TypeScript/Python/Bash/etc.) for tasks that require deterministic reliability or are repeatedly rewritten.\n\n- **When to include**: When the same code is being rewritten repeatedly or deterministic reliability is needed\n- **Example**: `scripts/rotate-pdf.ts` for PDF rotation tasks\n- **Benefits**: Token efficient, deterministic, may be executed without loading into context\n- **Note**: Scripts may still need to be read by Claude for patching or environment-specific adjustments\n\n##### References (`references/`)\n\nDocumentation and reference material intended to be loaded as needed into context to inform Claude's process and thinking.\n\n- **When to include**: For documentation that Claude should reference while working\n- **Examples**: `references/finance.md` for financial schemas, `references/mnda.md` for company NDA template, `references/policies.md` for company policies, `references/api_docs.md` for API specifications\n- **Use cases**: Database schemas, API documentation, domain knowledge, company policies, detailed workflow guides\n- **Benefits**: Keeps SKILL.md lean, loaded only when Claude determines it's needed\n- **Best practice**: If files are large (>10k words), include grep search patterns in SKILL.md\n- **Avoid duplication**: Information should live in either SKILL.md or references files, not both. Prefer references files for detailed information unless it's truly core to the skillâ€”this keeps SKILL.md lean while making information discoverable without hogging the context window. Keep only essential procedural instructions and workflow guidance in SKILL.md; move detailed reference material, schemas, and examples to references files.\n\n##### Assets (`assets/`)\n\nFiles not intended to be loaded into context, but rather used within the output Claude produces.\n\n- **When to include**: When the skill needs files that will be used in the final output\n- **Examples**: `assets/logo.png` for brand assets, `assets/slides.pptx` for PowerPoint templates, `assets/frontend-template/` for HTML/React boilerplate, `assets/font.ttf` for typography\n- **Use cases**: Templates, images, icons, boilerplate code, fonts, sample documents that get copied or modified\n- **Benefits**: Separates output resources from documentation, enables Claude to use files without loading them into context\n\n#### What to Not Include in a Skill\n\nA skill should only contain essential files that directly support its functionality. Do NOT create extraneous documentation or auxiliary files, including:\n\n- README.md\n- INSTALLATION_GUIDE.md\n- QUICK_REFERENCE.md\n- CHANGELOG.md\n- etc.\n\nThe skill should only contain the information needed for an AI agent to do the job at hand. It should not contain auxilary context about the process that went into creating it, setup and testing procedures, user-facing documentation, etc. Creating additional documentation files just adds clutter and confusion.\n\n### Progressive Disclosure Design Principle\n\nSkills use a three-level loading system to manage context efficiently:\n\n1. **Metadata (name + description)** - Always in context (~100 words)\n2. **SKILL.md body** - When skill triggers (<5k words)\n3. **Bundled resources** - As needed by Claude (Unlimited because scripts can be executed without reading into context window)\n\n#### Progressive Disclosure Patterns\n\nKeep SKILL.md body to the essentials and under 500 lines to minimize context bloat. Split content into separate files when approaching this limit. When splitting out content into other files, it is very important to reference them from SKILL.md and describe clearly when to read them, to ensure the reader of the skill knows they exist and when to use them.\n\n**Key principle:** When a skill supports multiple variations, frameworks, or options, keep only the core workflow and selection guidance in SKILL.md. Move variant-specific details (patterns, examples, configuration) into separate reference files.\n\n**Pattern 1: High-level guide with references**\n\n```markdown\n# PDF Processing\n\n## Quick start\n\nExtract text with pdfplumber:\n[code example]\n\n## Advanced features\n\n- **Form filling**: See [FORMS.md](FORMS.md) for complete guide\n- **API reference**: See [REFERENCE.md](REFERENCE.md) for all methods\n- **Examples**: See [EXAMPLES.md](EXAMPLES.md) for common patterns\n```\n\nClaude loads FORMS.md, REFERENCE.md, or EXAMPLES.md only when needed.\n\n**Pattern 2: Domain-specific organization**\n\nFor Skills with multiple domains, organize content by domain to avoid loading irrelevant context:\n\n```\nbigquery-skill/\nâ”œâ”€â”€ SKILL.md (overview and navigation)\nâ””â”€â”€ reference/\n    â”œâ”€â”€ finance.md (revenue, billing metrics)\n    â”œâ”€â”€ sales.md (opportunities, pipeline)\n    â”œâ”€â”€ product.md (API usage, features)\n    â””â”€â”€ marketing.md (campaigns, attribution)\n```\n\nWhen a user asks about sales metrics, Claude only reads sales.md.\n\nSimilarly, for skills supporting multiple frameworks or variants, organize by variant:\n\n```\ncloud-deploy/\nâ”œâ”€â”€ SKILL.md (workflow + provider selection)\nâ””â”€â”€ references/\n    â”œâ”€â”€ aws.md (AWS deployment patterns)\n    â”œâ”€â”€ gcp.md (GCP deployment patterns)\n    â””â”€â”€ azure.md (Azure deployment patterns)\n```\n\nWhen the user chooses AWS, Claude only reads aws.md.\n\n**Pattern 3: Conditional details**\n\nShow basic content, link to advanced content:\n\n```markdown\n# DOCX Processing\n\n## Creating documents\n\nUse docx-js for new documents. See [DOCX-JS.md](DOCX-JS.md).\n\n## Editing documents\n\nFor simple edits, modify the XML directly.\n\n**For tracked changes**: See [REDLINING.md](REDLINING.md)\n**For OOXML details**: See [OOXML.md](OOXML.md)\n```\n\nClaude reads REDLINING.md or OOXML.md only when the user needs those features.\n\n**Important guidelines:**\n\n- **Avoid deeply nested references** - Keep references one level deep from SKILL.md. All reference files should link directly from SKILL.md.\n- **Structure longer reference files** - For files longer than 100 lines, include a table of contents at the top so Claude can see the full scope when previewing.\n\n## Skill Creation Process\n\nSkill creation involves these steps:\n\n1. Understand the skill with concrete examples\n2. Plan reusable skill contents (scripts, references, assets)\n3. Initialize the skill (run init-skill.ts)\n4. Edit the skill (implement resources and write SKILL.md)\n5. Package the skill (run package-skill.ts)\n6. Iterate based on real usage\n\nFollow these steps in order, skipping only if there is a clear reason why they are not applicable.\n\n### Step 1: Understanding the Skill with Concrete Examples\n\nSkip this step only when the skill's usage patterns are already clearly understood. It remains valuable even when working with an existing skill.\n\nTo create an effective skill, clearly understand concrete examples of how the skill will be used. This understanding can come from either direct user examples or generated examples that are validated with user feedback.\n\nFor example, when building an image-editor skill, relevant questions include:\n\n- \"What functionality should the image-editor skill support? Editing, rotating, anything else?\"\n- \"Can you give some examples of how this skill would be used?\"\n- \"I can imagine users asking for things like 'Remove the red-eye from this image' or 'Rotate this image'. Are there other ways you imagine this skill being used?\"\n- \"What would a user say that should trigger this skill?\"\n\nTo avoid overwhelming users, avoid asking too many questions in a single message. Start with the most important questions and follow up as needed for better effectiveness.\n\nConclude this step when there is a clear sense of the functionality the skill should support.\n\n### Step 2: Planning the Reusable Skill Contents\n\nTo turn concrete examples into an effective skill, analyze each example by:\n\n1. Considering how to execute on the example from scratch\n2. Identifying what scripts, references, and assets would be helpful when executing these workflows repeatedly\n\nExample: When building a `pdf-editor` skill to handle queries like \"Help me rotate this PDF,\" the analysis shows:\n\n1. Rotating a PDF requires re-writing the same code each time\n2. A `scripts/rotate_pdf.py` script would be helpful to store in the skill\n\nExample: When designing a `frontend-webapp-builder` skill for queries like \"Build me a todo app\" or \"Build me a dashboard to track my steps,\" the analysis shows:\n\n1. Writing a frontend webapp requires the same boilerplate HTML/React each time\n2. An `assets/hello-world/` template containing the boilerplate HTML/React project files would be helpful to store in the skill\n\nExample: When building a `big-query` skill to handle queries like \"How many users have logged in today?\" the analysis shows:\n\n1. Querying BigQuery requires re-discovering the table schemas and relationships each time\n2. A `references/schema.md` file documenting the table schemas would be helpful to store in the skill\n\nTo establish the skill's contents, analyze each concrete example to create a list of the reusable resources to include: scripts, references, and assets.\n\n### Step 3: Initializing the Skill\n\nAt this point, it is time to actually create the skill.\n\nSkip this step only if the skill being developed already exists, and iteration or packaging is needed. In this case, continue to the next step.\n\nWhen creating a new skill from scratch, always run the `init-skill.ts` script. The script conveniently generates a new template skill directory that automatically includes everything a skill requires, making the skill creation process much more efficient and reliable.\n\nUsage:\n\n```bash\nnpx tsx scripts/init-skill.ts <skill-name> --path <output-directory>\n```\n\nThe script:\n\n- Creates the skill directory at the specified path\n- Generates a SKILL.md template with proper frontmatter and TODO placeholders\n- Creates example resource directories: `scripts/`, `references/`, and `assets/`\n- Adds example files in each directory that can be customized or deleted\n\nAfter initialization, customize or remove the generated SKILL.md and example files as needed.\n\n### Step 4: Edit the Skill\n\nWhen editing the (newly-generated or existing) skill, remember that the skill is being created for another instance of Claude to use. Include information that would be beneficial and non-obvious to Claude. Consider what procedural knowledge, domain-specific details, or reusable assets would help another Claude instance execute these tasks more effectively.\n\n#### Learn Proven Design Patterns\n\nConsult these helpful guides based on your skill's needs:\n\n- **Multi-step processes**: See references/workflows.md for sequential workflows and conditional logic\n- **Specific output formats or quality standards**: See references/output-patterns.md for template and example patterns\n\nThese files contain established best practices for effective skill design.\n\n#### Start with Reusable Skill Contents\n\nTo begin implementation, start with the reusable resources identified above: `scripts/`, `references/`, and `assets/` files. Note that this step may require user input. For example, when implementing a `brand-guidelines` skill, the user may need to provide brand assets or templates to store in `assets/`, or documentation to store in `references/`.\n\nAdded scripts must be tested by actually running them to ensure there are no bugs and that the output matches what is expected. If there are many similar scripts, only a representative sample needs to be tested to ensure confidence that they all work while balancing time to completion.\n\nAny example files and directories not needed for the skill should be deleted. The initialization script creates example files in `scripts/`, `references/`, and `assets/` to demonstrate structure, but most skills won't need all of them.\n\n#### Update SKILL.md\n\n**Writing Guidelines:** Always use imperative/infinitive form.\n\n##### Frontmatter\n\nWrite the YAML frontmatter with `name` and `description`:\n\n- `name`: The skill name\n- `description`: This is the primary triggering mechanism for your skill, and helps Claude understand when to use the skill.\n  - Include both what the Skill does and specific triggers/contexts for when to use it.\n  - Include all \"when to use\" information here - Not in the body. The body is only loaded after triggering, so \"When to Use This Skill\" sections in the body are not helpful to Claude.\n  - Example description for a `docx` skill: \"Comprehensive document creation, editing, and analysis with support for tracked changes, comments, formatting preservation, and text extraction. Use when Claude needs to work with professional documents (.docx files) for: (1) Creating new documents, (2) Modifying or editing content, (3) Working with tracked changes, (4) Adding comments, or any other document tasks\"\n\nDo not include any other fields in YAML frontmatter.\n\n##### Body\n\nWrite instructions for using the skill and its bundled resources.\n\n### Step 5: Packaging a Skill\n\nOnce development of the skill is complete, it must be packaged into a distributable .skill file that gets shared with the user. The packaging process automatically validates the skill first to ensure it meets all requirements:\n\n```bash\nnpx tsx scripts/package-skill.ts <path/to/skill-folder>\n```\n\nOptional output directory specification:\n\n```bash\nnpx tsx scripts/package-skill.ts <path/to/skill-folder> ./dist\n```\n\nThe packaging script will:\n\n1. **Validate** the skill automatically, checking:\n   - YAML frontmatter format and required fields\n   - Skill naming conventions and directory structure\n   - Description completeness and quality\n   - File organization and resource references\n\n2. **Package** the skill if validation passes, creating a .skill file named after the skill (e.g., `my-skill.skill`) that includes all files and maintains the proper directory structure for distribution. The .skill file is a zip file with a .skill extension.\n\nIf validation fails, the script will report the errors and exit without creating a package. Fix any validation errors and run the packaging command again.\n\n### Step 6: Iterate\n\nAfter testing the skill, users may request improvements. Often this happens right after using the skill, with fresh context of how the skill performed.\n\n**Iteration workflow:**\n\n1. Use the skill on real tasks\n2. Notice struggles or inefficiencies\n3. Identify how SKILL.md or bundled resources should be updated\n4. Implement changes and test again\n"
      },
      "discovered_at": "2026-01-11T15:36:08.719665Z",
      "fetch_error": null
    },
    {
      "name": "write-e2e-tests",
      "slug": "write-e2e-tests",
      "source": "skillsmp_top",
      "owner": "tldraw",
      "repo_name": "tldraw",
      "repository_url": "https://github.com/tldraw/tldraw",
      "skill_path": ".claude/skills/write-e2e-tests",
      "github_metadata": {
        "stars": 44522,
        "description": "very good whiteboard infinite canvas SDK",
        "default_branch": "main",
        "pushed_at": "2026-01-10T14:48:37Z",
        "created_at": "2021-05-09T11:48:37Z",
        "language": "TypeScript",
        "license": "NOASSERTION",
        "open_issues": 335,
        "forks": 2926
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/write-e2e-tests/SKILL.md",
        "branch": "main",
        "content": "---\nname: write-e2e-tests\ndescription: Writing Playwright E2E tests for tldraw. Use when creating browser tests, testing UI interactions, or adding E2E coverage in apps/examples/e2e or apps/dotcom/client/e2e.\n---\n\n# Writing E2E tests\n\nE2E tests use Playwright. Located in `apps/examples/e2e/` (SDK examples) and `apps/dotcom/client/e2e/` (tldraw.com).\n\n## Test file structure\n\n```\napps/examples/e2e/\nâ”œâ”€â”€ fixtures/\nâ”‚   â”œâ”€â”€ fixtures.ts        # Test fixtures (toolbar, menus, etc.)\nâ”‚   â””â”€â”€ menus/             # Page object models\nâ”œâ”€â”€ tests/\nâ”‚   â””â”€â”€ test-*.spec.ts     # Test files\nâ””â”€â”€ shared-e2e.ts          # Shared utilities\n```\n\nName test files `test-<feature>.spec.ts`.\n\n## Required declarations\n\nWhen using `page.evaluate()` to access the editor or UI events:\n\n```typescript\nimport { Editor } from 'tldraw'\n\ndeclare const editor: Editor\ndeclare const __tldraw_ui_event: { name: string; data?: any }\n```\n\n## Basic test structure\n\n```typescript\nimport { expect } from '@playwright/test'\nimport test from '../fixtures/fixtures'\nimport { setupOrReset } from '../shared-e2e'\n\ntest.describe('Feature name', () => {\n\ttest.beforeEach(setupOrReset)\n\n\ttest('does something', async ({ page, toolbar }) => {\n\t\t// Test implementation\n\t})\n})\n```\n\n## Setup patterns\n\n### Standard setup (recommended)\n\n```typescript\ntest.beforeEach(setupOrReset) // Smart: navigates first run, fast reset after\n```\n\n### Shared page for performance\n\nFor tests that don't need full isolation:\n\n```typescript\nlet page: Page\n\ntest.describe('Feature', () => {\n\ttest.beforeAll(async ({ browser }) => {\n\t\tpage = await browser.newPage()\n\t\tawait setupPage(page)\n\t})\n\n\ttest.beforeEach(async () => {\n\t\tawait hardResetEditor(page)\n\t})\n})\n```\n\n### Setup with shapes\n\n```typescript\nimport { setupPageWithShapes, hardResetWithShapes } from '../shared-e2e'\n\ntest.beforeEach(async ({ browser }) => {\n\tif (!page) {\n\t\tpage = await browser.newPage()\n\t\tawait setupPage(page)\n\t} else {\n\t\tawait hardResetEditor(page)\n\t}\n\tawait setupPageWithShapes(page)\n})\n```\n\n## Available fixtures\n\n```typescript\ntest('example', async ({\n\tpage, // Playwright page\n\ttoolbar, // Toolbar page object\n\tstylePanel, // Style panel\n\tactionsMenu, // Actions menu\n\tmainMenu, // Main menu\n\tpageMenu, // Page menu\n\tnavigationPanel, // Navigation panel\n\trichTextToolbar, // Rich text toolbar\n\tapi, // tldrawApi methods\n\tisMobile, // Mobile viewport check\n\tisMac, // Mac platform check\n}) => {})\n```\n\n## Interacting with the editor\n\n### Via page.evaluate\n\n```typescript\n// Execute code in browser context\nawait page.evaluate(() => {\n\teditor.createShapes([{ type: 'geo', x: 100, y: 100, props: { w: 100, h: 100 } }])\n})\n\n// Fast reset (faster than keyboard shortcuts)\nawait page.evaluate(() => {\n\teditor.selectAll().deleteShapes(editor.getSelectedShapeIds())\n\teditor.setCurrentTool('select')\n})\n\n// Get data from editor\nconst shape = await page.evaluate(() => editor.getOnlySelectedShape())\nexpect(shape).toMatchObject({ type: 'geo', x: 100, y: 100 })\n```\n\n### Testing UI events\n\n```typescript\nawait page.keyboard.press('Control+a')\nexpect(await page.evaluate(() => __tldraw_ui_event)).toMatchObject({\n\tname: 'select-all-shapes',\n\tdata: { source: 'kbd' },\n})\n```\n\n## Selecting tools and UI elements\n\n### By test ID\n\n```typescript\nawait page.getByTestId('tools.rectangle').click()\nawait page.getByTestId('tools.more.cloud').click() // In popover\nawait expect(page.getByTestId('tools.select')).toHaveAttribute('aria-pressed', 'true')\n```\n\n### Via toolbar fixture\n\n```typescript\nconst { select, draw, arrow, rectangle } = toolbar.tools\nawait rectangle.click()\nawait toolbar.isSelected(rectangle)\nawait toolbar.isNotSelected(select)\n\n// More tools popover\nawait toolbar.moreToolsButton.click()\nawait toolbar.popOverTools.popoverCloud.click()\n```\n\n## Menu interactions\n\n```typescript\nimport { clickMenu, withMenu } from '../shared-e2e'\n\n// Click a menu item\nawait clickMenu(page, 'main-menu.edit.copy')\nawait clickMenu(page, 'context-menu.copy-as.copy-as-png')\n\n// Focus and interact with menu item\nawait page.mouse.click(200, 200, { button: 'right' })\nawait withMenu(page, 'context-menu.arrange.distribute-horizontal', (item) => item.focus())\nawait page.keyboard.press('Enter')\n```\n\n## Data-driven tests\n\n```typescript\nconst tools = [\n\t{ tool: 'rectangle', shape: 'geo' },\n\t{ tool: 'arrow', shape: 'arrow' },\n\t{ tool: 'draw', shape: 'draw' },\n]\n\ntest('creates shapes with tools', async ({ page, toolbar }) => {\n\tfor (const { tool, shape } of tools) {\n\t\tawait page.getByTestId(`tools.${tool}`).click()\n\t\tawait page.mouse.click(200, 200)\n\t\texpect(await getAllShapeTypes(page)).toContain(shape)\n\n\t\t// Reset for next iteration\n\t\tawait page.evaluate(() => {\n\t\t\teditor.selectAll().deleteShapes(editor.getSelectedShapeIds())\n\t\t})\n\t}\n})\n```\n\n## Platform-specific handling\n\n### Modifier keys\n\n```typescript\ntest('copy paste', async ({ page, isMac }) => {\n\tconst modifier = isMac ? 'Meta' : 'Control'\n\tawait page.keyboard.down(modifier)\n\tawait page.keyboard.press('KeyC')\n\tawait page.keyboard.press('KeyV')\n\tawait page.keyboard.up(modifier)\n})\n```\n\n### Skip on mobile\n\n```typescript\ntest('desktop only feature', async ({ isMobile }) => {\n\tif (isMobile) return\n\t// Desktop-specific test\n})\n```\n\n## Helper functions\n\n```typescript\nimport { getAllShapeTypes, getAllShapeLabels, sleep, sleepFrames } from '../shared-e2e'\n\n// Get shape types on canvas\nconst shapes = await getAllShapeTypes(page)\nexpect(shapes).toEqual(['geo', 'arrow'])\n\n// Wait for async operations\nawait sleep(100)\nawait sleepFrames(2) // Wait for animation frames\n```\n\n## Assertions\n\n```typescript\n// Shape assertions\nexpect(await page.evaluate(() => editor.getOnlySelectedShape())).toMatchObject({\n\ttype: 'geo',\n\tprops: { w: 100, h: 100 },\n})\n\n// Attribute assertions\nawait expect(page.getByTestId('tools.select')).toHaveAttribute('aria-pressed', 'true')\n\n// CSS assertions (for selection state)\nawait expect(tool).toHaveCSS('color', 'rgb(255, 255, 255)')\n\n// Visibility\nawait expect(toolbar.moreToolsPopover).toBeVisible()\nawait expect(toolbar.toolLock).toBeHidden()\n```\n\n## Skipping flaky tests\n\n```typescript\ntest.describe.skip('clipboard tests', () => {\n\t// Skipped because flaky in CI\n})\n\ntest.skip('known issue', async () => {})\n```\n\n## Running E2E tests\n\n```bash\nyarn e2e                    # Examples E2E\nyarn e2e-dotcom            # Dotcom E2E\nyarn e2e-ui                # With Playwright UI\nyarn e2e -- --grep \"toolbar\"  # Filter by pattern\n```\n\n## Key patterns summary\n\n- Use `setupOrReset` in `beforeEach` for test isolation\n- Declare `editor` and `__tldraw_ui_event` for `page.evaluate()`\n- Use `page.evaluate()` for fast editor manipulation (faster than keyboard)\n- Use `getByTestId()` with `tools.<name>` pattern for tool selection\n- Use `clickMenu()` / `withMenu()` for menu interactions\n- Handle platform differences with `isMac` and `isMobile` fixtures\n- Test against `localhost:5420/end-to-end` example\n"
      },
      "discovered_at": "2026-01-11T15:36:09.144793Z",
      "fetch_error": null
    },
    {
      "name": "write-unit-tests",
      "slug": "write-unit-tests",
      "source": "skillsmp_top",
      "owner": "tldraw",
      "repo_name": "tldraw",
      "repository_url": "https://github.com/tldraw/tldraw",
      "skill_path": ".claude/skills/write-unit-tests",
      "github_metadata": {
        "stars": 44522,
        "description": "very good whiteboard infinite canvas SDK",
        "default_branch": "main",
        "pushed_at": "2026-01-10T14:48:37Z",
        "created_at": "2021-05-09T11:48:37Z",
        "language": "TypeScript",
        "license": "NOASSERTION",
        "open_issues": 335,
        "forks": 2926
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/write-unit-tests/SKILL.md",
        "branch": "main",
        "content": "---\nname: write-unit-tests\ndescription: Writing unit and integration tests for the tldraw SDK. Use when creating new tests, adding test coverage, or fixing failing tests in packages/editor or packages/tldraw. Covers Vitest patterns, TestEditor usage, and test file organization.\n---\n\n# Writing tests\n\nUnit and integration tests use Vitest. Tests run from workspace directories, not the repo root.\n\n## Test file locations\n\n**Unit tests** - alongside source files:\n\n```\npackages/editor/src/lib/primitives/Vec.ts\npackages/editor/src/lib/primitives/Vec.test.ts  # Same directory\n```\n\n**Integration tests** - in `src/test/` directory:\n\n```\npackages/tldraw/src/test/SelectTool.test.ts\npackages/tldraw/src/test/commands/createShape.test.ts\n```\n\n**Shape/tool tests** - alongside the implementation:\n\n```\npackages/tldraw/src/lib/shapes/arrow/ArrowShapeUtil.test.ts\npackages/tldraw/src/lib/shapes/arrow/ArrowShapeTool.test.ts\n```\n\n## Which workspace to test in\n\n- **packages/editor**: Core primitives, geometry, managers, base editor functionality\n- **packages/tldraw**: Anything needing default shapes/tools (most integration tests)\n\n```bash\ncd packages/tldraw && yarn test run\ncd packages/tldraw && yarn test run --grep \"SelectTool\"\n```\n\n## TestEditor vs Editor\n\nUse `TestEditor` for integration tests (includes default shapes/tools):\n\n```typescript\nimport { createShapeId } from '@tldraw/editor'\nimport { TestEditor } from './TestEditor'\n\nlet editor: TestEditor\n\nbeforeEach(() => {\n\teditor = new TestEditor()\n\teditor.selectAll().deleteShapes(editor.getSelectedShapeIds())\n})\n\nafterEach(() => {\n\teditor?.dispose()\n})\n```\n\nUse raw `Editor` when testing editor setup or custom configurations:\n\n```typescript\nimport { Editor, createTLStore } from '@tldraw/editor'\n\nbeforeEach(() => {\n\teditor = new Editor({\n\t\tshapeUtils: [CustomShape],\n\t\tbindingUtils: [],\n\t\ttools: [CustomTool],\n\t\tstore: createTLStore({ shapeUtils: [CustomShape], bindingUtils: [] }),\n\t\tgetContainer: () => document.body,\n\t})\n})\n```\n\n## Common TestEditor methods\n\n```typescript\n// Pointer simulation\neditor.pointerDown(x, y, options?)\neditor.pointerMove(x, y, options?)\neditor.pointerUp(x, y, options?)\neditor.click(x, y, shapeId?)\neditor.doubleClick(x, y, shapeId?)\n\n// Keyboard simulation\neditor.keyDown(key, options?)\neditor.keyUp(key, options?)\n\n// State assertions\neditor.expectToBeIn('select.idle')\neditor.expectToBeIn('select.crop.idle')\n\n// Shape assertions\neditor.expectShapeToMatch({ id, x, y, props: { ... } })\n\n// Shape operations\neditor.createShapes([{ id, type, x, y, props }])\neditor.updateShapes([{ id, type, props }])\neditor.getShape(id)\neditor.select(id1, id2)\neditor.selectAll()\neditor.selectNone()\neditor.getSelectedShapeIds()\neditor.getOnlySelectedShape()\n\n// Tool operations\neditor.setCurrentTool('arrow')\neditor.getCurrentToolId()\n\n// Undo/redo\neditor.undo()\neditor.redo()\n```\n\n## Pointer event options\n\n```typescript\neditor.pointerDown(100, 100, {\n\ttarget: 'shape', // 'canvas' | 'shape' | 'handle' | 'selection'\n\tshape: editor.getShape(id),\n})\n\neditor.pointerDown(150, 300, {\n\ttarget: 'selection',\n\thandle: 'bottom', // 'top' | 'bottom' | 'left' | 'right' | corners\n})\n\neditor.doubleClick(550, 550, {\n\ttarget: 'selection',\n\thandle: 'bottom_right',\n})\n```\n\n## Setup patterns\n\n### Standard setup with shape IDs\n\n```typescript\nconst ids = {\n\tbox1: createShapeId('box1'),\n\tbox2: createShapeId('box2'),\n\tarrow1: createShapeId('arrow1'),\n}\n\nvi.useFakeTimers()\n\nbeforeEach(() => {\n\teditor = new TestEditor()\n\teditor.selectAll().deleteShapes(editor.getSelectedShapeIds())\n\teditor.createShapes([\n\t\t{ id: ids.box1, type: 'geo', x: 100, y: 100, props: { w: 100, h: 100 } },\n\t\t{ id: ids.box2, type: 'geo', x: 300, y: 300, props: { w: 100, h: 100 } },\n\t])\n})\n\nafterEach(() => {\n\teditor?.dispose()\n})\n```\n\n### Reusable props\n\n```typescript\nconst imageProps = {\n\tassetId: null,\n\tplaying: true,\n\turl: '',\n\tw: 1200,\n\th: 800,\n}\n\neditor.createShapes([\n\t{ id: ids.imageA, type: 'image', x: 100, y: 100, props: imageProps },\n\t{ id: ids.imageB, type: 'image', x: 500, y: 500, props: { ...imageProps, w: 600, h: 400 } },\n])\n```\n\n### Helper functions\n\n```typescript\nfunction arrow(id = ids.arrow1) {\n\treturn editor.getShape(id) as TLArrowShape\n}\n\nfunction bindings(id = ids.arrow1) {\n\treturn getArrowBindings(editor, arrow(id))\n}\n```\n\n## Mocking with vi.spyOn\n\n```typescript\n// Mock return value\nvi.spyOn(editor, 'getIsReadonly').mockReturnValue(true)\n\n// Mock implementation\nconst isHiddenSpy = vi.spyOn(editor, 'isShapeHidden')\nisHiddenSpy.mockImplementation((shape) => shape.id === ids.hiddenShape)\n\n// Verify calls\nconst spy = vi.spyOn(editor, 'setSelectedShapes')\neditor.selectAll()\nexpect(spy).toHaveBeenCalled()\nexpect(spy).not.toHaveBeenCalled()\n\n// Always restore\nisHiddenSpy.mockRestore()\n```\n\n## Fake timers\n\n```typescript\nvi.useFakeTimers()\n\n// Mock animation frame\nwindow.requestAnimationFrame = (cb) => setTimeout(cb, 1000 / 60)\nwindow.cancelAnimationFrame = (id) => clearTimeout(id)\n\nit('handles animation', () => {\n\teditor.alignShapes(editor.getSelectedShapeIds(), 'right')\n\tvi.advanceTimersByTime(1000)\n\t// Assert after animation completes\n})\n```\n\n## Assertions\n\n### Shape matching\n\n```typescript\n// Partial matching (most common)\nexpect(editor.getShape(id)).toMatchObject({\n\ttype: 'geo',\n\tx: 100,\n\tprops: { w: 100 },\n})\n\neditor.expectShapeToMatch({\n\tid: ids.box1,\n\tx: 350,\n\ty: 350,\n})\n\n// Floating point matching (custom matcher)\nexpect(result).toCloselyMatchObject({\n\tprops: { normalizedAnchor: { x: 0.5, y: 0.75 } },\n})\n```\n\n### Array assertions\n\n```typescript\nexpect(editor.getSelectedShapeIds()).toMatchObject([ids.box1])\nexpect(Array.from(selectedIds).sort()).toEqual([id1, id2, id3].sort())\nexpect(shapes).toContain('geo')\nexpect(shapes).not.toContain(ids.lockedShape)\n```\n\n### State assertions\n\n```typescript\neditor.expectToBeIn('select.idle')\neditor.expectToBeIn('select.brushing')\neditor.expectToBeIn('select.crop.idle')\n```\n\n## Testing undo/redo\n\n```typescript\nit('handles undo/redo', () => {\n\teditor.doubleClick(550, 550, ids.image)\n\teditor.expectToBeIn('select.crop.idle')\n\n\teditor.updateShape({ id: ids.image, type: 'image', props: { crop: newCrop } })\n\n\teditor.undo()\n\teditor.expectToBeIn('select.crop.idle')\n\texpect(editor.getShape(ids.image)!.props.crop).toMatchObject(originalCrop)\n\n\teditor.redo()\n\texpect(editor.getShape(ids.image)!.props.crop).toMatchObject(newCrop)\n})\n```\n\n## Testing TypeScript types\n\n```typescript\nit('Uses typescript generics', () => {\n\texpect(() => {\n\t\t// @ts-expect-error - wrong props type\n\t\teditor.createShape({ id, type: 'geo', props: { w: 'OH NO' } })\n\n\t\t// @ts-expect-error - unknown prop\n\t\teditor.createShape({ id, type: 'geo', props: { foo: 'bar' } })\n\n\t\t// Valid\n\t\teditor.createShape<TLGeoShape>({ id, type: 'geo', props: { w: 100 } })\n\t}).toThrow()\n})\n```\n\n## Testing custom shapes\n\n```typescript\ndeclare module '@tldraw/tlschema' {\n\texport interface TLGlobalShapePropsMap {\n\t\t'my-custom-shape': { w: number; h: number; text: string | undefined }\n\t}\n}\n\nclass CustomShape extends ShapeUtil<ICustomShape> {\n\tstatic override type = 'my-custom-shape'\n\tstatic override props: RecordProps<ICustomShape> = {\n\t\tw: T.number,\n\t\th: T.number,\n\t\ttext: T.string.optional(),\n\t}\n\tgetDefaultProps() {\n\t\treturn { w: 200, h: 200, text: '' }\n\t}\n\tgetGeometry(shape) {\n\t\treturn new Rectangle2d({ width: shape.props.w, height: shape.props.h })\n\t}\n\tindicator() {}\n\tcomponent() {}\n}\n```\n\n## Testing side effects\n\n```typescript\nbeforeEach(() => {\n\teditor = new TestEditor()\n\teditor.sideEffects.registerAfterChangeHandler('instance_page_state', (prev, next) => {\n\t\tif (prev.croppingShapeId !== next.croppingShapeId) {\n\t\t\t// Handle state change\n\t\t}\n\t})\n})\n```\n\n## Testing events\n\n```typescript\nit('emits wheel events', () => {\n\tconst handler = vi.fn()\n\teditor.on('event', handler)\n\n\teditor.dispatch({\n\t\ttype: 'wheel',\n\t\tname: 'wheel',\n\t\tdelta: { x: 0, y: 10, z: 0 },\n\t\tpoint: { x: 100, y: 100, z: 1 },\n\t\tshiftKey: false,\n\t\t// ... other modifiers\n\t})\n\teditor.emit('tick', 16) // Flush batched events\n\n\texpect(handler).toHaveBeenCalledWith(expect.objectContaining({ name: 'wheel' }))\n})\n```\n\n## Method chaining\n\n```typescript\neditor\n\t.expectToBeIn('select.idle')\n\t.select(ids.imageA, ids.imageB)\n\t.doubleClick(550, 550, { target: 'selection', handle: 'bottom_right' })\n\t.expectToBeIn('select.idle')\n\neditor.setCurrentTool('arrow').pointerDown(0, 0).pointerMove(100, 100).pointerUp()\n```\n\n## Running tests\n\n```bash\ncd packages/tldraw && yarn test run\ncd packages/tldraw && yarn test run --grep \"arrow\"\ncd packages/editor && yarn test run --grep \"Vec\"\n\n# Watch mode\ncd packages/tldraw && yarn test\n```\n\n## Key patterns summary\n\n- Use `createShapeId()` for shape IDs\n- Use `vi.useFakeTimers()` for time-dependent behavior\n- Clear shapes in `beforeEach`, dispose in `afterEach`\n- Test in `packages/tldraw` for shapes/tools\n- Use `expectToBeIn()` for state machine assertions\n- Use `toMatchObject()` for partial matching\n- Use `toCloselyMatchObject()` for floating point values\n- Mock with `vi.spyOn()` and always `mockRestore()`\n"
      },
      "discovered_at": "2026-01-11T15:36:09.593416Z",
      "fetch_error": null
    },
    {
      "name": "write-docs",
      "slug": "write-docs",
      "source": "skillsmp_top",
      "owner": "tldraw",
      "repo_name": "tldraw",
      "repository_url": "https://github.com/tldraw/tldraw",
      "skill_path": ".claude/skills/write-docs",
      "github_metadata": {
        "stars": 44522,
        "description": "very good whiteboard infinite canvas SDK",
        "default_branch": "main",
        "pushed_at": "2026-01-10T14:48:37Z",
        "created_at": "2021-05-09T11:48:37Z",
        "language": "TypeScript",
        "license": "NOASSERTION",
        "open_issues": 335,
        "forks": 2926
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/write-docs/SKILL.md",
        "branch": "main",
        "content": "---\nname: write-docs\ndescription: Writing SDK documentation for tldraw. Use when creating new documentation articles, updating existing docs, or when documentation writing guidance is needed. Applies to docs in apps/docs/content/.\n---\n\n# Writing tldraw SDK documentation\n\n## The tldraw voice\n\nWrite like a colleague walking someone through code they know well. Confident, casual, code-first.\n\n**Characteristic patterns:**\n\n> Have five minutes? Run this command...\n\n> That's pretty much it!\n\n> Let's add local persistence by passing a `persistenceKey` prop...\n\n> Need to create some shapes? Use [Editor#createShapes](?). Need to delete them? Use [Editor#deleteShapes](?).\n\n**What makes it work:**\n\n- Direct address with \"you\" and \"let's\"\n- Questions as transitions (\"Need to create some shapes?\")\n- Exclamations that feel natural, not forced (\"That's pretty much it!\")\n- Jump straight to code, explain around it\n- Short sentences between code blocks\n\n### Confidence without hedging\n\nState facts. Don't soften them.\n\n```\n// Good\nThe Editor class is the main way of controlling tldraw's editor.\n\n// Bad\nThe Editor class can be used to control tldraw's editor.\n```\n\n### Density over exposition\n\nReal tldraw docs are code-heavy. A section might be 20 lines of code with 2 sentences of explanation. Don't pad with prose.\n\n## Avoid AI tells\n\nThese break trust instantly:\n\n- **Hollow claims**: \"plays a crucial role\", \"serves as a testament to\"\n- **Trailing gerunds**: \"...ensuring optimal performance\"\n- **Formulaic transitions**: \"Moreover,\", \"Furthermore,\", \"It's important to note\"\n- **Promotional language**: \"robust\", \"seamless\", \"empowers developers\"\n- **Three-item lists**: Real writing has 2, 4, 7 items\n- **Passive voice**: \"can be achieved by\" â€” just show how\n- **Conversational asides**: \"(or whatever)\", \"(if you want)\", \"(just saying)\"\n\n## Mechanics\n\n- **Sentence case headings**: \"Custom shapes\" not \"Custom Shapes\"\n- **Active voice**: \"The store validates records\"\n- **Present tense**: \"The migration system transforms\"\n- **Contractions**: it's, we've, you'll, don't\n\n## Frontmatter\n\n```yaml\n---\ntitle: Feature name\nstatus: published\nauthor: steveruizok\ndate: 3/22/2023\norder: 1\nkeywords:\n  - keyword1\n  - keyword2\n---\n```\n\n## MDX components\n\n### API links\n\nUse `[ClassName](?)` or `[ClassName#methodName](?)` for API references:\n\n```markdown\nThe [Editor](?) class has many methods. Use [Editor#createShapes](?) to create shapes.\n```\n\n### Code highlighting\n\nUse `<FocusLines>` to highlight specific lines:\n\n```markdown\n<FocusLines lines={[2,6,10]}>\n\n\\`\\`\\`tsx\nimport { Tldraw } from 'tldraw'\nimport { useSyncDemo } from '@tldraw/sync'\n\\`\\`\\`\n\n</FocusLines>\n```\n\n### Images\n\n```markdown\n<Image\n\tsrc=\"/images/api/events.png\"\n\talt=\"A diagram showing an event being sent to the editor.\"\n\ttitle=\"Caption text here.\"\n/>\n```\n\n### Tables for API documentation\n\nUse tables for listing methods, options, or properties:\n\n```markdown\n| Method                   | Description                                    |\n| ------------------------ | ---------------------------------------------- |\n| [Editor#screenToPage](?) | Convert a point in screen space to page space. |\n| [Editor#pageToScreen](?) | Convert a point in page space to screen space. |\n```\n\n```markdown\n| Value     | Description                                          |\n| --------- | ---------------------------------------------------- |\n| `default` | Sets the initial zoom to 100%.                       |\n| `fit-x`   | The x axis will completely fill the viewport bounds. |\n```\n\n## Code examples\n\nShow code early, explain around it. Don't build up to code with paragraphs of context.\n\n### Realistic, minimal\n\n```tsx\n// Good: Real shape, real values\neditor.createShapes([\n\t{\n\t\ttype: 'geo',\n\t\tx: 0,\n\t\ty: 0,\n\t\tprops: { geo: 'rectangle', w: 100, h: 100 },\n\t},\n])\n\n// Bad: Placeholder nonsense\neditor.createShape({ type: 'example-type', props: { prop1: 'value1' } })\n```\n\n### Context when needed\n\nFull components are fine when showing integration patterns:\n\n```tsx\nexport default function App() {\n\treturn (\n\t\t<div style={{ position: 'fixed', inset: 0 }}>\n\t\t\t<Tldraw persistenceKey=\"example\" />\n\t\t</div>\n\t)\n}\n```\n\nMinimal snippets when showing a single API:\n\n```tsx\neditor.setFocusedGroup(groupId)\n```\n\n## Structure\n\n### Overview first\n\n1-2 paragraphs establishing what and why before diving into how.\n\n### Progressive complexity\n\nStart with the common case. Add complexity incrementally. Put edge cases later.\n\n### Link to examples\n\nEnd sections with links to relevant examples:\n\n```markdown\n> For an example of how to create custom shapes, see our [custom shapes example](/examples/shapes/tools/custom-shape).\n```\n\nOr in a section:\n\n```markdown\n---\n\nSee the [tldraw repository](https://github.com/tldraw/tldraw/tree/main/apps/examples) for examples of how to use tldraw's Editor API.\n```\n\n## Priorities\n\n1. **Accuracy** â€” Code must work. API refs must be correct.\n2. **Clarity** â€” Understand on first read.\n3. **Brevity** â€” Say it once, move on.\n4. **Scannability** â€” Short paragraphs, clear headers, lots of code.\n"
      },
      "discovered_at": "2026-01-11T15:36:10.040917Z",
      "fetch_error": null
    },
    {
      "name": "write-pr",
      "slug": "write-pr",
      "source": "skillsmp_top",
      "owner": "tldraw",
      "repo_name": "tldraw",
      "repository_url": "https://github.com/tldraw/tldraw",
      "skill_path": ".claude/skills/write-pr",
      "github_metadata": {
        "stars": 44522,
        "description": "very good whiteboard infinite canvas SDK",
        "default_branch": "main",
        "pushed_at": "2026-01-10T14:48:37Z",
        "created_at": "2021-05-09T11:48:37Z",
        "language": "TypeScript",
        "license": "NOASSERTION",
        "open_issues": 335,
        "forks": 2926
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/write-pr/SKILL.md",
        "branch": "main",
        "content": "---\nname: write-pr\ndescription: Writing pull request titles and descriptions for the tldraw repository. Use when creating a new PR, updating an existing PR's title or body, or when the /pr command needs PR content guidance.\n---\n\n# Writing pull requests\n\nStandards for PR titles and descriptions in tldraw/tldraw.\n\n## PR title\n\nUse semantic PR titles (Conventional Commits format):\n\n```\n<type>(<scope>): <description>\n```\n\n### Types\n\n- `feat` - New feature\n- `fix` - Bug fix\n- `docs` - Documentation only\n- `refactor` - Code change that neither fixes a bug nor adds a feature\n- `perf` - Performance improvement\n- `test` - Adding or fixing tests\n- `chore` - Maintenance tasks\n\n### Scope (optional)\n\nA noun describing the affected area: `fix(editor):`, `feat(sync):`, `docs(examples):`\n\n### Examples\n\n- `feat(editor): add snap threshold configuration option`\n- `fix(arrows): correct binding behavior with rotated shapes`\n- `docs: update sync documentation`\n- `refactor(store): simplify migration system`\n\n## PR body\n\nUse this template:\n\n```md\n<description paragraph>\n\n### Change type\n\n- [x] `bugfix` | `improvement` | `feature` | `api` | `other`\n\n### Test plan\n\n1. Step to test...\n2. Another step...\n\n- [ ] Unit tests\n- [ ] End to end tests\n\n### Release notes\n\n- Brief description of changes for users\n```\n\n### Description paragraph\n\nStart with: \"In order to X, this PR does Y.\"\n\n- Keep it specific - avoid vague phrases like \"improve user experience\"\n- Link related issues in the first paragraph\n- Don't expect readers to also read the linked issue\n\n### Change type\n\n- Tick exactly one type with `[x]`\n- Delete unticked items\n\n### Test plan\n\n- List manual testing steps if applicable\n- Remove the numbered list if changes cannot be manually tested\n- Tick checkboxes for included test types\n\n### Release notes\n\n- Write brief notes describing user-facing changes\n- Use imperative mood: \"Add...\", \"Fix...\", \"Remove...\"\n- Omit this section entirely for internal work (CI, tooling, tests, etc.) that has no user-facing impact\n\n## API changes section\n\nInclude when changes affect `api-report.md`:\n\n```md\n### API changes\n\n- Added `Editor.newMethod()` for X\n- Breaking! Removed `Editor.oldMethod()`\n- Changed `Editor.method()` to accept optional `options` parameter\n```\n\n## Related issues\n\nSearch for and link relevant issues that this PR addresses.\n\n## Important\n\n- Never include \"Generated with Claude Code\" unless the PR directly relates to Claude Code\n- Never use title case for descriptions - use sentence case\n"
      },
      "discovered_at": "2026-01-11T15:36:10.604064Z",
      "fetch_error": null
    },
    {
      "name": "write-example",
      "slug": "write-example",
      "source": "skillsmp_top",
      "owner": "tldraw",
      "repo_name": "tldraw",
      "repository_url": "https://github.com/tldraw/tldraw",
      "skill_path": ".claude/skills/write-example",
      "github_metadata": {
        "stars": 44522,
        "description": "very good whiteboard infinite canvas SDK",
        "default_branch": "main",
        "pushed_at": "2026-01-10T14:48:37Z",
        "created_at": "2021-05-09T11:48:37Z",
        "language": "TypeScript",
        "license": "NOASSERTION",
        "open_issues": 335,
        "forks": 2926
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/write-example/SKILL.md",
        "branch": "main",
        "content": "---\nname: write-example\ndescription: Writing examples for the tldraw SDK examples app. Use when creating new examples, adding SDK demonstrations, or writing example code in apps/examples.\n---\n\n# Writing tldraw examples\n\nThe examples project (`apps/examples`) contains minimal demonstrations of how to use the tldraw SDK. Examples are embedded on the [docs site](https://tldraw.dev/examples) and deployed to [examples.tldraw.com](https://examples.tldraw.com).\n\nStandards for examples in `apps/examples/src/examples`.\n\n## Example structure\n\nEach example lives in its own folder:\n\n```\napps/examples/src/examples/\nâ””â”€â”€ my-example/\n    â”œâ”€â”€ README.md          # Required metadata\n    â”œâ”€â”€ MyExampleExample.tsx  # Main example file\n    â””â”€â”€ my-example.css     # Optional styles\n```\n\n## Folder name\n\n- Lowercase kebab-case: `custom-canvas`, `button-demo`, `magical-wand`\n- Used as the URL path for the example\n\n## README.md\n\nRequired frontmatter format:\n\n```md\n---\ntitle: Example title\ncomponent: ./ExampleFile.tsx\ncategory: category-id\npriority: 1\nkeywords: [keyword1, keyword2]\n---\n\nOne-line summary of what this example demonstrates.\n\n---\n\nDetailed explanation of the example. Include code snippets here if they help explain concepts not obvious from the example code itself.\n```\n\n### Frontmatter fields\n\n| Field     | Description                                      |\n| --------- | ------------------------------------------------ |\n| title     | Sentence case, corresponds to folder name        |\n| component | Relative path to example file                    |\n| category  | One of the valid category IDs (see below)        |\n| priority  | Display order within category (lower = higher)   |\n| keywords  | Search terms (avoid obvious terms like \"tldraw\") |\n\n### Valid categories\n\n`getting-started`, `configuration`, `editor-api`, `ui`, `layout`, `events`, `shapes/tools`, `collaboration`, `data/assets`, `use-cases`\n\n## Example file\n\n### Naming\n\n- PascalCase ending with \"Example\": `CustomCanvasExample.tsx`, `ButtonExample.tsx`\n- Name should correspond to the folder name and title\n\n### Structure\n\n```tsx\nimport { Tldraw } from 'tldraw'\nimport 'tldraw/tldraw.css'\n\nexport default function MyExampleExample() {\n\treturn (\n\t\t<div className=\"tldraw__editor\">\n\t\t\t<Tldraw />\n\t\t</div>\n\t)\n}\n```\n\n**Requirements:**\n\n- Must have a default export React component\n- Use `tldraw__editor` class for full-page examples\n- Import `tldraw/tldraw.css` for styles\n\n### Layout\n\n- Full page: wrap in `<div className=\"tldraw__editor\">`\n- Inset: see existing examples for page layout patterns\n\n## Styles\n\n- Put CSS in a separate file named after the example: `my-example.css`\n- Import alongside tldraw CSS: `import './my-example.css'`\n- Avoid extensive inline styles via the `style` prop\n\n## Control panels\n\nFor examples that need buttons or controls, use the `TopPanel` component slot with `TldrawUiButton`:\n\n```tsx\nimport { Tldraw, TldrawUiButton, useEditor } from 'tldraw'\nimport 'tldraw/tldraw.css'\nimport './my-example.css'\n\nfunction MyControls() {\n\tconst editor = useEditor()\n\treturn (\n\t\t<div className=\"tlui-menu my-controls\">\n\t\t\t<TldrawUiButton type=\"normal\" onClick={() => editor.zoomIn()}>\n\t\t\t\tZoom in\n\t\t\t</TldrawUiButton>\n\t\t\t<TldrawUiButton type=\"normal\" onClick={() => editor.zoomOut()}>\n\t\t\t\tZoom out\n\t\t\t</TldrawUiButton>\n\t\t</div>\n\t)\n}\n\nexport default function MyExampleExample() {\n\treturn (\n\t\t<div className=\"tldraw__editor\">\n\t\t\t<Tldraw components={{ TopPanel: MyControls }} />\n\t\t</div>\n\t)\n}\n```\n\nCSS for control panels:\n\n```css\n.my-controls {\n\tdisplay: flex;\n\tflex-wrap: wrap;\n\tmargin: 8px;\n}\n```\n\n## Comments\n\nUse footnote format with numbered references:\n\n```tsx\nimport { Tldraw, type TLComponents } from 'tldraw'\nimport 'tldraw/tldraw.css'\n\n// [1]\nconst components: TLComponents = {\n\tPageMenu: null,\n}\n\nexport default function CustomComponentsExample() {\n\treturn (\n\t\t<div className=\"tldraw__editor\">\n\t\t\t{/* [2] */}\n\t\t\t<Tldraw components={components} />\n\t\t</div>\n\t)\n}\n\n/*\n[1]\nDefine component overrides outside the React component so they're static.\nIf defined inside, use useMemo to prevent recreation on every render.\n\n[2]\nPass component overrides via the components prop.\n*/\n```\n\n## Example types\n\n### Tight examples\n\n- Narrow focus on a specific SDK feature\n- Minimal styling\n- Meant to be read, not used\n- Remove any extraneous code\n\n### Use-case examples\n\n- Show a recognizable user experience\n- Prioritize clarity and completeness\n- Category: `use-cases`\n\n## Additional files\n\n- Split complex code into separate files if it distracts from the example's purpose\n- Example: complex input component in `Input.tsx`\n- Keep the main example file focused on demonstrating the concept\n\n## Important\n\n- Follow React and TypeScript best practices\n- Never use title case for titles - use sentence case\n- Keep examples minimal and focused\n"
      },
      "discovered_at": "2026-01-11T15:36:11.117845Z",
      "fetch_error": null
    },
    {
      "name": "write-issue",
      "slug": "write-issue",
      "source": "skillsmp_top",
      "owner": "tldraw",
      "repo_name": "tldraw",
      "repository_url": "https://github.com/tldraw/tldraw",
      "skill_path": ".claude/skills/write-issue",
      "github_metadata": {
        "stars": 44522,
        "description": "very good whiteboard infinite canvas SDK",
        "default_branch": "main",
        "pushed_at": "2026-01-10T14:48:37Z",
        "created_at": "2021-05-09T11:48:37Z",
        "language": "TypeScript",
        "license": "NOASSERTION",
        "open_issues": 335,
        "forks": 2926
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/write-issue/SKILL.md",
        "branch": "main",
        "content": "---\nname: write-issue\ndescription: Writing and maintaining GitHub issues for the tldraw repository. Use when creating new issues, editing issue titles/bodies, triaging issues, or cleaning up issue metadata (types, labels).\n---\n\n# Writing and maintaining GitHub issues\n\nStandards for issues in tldraw/tldraw.\n\n## Title standards\n\n- **Sentence case** - Capitalize only the first word and proper nouns\n- **No type prefixes** - Use GitHub issue types, not `Bug:`, `Feature:`, `[Bug]`, etc.\n- **Imperative mood for enhancements** - \"Add padding option\" not \"Adding padding option\"\n- **Descriptive for bugs** - Describe the symptom: \"Arrow bindings break with rotated shapes\"\n- **Specific** - Readable without opening the issue body\n\n### Good titles\n\n- `Arrow bindings break with rotated shapes`\n- `Add padding option to zoomToFit method`\n- `Pinch zoom resets selection on Safari`\n\n### Bad titles\n\n- `Bug: arrow bug` (prefix, vague)\n- `[Feature] Add new feature` (prefix, vague)\n- `Not working` (vague)\n\n### Title cleanup transformations\n\n1. Remove prefixes: `Bug: X` â†’ `X`\n2. Fix capitalization: `Add Padding Option` â†’ `Add padding option`\n3. Use imperative: `Adding feature X` â†’ `Add feature X`\n4. Be specific: `Problem` â†’ `[Describe the actual problem]`\n5. Translate non-English titles to English\n\n## Issue types\n\nSet via the GitHub GraphQL API after creating the issue (the `--type` flag is not reliably supported):\n\n| Type      | Use for                             |\n| --------- | ----------------------------------- |\n| `Bug`     | Something isn't working as expected |\n| `Feature` | New capability or improvement       |\n| `Example` | Request for a new SDK example       |\n| `Task`    | Internal task or chore              |\n\n## Labels\n\nUse sparingly (1-2 per issue) for metadata, not categorization.\n\n### Common labels\n\n| Label              | Use for                          |\n| ------------------ | -------------------------------- |\n| `good first issue` | Well-scoped issues for newcomers |\n| `More Info Needed` | Requires additional information  |\n| `sdk`              | Affects the tldraw SDK           |\n| `dotcom`           | Related to tldraw.com            |\n| `a11y`             | Accessibility                    |\n| `performance`      | Performance improvement          |\n| `api`              | API change                       |\n\n### Automation labels (do not apply manually)\n\n`keep`, `stale`, `update-snapshots`, `publish-packages`, `major`, `minor`, `skip-release`, deploy triggers\n\n## Issue body standards\n\n### Bug reports\n\n1. Clear description of what's wrong\n2. Steps to reproduce\n3. Expected vs actual behavior\n4. Environment details (browser, OS, version) when relevant\n5. Screenshots/recordings when applicable\n\n### Feature requests\n\n1. Problem statement - What problem does this solve?\n2. Proposed solution - How should it work?\n3. Alternatives considered\n4. Use cases\n\n### Example requests\n\n1. What API/pattern to demonstrate\n2. Why it's useful\n3. Suggested approach\n4. Which example category it belongs to\n\n## Triage workflow\n\n### New issues\n\n1. Verify sufficient information to act on\n2. Set appropriate issue type\n3. Clean up title if needed\n4. Add `More Info Needed` label and comment if details missing\n5. Add `good first issue` if appropriate\n\n### Stale issues\n\n1. Review if still relevant\n2. Close if no longer applicable\n3. Add `keep` label if should remain open\n4. Request updates if waiting on information\n\n## Important\n\n- Never include \"Generated with Claude Code\" unless the PR directly relates to Claude Code\n- Never use title case for descriptions - use sentence case\n"
      },
      "discovered_at": "2026-01-11T15:36:11.513754Z",
      "fetch_error": null
    },
    {
      "name": "algorithmic-art",
      "slug": "algorithmic-art",
      "source": "anthropic_official",
      "owner": "anthropics",
      "repo_name": "skills",
      "repository_url": "https://github.com/anthropics/skills",
      "skill_path": "skills/algorithmic-art",
      "github_metadata": {
        "stars": 37534,
        "description": "Public repository for Agent Skills",
        "default_branch": "main",
        "pushed_at": "2025-12-20T18:09:45Z",
        "created_at": "2025-09-22T15:53:31Z",
        "language": "Python",
        "license": null,
        "open_issues": 137,
        "forks": 3406
      },
      "skill_md": {
        "found": true,
        "path": "skills/algorithmic-art/SKILL.md",
        "branch": "main",
        "content": "---\nname: algorithmic-art\ndescription: Creating algorithmic art using p5.js with seeded randomness and interactive parameter exploration. Use this when users request creating art using code, generative art, algorithmic art, flow fields, or particle systems. Create original algorithmic art rather than copying existing artists' work to avoid copyright violations.\nlicense: Complete terms in LICENSE.txt\n---\n\nAlgorithmic philosophies are computational aesthetic movements that are then expressed through code. Output .md files (philosophy), .html files (interactive viewer), and .js files (generative algorithms).\n\nThis happens in two steps:\n1. Algorithmic Philosophy Creation (.md file)\n2. Express by creating p5.js generative art (.html + .js files)\n\nFirst, undertake this task:\n\n## ALGORITHMIC PHILOSOPHY CREATION\n\nTo begin, create an ALGORITHMIC PHILOSOPHY (not static images or templates) that will be interpreted through:\n- Computational processes, emergent behavior, mathematical beauty\n- Seeded randomness, noise fields, organic systems\n- Particles, flows, fields, forces\n- Parametric variation and controlled chaos\n\n### THE CRITICAL UNDERSTANDING\n- What is received: Some subtle input or instructions by the user to take into account, but use as a foundation; it should not constrain creative freedom.\n- What is created: An algorithmic philosophy/generative aesthetic movement.\n- What happens next: The same version receives the philosophy and EXPRESSES IT IN CODE - creating p5.js sketches that are 90% algorithmic generation, 10% essential parameters.\n\nConsider this approach:\n- Write a manifesto for a generative art movement\n- The next phase involves writing the algorithm that brings it to life\n\nThe philosophy must emphasize: Algorithmic expression. Emergent behavior. Computational beauty. Seeded variation.\n\n### HOW TO GENERATE AN ALGORITHMIC PHILOSOPHY\n\n**Name the movement** (1-2 words): \"Organic Turbulence\" / \"Quantum Harmonics\" / \"Emergent Stillness\"\n\n**Articulate the philosophy** (4-6 paragraphs - concise but complete):\n\nTo capture the ALGORITHMIC essence, express how this philosophy manifests through:\n- Computational processes and mathematical relationships?\n- Noise functions and randomness patterns?\n- Particle behaviors and field dynamics?\n- Temporal evolution and system states?\n- Parametric variation and emergent complexity?\n\n**CRITICAL GUIDELINES:**\n- **Avoid redundancy**: Each algorithmic aspect should be mentioned once. Avoid repeating concepts about noise theory, particle dynamics, or mathematical principles unless adding new depth.\n- **Emphasize craftsmanship REPEATEDLY**: The philosophy MUST stress multiple times that the final algorithm should appear as though it took countless hours to develop, was refined with care, and comes from someone at the absolute top of their field. This framing is essential - repeat phrases like \"meticulously crafted algorithm,\" \"the product of deep computational expertise,\" \"painstaking optimization,\" \"master-level implementation.\"\n- **Leave creative space**: Be specific about the algorithmic direction, but concise enough that the next Claude has room to make interpretive implementation choices at an extremely high level of craftsmanship.\n\nThe philosophy must guide the next version to express ideas ALGORITHMICALLY, not through static images. Beauty lives in the process, not the final frame.\n\n### PHILOSOPHY EXAMPLES\n\n**\"Organic Turbulence\"**\nPhilosophy: Chaos constrained by natural law, order emerging from disorder.\nAlgorithmic expression: Flow fields driven by layered Perlin noise. Thousands of particles following vector forces, their trails accumulating into organic density maps. Multiple noise octaves create turbulent regions and calm zones. Color emerges from velocity and density - fast particles burn bright, slow ones fade to shadow. The algorithm runs until equilibrium - a meticulously tuned balance where every parameter was refined through countless iterations by a master of computational aesthetics.\n\n**\"Quantum Harmonics\"**\nPhilosophy: Discrete entities exhibiting wave-like interference patterns.\nAlgorithmic expression: Particles initialized on a grid, each carrying a phase value that evolves through sine waves. When particles are near, their phases interfere - constructive interference creates bright nodes, destructive creates voids. Simple harmonic motion generates complex emergent mandalas. The result of painstaking frequency calibration where every ratio was carefully chosen to produce resonant beauty.\n\n**\"Recursive Whispers\"**\nPhilosophy: Self-similarity across scales, infinite depth in finite space.\nAlgorithmic expression: Branching structures that subdivide recursively. Each branch slightly randomized but constrained by golden ratios. L-systems or recursive subdivision generate tree-like forms that feel both mathematical and organic. Subtle noise perturbations break perfect symmetry. Line weights diminish with each recursion level. Every branching angle the product of deep mathematical exploration.\n\n**\"Field Dynamics\"**\nPhilosophy: Invisible forces made visible through their effects on matter.\nAlgorithmic expression: Vector fields constructed from mathematical functions or noise. Particles born at edges, flowing along field lines, dying when they reach equilibrium or boundaries. Multiple fields can attract, repel, or rotate particles. The visualization shows only the traces - ghost-like evidence of invisible forces. A computational dance meticulously choreographed through force balance.\n\n**\"Stochastic Crystallization\"**\nPhilosophy: Random processes crystallizing into ordered structures.\nAlgorithmic expression: Randomized circle packing or Voronoi tessellation. Start with random points, let them evolve through relaxation algorithms. Cells push apart until equilibrium. Color based on cell size, neighbor count, or distance from center. The organic tiling that emerges feels both random and inevitable. Every seed produces unique crystalline beauty - the mark of a master-level generative algorithm.\n\n*These are condensed examples. The actual algorithmic philosophy should be 4-6 substantial paragraphs.*\n\n### ESSENTIAL PRINCIPLES\n- **ALGORITHMIC PHILOSOPHY**: Creating a computational worldview to be expressed through code\n- **PROCESS OVER PRODUCT**: Always emphasize that beauty emerges from the algorithm's execution - each run is unique\n- **PARAMETRIC EXPRESSION**: Ideas communicate through mathematical relationships, forces, behaviors - not static composition\n- **ARTISTIC FREEDOM**: The next Claude interprets the philosophy algorithmically - provide creative implementation room\n- **PURE GENERATIVE ART**: This is about making LIVING ALGORITHMS, not static images with randomness\n- **EXPERT CRAFTSMANSHIP**: Repeatedly emphasize the final algorithm must feel meticulously crafted, refined through countless iterations, the product of deep expertise by someone at the absolute top of their field in computational aesthetics\n\n**The algorithmic philosophy should be 4-6 paragraphs long.** Fill it with poetic computational philosophy that brings together the intended vision. Avoid repeating the same points. Output this algorithmic philosophy as a .md file.\n\n---\n\n## DEDUCING THE CONCEPTUAL SEED\n\n**CRITICAL STEP**: Before implementing the algorithm, identify the subtle conceptual thread from the original request.\n\n**THE ESSENTIAL PRINCIPLE**:\nThe concept is a **subtle, niche reference embedded within the algorithm itself** - not always literal, always sophisticated. Someone familiar with the subject should feel it intuitively, while others simply experience a masterful generative composition. The algorithmic philosophy provides the computational language. The deduced concept provides the soul - the quiet conceptual DNA woven invisibly into parameters, behaviors, and emergence patterns.\n\nThis is **VERY IMPORTANT**: The reference must be so refined that it enhances the work's depth without announcing itself. Think like a jazz musician quoting another song through algorithmic harmony - only those who know will catch it, but everyone appreciates the generative beauty.\n\n---\n\n## P5.JS IMPLEMENTATION\n\nWith the philosophy AND conceptual framework established, express it through code. Pause to gather thoughts before proceeding. Use only the algorithmic philosophy created and the instructions below.\n\n### âš ï¸ STEP 0: READ THE TEMPLATE FIRST âš ï¸\n\n**CRITICAL: BEFORE writing any HTML:**\n\n1. **Read** `templates/viewer.html` using the Read tool\n2. **Study** the exact structure, styling, and Anthropic branding\n3. **Use that file as the LITERAL STARTING POINT** - not just inspiration\n4. **Keep all FIXED sections exactly as shown** (header, sidebar structure, Anthropic colors/fonts, seed controls, action buttons)\n5. **Replace only the VARIABLE sections** marked in the file's comments (algorithm, parameters, UI controls for parameters)\n\n**Avoid:**\n- âŒ Creating HTML from scratch\n- âŒ Inventing custom styling or color schemes\n- âŒ Using system fonts or dark themes\n- âŒ Changing the sidebar structure\n\n**Follow these practices:**\n- âœ… Copy the template's exact HTML structure\n- âœ… Keep Anthropic branding (Poppins/Lora fonts, light colors, gradient backdrop)\n- âœ… Maintain the sidebar layout (Seed â†’ Parameters â†’ Colors? â†’ Actions)\n- âœ… Replace only the p5.js algorithm and parameter controls\n\nThe template is the foundation. Build on it, don't rebuild it.\n\n---\n\nTo create gallery-quality computational art that lives and breathes, use the algorithmic philosophy as the foundation.\n\n### TECHNICAL REQUIREMENTS\n\n**Seeded Randomness (Art Blocks Pattern)**:\n```javascript\n// ALWAYS use a seed for reproducibility\nlet seed = 12345; // or hash from user input\nrandomSeed(seed);\nnoiseSeed(seed);\n```\n\n**Parameter Structure - FOLLOW THE PHILOSOPHY**:\n\nTo establish parameters that emerge naturally from the algorithmic philosophy, consider: \"What qualities of this system can be adjusted?\"\n\n```javascript\nlet params = {\n  seed: 12345,  // Always include seed for reproducibility\n  // colors\n  // Add parameters that control YOUR algorithm:\n  // - Quantities (how many?)\n  // - Scales (how big? how fast?)\n  // - Probabilities (how likely?)\n  // - Ratios (what proportions?)\n  // - Angles (what direction?)\n  // - Thresholds (when does behavior change?)\n};\n```\n\n**To design effective parameters, focus on the properties the system needs to be tunable rather than thinking in terms of \"pattern types\".**\n\n**Core Algorithm - EXPRESS THE PHILOSOPHY**:\n\n**CRITICAL**: The algorithmic philosophy should dictate what to build.\n\nTo express the philosophy through code, avoid thinking \"which pattern should I use?\" and instead think \"how to express this philosophy through code?\"\n\nIf the philosophy is about **organic emergence**, consider using:\n- Elements that accumulate or grow over time\n- Random processes constrained by natural rules\n- Feedback loops and interactions\n\nIf the philosophy is about **mathematical beauty**, consider using:\n- Geometric relationships and ratios\n- Trigonometric functions and harmonics\n- Precise calculations creating unexpected patterns\n\nIf the philosophy is about **controlled chaos**, consider using:\n- Random variation within strict boundaries\n- Bifurcation and phase transitions\n- Order emerging from disorder\n\n**The algorithm flows from the philosophy, not from a menu of options.**\n\nTo guide the implementation, let the conceptual essence inform creative and original choices. Build something that expresses the vision for this particular request.\n\n**Canvas Setup**: Standard p5.js structure:\n```javascript\nfunction setup() {\n  createCanvas(1200, 1200);\n  // Initialize your system\n}\n\nfunction draw() {\n  // Your generative algorithm\n  // Can be static (noLoop) or animated\n}\n```\n\n### CRAFTSMANSHIP REQUIREMENTS\n\n**CRITICAL**: To achieve mastery, create algorithms that feel like they emerged through countless iterations by a master generative artist. Tune every parameter carefully. Ensure every pattern emerges with purpose. This is NOT random noise - this is CONTROLLED CHAOS refined through deep expertise.\n\n- **Balance**: Complexity without visual noise, order without rigidity\n- **Color Harmony**: Thoughtful palettes, not random RGB values\n- **Composition**: Even in randomness, maintain visual hierarchy and flow\n- **Performance**: Smooth execution, optimized for real-time if animated\n- **Reproducibility**: Same seed ALWAYS produces identical output\n\n### OUTPUT FORMAT\n\nOutput:\n1. **Algorithmic Philosophy** - As markdown or text explaining the generative aesthetic\n2. **Single HTML Artifact** - Self-contained interactive generative art built from `templates/viewer.html` (see STEP 0 and next section)\n\nThe HTML artifact contains everything: p5.js (from CDN), the algorithm, parameter controls, and UI - all in one file that works immediately in claude.ai artifacts or any browser. Start from the template file, not from scratch.\n\n---\n\n## INTERACTIVE ARTIFACT CREATION\n\n**REMINDER: `templates/viewer.html` should have already been read (see STEP 0). Use that file as the starting point.**\n\nTo allow exploration of the generative art, create a single, self-contained HTML artifact. Ensure this artifact works immediately in claude.ai or any browser - no setup required. Embed everything inline.\n\n### CRITICAL: WHAT'S FIXED VS VARIABLE\n\nThe `templates/viewer.html` file is the foundation. It contains the exact structure and styling needed.\n\n**FIXED (always include exactly as shown):**\n- Layout structure (header, sidebar, main canvas area)\n- Anthropic branding (UI colors, fonts, gradients)\n- Seed section in sidebar:\n  - Seed display\n  - Previous/Next buttons\n  - Random button\n  - Jump to seed input + Go button\n- Actions section in sidebar:\n  - Regenerate button\n  - Reset button\n\n**VARIABLE (customize for each artwork):**\n- The entire p5.js algorithm (setup/draw/classes)\n- The parameters object (define what the art needs)\n- The Parameters section in sidebar:\n  - Number of parameter controls\n  - Parameter names\n  - Min/max/step values for sliders\n  - Control types (sliders, inputs, etc.)\n- Colors section (optional):\n  - Some art needs color pickers\n  - Some art might use fixed colors\n  - Some art might be monochrome (no color controls needed)\n  - Decide based on the art's needs\n\n**Every artwork should have unique parameters and algorithm!** The fixed parts provide consistent UX - everything else expresses the unique vision.\n\n### REQUIRED FEATURES\n\n**1. Parameter Controls**\n- Sliders for numeric parameters (particle count, noise scale, speed, etc.)\n- Color pickers for palette colors\n- Real-time updates when parameters change\n- Reset button to restore defaults\n\n**2. Seed Navigation**\n- Display current seed number\n- \"Previous\" and \"Next\" buttons to cycle through seeds\n- \"Random\" button for random seed\n- Input field to jump to specific seed\n- Generate 100 variations when requested (seeds 1-100)\n\n**3. Single Artifact Structure**\n```html\n<!DOCTYPE html>\n<html>\n<head>\n  <!-- p5.js from CDN - always available -->\n  <script src=\"https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.7.0/p5.min.js\"></script>\n  <style>\n    /* All styling inline - clean, minimal */\n    /* Canvas on top, controls below */\n  </style>\n</head>\n<body>\n  <div id=\"canvas-container\"></div>\n  <div id=\"controls\">\n    <!-- All parameter controls -->\n  </div>\n  <script>\n    // ALL p5.js code inline here\n    // Parameter objects, classes, functions\n    // setup() and draw()\n    // UI handlers\n    // Everything self-contained\n  </script>\n</body>\n</html>\n```\n\n**CRITICAL**: This is a single artifact. No external files, no imports (except p5.js CDN). Everything inline.\n\n**4. Implementation Details - BUILD THE SIDEBAR**\n\nThe sidebar structure:\n\n**1. Seed (FIXED)** - Always include exactly as shown:\n- Seed display\n- Prev/Next/Random/Jump buttons\n\n**2. Parameters (VARIABLE)** - Create controls for the art:\n```html\n<div class=\"control-group\">\n    <label>Parameter Name</label>\n    <input type=\"range\" id=\"param\" min=\"...\" max=\"...\" step=\"...\" value=\"...\" oninput=\"updateParam('param', this.value)\">\n    <span class=\"value-display\" id=\"param-value\">...</span>\n</div>\n```\nAdd as many control-group divs as there are parameters.\n\n**3. Colors (OPTIONAL/VARIABLE)** - Include if the art needs adjustable colors:\n- Add color pickers if users should control palette\n- Skip this section if the art uses fixed colors\n- Skip if the art is monochrome\n\n**4. Actions (FIXED)** - Always include exactly as shown:\n- Regenerate button\n- Reset button\n- Download PNG button\n\n**Requirements**:\n- Seed controls must work (prev/next/random/jump/display)\n- All parameters must have UI controls\n- Regenerate, Reset, Download buttons must work\n- Keep Anthropic branding (UI styling, not art colors)\n\n### USING THE ARTIFACT\n\nThe HTML artifact works immediately:\n1. **In claude.ai**: Displayed as an interactive artifact - runs instantly\n2. **As a file**: Save and open in any browser - no server needed\n3. **Sharing**: Send the HTML file - it's completely self-contained\n\n---\n\n## VARIATIONS & EXPLORATION\n\nThe artifact includes seed navigation by default (prev/next/random buttons), allowing users to explore variations without creating multiple files. If the user wants specific variations highlighted:\n\n- Include seed presets (buttons for \"Variation 1: Seed 42\", \"Variation 2: Seed 127\", etc.)\n- Add a \"Gallery Mode\" that shows thumbnails of multiple seeds side-by-side\n- All within the same single artifact\n\nThis is like creating a series of prints from the same plate - the algorithm is consistent, but each seed reveals different facets of its potential. The interactive nature means users discover their own favorites by exploring the seed space.\n\n---\n\n## THE CREATIVE PROCESS\n\n**User request** â†’ **Algorithmic philosophy** â†’ **Implementation**\n\nEach request is unique. The process involves:\n\n1. **Interpret the user's intent** - What aesthetic is being sought?\n2. **Create an algorithmic philosophy** (4-6 paragraphs) describing the computational approach\n3. **Implement it in code** - Build the algorithm that expresses this philosophy\n4. **Design appropriate parameters** - What should be tunable?\n5. **Build matching UI controls** - Sliders/inputs for those parameters\n\n**The constants**:\n- Anthropic branding (colors, fonts, layout)\n- Seed navigation (always present)\n- Self-contained HTML artifact\n\n**Everything else is variable**:\n- The algorithm itself\n- The parameters\n- The UI controls\n- The visual outcome\n\nTo achieve the best results, trust creativity and let the philosophy guide the implementation.\n\n---\n\n## RESOURCES\n\nThis skill includes helpful templates and documentation:\n\n- **templates/viewer.html**: REQUIRED STARTING POINT for all HTML artifacts.\n  - This is the foundation - contains the exact structure and Anthropic branding\n  - **Keep unchanged**: Layout structure, sidebar organization, Anthropic colors/fonts, seed controls, action buttons\n  - **Replace**: The p5.js algorithm, parameter definitions, and UI controls in Parameters section\n  - The extensive comments in the file mark exactly what to keep vs replace\n\n- **templates/generator_template.js**: Reference for p5.js best practices and code structure principles.\n  - Shows how to organize parameters, use seeded randomness, structure classes\n  - NOT a pattern menu - use these principles to build unique algorithms\n  - Embed algorithms inline in the HTML artifact (don't create separate .js files)\n\n**Critical reminder**:\n- The **template is the STARTING POINT**, not inspiration\n- The **algorithm is where to create** something unique\n- Don't copy the flow field example - build what the philosophy demands\n- But DO keep the exact UI structure and Anthropic branding from the template"
      },
      "discovered_at": "2026-01-11T15:36:37.841354Z",
      "fetch_error": null
    },
    {
      "name": "brand-guidelines",
      "slug": "brand-guidelines",
      "source": "anthropic_official",
      "owner": "anthropics",
      "repo_name": "skills",
      "repository_url": "https://github.com/anthropics/skills",
      "skill_path": "skills/brand-guidelines",
      "github_metadata": {
        "stars": 37534,
        "description": "Public repository for Agent Skills",
        "default_branch": "main",
        "pushed_at": "2025-12-20T18:09:45Z",
        "created_at": "2025-09-22T15:53:31Z",
        "language": "Python",
        "license": null,
        "open_issues": 137,
        "forks": 3406
      },
      "skill_md": {
        "found": true,
        "path": "skills/brand-guidelines/SKILL.md",
        "branch": "main",
        "content": "---\nname: brand-guidelines\ndescription: Applies Anthropic's official brand colors and typography to any sort of artifact that may benefit from having Anthropic's look-and-feel. Use it when brand colors or style guidelines, visual formatting, or company design standards apply.\nlicense: Complete terms in LICENSE.txt\n---\n\n# Anthropic Brand Styling\n\n## Overview\n\nTo access Anthropic's official brand identity and style resources, use this skill.\n\n**Keywords**: branding, corporate identity, visual identity, post-processing, styling, brand colors, typography, Anthropic brand, visual formatting, visual design\n\n## Brand Guidelines\n\n### Colors\n\n**Main Colors:**\n\n- Dark: `#141413` - Primary text and dark backgrounds\n- Light: `#faf9f5` - Light backgrounds and text on dark\n- Mid Gray: `#b0aea5` - Secondary elements\n- Light Gray: `#e8e6dc` - Subtle backgrounds\n\n**Accent Colors:**\n\n- Orange: `#d97757` - Primary accent\n- Blue: `#6a9bcc` - Secondary accent\n- Green: `#788c5d` - Tertiary accent\n\n### Typography\n\n- **Headings**: Poppins (with Arial fallback)\n- **Body Text**: Lora (with Georgia fallback)\n- **Note**: Fonts should be pre-installed in your environment for best results\n\n## Features\n\n### Smart Font Application\n\n- Applies Poppins font to headings (24pt and larger)\n- Applies Lora font to body text\n- Automatically falls back to Arial/Georgia if custom fonts unavailable\n- Preserves readability across all systems\n\n### Text Styling\n\n- Headings (24pt+): Poppins font\n- Body text: Lora font\n- Smart color selection based on background\n- Preserves text hierarchy and formatting\n\n### Shape and Accent Colors\n\n- Non-text shapes use accent colors\n- Cycles through orange, blue, and green accents\n- Maintains visual interest while staying on-brand\n\n## Technical Details\n\n### Font Management\n\n- Uses system-installed Poppins and Lora fonts when available\n- Provides automatic fallback to Arial (headings) and Georgia (body)\n- No font installation required - works with existing system fonts\n- For best results, pre-install Poppins and Lora fonts in your environment\n\n### Color Application\n\n- Uses RGB color values for precise brand matching\n- Applied via python-pptx's RGBColor class\n- Maintains color fidelity across different systems\n"
      },
      "discovered_at": "2026-01-11T15:36:37.993481Z",
      "fetch_error": null
    },
    {
      "name": "canvas-design",
      "slug": "canvas-design",
      "source": "anthropic_official",
      "owner": "anthropics",
      "repo_name": "skills",
      "repository_url": "https://github.com/anthropics/skills",
      "skill_path": "skills/canvas-design",
      "github_metadata": {
        "stars": 37534,
        "description": "Public repository for Agent Skills",
        "default_branch": "main",
        "pushed_at": "2025-12-20T18:09:45Z",
        "created_at": "2025-09-22T15:53:31Z",
        "language": "Python",
        "license": null,
        "open_issues": 137,
        "forks": 3406
      },
      "skill_md": {
        "found": true,
        "path": "skills/canvas-design/SKILL.md",
        "branch": "main",
        "content": "---\nname: canvas-design\ndescription: Create beautiful visual art in .png and .pdf documents using design philosophy. You should use this skill when the user asks to create a poster, piece of art, design, or other static piece. Create original visual designs, never copying existing artists' work to avoid copyright violations.\nlicense: Complete terms in LICENSE.txt\n---\n\nThese are instructions for creating design philosophies - aesthetic movements that are then EXPRESSED VISUALLY. Output only .md files, .pdf files, and .png files.\n\nComplete this in two steps:\n1. Design Philosophy Creation (.md file)\n2. Express by creating it on a canvas (.pdf file or .png file)\n\nFirst, undertake this task:\n\n## DESIGN PHILOSOPHY CREATION\n\nTo begin, create a VISUAL PHILOSOPHY (not layouts or templates) that will be interpreted through:\n- Form, space, color, composition\n- Images, graphics, shapes, patterns\n- Minimal text as visual accent\n\n### THE CRITICAL UNDERSTANDING\n- What is received: Some subtle input or instructions by the user that should be taken into account, but used as a foundation; it should not constrain creative freedom.\n- What is created: A design philosophy/aesthetic movement.\n- What happens next: Then, the same version receives the philosophy and EXPRESSES IT VISUALLY - creating artifacts that are 90% visual design, 10% essential text.\n\nConsider this approach:\n- Write a manifesto for an art movement\n- The next phase involves making the artwork\n\nThe philosophy must emphasize: Visual expression. Spatial communication. Artistic interpretation. Minimal words.\n\n### HOW TO GENERATE A VISUAL PHILOSOPHY\n\n**Name the movement** (1-2 words): \"Brutalist Joy\" / \"Chromatic Silence\" / \"Metabolist Dreams\"\n\n**Articulate the philosophy** (4-6 paragraphs - concise but complete):\n\nTo capture the VISUAL essence, express how the philosophy manifests through:\n- Space and form\n- Color and material\n- Scale and rhythm\n- Composition and balance\n- Visual hierarchy\n\n**CRITICAL GUIDELINES:**\n- **Avoid redundancy**: Each design aspect should be mentioned once. Avoid repeating points about color theory, spatial relationships, or typographic principles unless adding new depth.\n- **Emphasize craftsmanship REPEATEDLY**: The philosophy MUST stress multiple times that the final work should appear as though it took countless hours to create, was labored over with care, and comes from someone at the absolute top of their field. This framing is essential - repeat phrases like \"meticulously crafted,\" \"the product of deep expertise,\" \"painstaking attention,\" \"master-level execution.\"\n- **Leave creative space**: Remain specific about the aesthetic direction, but concise enough that the next Claude has room to make interpretive choices also at a extremely high level of craftmanship.\n\nThe philosophy must guide the next version to express ideas VISUALLY, not through text. Information lives in design, not paragraphs.\n\n### PHILOSOPHY EXAMPLES\n\n**\"Concrete Poetry\"**\nPhilosophy: Communication through monumental form and bold geometry.\nVisual expression: Massive color blocks, sculptural typography (huge single words, tiny labels), Brutalist spatial divisions, Polish poster energy meets Le Corbusier. Ideas expressed through visual weight and spatial tension, not explanation. Text as rare, powerful gesture - never paragraphs, only essential words integrated into the visual architecture. Every element placed with the precision of a master craftsman.\n\n**\"Chromatic Language\"**\nPhilosophy: Color as the primary information system.\nVisual expression: Geometric precision where color zones create meaning. Typography minimal - small sans-serif labels letting chromatic fields communicate. Think Josef Albers' interaction meets data visualization. Information encoded spatially and chromatically. Words only to anchor what color already shows. The result of painstaking chromatic calibration.\n\n**\"Analog Meditation\"**\nPhilosophy: Quiet visual contemplation through texture and breathing room.\nVisual expression: Paper grain, ink bleeds, vast negative space. Photography and illustration dominate. Typography whispered (small, restrained, serving the visual). Japanese photobook aesthetic. Images breathe across pages. Text appears sparingly - short phrases, never explanatory blocks. Each composition balanced with the care of a meditation practice.\n\n**\"Organic Systems\"**\nPhilosophy: Natural clustering and modular growth patterns.\nVisual expression: Rounded forms, organic arrangements, color from nature through architecture. Information shown through visual diagrams, spatial relationships, iconography. Text only for key labels floating in space. The composition tells the story through expert spatial orchestration.\n\n**\"Geometric Silence\"**\nPhilosophy: Pure order and restraint.\nVisual expression: Grid-based precision, bold photography or stark graphics, dramatic negative space. Typography precise but minimal - small essential text, large quiet zones. Swiss formalism meets Brutalist material honesty. Structure communicates, not words. Every alignment the work of countless refinements.\n\n*These are condensed examples. The actual design philosophy should be 4-6 substantial paragraphs.*\n\n### ESSENTIAL PRINCIPLES\n- **VISUAL PHILOSOPHY**: Create an aesthetic worldview to be expressed through design\n- **MINIMAL TEXT**: Always emphasize that text is sparse, essential-only, integrated as visual element - never lengthy\n- **SPATIAL EXPRESSION**: Ideas communicate through space, form, color, composition - not paragraphs\n- **ARTISTIC FREEDOM**: The next Claude interprets the philosophy visually - provide creative room\n- **PURE DESIGN**: This is about making ART OBJECTS, not documents with decoration\n- **EXPERT CRAFTSMANSHIP**: Repeatedly emphasize the final work must look meticulously crafted, labored over with care, the product of countless hours by someone at the top of their field\n\n**The design philosophy should be 4-6 paragraphs long.** Fill it with poetic design philosophy that brings together the core vision. Avoid repeating the same points. Keep the design philosophy generic without mentioning the intention of the art, as if it can be used wherever. Output the design philosophy as a .md file.\n\n---\n\n## DEDUCING THE SUBTLE REFERENCE\n\n**CRITICAL STEP**: Before creating the canvas, identify the subtle conceptual thread from the original request.\n\n**THE ESSENTIAL PRINCIPLE**:\nThe topic is a **subtle, niche reference embedded within the art itself** - not always literal, always sophisticated. Someone familiar with the subject should feel it intuitively, while others simply experience a masterful abstract composition. The design philosophy provides the aesthetic language. The deduced topic provides the soul - the quiet conceptual DNA woven invisibly into form, color, and composition.\n\nThis is **VERY IMPORTANT**: The reference must be refined so it enhances the work's depth without announcing itself. Think like a jazz musician quoting another song - only those who know will catch it, but everyone appreciates the music.\n\n---\n\n## CANVAS CREATION\n\nWith both the philosophy and the conceptual framework established, express it on a canvas. Take a moment to gather thoughts and clear the mind. Use the design philosophy created and the instructions below to craft a masterpiece, embodying all aspects of the philosophy with expert craftsmanship.\n\n**IMPORTANT**: For any type of content, even if the user requests something for a movie/game/book, the approach should still be sophisticated. Never lose sight of the idea that this should be art, not something that's cartoony or amateur.\n\nTo create museum or magazine quality work, use the design philosophy as the foundation. Create one single page, highly visual, design-forward PDF or PNG output (unless asked for more pages). Generally use repeating patterns and perfect shapes. Treat the abstract philosophical design as if it were a scientific bible, borrowing the visual language of systematic observationâ€”dense accumulation of marks, repeated elements, or layered patterns that build meaning through patient repetition and reward sustained viewing. Add sparse, clinical typography and systematic reference markers that suggest this could be a diagram from an imaginary discipline, treating the invisible subject with the same reverence typically reserved for documenting observable phenomena. Anchor the piece with simple phrase(s) or details positioned subtly, using a limited color palette that feels intentional and cohesive. Embrace the paradox of using analytical visual language to express ideas about human experience: the result should feel like an artifact that proves something ephemeral can be studied, mapped, and understood through careful attention. This is true art. \n\n**Text as a contextual element**: Text is always minimal and visual-first, but let context guide whether that means whisper-quiet labels or bold typographic gestures. A punk venue poster might have larger, more aggressive type than a minimalist ceramics studio identity. Most of the time, font should be thin. All use of fonts must be design-forward and prioritize visual communication. Regardless of text scale, nothing falls off the page and nothing overlaps. Every element must be contained within the canvas boundaries with proper margins. Check carefully that all text, graphics, and visual elements have breathing room and clear separation. This is non-negotiable for professional execution. **IMPORTANT: Use different fonts if writing text. Search the `./canvas-fonts` directory. Regardless of approach, sophistication is non-negotiable.**\n\nDownload and use whatever fonts are needed to make this a reality. Get creative by making the typography actually part of the art itself -- if the art is abstract, bring the font onto the canvas, not typeset digitally.\n\nTo push boundaries, follow design instinct/intuition while using the philosophy as a guiding principle. Embrace ultimate design freedom and choice. Push aesthetics and design to the frontier. \n\n**CRITICAL**: To achieve human-crafted quality (not AI-generated), create work that looks like it took countless hours. Make it appear as though someone at the absolute top of their field labored over every detail with painstaking care. Ensure the composition, spacing, color choices, typography - everything screams expert-level craftsmanship. Double-check that nothing overlaps, formatting is flawless, every detail perfect. Create something that could be shown to people to prove expertise and rank as undeniably impressive.\n\nOutput the final result as a single, downloadable .pdf or .png file, alongside the design philosophy used as a .md file.\n\n---\n\n## FINAL STEP\n\n**IMPORTANT**: The user ALREADY said \"It isn't perfect enough. It must be pristine, a masterpiece if craftsmanship, as if it were about to be displayed in a museum.\"\n\n**CRITICAL**: To refine the work, avoid adding more graphics; instead refine what has been created and make it extremely crisp, respecting the design philosophy and the principles of minimalism entirely. Rather than adding a fun filter or refactoring a font, consider how to make the existing composition more cohesive with the art. If the instinct is to call a new function or draw a new shape, STOP and instead ask: \"How can I make what's already here more of a piece of art?\"\n\nTake a second pass. Go back to the code and refine/polish further to make this a philosophically designed masterpiece.\n\n## MULTI-PAGE OPTION\n\nTo create additional pages when requested, create more creative pages along the same lines as the design philosophy but distinctly different as well. Bundle those pages in the same .pdf or many .pngs. Treat the first page as just a single page in a whole coffee table book waiting to be filled. Make the next pages unique twists and memories of the original. Have them almost tell a story in a very tasteful way. Exercise full creative freedom."
      },
      "discovered_at": "2026-01-11T15:36:38.153232Z",
      "fetch_error": null
    },
    {
      "name": "doc-coauthoring",
      "slug": "doc-coauthoring",
      "source": "anthropic_official",
      "owner": "anthropics",
      "repo_name": "skills",
      "repository_url": "https://github.com/anthropics/skills",
      "skill_path": "skills/doc-coauthoring",
      "github_metadata": {
        "stars": 37534,
        "description": "Public repository for Agent Skills",
        "default_branch": "main",
        "pushed_at": "2025-12-20T18:09:45Z",
        "created_at": "2025-09-22T15:53:31Z",
        "language": "Python",
        "license": null,
        "open_issues": 137,
        "forks": 3406
      },
      "skill_md": {
        "found": true,
        "path": "skills/doc-coauthoring/SKILL.md",
        "branch": "main",
        "content": "---\nname: doc-coauthoring\ndescription: Guide users through a structured workflow for co-authoring documentation. Use when user wants to write documentation, proposals, technical specs, decision docs, or similar structured content. This workflow helps users efficiently transfer context, refine content through iteration, and verify the doc works for readers. Trigger when user mentions writing docs, creating proposals, drafting specs, or similar documentation tasks.\n---\n\n# Doc Co-Authoring Workflow\n\nThis skill provides a structured workflow for guiding users through collaborative document creation. Act as an active guide, walking users through three stages: Context Gathering, Refinement & Structure, and Reader Testing.\n\n## When to Offer This Workflow\n\n**Trigger conditions:**\n- User mentions writing documentation: \"write a doc\", \"draft a proposal\", \"create a spec\", \"write up\"\n- User mentions specific doc types: \"PRD\", \"design doc\", \"decision doc\", \"RFC\"\n- User seems to be starting a substantial writing task\n\n**Initial offer:**\nOffer the user a structured workflow for co-authoring the document. Explain the three stages:\n\n1. **Context Gathering**: User provides all relevant context while Claude asks clarifying questions\n2. **Refinement & Structure**: Iteratively build each section through brainstorming and editing\n3. **Reader Testing**: Test the doc with a fresh Claude (no context) to catch blind spots before others read it\n\nExplain that this approach helps ensure the doc works well when others read it (including when they paste it into Claude). Ask if they want to try this workflow or prefer to work freeform.\n\nIf user declines, work freeform. If user accepts, proceed to Stage 1.\n\n## Stage 1: Context Gathering\n\n**Goal:** Close the gap between what the user knows and what Claude knows, enabling smart guidance later.\n\n### Initial Questions\n\nStart by asking the user for meta-context about the document:\n\n1. What type of document is this? (e.g., technical spec, decision doc, proposal)\n2. Who's the primary audience?\n3. What's the desired impact when someone reads this?\n4. Is there a template or specific format to follow?\n5. Any other constraints or context to know?\n\nInform them they can answer in shorthand or dump information however works best for them.\n\n**If user provides a template or mentions a doc type:**\n- Ask if they have a template document to share\n- If they provide a link to a shared document, use the appropriate integration to fetch it\n- If they provide a file, read it\n\n**If user mentions editing an existing shared document:**\n- Use the appropriate integration to read the current state\n- Check for images without alt-text\n- If images exist without alt-text, explain that when others use Claude to understand the doc, Claude won't be able to see them. Ask if they want alt-text generated. If so, request they paste each image into chat for descriptive alt-text generation.\n\n### Info Dumping\n\nOnce initial questions are answered, encourage the user to dump all the context they have. Request information such as:\n- Background on the project/problem\n- Related team discussions or shared documents\n- Why alternative solutions aren't being used\n- Organizational context (team dynamics, past incidents, politics)\n- Timeline pressures or constraints\n- Technical architecture or dependencies\n- Stakeholder concerns\n\nAdvise them not to worry about organizing it - just get it all out. Offer multiple ways to provide context:\n- Info dump stream-of-consciousness\n- Point to team channels or threads to read\n- Link to shared documents\n\n**If integrations are available** (e.g., Slack, Teams, Google Drive, SharePoint, or other MCP servers), mention that these can be used to pull in context directly.\n\n**If no integrations are detected and in Claude.ai or Claude app:** Suggest they can enable connectors in their Claude settings to allow pulling context from messaging apps and document storage directly.\n\nInform them clarifying questions will be asked once they've done their initial dump.\n\n**During context gathering:**\n\n- If user mentions team channels or shared documents:\n  - If integrations available: Inform them the content will be read now, then use the appropriate integration\n  - If integrations not available: Explain lack of access. Suggest they enable connectors in Claude settings, or paste the relevant content directly.\n\n- If user mentions entities/projects that are unknown:\n  - Ask if connected tools should be searched to learn more\n  - Wait for user confirmation before searching\n\n- As user provides context, track what's being learned and what's still unclear\n\n**Asking clarifying questions:**\n\nWhen user signals they've done their initial dump (or after substantial context provided), ask clarifying questions to ensure understanding:\n\nGenerate 5-10 numbered questions based on gaps in the context.\n\nInform them they can use shorthand to answer (e.g., \"1: yes, 2: see #channel, 3: no because backwards compat\"), link to more docs, point to channels to read, or just keep info-dumping. Whatever's most efficient for them.\n\n**Exit condition:**\nSufficient context has been gathered when questions show understanding - when edge cases and trade-offs can be asked about without needing basics explained.\n\n**Transition:**\nAsk if there's any more context they want to provide at this stage, or if it's time to move on to drafting the document.\n\nIf user wants to add more, let them. When ready, proceed to Stage 2.\n\n## Stage 2: Refinement & Structure\n\n**Goal:** Build the document section by section through brainstorming, curation, and iterative refinement.\n\n**Instructions to user:**\nExplain that the document will be built section by section. For each section:\n1. Clarifying questions will be asked about what to include\n2. 5-20 options will be brainstormed\n3. User will indicate what to keep/remove/combine\n4. The section will be drafted\n5. It will be refined through surgical edits\n\nStart with whichever section has the most unknowns (usually the core decision/proposal), then work through the rest.\n\n**Section ordering:**\n\nIf the document structure is clear:\nAsk which section they'd like to start with.\n\nSuggest starting with whichever section has the most unknowns. For decision docs, that's usually the core proposal. For specs, it's typically the technical approach. Summary sections are best left for last.\n\nIf user doesn't know what sections they need:\nBased on the type of document and template, suggest 3-5 sections appropriate for the doc type.\n\nAsk if this structure works, or if they want to adjust it.\n\n**Once structure is agreed:**\n\nCreate the initial document structure with placeholder text for all sections.\n\n**If access to artifacts is available:**\nUse `create_file` to create an artifact. This gives both Claude and the user a scaffold to work from.\n\nInform them that the initial structure with placeholders for all sections will be created.\n\nCreate artifact with all section headers and brief placeholder text like \"[To be written]\" or \"[Content here]\".\n\nProvide the scaffold link and indicate it's time to fill in each section.\n\n**If no access to artifacts:**\nCreate a markdown file in the working directory. Name it appropriately (e.g., `decision-doc.md`, `technical-spec.md`).\n\nInform them that the initial structure with placeholders for all sections will be created.\n\nCreate file with all section headers and placeholder text.\n\nConfirm the filename has been created and indicate it's time to fill in each section.\n\n**For each section:**\n\n### Step 1: Clarifying Questions\n\nAnnounce work will begin on the [SECTION NAME] section. Ask 5-10 clarifying questions about what should be included:\n\nGenerate 5-10 specific questions based on context and section purpose.\n\nInform them they can answer in shorthand or just indicate what's important to cover.\n\n### Step 2: Brainstorming\n\nFor the [SECTION NAME] section, brainstorm [5-20] things that might be included, depending on the section's complexity. Look for:\n- Context shared that might have been forgotten\n- Angles or considerations not yet mentioned\n\nGenerate 5-20 numbered options based on section complexity. At the end, offer to brainstorm more if they want additional options.\n\n### Step 3: Curation\n\nAsk which points should be kept, removed, or combined. Request brief justifications to help learn priorities for the next sections.\n\nProvide examples:\n- \"Keep 1,4,7,9\"\n- \"Remove 3 (duplicates 1)\"\n- \"Remove 6 (audience already knows this)\"\n- \"Combine 11 and 12\"\n\n**If user gives freeform feedback** (e.g., \"looks good\" or \"I like most of it but...\") instead of numbered selections, extract their preferences and proceed. Parse what they want kept/removed/changed and apply it.\n\n### Step 4: Gap Check\n\nBased on what they've selected, ask if there's anything important missing for the [SECTION NAME] section.\n\n### Step 5: Drafting\n\nUse `str_replace` to replace the placeholder text for this section with the actual drafted content.\n\nAnnounce the [SECTION NAME] section will be drafted now based on what they've selected.\n\n**If using artifacts:**\nAfter drafting, provide a link to the artifact.\n\nAsk them to read through it and indicate what to change. Note that being specific helps learning for the next sections.\n\n**If using a file (no artifacts):**\nAfter drafting, confirm completion.\n\nInform them the [SECTION NAME] section has been drafted in [filename]. Ask them to read through it and indicate what to change. Note that being specific helps learning for the next sections.\n\n**Key instruction for user (include when drafting the first section):**\nProvide a note: Instead of editing the doc directly, ask them to indicate what to change. This helps learning of their style for future sections. For example: \"Remove the X bullet - already covered by Y\" or \"Make the third paragraph more concise\".\n\n### Step 6: Iterative Refinement\n\nAs user provides feedback:\n- Use `str_replace` to make edits (never reprint the whole doc)\n- **If using artifacts:** Provide link to artifact after each edit\n- **If using files:** Just confirm edits are complete\n- If user edits doc directly and asks to read it: mentally note the changes they made and keep them in mind for future sections (this shows their preferences)\n\n**Continue iterating** until user is satisfied with the section.\n\n### Quality Checking\n\nAfter 3 consecutive iterations with no substantial changes, ask if anything can be removed without losing important information.\n\nWhen section is done, confirm [SECTION NAME] is complete. Ask if ready to move to the next section.\n\n**Repeat for all sections.**\n\n### Near Completion\n\nAs approaching completion (80%+ of sections done), announce intention to re-read the entire document and check for:\n- Flow and consistency across sections\n- Redundancy or contradictions\n- Anything that feels like \"slop\" or generic filler\n- Whether every sentence carries weight\n\nRead entire document and provide feedback.\n\n**When all sections are drafted and refined:**\nAnnounce all sections are drafted. Indicate intention to review the complete document one more time.\n\nReview for overall coherence, flow, completeness.\n\nProvide any final suggestions.\n\nAsk if ready to move to Reader Testing, or if they want to refine anything else.\n\n## Stage 3: Reader Testing\n\n**Goal:** Test the document with a fresh Claude (no context bleed) to verify it works for readers.\n\n**Instructions to user:**\nExplain that testing will now occur to see if the document actually works for readers. This catches blind spots - things that make sense to the authors but might confuse others.\n\n### Testing Approach\n\n**If access to sub-agents is available (e.g., in Claude Code):**\n\nPerform the testing directly without user involvement.\n\n### Step 1: Predict Reader Questions\n\nAnnounce intention to predict what questions readers might ask when trying to discover this document.\n\nGenerate 5-10 questions that readers would realistically ask.\n\n### Step 2: Test with Sub-Agent\n\nAnnounce that these questions will be tested with a fresh Claude instance (no context from this conversation).\n\nFor each question, invoke a sub-agent with just the document content and the question.\n\nSummarize what Reader Claude got right/wrong for each question.\n\n### Step 3: Run Additional Checks\n\nAnnounce additional checks will be performed.\n\nInvoke sub-agent to check for ambiguity, false assumptions, contradictions.\n\nSummarize any issues found.\n\n### Step 4: Report and Fix\n\nIf issues found:\nReport that Reader Claude struggled with specific issues.\n\nList the specific issues.\n\nIndicate intention to fix these gaps.\n\nLoop back to refinement for problematic sections.\n\n---\n\n**If no access to sub-agents (e.g., claude.ai web interface):**\n\nThe user will need to do the testing manually.\n\n### Step 1: Predict Reader Questions\n\nAsk what questions people might ask when trying to discover this document. What would they type into Claude.ai?\n\nGenerate 5-10 questions that readers would realistically ask.\n\n### Step 2: Setup Testing\n\nProvide testing instructions:\n1. Open a fresh Claude conversation: https://claude.ai\n2. Paste or share the document content (if using a shared doc platform with connectors enabled, provide the link)\n3. Ask Reader Claude the generated questions\n\nFor each question, instruct Reader Claude to provide:\n- The answer\n- Whether anything was ambiguous or unclear\n- What knowledge/context the doc assumes is already known\n\nCheck if Reader Claude gives correct answers or misinterprets anything.\n\n### Step 3: Additional Checks\n\nAlso ask Reader Claude:\n- \"What in this doc might be ambiguous or unclear to readers?\"\n- \"What knowledge or context does this doc assume readers already have?\"\n- \"Are there any internal contradictions or inconsistencies?\"\n\n### Step 4: Iterate Based on Results\n\nAsk what Reader Claude got wrong or struggled with. Indicate intention to fix those gaps.\n\nLoop back to refinement for any problematic sections.\n\n---\n\n### Exit Condition (Both Approaches)\n\nWhen Reader Claude consistently answers questions correctly and doesn't surface new gaps or ambiguities, the doc is ready.\n\n## Final Review\n\nWhen Reader Testing passes:\nAnnounce the doc has passed Reader Claude testing. Before completion:\n\n1. Recommend they do a final read-through themselves - they own this document and are responsible for its quality\n2. Suggest double-checking any facts, links, or technical details\n3. Ask them to verify it achieves the impact they wanted\n\nAsk if they want one more review, or if the work is done.\n\n**If user wants final review, provide it. Otherwise:**\nAnnounce document completion. Provide a few final tips:\n- Consider linking this conversation in an appendix so readers can see how the doc was developed\n- Use appendices to provide depth without bloating the main doc\n- Update the doc as feedback is received from real readers\n\n## Tips for Effective Guidance\n\n**Tone:**\n- Be direct and procedural\n- Explain rationale briefly when it affects user behavior\n- Don't try to \"sell\" the approach - just execute it\n\n**Handling Deviations:**\n- If user wants to skip a stage: Ask if they want to skip this and write freeform\n- If user seems frustrated: Acknowledge this is taking longer than expected. Suggest ways to move faster\n- Always give user agency to adjust the process\n\n**Context Management:**\n- Throughout, if context is missing on something mentioned, proactively ask\n- Don't let gaps accumulate - address them as they come up\n\n**Artifact Management:**\n- Use `create_file` for drafting full sections\n- Use `str_replace` for all edits\n- Provide artifact link after every change\n- Never use artifacts for brainstorming lists - that's just conversation\n\n**Quality over Speed:**\n- Don't rush through stages\n- Each iteration should make meaningful improvements\n- The goal is a document that actually works for readers\n"
      },
      "discovered_at": "2026-01-11T15:36:38.316199Z",
      "fetch_error": null
    },
    {
      "name": "docx",
      "slug": "docx",
      "source": "anthropic_official",
      "owner": "anthropics",
      "repo_name": "skills",
      "repository_url": "https://github.com/anthropics/skills",
      "skill_path": "skills/docx",
      "github_metadata": {
        "stars": 37534,
        "description": "Public repository for Agent Skills",
        "default_branch": "main",
        "pushed_at": "2025-12-20T18:09:45Z",
        "created_at": "2025-09-22T15:53:31Z",
        "language": "Python",
        "license": null,
        "open_issues": 137,
        "forks": 3406
      },
      "skill_md": {
        "found": true,
        "path": "skills/docx/SKILL.md",
        "branch": "main",
        "content": "---\nname: docx\ndescription: \"Comprehensive document creation, editing, and analysis with support for tracked changes, comments, formatting preservation, and text extraction. When Claude needs to work with professional documents (.docx files) for: (1) Creating new documents, (2) Modifying or editing content, (3) Working with tracked changes, (4) Adding comments, or any other document tasks\"\nlicense: Proprietary. LICENSE.txt has complete terms\n---\n\n# DOCX creation, editing, and analysis\n\n## Overview\n\nA user may ask you to create, edit, or analyze the contents of a .docx file. A .docx file is essentially a ZIP archive containing XML files and other resources that you can read or edit. You have different tools and workflows available for different tasks.\n\n## Workflow Decision Tree\n\n### Reading/Analyzing Content\nUse \"Text extraction\" or \"Raw XML access\" sections below\n\n### Creating New Document\nUse \"Creating a new Word document\" workflow\n\n### Editing Existing Document\n- **Your own document + simple changes**\n  Use \"Basic OOXML editing\" workflow\n\n- **Someone else's document**\n  Use **\"Redlining workflow\"** (recommended default)\n\n- **Legal, academic, business, or government docs**\n  Use **\"Redlining workflow\"** (required)\n\n## Reading and analyzing content\n\n### Text extraction\nIf you just need to read the text contents of a document, you should convert the document to markdown using pandoc. Pandoc provides excellent support for preserving document structure and can show tracked changes:\n\n```bash\n# Convert document to markdown with tracked changes\npandoc --track-changes=all path-to-file.docx -o output.md\n# Options: --track-changes=accept/reject/all\n```\n\n### Raw XML access\nYou need raw XML access for: comments, complex formatting, document structure, embedded media, and metadata. For any of these features, you'll need to unpack a document and read its raw XML contents.\n\n#### Unpacking a file\n`python ooxml/scripts/unpack.py <office_file> <output_directory>`\n\n#### Key file structures\n* `word/document.xml` - Main document contents\n* `word/comments.xml` - Comments referenced in document.xml\n* `word/media/` - Embedded images and media files\n* Tracked changes use `<w:ins>` (insertions) and `<w:del>` (deletions) tags\n\n## Creating a new Word document\n\nWhen creating a new Word document from scratch, use **docx-js**, which allows you to create Word documents using JavaScript/TypeScript.\n\n### Workflow\n1. **MANDATORY - READ ENTIRE FILE**: Read [`docx-js.md`](docx-js.md) (~500 lines) completely from start to finish. **NEVER set any range limits when reading this file.** Read the full file content for detailed syntax, critical formatting rules, and best practices before proceeding with document creation.\n2. Create a JavaScript/TypeScript file using Document, Paragraph, TextRun components (You can assume all dependencies are installed, but if not, refer to the dependencies section below)\n3. Export as .docx using Packer.toBuffer()\n\n## Editing an existing Word document\n\nWhen editing an existing Word document, use the **Document library** (a Python library for OOXML manipulation). The library automatically handles infrastructure setup and provides methods for document manipulation. For complex scenarios, you can access the underlying DOM directly through the library.\n\n### Workflow\n1. **MANDATORY - READ ENTIRE FILE**: Read [`ooxml.md`](ooxml.md) (~600 lines) completely from start to finish. **NEVER set any range limits when reading this file.** Read the full file content for the Document library API and XML patterns for directly editing document files.\n2. Unpack the document: `python ooxml/scripts/unpack.py <office_file> <output_directory>`\n3. Create and run a Python script using the Document library (see \"Document Library\" section in ooxml.md)\n4. Pack the final document: `python ooxml/scripts/pack.py <input_directory> <office_file>`\n\nThe Document library provides both high-level methods for common operations and direct DOM access for complex scenarios.\n\n## Redlining workflow for document review\n\nThis workflow allows you to plan comprehensive tracked changes using markdown before implementing them in OOXML. **CRITICAL**: For complete tracked changes, you must implement ALL changes systematically.\n\n**Batching Strategy**: Group related changes into batches of 3-10 changes. This makes debugging manageable while maintaining efficiency. Test each batch before moving to the next.\n\n**Principle: Minimal, Precise Edits**\nWhen implementing tracked changes, only mark text that actually changes. Repeating unchanged text makes edits harder to review and appears unprofessional. Break replacements into: [unchanged text] + [deletion] + [insertion] + [unchanged text]. Preserve the original run's RSID for unchanged text by extracting the `<w:r>` element from the original and reusing it.\n\nExample - Changing \"30 days\" to \"60 days\" in a sentence:\n```python\n# BAD - Replaces entire sentence\n'<w:del><w:r><w:delText>The term is 30 days.</w:delText></w:r></w:del><w:ins><w:r><w:t>The term is 60 days.</w:t></w:r></w:ins>'\n\n# GOOD - Only marks what changed, preserves original <w:r> for unchanged text\n'<w:r w:rsidR=\"00AB12CD\"><w:t>The term is </w:t></w:r><w:del><w:r><w:delText>30</w:delText></w:r></w:del><w:ins><w:r><w:t>60</w:t></w:r></w:ins><w:r w:rsidR=\"00AB12CD\"><w:t> days.</w:t></w:r>'\n```\n\n### Tracked changes workflow\n\n1. **Get markdown representation**: Convert document to markdown with tracked changes preserved:\n   ```bash\n   pandoc --track-changes=all path-to-file.docx -o current.md\n   ```\n\n2. **Identify and group changes**: Review the document and identify ALL changes needed, organizing them into logical batches:\n\n   **Location methods** (for finding changes in XML):\n   - Section/heading numbers (e.g., \"Section 3.2\", \"Article IV\")\n   - Paragraph identifiers if numbered\n   - Grep patterns with unique surrounding text\n   - Document structure (e.g., \"first paragraph\", \"signature block\")\n   - **DO NOT use markdown line numbers** - they don't map to XML structure\n\n   **Batch organization** (group 3-10 related changes per batch):\n   - By section: \"Batch 1: Section 2 amendments\", \"Batch 2: Section 5 updates\"\n   - By type: \"Batch 1: Date corrections\", \"Batch 2: Party name changes\"\n   - By complexity: Start with simple text replacements, then tackle complex structural changes\n   - Sequential: \"Batch 1: Pages 1-3\", \"Batch 2: Pages 4-6\"\n\n3. **Read documentation and unpack**:\n   - **MANDATORY - READ ENTIRE FILE**: Read [`ooxml.md`](ooxml.md) (~600 lines) completely from start to finish. **NEVER set any range limits when reading this file.** Pay special attention to the \"Document Library\" and \"Tracked Change Patterns\" sections.\n   - **Unpack the document**: `python ooxml/scripts/unpack.py <file.docx> <dir>`\n   - **Note the suggested RSID**: The unpack script will suggest an RSID to use for your tracked changes. Copy this RSID for use in step 4b.\n\n4. **Implement changes in batches**: Group changes logically (by section, by type, or by proximity) and implement them together in a single script. This approach:\n   - Makes debugging easier (smaller batch = easier to isolate errors)\n   - Allows incremental progress\n   - Maintains efficiency (batch size of 3-10 changes works well)\n\n   **Suggested batch groupings:**\n   - By document section (e.g., \"Section 3 changes\", \"Definitions\", \"Termination clause\")\n   - By change type (e.g., \"Date changes\", \"Party name updates\", \"Legal term replacements\")\n   - By proximity (e.g., \"Changes on pages 1-3\", \"Changes in first half of document\")\n\n   For each batch of related changes:\n\n   **a. Map text to XML**: Grep for text in `word/document.xml` to verify how text is split across `<w:r>` elements.\n\n   **b. Create and run script**: Use `get_node` to find nodes, implement changes, then `doc.save()`. See **\"Document Library\"** section in ooxml.md for patterns.\n\n   **Note**: Always grep `word/document.xml` immediately before writing a script to get current line numbers and verify text content. Line numbers change after each script run.\n\n5. **Pack the document**: After all batches are complete, convert the unpacked directory back to .docx:\n   ```bash\n   python ooxml/scripts/pack.py unpacked reviewed-document.docx\n   ```\n\n6. **Final verification**: Do a comprehensive check of the complete document:\n   - Convert final document to markdown:\n     ```bash\n     pandoc --track-changes=all reviewed-document.docx -o verification.md\n     ```\n   - Verify ALL changes were applied correctly:\n     ```bash\n     grep \"original phrase\" verification.md  # Should NOT find it\n     grep \"replacement phrase\" verification.md  # Should find it\n     ```\n   - Check that no unintended changes were introduced\n\n\n## Converting Documents to Images\n\nTo visually analyze Word documents, convert them to images using a two-step process:\n\n1. **Convert DOCX to PDF**:\n   ```bash\n   soffice --headless --convert-to pdf document.docx\n   ```\n\n2. **Convert PDF pages to JPEG images**:\n   ```bash\n   pdftoppm -jpeg -r 150 document.pdf page\n   ```\n   This creates files like `page-1.jpg`, `page-2.jpg`, etc.\n\nOptions:\n- `-r 150`: Sets resolution to 150 DPI (adjust for quality/size balance)\n- `-jpeg`: Output JPEG format (use `-png` for PNG if preferred)\n- `-f N`: First page to convert (e.g., `-f 2` starts from page 2)\n- `-l N`: Last page to convert (e.g., `-l 5` stops at page 5)\n- `page`: Prefix for output files\n\nExample for specific range:\n```bash\npdftoppm -jpeg -r 150 -f 2 -l 5 document.pdf page  # Converts only pages 2-5\n```\n\n## Code Style Guidelines\n**IMPORTANT**: When generating code for DOCX operations:\n- Write concise code\n- Avoid verbose variable names and redundant operations\n- Avoid unnecessary print statements\n\n## Dependencies\n\nRequired dependencies (install if not available):\n\n- **pandoc**: `sudo apt-get install pandoc` (for text extraction)\n- **docx**: `npm install -g docx` (for creating new documents)\n- **LibreOffice**: `sudo apt-get install libreoffice` (for PDF conversion)\n- **Poppler**: `sudo apt-get install poppler-utils` (for pdftoppm to convert PDF to images)\n- **defusedxml**: `pip install defusedxml` (for secure XML parsing)"
      },
      "discovered_at": "2026-01-11T15:36:38.460044Z",
      "fetch_error": null
    },
    {
      "name": "frontend-design",
      "slug": "frontend-design",
      "source": "anthropic_official",
      "owner": "anthropics",
      "repo_name": "skills",
      "repository_url": "https://github.com/anthropics/skills",
      "skill_path": "skills/frontend-design",
      "github_metadata": {
        "stars": 37534,
        "description": "Public repository for Agent Skills",
        "default_branch": "main",
        "pushed_at": "2025-12-20T18:09:45Z",
        "created_at": "2025-09-22T15:53:31Z",
        "language": "Python",
        "license": null,
        "open_issues": 137,
        "forks": 3406
      },
      "skill_md": {
        "found": true,
        "path": "skills/frontend-design/SKILL.md",
        "branch": "main",
        "content": "---\nname: frontend-design\ndescription: Create distinctive, production-grade frontend interfaces with high design quality. Use this skill when the user asks to build web components, pages, artifacts, posters, or applications (examples include websites, landing pages, dashboards, React components, HTML/CSS layouts, or when styling/beautifying any web UI). Generates creative, polished code and UI design that avoids generic AI aesthetics.\nlicense: Complete terms in LICENSE.txt\n---\n\nThis skill guides creation of distinctive, production-grade frontend interfaces that avoid generic \"AI slop\" aesthetics. Implement real working code with exceptional attention to aesthetic details and creative choices.\n\nThe user provides frontend requirements: a component, page, application, or interface to build. They may include context about the purpose, audience, or technical constraints.\n\n## Design Thinking\n\nBefore coding, understand the context and commit to a BOLD aesthetic direction:\n- **Purpose**: What problem does this interface solve? Who uses it?\n- **Tone**: Pick an extreme: brutally minimal, maximalist chaos, retro-futuristic, organic/natural, luxury/refined, playful/toy-like, editorial/magazine, brutalist/raw, art deco/geometric, soft/pastel, industrial/utilitarian, etc. There are so many flavors to choose from. Use these for inspiration but design one that is true to the aesthetic direction.\n- **Constraints**: Technical requirements (framework, performance, accessibility).\n- **Differentiation**: What makes this UNFORGETTABLE? What's the one thing someone will remember?\n\n**CRITICAL**: Choose a clear conceptual direction and execute it with precision. Bold maximalism and refined minimalism both work - the key is intentionality, not intensity.\n\nThen implement working code (HTML/CSS/JS, React, Vue, etc.) that is:\n- Production-grade and functional\n- Visually striking and memorable\n- Cohesive with a clear aesthetic point-of-view\n- Meticulously refined in every detail\n\n## Frontend Aesthetics Guidelines\n\nFocus on:\n- **Typography**: Choose fonts that are beautiful, unique, and interesting. Avoid generic fonts like Arial and Inter; opt instead for distinctive choices that elevate the frontend's aesthetics; unexpected, characterful font choices. Pair a distinctive display font with a refined body font.\n- **Color & Theme**: Commit to a cohesive aesthetic. Use CSS variables for consistency. Dominant colors with sharp accents outperform timid, evenly-distributed palettes.\n- **Motion**: Use animations for effects and micro-interactions. Prioritize CSS-only solutions for HTML. Use Motion library for React when available. Focus on high-impact moments: one well-orchestrated page load with staggered reveals (animation-delay) creates more delight than scattered micro-interactions. Use scroll-triggering and hover states that surprise.\n- **Spatial Composition**: Unexpected layouts. Asymmetry. Overlap. Diagonal flow. Grid-breaking elements. Generous negative space OR controlled density.\n- **Backgrounds & Visual Details**: Create atmosphere and depth rather than defaulting to solid colors. Add contextual effects and textures that match the overall aesthetic. Apply creative forms like gradient meshes, noise textures, geometric patterns, layered transparencies, dramatic shadows, decorative borders, custom cursors, and grain overlays.\n\nNEVER use generic AI-generated aesthetics like overused font families (Inter, Roboto, Arial, system fonts), cliched color schemes (particularly purple gradients on white backgrounds), predictable layouts and component patterns, and cookie-cutter design that lacks context-specific character.\n\nInterpret creatively and make unexpected choices that feel genuinely designed for the context. No design should be the same. Vary between light and dark themes, different fonts, different aesthetics. NEVER converge on common choices (Space Grotesk, for example) across generations.\n\n**IMPORTANT**: Match implementation complexity to the aesthetic vision. Maximalist designs need elaborate code with extensive animations and effects. Minimalist or refined designs need restraint, precision, and careful attention to spacing, typography, and subtle details. Elegance comes from executing the vision well.\n\nRemember: Claude is capable of extraordinary creative work. Don't hold back, show what can truly be created when thinking outside the box and committing fully to a distinctive vision.\n"
      },
      "discovered_at": "2026-01-11T15:36:38.509094Z",
      "fetch_error": null
    },
    {
      "name": "internal-comms",
      "slug": "internal-comms",
      "source": "anthropic_official",
      "owner": "anthropics",
      "repo_name": "skills",
      "repository_url": "https://github.com/anthropics/skills",
      "skill_path": "skills/internal-comms",
      "github_metadata": {
        "stars": 37534,
        "description": "Public repository for Agent Skills",
        "default_branch": "main",
        "pushed_at": "2025-12-20T18:09:45Z",
        "created_at": "2025-09-22T15:53:31Z",
        "language": "Python",
        "license": null,
        "open_issues": 137,
        "forks": 3406
      },
      "skill_md": {
        "found": true,
        "path": "skills/internal-comms/SKILL.md",
        "branch": "main",
        "content": "---\nname: internal-comms\ndescription: A set of resources to help me write all kinds of internal communications, using the formats that my company likes to use. Claude should use this skill whenever asked to write some sort of internal communications (status reports, leadership updates, 3P updates, company newsletters, FAQs, incident reports, project updates, etc.).\nlicense: Complete terms in LICENSE.txt\n---\n\n## When to use this skill\nTo write internal communications, use this skill for:\n- 3P updates (Progress, Plans, Problems)\n- Company newsletters\n- FAQ responses\n- Status reports\n- Leadership updates\n- Project updates\n- Incident reports\n\n## How to use this skill\n\nTo write any internal communication:\n\n1. **Identify the communication type** from the request\n2. **Load the appropriate guideline file** from the `examples/` directory:\n    - `examples/3p-updates.md` - For Progress/Plans/Problems team updates\n    - `examples/company-newsletter.md` - For company-wide newsletters\n    - `examples/faq-answers.md` - For answering frequently asked questions\n    - `examples/general-comms.md` - For anything else that doesn't explicitly match one of the above\n3. **Follow the specific instructions** in that file for formatting, tone, and content gathering\n\nIf the communication type doesn't match any existing guideline, ask for clarification or more context about the desired format.\n\n## Keywords\n3P updates, company newsletter, company comms, weekly update, faqs, common questions, updates, internal comms\n"
      },
      "discovered_at": "2026-01-11T15:36:38.646814Z",
      "fetch_error": null
    },
    {
      "name": "mcp-builder",
      "slug": "mcp-builder",
      "source": "anthropic_official",
      "owner": "anthropics",
      "repo_name": "skills",
      "repository_url": "https://github.com/anthropics/skills",
      "skill_path": "skills/mcp-builder",
      "github_metadata": {
        "stars": 37534,
        "description": "Public repository for Agent Skills",
        "default_branch": "main",
        "pushed_at": "2025-12-20T18:09:45Z",
        "created_at": "2025-09-22T15:53:31Z",
        "language": "Python",
        "license": null,
        "open_issues": 137,
        "forks": 3406
      },
      "skill_md": {
        "found": true,
        "path": "skills/mcp-builder/SKILL.md",
        "branch": "main",
        "content": "---\nname: mcp-builder\ndescription: Guide for creating high-quality MCP (Model Context Protocol) servers that enable LLMs to interact with external services through well-designed tools. Use when building MCP servers to integrate external APIs or services, whether in Python (FastMCP) or Node/TypeScript (MCP SDK).\nlicense: Complete terms in LICENSE.txt\n---\n\n# MCP Server Development Guide\n\n## Overview\n\nCreate MCP (Model Context Protocol) servers that enable LLMs to interact with external services through well-designed tools. The quality of an MCP server is measured by how well it enables LLMs to accomplish real-world tasks.\n\n---\n\n# Process\n\n## ğŸš€ High-Level Workflow\n\nCreating a high-quality MCP server involves four main phases:\n\n### Phase 1: Deep Research and Planning\n\n#### 1.1 Understand Modern MCP Design\n\n**API Coverage vs. Workflow Tools:**\nBalance comprehensive API endpoint coverage with specialized workflow tools. Workflow tools can be more convenient for specific tasks, while comprehensive coverage gives agents flexibility to compose operations. Performance varies by clientâ€”some clients benefit from code execution that combines basic tools, while others work better with higher-level workflows. When uncertain, prioritize comprehensive API coverage.\n\n**Tool Naming and Discoverability:**\nClear, descriptive tool names help agents find the right tools quickly. Use consistent prefixes (e.g., `github_create_issue`, `github_list_repos`) and action-oriented naming.\n\n**Context Management:**\nAgents benefit from concise tool descriptions and the ability to filter/paginate results. Design tools that return focused, relevant data. Some clients support code execution which can help agents filter and process data efficiently.\n\n**Actionable Error Messages:**\nError messages should guide agents toward solutions with specific suggestions and next steps.\n\n#### 1.2 Study MCP Protocol Documentation\n\n**Navigate the MCP specification:**\n\nStart with the sitemap to find relevant pages: `https://modelcontextprotocol.io/sitemap.xml`\n\nThen fetch specific pages with `.md` suffix for markdown format (e.g., `https://modelcontextprotocol.io/specification/draft.md`).\n\nKey pages to review:\n- Specification overview and architecture\n- Transport mechanisms (streamable HTTP, stdio)\n- Tool, resource, and prompt definitions\n\n#### 1.3 Study Framework Documentation\n\n**Recommended stack:**\n- **Language**: TypeScript (high-quality SDK support and good compatibility in many execution environments e.g. MCPB. Plus AI models are good at generating TypeScript code, benefiting from its broad usage, static typing and good linting tools)\n- **Transport**: Streamable HTTP for remote servers, using stateless JSON (simpler to scale and maintain, as opposed to stateful sessions and streaming responses). stdio for local servers.\n\n**Load framework documentation:**\n\n- **MCP Best Practices**: [ğŸ“‹ View Best Practices](./reference/mcp_best_practices.md) - Core guidelines\n\n**For TypeScript (recommended):**\n- **TypeScript SDK**: Use WebFetch to load `https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/README.md`\n- [âš¡ TypeScript Guide](./reference/node_mcp_server.md) - TypeScript patterns and examples\n\n**For Python:**\n- **Python SDK**: Use WebFetch to load `https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/README.md`\n- [ğŸ Python Guide](./reference/python_mcp_server.md) - Python patterns and examples\n\n#### 1.4 Plan Your Implementation\n\n**Understand the API:**\nReview the service's API documentation to identify key endpoints, authentication requirements, and data models. Use web search and WebFetch as needed.\n\n**Tool Selection:**\nPrioritize comprehensive API coverage. List endpoints to implement, starting with the most common operations.\n\n---\n\n### Phase 2: Implementation\n\n#### 2.1 Set Up Project Structure\n\nSee language-specific guides for project setup:\n- [âš¡ TypeScript Guide](./reference/node_mcp_server.md) - Project structure, package.json, tsconfig.json\n- [ğŸ Python Guide](./reference/python_mcp_server.md) - Module organization, dependencies\n\n#### 2.2 Implement Core Infrastructure\n\nCreate shared utilities:\n- API client with authentication\n- Error handling helpers\n- Response formatting (JSON/Markdown)\n- Pagination support\n\n#### 2.3 Implement Tools\n\nFor each tool:\n\n**Input Schema:**\n- Use Zod (TypeScript) or Pydantic (Python)\n- Include constraints and clear descriptions\n- Add examples in field descriptions\n\n**Output Schema:**\n- Define `outputSchema` where possible for structured data\n- Use `structuredContent` in tool responses (TypeScript SDK feature)\n- Helps clients understand and process tool outputs\n\n**Tool Description:**\n- Concise summary of functionality\n- Parameter descriptions\n- Return type schema\n\n**Implementation:**\n- Async/await for I/O operations\n- Proper error handling with actionable messages\n- Support pagination where applicable\n- Return both text content and structured data when using modern SDKs\n\n**Annotations:**\n- `readOnlyHint`: true/false\n- `destructiveHint`: true/false\n- `idempotentHint`: true/false\n- `openWorldHint`: true/false\n\n---\n\n### Phase 3: Review and Test\n\n#### 3.1 Code Quality\n\nReview for:\n- No duplicated code (DRY principle)\n- Consistent error handling\n- Full type coverage\n- Clear tool descriptions\n\n#### 3.2 Build and Test\n\n**TypeScript:**\n- Run `npm run build` to verify compilation\n- Test with MCP Inspector: `npx @modelcontextprotocol/inspector`\n\n**Python:**\n- Verify syntax: `python -m py_compile your_server.py`\n- Test with MCP Inspector\n\nSee language-specific guides for detailed testing approaches and quality checklists.\n\n---\n\n### Phase 4: Create Evaluations\n\nAfter implementing your MCP server, create comprehensive evaluations to test its effectiveness.\n\n**Load [âœ… Evaluation Guide](./reference/evaluation.md) for complete evaluation guidelines.**\n\n#### 4.1 Understand Evaluation Purpose\n\nUse evaluations to test whether LLMs can effectively use your MCP server to answer realistic, complex questions.\n\n#### 4.2 Create 10 Evaluation Questions\n\nTo create effective evaluations, follow the process outlined in the evaluation guide:\n\n1. **Tool Inspection**: List available tools and understand their capabilities\n2. **Content Exploration**: Use READ-ONLY operations to explore available data\n3. **Question Generation**: Create 10 complex, realistic questions\n4. **Answer Verification**: Solve each question yourself to verify answers\n\n#### 4.3 Evaluation Requirements\n\nEnsure each question is:\n- **Independent**: Not dependent on other questions\n- **Read-only**: Only non-destructive operations required\n- **Complex**: Requiring multiple tool calls and deep exploration\n- **Realistic**: Based on real use cases humans would care about\n- **Verifiable**: Single, clear answer that can be verified by string comparison\n- **Stable**: Answer won't change over time\n\n#### 4.4 Output Format\n\nCreate an XML file with this structure:\n\n```xml\n<evaluation>\n  <qa_pair>\n    <question>Find discussions about AI model launches with animal codenames. One model needed a specific safety designation that uses the format ASL-X. What number X was being determined for the model named after a spotted wild cat?</question>\n    <answer>3</answer>\n  </qa_pair>\n<!-- More qa_pairs... -->\n</evaluation>\n```\n\n---\n\n# Reference Files\n\n## ğŸ“š Documentation Library\n\nLoad these resources as needed during development:\n\n### Core MCP Documentation (Load First)\n- **MCP Protocol**: Start with sitemap at `https://modelcontextprotocol.io/sitemap.xml`, then fetch specific pages with `.md` suffix\n- [ğŸ“‹ MCP Best Practices](./reference/mcp_best_practices.md) - Universal MCP guidelines including:\n  - Server and tool naming conventions\n  - Response format guidelines (JSON vs Markdown)\n  - Pagination best practices\n  - Transport selection (streamable HTTP vs stdio)\n  - Security and error handling standards\n\n### SDK Documentation (Load During Phase 1/2)\n- **Python SDK**: Fetch from `https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/README.md`\n- **TypeScript SDK**: Fetch from `https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/README.md`\n\n### Language-Specific Implementation Guides (Load During Phase 2)\n- [ğŸ Python Implementation Guide](./reference/python_mcp_server.md) - Complete Python/FastMCP guide with:\n  - Server initialization patterns\n  - Pydantic model examples\n  - Tool registration with `@mcp.tool`\n  - Complete working examples\n  - Quality checklist\n\n- [âš¡ TypeScript Implementation Guide](./reference/node_mcp_server.md) - Complete TypeScript guide with:\n  - Project structure\n  - Zod schema patterns\n  - Tool registration with `server.registerTool`\n  - Complete working examples\n  - Quality checklist\n\n### Evaluation Guide (Load During Phase 4)\n- [âœ… Evaluation Guide](./reference/evaluation.md) - Complete evaluation creation guide with:\n  - Question creation guidelines\n  - Answer verification strategies\n  - XML format specifications\n  - Example questions and answers\n  - Running an evaluation with the provided scripts\n"
      },
      "discovered_at": "2026-01-11T15:36:38.694762Z",
      "fetch_error": null
    },
    {
      "name": "pdf",
      "slug": "pdf",
      "source": "anthropic_official",
      "owner": "anthropics",
      "repo_name": "skills",
      "repository_url": "https://github.com/anthropics/skills",
      "skill_path": "skills/pdf",
      "github_metadata": {
        "stars": 37534,
        "description": "Public repository for Agent Skills",
        "default_branch": "main",
        "pushed_at": "2025-12-20T18:09:45Z",
        "created_at": "2025-09-22T15:53:31Z",
        "language": "Python",
        "license": null,
        "open_issues": 137,
        "forks": 3406
      },
      "skill_md": {
        "found": true,
        "path": "skills/pdf/SKILL.md",
        "branch": "main",
        "content": "---\nname: pdf\ndescription: Comprehensive PDF manipulation toolkit for extracting text and tables, creating new PDFs, merging/splitting documents, and handling forms. When Claude needs to fill in a PDF form or programmatically process, generate, or analyze PDF documents at scale.\nlicense: Proprietary. LICENSE.txt has complete terms\n---\n\n# PDF Processing Guide\n\n## Overview\n\nThis guide covers essential PDF processing operations using Python libraries and command-line tools. For advanced features, JavaScript libraries, and detailed examples, see reference.md. If you need to fill out a PDF form, read forms.md and follow its instructions.\n\n## Quick Start\n\n```python\nfrom pypdf import PdfReader, PdfWriter\n\n# Read a PDF\nreader = PdfReader(\"document.pdf\")\nprint(f\"Pages: {len(reader.pages)}\")\n\n# Extract text\ntext = \"\"\nfor page in reader.pages:\n    text += page.extract_text()\n```\n\n## Python Libraries\n\n### pypdf - Basic Operations\n\n#### Merge PDFs\n```python\nfrom pypdf import PdfWriter, PdfReader\n\nwriter = PdfWriter()\nfor pdf_file in [\"doc1.pdf\", \"doc2.pdf\", \"doc3.pdf\"]:\n    reader = PdfReader(pdf_file)\n    for page in reader.pages:\n        writer.add_page(page)\n\nwith open(\"merged.pdf\", \"wb\") as output:\n    writer.write(output)\n```\n\n#### Split PDF\n```python\nreader = PdfReader(\"input.pdf\")\nfor i, page in enumerate(reader.pages):\n    writer = PdfWriter()\n    writer.add_page(page)\n    with open(f\"page_{i+1}.pdf\", \"wb\") as output:\n        writer.write(output)\n```\n\n#### Extract Metadata\n```python\nreader = PdfReader(\"document.pdf\")\nmeta = reader.metadata\nprint(f\"Title: {meta.title}\")\nprint(f\"Author: {meta.author}\")\nprint(f\"Subject: {meta.subject}\")\nprint(f\"Creator: {meta.creator}\")\n```\n\n#### Rotate Pages\n```python\nreader = PdfReader(\"input.pdf\")\nwriter = PdfWriter()\n\npage = reader.pages[0]\npage.rotate(90)  # Rotate 90 degrees clockwise\nwriter.add_page(page)\n\nwith open(\"rotated.pdf\", \"wb\") as output:\n    writer.write(output)\n```\n\n### pdfplumber - Text and Table Extraction\n\n#### Extract Text with Layout\n```python\nimport pdfplumber\n\nwith pdfplumber.open(\"document.pdf\") as pdf:\n    for page in pdf.pages:\n        text = page.extract_text()\n        print(text)\n```\n\n#### Extract Tables\n```python\nwith pdfplumber.open(\"document.pdf\") as pdf:\n    for i, page in enumerate(pdf.pages):\n        tables = page.extract_tables()\n        for j, table in enumerate(tables):\n            print(f\"Table {j+1} on page {i+1}:\")\n            for row in table:\n                print(row)\n```\n\n#### Advanced Table Extraction\n```python\nimport pandas as pd\n\nwith pdfplumber.open(\"document.pdf\") as pdf:\n    all_tables = []\n    for page in pdf.pages:\n        tables = page.extract_tables()\n        for table in tables:\n            if table:  # Check if table is not empty\n                df = pd.DataFrame(table[1:], columns=table[0])\n                all_tables.append(df)\n\n# Combine all tables\nif all_tables:\n    combined_df = pd.concat(all_tables, ignore_index=True)\n    combined_df.to_excel(\"extracted_tables.xlsx\", index=False)\n```\n\n### reportlab - Create PDFs\n\n#### Basic PDF Creation\n```python\nfrom reportlab.lib.pagesizes import letter\nfrom reportlab.pdfgen import canvas\n\nc = canvas.Canvas(\"hello.pdf\", pagesize=letter)\nwidth, height = letter\n\n# Add text\nc.drawString(100, height - 100, \"Hello World!\")\nc.drawString(100, height - 120, \"This is a PDF created with reportlab\")\n\n# Add a line\nc.line(100, height - 140, 400, height - 140)\n\n# Save\nc.save()\n```\n\n#### Create PDF with Multiple Pages\n```python\nfrom reportlab.lib.pagesizes import letter\nfrom reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak\nfrom reportlab.lib.styles import getSampleStyleSheet\n\ndoc = SimpleDocTemplate(\"report.pdf\", pagesize=letter)\nstyles = getSampleStyleSheet()\nstory = []\n\n# Add content\ntitle = Paragraph(\"Report Title\", styles['Title'])\nstory.append(title)\nstory.append(Spacer(1, 12))\n\nbody = Paragraph(\"This is the body of the report. \" * 20, styles['Normal'])\nstory.append(body)\nstory.append(PageBreak())\n\n# Page 2\nstory.append(Paragraph(\"Page 2\", styles['Heading1']))\nstory.append(Paragraph(\"Content for page 2\", styles['Normal']))\n\n# Build PDF\ndoc.build(story)\n```\n\n## Command-Line Tools\n\n### pdftotext (poppler-utils)\n```bash\n# Extract text\npdftotext input.pdf output.txt\n\n# Extract text preserving layout\npdftotext -layout input.pdf output.txt\n\n# Extract specific pages\npdftotext -f 1 -l 5 input.pdf output.txt  # Pages 1-5\n```\n\n### qpdf\n```bash\n# Merge PDFs\nqpdf --empty --pages file1.pdf file2.pdf -- merged.pdf\n\n# Split pages\nqpdf input.pdf --pages . 1-5 -- pages1-5.pdf\nqpdf input.pdf --pages . 6-10 -- pages6-10.pdf\n\n# Rotate pages\nqpdf input.pdf output.pdf --rotate=+90:1  # Rotate page 1 by 90 degrees\n\n# Remove password\nqpdf --password=mypassword --decrypt encrypted.pdf decrypted.pdf\n```\n\n### pdftk (if available)\n```bash\n# Merge\npdftk file1.pdf file2.pdf cat output merged.pdf\n\n# Split\npdftk input.pdf burst\n\n# Rotate\npdftk input.pdf rotate 1east output rotated.pdf\n```\n\n## Common Tasks\n\n### Extract Text from Scanned PDFs\n```python\n# Requires: pip install pytesseract pdf2image\nimport pytesseract\nfrom pdf2image import convert_from_path\n\n# Convert PDF to images\nimages = convert_from_path('scanned.pdf')\n\n# OCR each page\ntext = \"\"\nfor i, image in enumerate(images):\n    text += f\"Page {i+1}:\\n\"\n    text += pytesseract.image_to_string(image)\n    text += \"\\n\\n\"\n\nprint(text)\n```\n\n### Add Watermark\n```python\nfrom pypdf import PdfReader, PdfWriter\n\n# Create watermark (or load existing)\nwatermark = PdfReader(\"watermark.pdf\").pages[0]\n\n# Apply to all pages\nreader = PdfReader(\"document.pdf\")\nwriter = PdfWriter()\n\nfor page in reader.pages:\n    page.merge_page(watermark)\n    writer.add_page(page)\n\nwith open(\"watermarked.pdf\", \"wb\") as output:\n    writer.write(output)\n```\n\n### Extract Images\n```bash\n# Using pdfimages (poppler-utils)\npdfimages -j input.pdf output_prefix\n\n# This extracts all images as output_prefix-000.jpg, output_prefix-001.jpg, etc.\n```\n\n### Password Protection\n```python\nfrom pypdf import PdfReader, PdfWriter\n\nreader = PdfReader(\"input.pdf\")\nwriter = PdfWriter()\n\nfor page in reader.pages:\n    writer.add_page(page)\n\n# Add password\nwriter.encrypt(\"userpassword\", \"ownerpassword\")\n\nwith open(\"encrypted.pdf\", \"wb\") as output:\n    writer.write(output)\n```\n\n## Quick Reference\n\n| Task | Best Tool | Command/Code |\n|------|-----------|--------------|\n| Merge PDFs | pypdf | `writer.add_page(page)` |\n| Split PDFs | pypdf | One page per file |\n| Extract text | pdfplumber | `page.extract_text()` |\n| Extract tables | pdfplumber | `page.extract_tables()` |\n| Create PDFs | reportlab | Canvas or Platypus |\n| Command line merge | qpdf | `qpdf --empty --pages ...` |\n| OCR scanned PDFs | pytesseract | Convert to image first |\n| Fill PDF forms | pdf-lib or pypdf (see forms.md) | See forms.md |\n\n## Next Steps\n\n- For advanced pypdfium2 usage, see reference.md\n- For JavaScript libraries (pdf-lib), see reference.md\n- If you need to fill out a PDF form, follow the instructions in forms.md\n- For troubleshooting guides, see reference.md\n"
      },
      "discovered_at": "2026-01-11T15:36:38.842178Z",
      "fetch_error": null
    },
    {
      "name": "pptx",
      "slug": "pptx",
      "source": "anthropic_official",
      "owner": "anthropics",
      "repo_name": "skills",
      "repository_url": "https://github.com/anthropics/skills",
      "skill_path": "skills/pptx",
      "github_metadata": {
        "stars": 37534,
        "description": "Public repository for Agent Skills",
        "default_branch": "main",
        "pushed_at": "2025-12-20T18:09:45Z",
        "created_at": "2025-09-22T15:53:31Z",
        "language": "Python",
        "license": null,
        "open_issues": 137,
        "forks": 3406
      },
      "skill_md": {
        "found": true,
        "path": "skills/pptx/SKILL.md",
        "branch": "main",
        "content": "---\nname: pptx\ndescription: \"Presentation creation, editing, and analysis. When Claude needs to work with presentations (.pptx files) for: (1) Creating new presentations, (2) Modifying or editing content, (3) Working with layouts, (4) Adding comments or speaker notes, or any other presentation tasks\"\nlicense: Proprietary. LICENSE.txt has complete terms\n---\n\n# PPTX creation, editing, and analysis\n\n## Overview\n\nA user may ask you to create, edit, or analyze the contents of a .pptx file. A .pptx file is essentially a ZIP archive containing XML files and other resources that you can read or edit. You have different tools and workflows available for different tasks.\n\n## Reading and analyzing content\n\n### Text extraction\nIf you just need to read the text contents of a presentation, you should convert the document to markdown:\n\n```bash\n# Convert document to markdown\npython -m markitdown path-to-file.pptx\n```\n\n### Raw XML access\nYou need raw XML access for: comments, speaker notes, slide layouts, animations, design elements, and complex formatting. For any of these features, you'll need to unpack a presentation and read its raw XML contents.\n\n#### Unpacking a file\n`python ooxml/scripts/unpack.py <office_file> <output_dir>`\n\n**Note**: The unpack.py script is located at `skills/pptx/ooxml/scripts/unpack.py` relative to the project root. If the script doesn't exist at this path, use `find . -name \"unpack.py\"` to locate it.\n\n#### Key file structures\n* `ppt/presentation.xml` - Main presentation metadata and slide references\n* `ppt/slides/slide{N}.xml` - Individual slide contents (slide1.xml, slide2.xml, etc.)\n* `ppt/notesSlides/notesSlide{N}.xml` - Speaker notes for each slide\n* `ppt/comments/modernComment_*.xml` - Comments for specific slides\n* `ppt/slideLayouts/` - Layout templates for slides\n* `ppt/slideMasters/` - Master slide templates\n* `ppt/theme/` - Theme and styling information\n* `ppt/media/` - Images and other media files\n\n#### Typography and color extraction\n**When given an example design to emulate**: Always analyze the presentation's typography and colors first using the methods below:\n1. **Read theme file**: Check `ppt/theme/theme1.xml` for colors (`<a:clrScheme>`) and fonts (`<a:fontScheme>`)\n2. **Sample slide content**: Examine `ppt/slides/slide1.xml` for actual font usage (`<a:rPr>`) and colors\n3. **Search for patterns**: Use grep to find color (`<a:solidFill>`, `<a:srgbClr>`) and font references across all XML files\n\n## Creating a new PowerPoint presentation **without a template**\n\nWhen creating a new PowerPoint presentation from scratch, use the **html2pptx** workflow to convert HTML slides to PowerPoint with accurate positioning.\n\n### Design Principles\n\n**CRITICAL**: Before creating any presentation, analyze the content and choose appropriate design elements:\n1. **Consider the subject matter**: What is this presentation about? What tone, industry, or mood does it suggest?\n2. **Check for branding**: If the user mentions a company/organization, consider their brand colors and identity\n3. **Match palette to content**: Select colors that reflect the subject\n4. **State your approach**: Explain your design choices before writing code\n\n**Requirements**:\n- âœ… State your content-informed design approach BEFORE writing code\n- âœ… Use web-safe fonts only: Arial, Helvetica, Times New Roman, Georgia, Courier New, Verdana, Tahoma, Trebuchet MS, Impact\n- âœ… Create clear visual hierarchy through size, weight, and color\n- âœ… Ensure readability: strong contrast, appropriately sized text, clean alignment\n- âœ… Be consistent: repeat patterns, spacing, and visual language across slides\n\n#### Color Palette Selection\n\n**Choosing colors creatively**:\n- **Think beyond defaults**: What colors genuinely match this specific topic? Avoid autopilot choices.\n- **Consider multiple angles**: Topic, industry, mood, energy level, target audience, brand identity (if mentioned)\n- **Be adventurous**: Try unexpected combinations - a healthcare presentation doesn't have to be green, finance doesn't have to be navy\n- **Build your palette**: Pick 3-5 colors that work together (dominant colors + supporting tones + accent)\n- **Ensure contrast**: Text must be clearly readable on backgrounds\n\n**Example color palettes** (use these to spark creativity - choose one, adapt it, or create your own):\n\n1. **Classic Blue**: Deep navy (#1C2833), slate gray (#2E4053), silver (#AAB7B8), off-white (#F4F6F6)\n2. **Teal & Coral**: Teal (#5EA8A7), deep teal (#277884), coral (#FE4447), white (#FFFFFF)\n3. **Bold Red**: Red (#C0392B), bright red (#E74C3C), orange (#F39C12), yellow (#F1C40F), green (#2ECC71)\n4. **Warm Blush**: Mauve (#A49393), blush (#EED6D3), rose (#E8B4B8), cream (#FAF7F2)\n5. **Burgundy Luxury**: Burgundy (#5D1D2E), crimson (#951233), rust (#C15937), gold (#997929)\n6. **Deep Purple & Emerald**: Purple (#B165FB), dark blue (#181B24), emerald (#40695B), white (#FFFFFF)\n7. **Cream & Forest Green**: Cream (#FFE1C7), forest green (#40695B), white (#FCFCFC)\n8. **Pink & Purple**: Pink (#F8275B), coral (#FF574A), rose (#FF737D), purple (#3D2F68)\n9. **Lime & Plum**: Lime (#C5DE82), plum (#7C3A5F), coral (#FD8C6E), blue-gray (#98ACB5)\n10. **Black & Gold**: Gold (#BF9A4A), black (#000000), cream (#F4F6F6)\n11. **Sage & Terracotta**: Sage (#87A96B), terracotta (#E07A5F), cream (#F4F1DE), charcoal (#2C2C2C)\n12. **Charcoal & Red**: Charcoal (#292929), red (#E33737), light gray (#CCCBCB)\n13. **Vibrant Orange**: Orange (#F96D00), light gray (#F2F2F2), charcoal (#222831)\n14. **Forest Green**: Black (#191A19), green (#4E9F3D), dark green (#1E5128), white (#FFFFFF)\n15. **Retro Rainbow**: Purple (#722880), pink (#D72D51), orange (#EB5C18), amber (#F08800), gold (#DEB600)\n16. **Vintage Earthy**: Mustard (#E3B448), sage (#CBD18F), forest green (#3A6B35), cream (#F4F1DE)\n17. **Coastal Rose**: Old rose (#AD7670), beaver (#B49886), eggshell (#F3ECDC), ash gray (#BFD5BE)\n18. **Orange & Turquoise**: Light orange (#FC993E), grayish turquoise (#667C6F), white (#FCFCFC)\n\n#### Visual Details Options\n\n**Geometric Patterns**:\n- Diagonal section dividers instead of horizontal\n- Asymmetric column widths (30/70, 40/60, 25/75)\n- Rotated text headers at 90Â° or 270Â°\n- Circular/hexagonal frames for images\n- Triangular accent shapes in corners\n- Overlapping shapes for depth\n\n**Border & Frame Treatments**:\n- Thick single-color borders (10-20pt) on one side only\n- Double-line borders with contrasting colors\n- Corner brackets instead of full frames\n- L-shaped borders (top+left or bottom+right)\n- Underline accents beneath headers (3-5pt thick)\n\n**Typography Treatments**:\n- Extreme size contrast (72pt headlines vs 11pt body)\n- All-caps headers with wide letter spacing\n- Numbered sections in oversized display type\n- Monospace (Courier New) for data/stats/technical content\n- Condensed fonts (Arial Narrow) for dense information\n- Outlined text for emphasis\n\n**Chart & Data Styling**:\n- Monochrome charts with single accent color for key data\n- Horizontal bar charts instead of vertical\n- Dot plots instead of bar charts\n- Minimal gridlines or none at all\n- Data labels directly on elements (no legends)\n- Oversized numbers for key metrics\n\n**Layout Innovations**:\n- Full-bleed images with text overlays\n- Sidebar column (20-30% width) for navigation/context\n- Modular grid systems (3Ã—3, 4Ã—4 blocks)\n- Z-pattern or F-pattern content flow\n- Floating text boxes over colored shapes\n- Magazine-style multi-column layouts\n\n**Background Treatments**:\n- Solid color blocks occupying 40-60% of slide\n- Gradient fills (vertical or diagonal only)\n- Split backgrounds (two colors, diagonal or vertical)\n- Edge-to-edge color bands\n- Negative space as a design element\n\n### Layout Tips\n**When creating slides with charts or tables:**\n- **Two-column layout (PREFERRED)**: Use a header spanning the full width, then two columns below - text/bullets in one column and the featured content in the other. This provides better balance and makes charts/tables more readable. Use flexbox with unequal column widths (e.g., 40%/60% split) to optimize space for each content type.\n- **Full-slide layout**: Let the featured content (chart/table) take up the entire slide for maximum impact and readability\n- **NEVER vertically stack**: Do not place charts/tables below text in a single column - this causes poor readability and layout issues\n\n### Workflow\n1. **MANDATORY - READ ENTIRE FILE**: Read [`html2pptx.md`](html2pptx.md) completely from start to finish. **NEVER set any range limits when reading this file.** Read the full file content for detailed syntax, critical formatting rules, and best practices before proceeding with presentation creation.\n2. Create an HTML file for each slide with proper dimensions (e.g., 720pt Ã— 405pt for 16:9)\n   - Use `<p>`, `<h1>`-`<h6>`, `<ul>`, `<ol>` for all text content\n   - Use `class=\"placeholder\"` for areas where charts/tables will be added (render with gray background for visibility)\n   - **CRITICAL**: Rasterize gradients and icons as PNG images FIRST using Sharp, then reference in HTML\n   - **LAYOUT**: For slides with charts/tables/images, use either full-slide layout or two-column layout for better readability\n3. Create and run a JavaScript file using the [`html2pptx.js`](scripts/html2pptx.js) library to convert HTML slides to PowerPoint and save the presentation\n   - Use the `html2pptx()` function to process each HTML file\n   - Add charts and tables to placeholder areas using PptxGenJS API\n   - Save the presentation using `pptx.writeFile()`\n4. **Visual validation**: Generate thumbnails and inspect for layout issues\n   - Create thumbnail grid: `python scripts/thumbnail.py output.pptx workspace/thumbnails --cols 4`\n   - Read and carefully examine the thumbnail image for:\n     - **Text cutoff**: Text being cut off by header bars, shapes, or slide edges\n     - **Text overlap**: Text overlapping with other text or shapes\n     - **Positioning issues**: Content too close to slide boundaries or other elements\n     - **Contrast issues**: Insufficient contrast between text and backgrounds\n   - If issues found, adjust HTML margins/spacing/colors and regenerate the presentation\n   - Repeat until all slides are visually correct\n\n## Editing an existing PowerPoint presentation\n\nWhen edit slides in an existing PowerPoint presentation, you need to work with the raw Office Open XML (OOXML) format. This involves unpacking the .pptx file, editing the XML content, and repacking it.\n\n### Workflow\n1. **MANDATORY - READ ENTIRE FILE**: Read [`ooxml.md`](ooxml.md) (~500 lines) completely from start to finish.  **NEVER set any range limits when reading this file.**  Read the full file content for detailed guidance on OOXML structure and editing workflows before any presentation editing.\n2. Unpack the presentation: `python ooxml/scripts/unpack.py <office_file> <output_dir>`\n3. Edit the XML files (primarily `ppt/slides/slide{N}.xml` and related files)\n4. **CRITICAL**: Validate immediately after each edit and fix any validation errors before proceeding: `python ooxml/scripts/validate.py <dir> --original <file>`\n5. Pack the final presentation: `python ooxml/scripts/pack.py <input_directory> <office_file>`\n\n## Creating a new PowerPoint presentation **using a template**\n\nWhen you need to create a presentation that follows an existing template's design, you'll need to duplicate and re-arrange template slides before then replacing placeholder context.\n\n### Workflow\n1. **Extract template text AND create visual thumbnail grid**:\n   * Extract text: `python -m markitdown template.pptx > template-content.md`\n   * Read `template-content.md`: Read the entire file to understand the contents of the template presentation. **NEVER set any range limits when reading this file.**\n   * Create thumbnail grids: `python scripts/thumbnail.py template.pptx`\n   * See [Creating Thumbnail Grids](#creating-thumbnail-grids) section for more details\n\n2. **Analyze template and save inventory to a file**:\n   * **Visual Analysis**: Review thumbnail grid(s) to understand slide layouts, design patterns, and visual structure\n   * Create and save a template inventory file at `template-inventory.md` containing:\n     ```markdown\n     # Template Inventory Analysis\n     **Total Slides: [count]**\n     **IMPORTANT: Slides are 0-indexed (first slide = 0, last slide = count-1)**\n\n     ## [Category Name]\n     - Slide 0: [Layout code if available] - Description/purpose\n     - Slide 1: [Layout code] - Description/purpose\n     - Slide 2: [Layout code] - Description/purpose\n     [... EVERY slide must be listed individually with its index ...]\n     ```\n   * **Using the thumbnail grid**: Reference the visual thumbnails to identify:\n     - Layout patterns (title slides, content layouts, section dividers)\n     - Image placeholder locations and counts\n     - Design consistency across slide groups\n     - Visual hierarchy and structure\n   * This inventory file is REQUIRED for selecting appropriate templates in the next step\n\n3. **Create presentation outline based on template inventory**:\n   * Review available templates from step 2.\n   * Choose an intro or title template for the first slide. This should be one of the first templates.\n   * Choose safe, text-based layouts for the other slides.\n   * **CRITICAL: Match layout structure to actual content**:\n     - Single-column layouts: Use for unified narrative or single topic\n     - Two-column layouts: Use ONLY when you have exactly 2 distinct items/concepts\n     - Three-column layouts: Use ONLY when you have exactly 3 distinct items/concepts\n     - Image + text layouts: Use ONLY when you have actual images to insert\n     - Quote layouts: Use ONLY for actual quotes from people (with attribution), never for emphasis\n     - Never use layouts with more placeholders than you have content\n     - If you have 2 items, don't force them into a 3-column layout\n     - If you have 4+ items, consider breaking into multiple slides or using a list format\n   * Count your actual content pieces BEFORE selecting the layout\n   * Verify each placeholder in the chosen layout will be filled with meaningful content\n   * Select one option representing the **best** layout for each content section.\n   * Save `outline.md` with content AND template mapping that leverages available designs\n   * Example template mapping:\n      ```\n      # Template slides to use (0-based indexing)\n      # WARNING: Verify indices are within range! Template with 73 slides has indices 0-72\n      # Mapping: slide numbers from outline -> template slide indices\n      template_mapping = [\n          0,   # Use slide 0 (Title/Cover)\n          34,  # Use slide 34 (B1: Title and body)\n          34,  # Use slide 34 again (duplicate for second B1)\n          50,  # Use slide 50 (E1: Quote)\n          54,  # Use slide 54 (F2: Closing + Text)\n      ]\n      ```\n\n4. **Duplicate, reorder, and delete slides using `rearrange.py`**:\n   * Use the `scripts/rearrange.py` script to create a new presentation with slides in the desired order:\n     ```bash\n     python scripts/rearrange.py template.pptx working.pptx 0,34,34,50,52\n     ```\n   * The script handles duplicating repeated slides, deleting unused slides, and reordering automatically\n   * Slide indices are 0-based (first slide is 0, second is 1, etc.)\n   * The same slide index can appear multiple times to duplicate that slide\n\n5. **Extract ALL text using the `inventory.py` script**:\n   * **Run inventory extraction**:\n     ```bash\n     python scripts/inventory.py working.pptx text-inventory.json\n     ```\n   * **Read text-inventory.json**: Read the entire text-inventory.json file to understand all shapes and their properties. **NEVER set any range limits when reading this file.**\n\n   * The inventory JSON structure:\n      ```json\n        {\n          \"slide-0\": {\n            \"shape-0\": {\n              \"placeholder_type\": \"TITLE\",  // or null for non-placeholders\n              \"left\": 1.5,                  // position in inches\n              \"top\": 2.0,\n              \"width\": 7.5,\n              \"height\": 1.2,\n              \"paragraphs\": [\n                {\n                  \"text\": \"Paragraph text\",\n                  // Optional properties (only included when non-default):\n                  \"bullet\": true,           // explicit bullet detected\n                  \"level\": 0,               // only included when bullet is true\n                  \"alignment\": \"CENTER\",    // CENTER, RIGHT (not LEFT)\n                  \"space_before\": 10.0,     // space before paragraph in points\n                  \"space_after\": 6.0,       // space after paragraph in points\n                  \"line_spacing\": 22.4,     // line spacing in points\n                  \"font_name\": \"Arial\",     // from first run\n                  \"font_size\": 14.0,        // in points\n                  \"bold\": true,\n                  \"italic\": false,\n                  \"underline\": false,\n                  \"color\": \"FF0000\"         // RGB color\n                }\n              ]\n            }\n          }\n        }\n      ```\n\n   * Key features:\n     - **Slides**: Named as \"slide-0\", \"slide-1\", etc.\n     - **Shapes**: Ordered by visual position (top-to-bottom, left-to-right) as \"shape-0\", \"shape-1\", etc.\n     - **Placeholder types**: TITLE, CENTER_TITLE, SUBTITLE, BODY, OBJECT, or null\n     - **Default font size**: `default_font_size` in points extracted from layout placeholders (when available)\n     - **Slide numbers are filtered**: Shapes with SLIDE_NUMBER placeholder type are automatically excluded from inventory\n     - **Bullets**: When `bullet: true`, `level` is always included (even if 0)\n     - **Spacing**: `space_before`, `space_after`, and `line_spacing` in points (only included when set)\n     - **Colors**: `color` for RGB (e.g., \"FF0000\"), `theme_color` for theme colors (e.g., \"DARK_1\")\n     - **Properties**: Only non-default values are included in the output\n\n6. **Generate replacement text and save the data to a JSON file**\n   Based on the text inventory from the previous step:\n   - **CRITICAL**: First verify which shapes exist in the inventory - only reference shapes that are actually present\n   - **VALIDATION**: The replace.py script will validate that all shapes in your replacement JSON exist in the inventory\n     - If you reference a non-existent shape, you'll get an error showing available shapes\n     - If you reference a non-existent slide, you'll get an error indicating the slide doesn't exist\n     - All validation errors are shown at once before the script exits\n   - **IMPORTANT**: The replace.py script uses inventory.py internally to identify ALL text shapes\n   - **AUTOMATIC CLEARING**: ALL text shapes from the inventory will be cleared unless you provide \"paragraphs\" for them\n   - Add a \"paragraphs\" field to shapes that need content (not \"replacement_paragraphs\")\n   - Shapes without \"paragraphs\" in the replacement JSON will have their text cleared automatically\n   - Paragraphs with bullets will be automatically left aligned. Don't set the `alignment` property on when `\"bullet\": true`\n   - Generate appropriate replacement content for placeholder text\n   - Use shape size to determine appropriate content length\n   - **CRITICAL**: Include paragraph properties from the original inventory - don't just provide text\n   - **IMPORTANT**: When bullet: true, do NOT include bullet symbols (â€¢, -, *) in text - they're added automatically\n   - **ESSENTIAL FORMATTING RULES**:\n     - Headers/titles should typically have `\"bold\": true`\n     - List items should have `\"bullet\": true, \"level\": 0` (level is required when bullet is true)\n     - Preserve any alignment properties (e.g., `\"alignment\": \"CENTER\"` for centered text)\n     - Include font properties when different from default (e.g., `\"font_size\": 14.0`, `\"font_name\": \"Lora\"`)\n     - Colors: Use `\"color\": \"FF0000\"` for RGB or `\"theme_color\": \"DARK_1\"` for theme colors\n     - The replacement script expects **properly formatted paragraphs**, not just text strings\n     - **Overlapping shapes**: Prefer shapes with larger default_font_size or more appropriate placeholder_type\n   - Save the updated inventory with replacements to `replacement-text.json`\n   - **WARNING**: Different template layouts have different shape counts - always check the actual inventory before creating replacements\n\n   Example paragraphs field showing proper formatting:\n   ```json\n   \"paragraphs\": [\n     {\n       \"text\": \"New presentation title text\",\n       \"alignment\": \"CENTER\",\n       \"bold\": true\n     },\n     {\n       \"text\": \"Section Header\",\n       \"bold\": true\n     },\n     {\n       \"text\": \"First bullet point without bullet symbol\",\n       \"bullet\": true,\n       \"level\": 0\n     },\n     {\n       \"text\": \"Red colored text\",\n       \"color\": \"FF0000\"\n     },\n     {\n       \"text\": \"Theme colored text\",\n       \"theme_color\": \"DARK_1\"\n     },\n     {\n       \"text\": \"Regular paragraph text without special formatting\"\n     }\n   ]\n   ```\n\n   **Shapes not listed in the replacement JSON are automatically cleared**:\n   ```json\n   {\n     \"slide-0\": {\n       \"shape-0\": {\n         \"paragraphs\": [...] // This shape gets new text\n       }\n       // shape-1 and shape-2 from inventory will be cleared automatically\n     }\n   }\n   ```\n\n   **Common formatting patterns for presentations**:\n   - Title slides: Bold text, sometimes centered\n   - Section headers within slides: Bold text\n   - Bullet lists: Each item needs `\"bullet\": true, \"level\": 0`\n   - Body text: Usually no special properties needed\n   - Quotes: May have special alignment or font properties\n\n7. **Apply replacements using the `replace.py` script**\n   ```bash\n   python scripts/replace.py working.pptx replacement-text.json output.pptx\n   ```\n\n   The script will:\n   - First extract the inventory of ALL text shapes using functions from inventory.py\n   - Validate that all shapes in the replacement JSON exist in the inventory\n   - Clear text from ALL shapes identified in the inventory\n   - Apply new text only to shapes with \"paragraphs\" defined in the replacement JSON\n   - Preserve formatting by applying paragraph properties from the JSON\n   - Handle bullets, alignment, font properties, and colors automatically\n   - Save the updated presentation\n\n   Example validation errors:\n   ```\n   ERROR: Invalid shapes in replacement JSON:\n     - Shape 'shape-99' not found on 'slide-0'. Available shapes: shape-0, shape-1, shape-4\n     - Slide 'slide-999' not found in inventory\n   ```\n\n   ```\n   ERROR: Replacement text made overflow worse in these shapes:\n     - slide-0/shape-2: overflow worsened by 1.25\" (was 0.00\", now 1.25\")\n   ```\n\n## Creating Thumbnail Grids\n\nTo create visual thumbnail grids of PowerPoint slides for quick analysis and reference:\n\n```bash\npython scripts/thumbnail.py template.pptx [output_prefix]\n```\n\n**Features**:\n- Creates: `thumbnails.jpg` (or `thumbnails-1.jpg`, `thumbnails-2.jpg`, etc. for large decks)\n- Default: 5 columns, max 30 slides per grid (5Ã—6)\n- Custom prefix: `python scripts/thumbnail.py template.pptx my-grid`\n  - Note: The output prefix should include the path if you want output in a specific directory (e.g., `workspace/my-grid`)\n- Adjust columns: `--cols 4` (range: 3-6, affects slides per grid)\n- Grid limits: 3 cols = 12 slides/grid, 4 cols = 20, 5 cols = 30, 6 cols = 42\n- Slides are zero-indexed (Slide 0, Slide 1, etc.)\n\n**Use cases**:\n- Template analysis: Quickly understand slide layouts and design patterns\n- Content review: Visual overview of entire presentation\n- Navigation reference: Find specific slides by their visual appearance\n- Quality check: Verify all slides are properly formatted\n\n**Examples**:\n```bash\n# Basic usage\npython scripts/thumbnail.py presentation.pptx\n\n# Combine options: custom name, columns\npython scripts/thumbnail.py template.pptx analysis --cols 4\n```\n\n## Converting Slides to Images\n\nTo visually analyze PowerPoint slides, convert them to images using a two-step process:\n\n1. **Convert PPTX to PDF**:\n   ```bash\n   soffice --headless --convert-to pdf template.pptx\n   ```\n\n2. **Convert PDF pages to JPEG images**:\n   ```bash\n   pdftoppm -jpeg -r 150 template.pdf slide\n   ```\n   This creates files like `slide-1.jpg`, `slide-2.jpg`, etc.\n\nOptions:\n- `-r 150`: Sets resolution to 150 DPI (adjust for quality/size balance)\n- `-jpeg`: Output JPEG format (use `-png` for PNG if preferred)\n- `-f N`: First page to convert (e.g., `-f 2` starts from page 2)\n- `-l N`: Last page to convert (e.g., `-l 5` stops at page 5)\n- `slide`: Prefix for output files\n\nExample for specific range:\n```bash\npdftoppm -jpeg -r 150 -f 2 -l 5 template.pdf slide  # Converts only pages 2-5\n```\n\n## Code Style Guidelines\n**IMPORTANT**: When generating code for PPTX operations:\n- Write concise code\n- Avoid verbose variable names and redundant operations\n- Avoid unnecessary print statements\n\n## Dependencies\n\nRequired dependencies (should already be installed):\n\n- **markitdown**: `pip install \"markitdown[pptx]\"` (for text extraction from presentations)\n- **pptxgenjs**: `npm install -g pptxgenjs` (for creating presentations via html2pptx)\n- **playwright**: `npm install -g playwright` (for HTML rendering in html2pptx)\n- **react-icons**: `npm install -g react-icons react react-dom` (for icons)\n- **sharp**: `npm install -g sharp` (for SVG rasterization and image processing)\n- **LibreOffice**: `sudo apt-get install libreoffice` (for PDF conversion)\n- **Poppler**: `sudo apt-get install poppler-utils` (for pdftoppm to convert PDF to images)\n- **defusedxml**: `pip install defusedxml` (for secure XML parsing)"
      },
      "discovered_at": "2026-01-11T15:36:38.990725Z",
      "fetch_error": null
    },
    {
      "name": "skill-creator",
      "slug": "skill-creator",
      "source": "anthropic_official",
      "owner": "anthropics",
      "repo_name": "skills",
      "repository_url": "https://github.com/anthropics/skills",
      "skill_path": "skills/skill-creator",
      "github_metadata": {
        "stars": 37534,
        "description": "Public repository for Agent Skills",
        "default_branch": "main",
        "pushed_at": "2025-12-20T18:09:45Z",
        "created_at": "2025-09-22T15:53:31Z",
        "language": "Python",
        "license": null,
        "open_issues": 137,
        "forks": 3406
      },
      "skill_md": {
        "found": true,
        "path": "skills/skill-creator/SKILL.md",
        "branch": "main",
        "content": "---\nname: skill-creator\ndescription: Guide for creating effective skills. This skill should be used when users want to create a new skill (or update an existing skill) that extends Claude's capabilities with specialized knowledge, workflows, or tool integrations.\nlicense: Complete terms in LICENSE.txt\n---\n\n# Skill Creator\n\nThis skill provides guidance for creating effective skills.\n\n## About Skills\n\nSkills are modular, self-contained packages that extend Claude's capabilities by providing\nspecialized knowledge, workflows, and tools. Think of them as \"onboarding guides\" for specific\ndomains or tasksâ€”they transform Claude from a general-purpose agent into a specialized agent\nequipped with procedural knowledge that no model can fully possess.\n\n### What Skills Provide\n\n1. Specialized workflows - Multi-step procedures for specific domains\n2. Tool integrations - Instructions for working with specific file formats or APIs\n3. Domain expertise - Company-specific knowledge, schemas, business logic\n4. Bundled resources - Scripts, references, and assets for complex and repetitive tasks\n\n## Core Principles\n\n### Concise is Key\n\nThe context window is a public good. Skills share the context window with everything else Claude needs: system prompt, conversation history, other Skills' metadata, and the actual user request.\n\n**Default assumption: Claude is already very smart.** Only add context Claude doesn't already have. Challenge each piece of information: \"Does Claude really need this explanation?\" and \"Does this paragraph justify its token cost?\"\n\nPrefer concise examples over verbose explanations.\n\n### Set Appropriate Degrees of Freedom\n\nMatch the level of specificity to the task's fragility and variability:\n\n**High freedom (text-based instructions)**: Use when multiple approaches are valid, decisions depend on context, or heuristics guide the approach.\n\n**Medium freedom (pseudocode or scripts with parameters)**: Use when a preferred pattern exists, some variation is acceptable, or configuration affects behavior.\n\n**Low freedom (specific scripts, few parameters)**: Use when operations are fragile and error-prone, consistency is critical, or a specific sequence must be followed.\n\nThink of Claude as exploring a path: a narrow bridge with cliffs needs specific guardrails (low freedom), while an open field allows many routes (high freedom).\n\n### Anatomy of a Skill\n\nEvery skill consists of a required SKILL.md file and optional bundled resources:\n\n```\nskill-name/\nâ”œâ”€â”€ SKILL.md (required)\nâ”‚   â”œâ”€â”€ YAML frontmatter metadata (required)\nâ”‚   â”‚   â”œâ”€â”€ name: (required)\nâ”‚   â”‚   â””â”€â”€ description: (required)\nâ”‚   â””â”€â”€ Markdown instructions (required)\nâ””â”€â”€ Bundled Resources (optional)\n    â”œâ”€â”€ scripts/          - Executable code (Python/Bash/etc.)\n    â”œâ”€â”€ references/       - Documentation intended to be loaded into context as needed\n    â””â”€â”€ assets/           - Files used in output (templates, icons, fonts, etc.)\n```\n\n#### SKILL.md (required)\n\nEvery SKILL.md consists of:\n\n- **Frontmatter** (YAML): Contains `name` and `description` fields. These are the only fields that Claude reads to determine when the skill gets used, thus it is very important to be clear and comprehensive in describing what the skill is, and when it should be used.\n- **Body** (Markdown): Instructions and guidance for using the skill. Only loaded AFTER the skill triggers (if at all).\n\n#### Bundled Resources (optional)\n\n##### Scripts (`scripts/`)\n\nExecutable code (Python/Bash/etc.) for tasks that require deterministic reliability or are repeatedly rewritten.\n\n- **When to include**: When the same code is being rewritten repeatedly or deterministic reliability is needed\n- **Example**: `scripts/rotate_pdf.py` for PDF rotation tasks\n- **Benefits**: Token efficient, deterministic, may be executed without loading into context\n- **Note**: Scripts may still need to be read by Claude for patching or environment-specific adjustments\n\n##### References (`references/`)\n\nDocumentation and reference material intended to be loaded as needed into context to inform Claude's process and thinking.\n\n- **When to include**: For documentation that Claude should reference while working\n- **Examples**: `references/finance.md` for financial schemas, `references/mnda.md` for company NDA template, `references/policies.md` for company policies, `references/api_docs.md` for API specifications\n- **Use cases**: Database schemas, API documentation, domain knowledge, company policies, detailed workflow guides\n- **Benefits**: Keeps SKILL.md lean, loaded only when Claude determines it's needed\n- **Best practice**: If files are large (>10k words), include grep search patterns in SKILL.md\n- **Avoid duplication**: Information should live in either SKILL.md or references files, not both. Prefer references files for detailed information unless it's truly core to the skillâ€”this keeps SKILL.md lean while making information discoverable without hogging the context window. Keep only essential procedural instructions and workflow guidance in SKILL.md; move detailed reference material, schemas, and examples to references files.\n\n##### Assets (`assets/`)\n\nFiles not intended to be loaded into context, but rather used within the output Claude produces.\n\n- **When to include**: When the skill needs files that will be used in the final output\n- **Examples**: `assets/logo.png` for brand assets, `assets/slides.pptx` for PowerPoint templates, `assets/frontend-template/` for HTML/React boilerplate, `assets/font.ttf` for typography\n- **Use cases**: Templates, images, icons, boilerplate code, fonts, sample documents that get copied or modified\n- **Benefits**: Separates output resources from documentation, enables Claude to use files without loading them into context\n\n#### What to Not Include in a Skill\n\nA skill should only contain essential files that directly support its functionality. Do NOT create extraneous documentation or auxiliary files, including:\n\n- README.md\n- INSTALLATION_GUIDE.md\n- QUICK_REFERENCE.md\n- CHANGELOG.md\n- etc.\n\nThe skill should only contain the information needed for an AI agent to do the job at hand. It should not contain auxilary context about the process that went into creating it, setup and testing procedures, user-facing documentation, etc. Creating additional documentation files just adds clutter and confusion.\n\n### Progressive Disclosure Design Principle\n\nSkills use a three-level loading system to manage context efficiently:\n\n1. **Metadata (name + description)** - Always in context (~100 words)\n2. **SKILL.md body** - When skill triggers (<5k words)\n3. **Bundled resources** - As needed by Claude (Unlimited because scripts can be executed without reading into context window)\n\n#### Progressive Disclosure Patterns\n\nKeep SKILL.md body to the essentials and under 500 lines to minimize context bloat. Split content into separate files when approaching this limit. When splitting out content into other files, it is very important to reference them from SKILL.md and describe clearly when to read them, to ensure the reader of the skill knows they exist and when to use them.\n\n**Key principle:** When a skill supports multiple variations, frameworks, or options, keep only the core workflow and selection guidance in SKILL.md. Move variant-specific details (patterns, examples, configuration) into separate reference files.\n\n**Pattern 1: High-level guide with references**\n\n```markdown\n# PDF Processing\n\n## Quick start\n\nExtract text with pdfplumber:\n[code example]\n\n## Advanced features\n\n- **Form filling**: See [FORMS.md](FORMS.md) for complete guide\n- **API reference**: See [REFERENCE.md](REFERENCE.md) for all methods\n- **Examples**: See [EXAMPLES.md](EXAMPLES.md) for common patterns\n```\n\nClaude loads FORMS.md, REFERENCE.md, or EXAMPLES.md only when needed.\n\n**Pattern 2: Domain-specific organization**\n\nFor Skills with multiple domains, organize content by domain to avoid loading irrelevant context:\n\n```\nbigquery-skill/\nâ”œâ”€â”€ SKILL.md (overview and navigation)\nâ””â”€â”€ reference/\n    â”œâ”€â”€ finance.md (revenue, billing metrics)\n    â”œâ”€â”€ sales.md (opportunities, pipeline)\n    â”œâ”€â”€ product.md (API usage, features)\n    â””â”€â”€ marketing.md (campaigns, attribution)\n```\n\nWhen a user asks about sales metrics, Claude only reads sales.md.\n\nSimilarly, for skills supporting multiple frameworks or variants, organize by variant:\n\n```\ncloud-deploy/\nâ”œâ”€â”€ SKILL.md (workflow + provider selection)\nâ””â”€â”€ references/\n    â”œâ”€â”€ aws.md (AWS deployment patterns)\n    â”œâ”€â”€ gcp.md (GCP deployment patterns)\n    â””â”€â”€ azure.md (Azure deployment patterns)\n```\n\nWhen the user chooses AWS, Claude only reads aws.md.\n\n**Pattern 3: Conditional details**\n\nShow basic content, link to advanced content:\n\n```markdown\n# DOCX Processing\n\n## Creating documents\n\nUse docx-js for new documents. See [DOCX-JS.md](DOCX-JS.md).\n\n## Editing documents\n\nFor simple edits, modify the XML directly.\n\n**For tracked changes**: See [REDLINING.md](REDLINING.md)\n**For OOXML details**: See [OOXML.md](OOXML.md)\n```\n\nClaude reads REDLINING.md or OOXML.md only when the user needs those features.\n\n**Important guidelines:**\n\n- **Avoid deeply nested references** - Keep references one level deep from SKILL.md. All reference files should link directly from SKILL.md.\n- **Structure longer reference files** - For files longer than 100 lines, include a table of contents at the top so Claude can see the full scope when previewing.\n\n## Skill Creation Process\n\nSkill creation involves these steps:\n\n1. Understand the skill with concrete examples\n2. Plan reusable skill contents (scripts, references, assets)\n3. Initialize the skill (run init_skill.py)\n4. Edit the skill (implement resources and write SKILL.md)\n5. Package the skill (run package_skill.py)\n6. Iterate based on real usage\n\nFollow these steps in order, skipping only if there is a clear reason why they are not applicable.\n\n### Step 1: Understanding the Skill with Concrete Examples\n\nSkip this step only when the skill's usage patterns are already clearly understood. It remains valuable even when working with an existing skill.\n\nTo create an effective skill, clearly understand concrete examples of how the skill will be used. This understanding can come from either direct user examples or generated examples that are validated with user feedback.\n\nFor example, when building an image-editor skill, relevant questions include:\n\n- \"What functionality should the image-editor skill support? Editing, rotating, anything else?\"\n- \"Can you give some examples of how this skill would be used?\"\n- \"I can imagine users asking for things like 'Remove the red-eye from this image' or 'Rotate this image'. Are there other ways you imagine this skill being used?\"\n- \"What would a user say that should trigger this skill?\"\n\nTo avoid overwhelming users, avoid asking too many questions in a single message. Start with the most important questions and follow up as needed for better effectiveness.\n\nConclude this step when there is a clear sense of the functionality the skill should support.\n\n### Step 2: Planning the Reusable Skill Contents\n\nTo turn concrete examples into an effective skill, analyze each example by:\n\n1. Considering how to execute on the example from scratch\n2. Identifying what scripts, references, and assets would be helpful when executing these workflows repeatedly\n\nExample: When building a `pdf-editor` skill to handle queries like \"Help me rotate this PDF,\" the analysis shows:\n\n1. Rotating a PDF requires re-writing the same code each time\n2. A `scripts/rotate_pdf.py` script would be helpful to store in the skill\n\nExample: When designing a `frontend-webapp-builder` skill for queries like \"Build me a todo app\" or \"Build me a dashboard to track my steps,\" the analysis shows:\n\n1. Writing a frontend webapp requires the same boilerplate HTML/React each time\n2. An `assets/hello-world/` template containing the boilerplate HTML/React project files would be helpful to store in the skill\n\nExample: When building a `big-query` skill to handle queries like \"How many users have logged in today?\" the analysis shows:\n\n1. Querying BigQuery requires re-discovering the table schemas and relationships each time\n2. A `references/schema.md` file documenting the table schemas would be helpful to store in the skill\n\nTo establish the skill's contents, analyze each concrete example to create a list of the reusable resources to include: scripts, references, and assets.\n\n### Step 3: Initializing the Skill\n\nAt this point, it is time to actually create the skill.\n\nSkip this step only if the skill being developed already exists, and iteration or packaging is needed. In this case, continue to the next step.\n\nWhen creating a new skill from scratch, always run the `init_skill.py` script. The script conveniently generates a new template skill directory that automatically includes everything a skill requires, making the skill creation process much more efficient and reliable.\n\nUsage:\n\n```bash\nscripts/init_skill.py <skill-name> --path <output-directory>\n```\n\nThe script:\n\n- Creates the skill directory at the specified path\n- Generates a SKILL.md template with proper frontmatter and TODO placeholders\n- Creates example resource directories: `scripts/`, `references/`, and `assets/`\n- Adds example files in each directory that can be customized or deleted\n\nAfter initialization, customize or remove the generated SKILL.md and example files as needed.\n\n### Step 4: Edit the Skill\n\nWhen editing the (newly-generated or existing) skill, remember that the skill is being created for another instance of Claude to use. Include information that would be beneficial and non-obvious to Claude. Consider what procedural knowledge, domain-specific details, or reusable assets would help another Claude instance execute these tasks more effectively.\n\n#### Learn Proven Design Patterns\n\nConsult these helpful guides based on your skill's needs:\n\n- **Multi-step processes**: See references/workflows.md for sequential workflows and conditional logic\n- **Specific output formats or quality standards**: See references/output-patterns.md for template and example patterns\n\nThese files contain established best practices for effective skill design.\n\n#### Start with Reusable Skill Contents\n\nTo begin implementation, start with the reusable resources identified above: `scripts/`, `references/`, and `assets/` files. Note that this step may require user input. For example, when implementing a `brand-guidelines` skill, the user may need to provide brand assets or templates to store in `assets/`, or documentation to store in `references/`.\n\nAdded scripts must be tested by actually running them to ensure there are no bugs and that the output matches what is expected. If there are many similar scripts, only a representative sample needs to be tested to ensure confidence that they all work while balancing time to completion.\n\nAny example files and directories not needed for the skill should be deleted. The initialization script creates example files in `scripts/`, `references/`, and `assets/` to demonstrate structure, but most skills won't need all of them.\n\n#### Update SKILL.md\n\n**Writing Guidelines:** Always use imperative/infinitive form.\n\n##### Frontmatter\n\nWrite the YAML frontmatter with `name` and `description`:\n\n- `name`: The skill name\n- `description`: This is the primary triggering mechanism for your skill, and helps Claude understand when to use the skill.\n  - Include both what the Skill does and specific triggers/contexts for when to use it.\n  - Include all \"when to use\" information here - Not in the body. The body is only loaded after triggering, so \"When to Use This Skill\" sections in the body are not helpful to Claude.\n  - Example description for a `docx` skill: \"Comprehensive document creation, editing, and analysis with support for tracked changes, comments, formatting preservation, and text extraction. Use when Claude needs to work with professional documents (.docx files) for: (1) Creating new documents, (2) Modifying or editing content, (3) Working with tracked changes, (4) Adding comments, or any other document tasks\"\n\nDo not include any other fields in YAML frontmatter.\n\n##### Body\n\nWrite instructions for using the skill and its bundled resources.\n\n### Step 5: Packaging a Skill\n\nOnce development of the skill is complete, it must be packaged into a distributable .skill file that gets shared with the user. The packaging process automatically validates the skill first to ensure it meets all requirements:\n\n```bash\nscripts/package_skill.py <path/to/skill-folder>\n```\n\nOptional output directory specification:\n\n```bash\nscripts/package_skill.py <path/to/skill-folder> ./dist\n```\n\nThe packaging script will:\n\n1. **Validate** the skill automatically, checking:\n\n   - YAML frontmatter format and required fields\n   - Skill naming conventions and directory structure\n   - Description completeness and quality\n   - File organization and resource references\n\n2. **Package** the skill if validation passes, creating a .skill file named after the skill (e.g., `my-skill.skill`) that includes all files and maintains the proper directory structure for distribution. The .skill file is a zip file with a .skill extension.\n\nIf validation fails, the script will report the errors and exit without creating a package. Fix any validation errors and run the packaging command again.\n\n### Step 6: Iterate\n\nAfter testing the skill, users may request improvements. Often this happens right after using the skill, with fresh context of how the skill performed.\n\n**Iteration workflow:**\n\n1. Use the skill on real tasks\n2. Notice struggles or inefficiencies\n3. Identify how SKILL.md or bundled resources should be updated\n4. Implement changes and test again\n"
      },
      "discovered_at": "2026-01-11T15:36:39.035086Z",
      "fetch_error": null
    },
    {
      "name": "slack-gif-creator",
      "slug": "slack-gif-creator",
      "source": "anthropic_official",
      "owner": "anthropics",
      "repo_name": "skills",
      "repository_url": "https://github.com/anthropics/skills",
      "skill_path": "skills/slack-gif-creator",
      "github_metadata": {
        "stars": 37534,
        "description": "Public repository for Agent Skills",
        "default_branch": "main",
        "pushed_at": "2025-12-20T18:09:45Z",
        "created_at": "2025-09-22T15:53:31Z",
        "language": "Python",
        "license": null,
        "open_issues": 137,
        "forks": 3406
      },
      "skill_md": {
        "found": true,
        "path": "skills/slack-gif-creator/SKILL.md",
        "branch": "main",
        "content": "---\nname: slack-gif-creator\ndescription: Knowledge and utilities for creating animated GIFs optimized for Slack. Provides constraints, validation tools, and animation concepts. Use when users request animated GIFs for Slack like \"make me a GIF of X doing Y for Slack.\"\nlicense: Complete terms in LICENSE.txt\n---\n\n# Slack GIF Creator\n\nA toolkit providing utilities and knowledge for creating animated GIFs optimized for Slack.\n\n## Slack Requirements\n\n**Dimensions:**\n- Emoji GIFs: 128x128 (recommended)\n- Message GIFs: 480x480\n\n**Parameters:**\n- FPS: 10-30 (lower is smaller file size)\n- Colors: 48-128 (fewer = smaller file size)\n- Duration: Keep under 3 seconds for emoji GIFs\n\n## Core Workflow\n\n```python\nfrom core.gif_builder import GIFBuilder\nfrom PIL import Image, ImageDraw\n\n# 1. Create builder\nbuilder = GIFBuilder(width=128, height=128, fps=10)\n\n# 2. Generate frames\nfor i in range(12):\n    frame = Image.new('RGB', (128, 128), (240, 248, 255))\n    draw = ImageDraw.Draw(frame)\n\n    # Draw your animation using PIL primitives\n    # (circles, polygons, lines, etc.)\n\n    builder.add_frame(frame)\n\n# 3. Save with optimization\nbuilder.save('output.gif', num_colors=48, optimize_for_emoji=True)\n```\n\n## Drawing Graphics\n\n### Working with User-Uploaded Images\nIf a user uploads an image, consider whether they want to:\n- **Use it directly** (e.g., \"animate this\", \"split this into frames\")\n- **Use it as inspiration** (e.g., \"make something like this\")\n\nLoad and work with images using PIL:\n```python\nfrom PIL import Image\n\nuploaded = Image.open('file.png')\n# Use directly, or just as reference for colors/style\n```\n\n### Drawing from Scratch\nWhen drawing graphics from scratch, use PIL ImageDraw primitives:\n\n```python\nfrom PIL import ImageDraw\n\ndraw = ImageDraw.Draw(frame)\n\n# Circles/ovals\ndraw.ellipse([x1, y1, x2, y2], fill=(r, g, b), outline=(r, g, b), width=3)\n\n# Stars, triangles, any polygon\npoints = [(x1, y1), (x2, y2), (x3, y3), ...]\ndraw.polygon(points, fill=(r, g, b), outline=(r, g, b), width=3)\n\n# Lines\ndraw.line([(x1, y1), (x2, y2)], fill=(r, g, b), width=5)\n\n# Rectangles\ndraw.rectangle([x1, y1, x2, y2], fill=(r, g, b), outline=(r, g, b), width=3)\n```\n\n**Don't use:** Emoji fonts (unreliable across platforms) or assume pre-packaged graphics exist in this skill.\n\n### Making Graphics Look Good\n\nGraphics should look polished and creative, not basic. Here's how:\n\n**Use thicker lines** - Always set `width=2` or higher for outlines and lines. Thin lines (width=1) look choppy and amateurish.\n\n**Add visual depth**:\n- Use gradients for backgrounds (`create_gradient_background`)\n- Layer multiple shapes for complexity (e.g., a star with a smaller star inside)\n\n**Make shapes more interesting**:\n- Don't just draw a plain circle - add highlights, rings, or patterns\n- Stars can have glows (draw larger, semi-transparent versions behind)\n- Combine multiple shapes (stars + sparkles, circles + rings)\n\n**Pay attention to colors**:\n- Use vibrant, complementary colors\n- Add contrast (dark outlines on light shapes, light outlines on dark shapes)\n- Consider the overall composition\n\n**For complex shapes** (hearts, snowflakes, etc.):\n- Use combinations of polygons and ellipses\n- Calculate points carefully for symmetry\n- Add details (a heart can have a highlight curve, snowflakes have intricate branches)\n\nBe creative and detailed! A good Slack GIF should look polished, not like placeholder graphics.\n\n## Available Utilities\n\n### GIFBuilder (`core.gif_builder`)\nAssembles frames and optimizes for Slack:\n```python\nbuilder = GIFBuilder(width=128, height=128, fps=10)\nbuilder.add_frame(frame)  # Add PIL Image\nbuilder.add_frames(frames)  # Add list of frames\nbuilder.save('out.gif', num_colors=48, optimize_for_emoji=True, remove_duplicates=True)\n```\n\n### Validators (`core.validators`)\nCheck if GIF meets Slack requirements:\n```python\nfrom core.validators import validate_gif, is_slack_ready\n\n# Detailed validation\npasses, info = validate_gif('my.gif', is_emoji=True, verbose=True)\n\n# Quick check\nif is_slack_ready('my.gif'):\n    print(\"Ready!\")\n```\n\n### Easing Functions (`core.easing`)\nSmooth motion instead of linear:\n```python\nfrom core.easing import interpolate\n\n# Progress from 0.0 to 1.0\nt = i / (num_frames - 1)\n\n# Apply easing\ny = interpolate(start=0, end=400, t=t, easing='ease_out')\n\n# Available: linear, ease_in, ease_out, ease_in_out,\n#           bounce_out, elastic_out, back_out\n```\n\n### Frame Helpers (`core.frame_composer`)\nConvenience functions for common needs:\n```python\nfrom core.frame_composer import (\n    create_blank_frame,         # Solid color background\n    create_gradient_background,  # Vertical gradient\n    draw_circle,                # Helper for circles\n    draw_text,                  # Simple text rendering\n    draw_star                   # 5-pointed star\n)\n```\n\n## Animation Concepts\n\n### Shake/Vibrate\nOffset object position with oscillation:\n- Use `math.sin()` or `math.cos()` with frame index\n- Add small random variations for natural feel\n- Apply to x and/or y position\n\n### Pulse/Heartbeat\nScale object size rhythmically:\n- Use `math.sin(t * frequency * 2 * math.pi)` for smooth pulse\n- For heartbeat: two quick pulses then pause (adjust sine wave)\n- Scale between 0.8 and 1.2 of base size\n\n### Bounce\nObject falls and bounces:\n- Use `interpolate()` with `easing='bounce_out'` for landing\n- Use `easing='ease_in'` for falling (accelerating)\n- Apply gravity by increasing y velocity each frame\n\n### Spin/Rotate\nRotate object around center:\n- PIL: `image.rotate(angle, resample=Image.BICUBIC)`\n- For wobble: use sine wave for angle instead of linear\n\n### Fade In/Out\nGradually appear or disappear:\n- Create RGBA image, adjust alpha channel\n- Or use `Image.blend(image1, image2, alpha)`\n- Fade in: alpha from 0 to 1\n- Fade out: alpha from 1 to 0\n\n### Slide\nMove object from off-screen to position:\n- Start position: outside frame bounds\n- End position: target location\n- Use `interpolate()` with `easing='ease_out'` for smooth stop\n- For overshoot: use `easing='back_out'`\n\n### Zoom\nScale and position for zoom effect:\n- Zoom in: scale from 0.1 to 2.0, crop center\n- Zoom out: scale from 2.0 to 1.0\n- Can add motion blur for drama (PIL filter)\n\n### Explode/Particle Burst\nCreate particles radiating outward:\n- Generate particles with random angles and velocities\n- Update each particle: `x += vx`, `y += vy`\n- Add gravity: `vy += gravity_constant`\n- Fade out particles over time (reduce alpha)\n\n## Optimization Strategies\n\nOnly when asked to make the file size smaller, implement a few of the following methods:\n\n1. **Fewer frames** - Lower FPS (10 instead of 20) or shorter duration\n2. **Fewer colors** - `num_colors=48` instead of 128\n3. **Smaller dimensions** - 128x128 instead of 480x480\n4. **Remove duplicates** - `remove_duplicates=True` in save()\n5. **Emoji mode** - `optimize_for_emoji=True` auto-optimizes\n\n```python\n# Maximum optimization for emoji\nbuilder.save(\n    'emoji.gif',\n    num_colors=48,\n    optimize_for_emoji=True,\n    remove_duplicates=True\n)\n```\n\n## Philosophy\n\nThis skill provides:\n- **Knowledge**: Slack's requirements and animation concepts\n- **Utilities**: GIFBuilder, validators, easing functions\n- **Flexibility**: Create the animation logic using PIL primitives\n\nIt does NOT provide:\n- Rigid animation templates or pre-made functions\n- Emoji font rendering (unreliable across platforms)\n- A library of pre-packaged graphics built into the skill\n\n**Note on user uploads**: This skill doesn't include pre-built graphics, but if a user uploads an image, use PIL to load and work with it - interpret based on their request whether they want it used directly or just as inspiration.\n\nBe creative! Combine concepts (bouncing + rotating, pulsing + sliding, etc.) and use PIL's full capabilities.\n\n## Dependencies\n\n```bash\npip install pillow imageio numpy\n```\n"
      },
      "discovered_at": "2026-01-11T15:36:39.179507Z",
      "fetch_error": null
    },
    {
      "name": "theme-factory",
      "slug": "theme-factory",
      "source": "anthropic_official",
      "owner": "anthropics",
      "repo_name": "skills",
      "repository_url": "https://github.com/anthropics/skills",
      "skill_path": "skills/theme-factory",
      "github_metadata": {
        "stars": 37534,
        "description": "Public repository for Agent Skills",
        "default_branch": "main",
        "pushed_at": "2025-12-20T18:09:45Z",
        "created_at": "2025-09-22T15:53:31Z",
        "language": "Python",
        "license": null,
        "open_issues": 137,
        "forks": 3406
      },
      "skill_md": {
        "found": true,
        "path": "skills/theme-factory/SKILL.md",
        "branch": "main",
        "content": "---\nname: theme-factory\ndescription: Toolkit for styling artifacts with a theme. These artifacts can be slides, docs, reportings, HTML landing pages, etc. There are 10 pre-set themes with colors/fonts that you can apply to any artifact that has been creating, or can generate a new theme on-the-fly.\nlicense: Complete terms in LICENSE.txt\n---\n\n\n# Theme Factory Skill\n\nThis skill provides a curated collection of professional font and color themes themes, each with carefully selected color palettes and font pairings. Once a theme is chosen, it can be applied to any artifact.\n\n## Purpose\n\nTo apply consistent, professional styling to presentation slide decks, use this skill. Each theme includes:\n- A cohesive color palette with hex codes\n- Complementary font pairings for headers and body text\n- A distinct visual identity suitable for different contexts and audiences\n\n## Usage Instructions\n\nTo apply styling to a slide deck or other artifact:\n\n1. **Show the theme showcase**: Display the `theme-showcase.pdf` file to allow users to see all available themes visually. Do not make any modifications to it; simply show the file for viewing.\n2. **Ask for their choice**: Ask which theme to apply to the deck\n3. **Wait for selection**: Get explicit confirmation about the chosen theme\n4. **Apply the theme**: Once a theme has been chosen, apply the selected theme's colors and fonts to the deck/artifact\n\n## Themes Available\n\nThe following 10 themes are available, each showcased in `theme-showcase.pdf`:\n\n1. **Ocean Depths** - Professional and calming maritime theme\n2. **Sunset Boulevard** - Warm and vibrant sunset colors\n3. **Forest Canopy** - Natural and grounded earth tones\n4. **Modern Minimalist** - Clean and contemporary grayscale\n5. **Golden Hour** - Rich and warm autumnal palette\n6. **Arctic Frost** - Cool and crisp winter-inspired theme\n7. **Desert Rose** - Soft and sophisticated dusty tones\n8. **Tech Innovation** - Bold and modern tech aesthetic\n9. **Botanical Garden** - Fresh and organic garden colors\n10. **Midnight Galaxy** - Dramatic and cosmic deep tones\n\n## Theme Details\n\nEach theme is defined in the `themes/` directory with complete specifications including:\n- Cohesive color palette with hex codes\n- Complementary font pairings for headers and body text\n- Distinct visual identity suitable for different contexts and audiences\n\n## Application Process\n\nAfter a preferred theme is selected:\n1. Read the corresponding theme file from the `themes/` directory\n2. Apply the specified colors and fonts consistently throughout the deck\n3. Ensure proper contrast and readability\n4. Maintain the theme's visual identity across all slides\n\n## Create your Own Theme\nTo handle cases where none of the existing themes work for an artifact, create a custom theme. Based on provided inputs, generate a new theme similar to the ones above. Give the theme a similar name describing what the font/color combinations represent. Use any basic description provided to choose appropriate colors/fonts. After generating the theme, show it for review and verification. Following that, apply the theme as described above.\n"
      },
      "discovered_at": "2026-01-11T15:36:39.323535Z",
      "fetch_error": null
    },
    {
      "name": "web-artifacts-builder",
      "slug": "web-artifacts-builder",
      "source": "anthropic_official",
      "owner": "anthropics",
      "repo_name": "skills",
      "repository_url": "https://github.com/anthropics/skills",
      "skill_path": "skills/web-artifacts-builder",
      "github_metadata": {
        "stars": 37534,
        "description": "Public repository for Agent Skills",
        "default_branch": "main",
        "pushed_at": "2025-12-20T18:09:45Z",
        "created_at": "2025-09-22T15:53:31Z",
        "language": "Python",
        "license": null,
        "open_issues": 137,
        "forks": 3406
      },
      "skill_md": {
        "found": true,
        "path": "skills/web-artifacts-builder/SKILL.md",
        "branch": "main",
        "content": "---\nname: web-artifacts-builder\ndescription: Suite of tools for creating elaborate, multi-component claude.ai HTML artifacts using modern frontend web technologies (React, Tailwind CSS, shadcn/ui). Use for complex artifacts requiring state management, routing, or shadcn/ui components - not for simple single-file HTML/JSX artifacts.\nlicense: Complete terms in LICENSE.txt\n---\n\n# Web Artifacts Builder\n\nTo build powerful frontend claude.ai artifacts, follow these steps:\n1. Initialize the frontend repo using `scripts/init-artifact.sh`\n2. Develop your artifact by editing the generated code\n3. Bundle all code into a single HTML file using `scripts/bundle-artifact.sh`\n4. Display artifact to user\n5. (Optional) Test the artifact\n\n**Stack**: React 18 + TypeScript + Vite + Parcel (bundling) + Tailwind CSS + shadcn/ui\n\n## Design & Style Guidelines\n\nVERY IMPORTANT: To avoid what is often referred to as \"AI slop\", avoid using excessive centered layouts, purple gradients, uniform rounded corners, and Inter font.\n\n## Quick Start\n\n### Step 1: Initialize Project\n\nRun the initialization script to create a new React project:\n```bash\nbash scripts/init-artifact.sh <project-name>\ncd <project-name>\n```\n\nThis creates a fully configured project with:\n- âœ… React + TypeScript (via Vite)\n- âœ… Tailwind CSS 3.4.1 with shadcn/ui theming system\n- âœ… Path aliases (`@/`) configured\n- âœ… 40+ shadcn/ui components pre-installed\n- âœ… All Radix UI dependencies included\n- âœ… Parcel configured for bundling (via .parcelrc)\n- âœ… Node 18+ compatibility (auto-detects and pins Vite version)\n\n### Step 2: Develop Your Artifact\n\nTo build the artifact, edit the generated files. See **Common Development Tasks** below for guidance.\n\n### Step 3: Bundle to Single HTML File\n\nTo bundle the React app into a single HTML artifact:\n```bash\nbash scripts/bundle-artifact.sh\n```\n\nThis creates `bundle.html` - a self-contained artifact with all JavaScript, CSS, and dependencies inlined. This file can be directly shared in Claude conversations as an artifact.\n\n**Requirements**: Your project must have an `index.html` in the root directory.\n\n**What the script does**:\n- Installs bundling dependencies (parcel, @parcel/config-default, parcel-resolver-tspaths, html-inline)\n- Creates `.parcelrc` config with path alias support\n- Builds with Parcel (no source maps)\n- Inlines all assets into single HTML using html-inline\n\n### Step 4: Share Artifact with User\n\nFinally, share the bundled HTML file in conversation with the user so they can view it as an artifact.\n\n### Step 5: Testing/Visualizing the Artifact (Optional)\n\nNote: This is a completely optional step. Only perform if necessary or requested.\n\nTo test/visualize the artifact, use available tools (including other Skills or built-in tools like Playwright or Puppeteer). In general, avoid testing the artifact upfront as it adds latency between the request and when the finished artifact can be seen. Test later, after presenting the artifact, if requested or if issues arise.\n\n## Reference\n\n- **shadcn/ui components**: https://ui.shadcn.com/docs/components"
      },
      "discovered_at": "2026-01-11T15:36:39.465262Z",
      "fetch_error": null
    },
    {
      "name": "webapp-testing",
      "slug": "webapp-testing",
      "source": "anthropic_official",
      "owner": "anthropics",
      "repo_name": "skills",
      "repository_url": "https://github.com/anthropics/skills",
      "skill_path": "skills/webapp-testing",
      "github_metadata": {
        "stars": 37534,
        "description": "Public repository for Agent Skills",
        "default_branch": "main",
        "pushed_at": "2025-12-20T18:09:45Z",
        "created_at": "2025-09-22T15:53:31Z",
        "language": "Python",
        "license": null,
        "open_issues": 137,
        "forks": 3406
      },
      "skill_md": {
        "found": true,
        "path": "skills/webapp-testing/SKILL.md",
        "branch": "main",
        "content": "---\nname: webapp-testing\ndescription: Toolkit for interacting with and testing local web applications using Playwright. Supports verifying frontend functionality, debugging UI behavior, capturing browser screenshots, and viewing browser logs.\nlicense: Complete terms in LICENSE.txt\n---\n\n# Web Application Testing\n\nTo test local web applications, write native Python Playwright scripts.\n\n**Helper Scripts Available**:\n- `scripts/with_server.py` - Manages server lifecycle (supports multiple servers)\n\n**Always run scripts with `--help` first** to see usage. DO NOT read the source until you try running the script first and find that a customized solution is abslutely necessary. These scripts can be very large and thus pollute your context window. They exist to be called directly as black-box scripts rather than ingested into your context window.\n\n## Decision Tree: Choosing Your Approach\n\n```\nUser task â†’ Is it static HTML?\n    â”œâ”€ Yes â†’ Read HTML file directly to identify selectors\n    â”‚         â”œâ”€ Success â†’ Write Playwright script using selectors\n    â”‚         â””â”€ Fails/Incomplete â†’ Treat as dynamic (below)\n    â”‚\n    â””â”€ No (dynamic webapp) â†’ Is the server already running?\n        â”œâ”€ No â†’ Run: python scripts/with_server.py --help\n        â”‚        Then use the helper + write simplified Playwright script\n        â”‚\n        â””â”€ Yes â†’ Reconnaissance-then-action:\n            1. Navigate and wait for networkidle\n            2. Take screenshot or inspect DOM\n            3. Identify selectors from rendered state\n            4. Execute actions with discovered selectors\n```\n\n## Example: Using with_server.py\n\nTo start a server, run `--help` first, then use the helper:\n\n**Single server:**\n```bash\npython scripts/with_server.py --server \"npm run dev\" --port 5173 -- python your_automation.py\n```\n\n**Multiple servers (e.g., backend + frontend):**\n```bash\npython scripts/with_server.py \\\n  --server \"cd backend && python server.py\" --port 3000 \\\n  --server \"cd frontend && npm run dev\" --port 5173 \\\n  -- python your_automation.py\n```\n\nTo create an automation script, include only Playwright logic (servers are managed automatically):\n```python\nfrom playwright.sync_api import sync_playwright\n\nwith sync_playwright() as p:\n    browser = p.chromium.launch(headless=True) # Always launch chromium in headless mode\n    page = browser.new_page()\n    page.goto('http://localhost:5173') # Server already running and ready\n    page.wait_for_load_state('networkidle') # CRITICAL: Wait for JS to execute\n    # ... your automation logic\n    browser.close()\n```\n\n## Reconnaissance-Then-Action Pattern\n\n1. **Inspect rendered DOM**:\n   ```python\n   page.screenshot(path='/tmp/inspect.png', full_page=True)\n   content = page.content()\n   page.locator('button').all()\n   ```\n\n2. **Identify selectors** from inspection results\n\n3. **Execute actions** using discovered selectors\n\n## Common Pitfall\n\nâŒ **Don't** inspect the DOM before waiting for `networkidle` on dynamic apps\nâœ… **Do** wait for `page.wait_for_load_state('networkidle')` before inspection\n\n## Best Practices\n\n- **Use bundled scripts as black boxes** - To accomplish a task, consider whether one of the scripts available in `scripts/` can help. These scripts handle common, complex workflows reliably without cluttering the context window. Use `--help` to see usage, then invoke directly. \n- Use `sync_playwright()` for synchronous scripts\n- Always close the browser when done\n- Use descriptive selectors: `text=`, `role=`, CSS selectors, or IDs\n- Add appropriate waits: `page.wait_for_selector()` or `page.wait_for_timeout()`\n\n## Reference Files\n\n- **examples/** - Examples showing common patterns:\n  - `element_discovery.py` - Discovering buttons, links, and inputs on a page\n  - `static_html_automation.py` - Using file:// URLs for local HTML\n  - `console_logging.py` - Capturing console logs during automation"
      },
      "discovered_at": "2026-01-11T15:36:39.518282Z",
      "fetch_error": null
    },
    {
      "name": "xlsx",
      "slug": "xlsx",
      "source": "anthropic_official",
      "owner": "anthropics",
      "repo_name": "skills",
      "repository_url": "https://github.com/anthropics/skills",
      "skill_path": "skills/xlsx",
      "github_metadata": {
        "stars": 37534,
        "description": "Public repository for Agent Skills",
        "default_branch": "main",
        "pushed_at": "2025-12-20T18:09:45Z",
        "created_at": "2025-09-22T15:53:31Z",
        "language": "Python",
        "license": null,
        "open_issues": 137,
        "forks": 3406
      },
      "skill_md": {
        "found": true,
        "path": "skills/xlsx/SKILL.md",
        "branch": "main",
        "content": "---\nname: xlsx\ndescription: \"Comprehensive spreadsheet creation, editing, and analysis with support for formulas, formatting, data analysis, and visualization. When Claude needs to work with spreadsheets (.xlsx, .xlsm, .csv, .tsv, etc) for: (1) Creating new spreadsheets with formulas and formatting, (2) Reading or analyzing data, (3) Modify existing spreadsheets while preserving formulas, (4) Data analysis and visualization in spreadsheets, or (5) Recalculating formulas\"\nlicense: Proprietary. LICENSE.txt has complete terms\n---\n\n# Requirements for Outputs\n\n## All Excel files\n\n### Zero Formula Errors\n- Every Excel model MUST be delivered with ZERO formula errors (#REF!, #DIV/0!, #VALUE!, #N/A, #NAME?)\n\n### Preserve Existing Templates (when updating templates)\n- Study and EXACTLY match existing format, style, and conventions when modifying files\n- Never impose standardized formatting on files with established patterns\n- Existing template conventions ALWAYS override these guidelines\n\n## Financial models\n\n### Color Coding Standards\nUnless otherwise stated by the user or existing template\n\n#### Industry-Standard Color Conventions\n- **Blue text (RGB: 0,0,255)**: Hardcoded inputs, and numbers users will change for scenarios\n- **Black text (RGB: 0,0,0)**: ALL formulas and calculations\n- **Green text (RGB: 0,128,0)**: Links pulling from other worksheets within same workbook\n- **Red text (RGB: 255,0,0)**: External links to other files\n- **Yellow background (RGB: 255,255,0)**: Key assumptions needing attention or cells that need to be updated\n\n### Number Formatting Standards\n\n#### Required Format Rules\n- **Years**: Format as text strings (e.g., \"2024\" not \"2,024\")\n- **Currency**: Use $#,##0 format; ALWAYS specify units in headers (\"Revenue ($mm)\")\n- **Zeros**: Use number formatting to make all zeros \"-\", including percentages (e.g., \"$#,##0;($#,##0);-\")\n- **Percentages**: Default to 0.0% format (one decimal)\n- **Multiples**: Format as 0.0x for valuation multiples (EV/EBITDA, P/E)\n- **Negative numbers**: Use parentheses (123) not minus -123\n\n### Formula Construction Rules\n\n#### Assumptions Placement\n- Place ALL assumptions (growth rates, margins, multiples, etc.) in separate assumption cells\n- Use cell references instead of hardcoded values in formulas\n- Example: Use =B5*(1+$B$6) instead of =B5*1.05\n\n#### Formula Error Prevention\n- Verify all cell references are correct\n- Check for off-by-one errors in ranges\n- Ensure consistent formulas across all projection periods\n- Test with edge cases (zero values, negative numbers)\n- Verify no unintended circular references\n\n#### Documentation Requirements for Hardcodes\n- Comment or in cells beside (if end of table). Format: \"Source: [System/Document], [Date], [Specific Reference], [URL if applicable]\"\n- Examples:\n  - \"Source: Company 10-K, FY2024, Page 45, Revenue Note, [SEC EDGAR URL]\"\n  - \"Source: Company 10-Q, Q2 2025, Exhibit 99.1, [SEC EDGAR URL]\"\n  - \"Source: Bloomberg Terminal, 8/15/2025, AAPL US Equity\"\n  - \"Source: FactSet, 8/20/2025, Consensus Estimates Screen\"\n\n# XLSX creation, editing, and analysis\n\n## Overview\n\nA user may ask you to create, edit, or analyze the contents of an .xlsx file. You have different tools and workflows available for different tasks.\n\n## Important Requirements\n\n**LibreOffice Required for Formula Recalculation**: You can assume LibreOffice is installed for recalculating formula values using the `recalc.py` script. The script automatically configures LibreOffice on first run\n\n## Reading and analyzing data\n\n### Data analysis with pandas\nFor data analysis, visualization, and basic operations, use **pandas** which provides powerful data manipulation capabilities:\n\n```python\nimport pandas as pd\n\n# Read Excel\ndf = pd.read_excel('file.xlsx')  # Default: first sheet\nall_sheets = pd.read_excel('file.xlsx', sheet_name=None)  # All sheets as dict\n\n# Analyze\ndf.head()      # Preview data\ndf.info()      # Column info\ndf.describe()  # Statistics\n\n# Write Excel\ndf.to_excel('output.xlsx', index=False)\n```\n\n## Excel File Workflows\n\n## CRITICAL: Use Formulas, Not Hardcoded Values\n\n**Always use Excel formulas instead of calculating values in Python and hardcoding them.** This ensures the spreadsheet remains dynamic and updateable.\n\n### âŒ WRONG - Hardcoding Calculated Values\n```python\n# Bad: Calculating in Python and hardcoding result\ntotal = df['Sales'].sum()\nsheet['B10'] = total  # Hardcodes 5000\n\n# Bad: Computing growth rate in Python\ngrowth = (df.iloc[-1]['Revenue'] - df.iloc[0]['Revenue']) / df.iloc[0]['Revenue']\nsheet['C5'] = growth  # Hardcodes 0.15\n\n# Bad: Python calculation for average\navg = sum(values) / len(values)\nsheet['D20'] = avg  # Hardcodes 42.5\n```\n\n### âœ… CORRECT - Using Excel Formulas\n```python\n# Good: Let Excel calculate the sum\nsheet['B10'] = '=SUM(B2:B9)'\n\n# Good: Growth rate as Excel formula\nsheet['C5'] = '=(C4-C2)/C2'\n\n# Good: Average using Excel function\nsheet['D20'] = '=AVERAGE(D2:D19)'\n```\n\nThis applies to ALL calculations - totals, percentages, ratios, differences, etc. The spreadsheet should be able to recalculate when source data changes.\n\n## Common Workflow\n1. **Choose tool**: pandas for data, openpyxl for formulas/formatting\n2. **Create/Load**: Create new workbook or load existing file\n3. **Modify**: Add/edit data, formulas, and formatting\n4. **Save**: Write to file\n5. **Recalculate formulas (MANDATORY IF USING FORMULAS)**: Use the recalc.py script\n   ```bash\n   python recalc.py output.xlsx\n   ```\n6. **Verify and fix any errors**: \n   - The script returns JSON with error details\n   - If `status` is `errors_found`, check `error_summary` for specific error types and locations\n   - Fix the identified errors and recalculate again\n   - Common errors to fix:\n     - `#REF!`: Invalid cell references\n     - `#DIV/0!`: Division by zero\n     - `#VALUE!`: Wrong data type in formula\n     - `#NAME?`: Unrecognized formula name\n\n### Creating new Excel files\n\n```python\n# Using openpyxl for formulas and formatting\nfrom openpyxl import Workbook\nfrom openpyxl.styles import Font, PatternFill, Alignment\n\nwb = Workbook()\nsheet = wb.active\n\n# Add data\nsheet['A1'] = 'Hello'\nsheet['B1'] = 'World'\nsheet.append(['Row', 'of', 'data'])\n\n# Add formula\nsheet['B2'] = '=SUM(A1:A10)'\n\n# Formatting\nsheet['A1'].font = Font(bold=True, color='FF0000')\nsheet['A1'].fill = PatternFill('solid', start_color='FFFF00')\nsheet['A1'].alignment = Alignment(horizontal='center')\n\n# Column width\nsheet.column_dimensions['A'].width = 20\n\nwb.save('output.xlsx')\n```\n\n### Editing existing Excel files\n\n```python\n# Using openpyxl to preserve formulas and formatting\nfrom openpyxl import load_workbook\n\n# Load existing file\nwb = load_workbook('existing.xlsx')\nsheet = wb.active  # or wb['SheetName'] for specific sheet\n\n# Working with multiple sheets\nfor sheet_name in wb.sheetnames:\n    sheet = wb[sheet_name]\n    print(f\"Sheet: {sheet_name}\")\n\n# Modify cells\nsheet['A1'] = 'New Value'\nsheet.insert_rows(2)  # Insert row at position 2\nsheet.delete_cols(3)  # Delete column 3\n\n# Add new sheet\nnew_sheet = wb.create_sheet('NewSheet')\nnew_sheet['A1'] = 'Data'\n\nwb.save('modified.xlsx')\n```\n\n## Recalculating formulas\n\nExcel files created or modified by openpyxl contain formulas as strings but not calculated values. Use the provided `recalc.py` script to recalculate formulas:\n\n```bash\npython recalc.py <excel_file> [timeout_seconds]\n```\n\nExample:\n```bash\npython recalc.py output.xlsx 30\n```\n\nThe script:\n- Automatically sets up LibreOffice macro on first run\n- Recalculates all formulas in all sheets\n- Scans ALL cells for Excel errors (#REF!, #DIV/0!, etc.)\n- Returns JSON with detailed error locations and counts\n- Works on both Linux and macOS\n\n## Formula Verification Checklist\n\nQuick checks to ensure formulas work correctly:\n\n### Essential Verification\n- [ ] **Test 2-3 sample references**: Verify they pull correct values before building full model\n- [ ] **Column mapping**: Confirm Excel columns match (e.g., column 64 = BL, not BK)\n- [ ] **Row offset**: Remember Excel rows are 1-indexed (DataFrame row 5 = Excel row 6)\n\n### Common Pitfalls\n- [ ] **NaN handling**: Check for null values with `pd.notna()`\n- [ ] **Far-right columns**: FY data often in columns 50+ \n- [ ] **Multiple matches**: Search all occurrences, not just first\n- [ ] **Division by zero**: Check denominators before using `/` in formulas (#DIV/0!)\n- [ ] **Wrong references**: Verify all cell references point to intended cells (#REF!)\n- [ ] **Cross-sheet references**: Use correct format (Sheet1!A1) for linking sheets\n\n### Formula Testing Strategy\n- [ ] **Start small**: Test formulas on 2-3 cells before applying broadly\n- [ ] **Verify dependencies**: Check all cells referenced in formulas exist\n- [ ] **Test edge cases**: Include zero, negative, and very large values\n\n### Interpreting recalc.py Output\nThe script returns JSON with error details:\n```json\n{\n  \"status\": \"success\",           // or \"errors_found\"\n  \"total_errors\": 0,              // Total error count\n  \"total_formulas\": 42,           // Number of formulas in file\n  \"error_summary\": {              // Only present if errors found\n    \"#REF!\": {\n      \"count\": 2,\n      \"locations\": [\"Sheet1!B5\", \"Sheet1!C10\"]\n    }\n  }\n}\n```\n\n## Best Practices\n\n### Library Selection\n- **pandas**: Best for data analysis, bulk operations, and simple data export\n- **openpyxl**: Best for complex formatting, formulas, and Excel-specific features\n\n### Working with openpyxl\n- Cell indices are 1-based (row=1, column=1 refers to cell A1)\n- Use `data_only=True` to read calculated values: `load_workbook('file.xlsx', data_only=True)`\n- **Warning**: If opened with `data_only=True` and saved, formulas are replaced with values and permanently lost\n- For large files: Use `read_only=True` for reading or `write_only=True` for writing\n- Formulas are preserved but not evaluated - use recalc.py to update values\n\n### Working with pandas\n- Specify data types to avoid inference issues: `pd.read_excel('file.xlsx', dtype={'id': str})`\n- For large files, read specific columns: `pd.read_excel('file.xlsx', usecols=['A', 'C', 'E'])`\n- Handle dates properly: `pd.read_excel('file.xlsx', parse_dates=['date_column'])`\n\n## Code Style Guidelines\n**IMPORTANT**: When generating Python code for Excel operations:\n- Write minimal, concise Python code without unnecessary comments\n- Avoid verbose variable names and redundant operations\n- Avoid unnecessary print statements\n\n**For Excel files themselves**:\n- Add comments to cells with complex formulas or important assumptions\n- Document data sources for hardcoded values\n- Include notes for key calculations and model sections"
      },
      "discovered_at": "2026-01-11T15:36:39.670878Z",
      "fetch_error": null
    },
    {
      "name": "marketplace-manager",
      "slug": "marketplace-manager",
      "source": "skillsmp",
      "owner": "jeremylongshore",
      "repo_name": "claude-code-plugins-plus-skills",
      "repository_url": "https://github.com/jeremylongshore/claude-code-plugins-plus-skills",
      "skill_path": "backups/skill-structure-cleanup-20251108-073936/plugins/examples/skills-powerkit/skills/marketplace-manager",
      "github_metadata": {
        "stars": 943,
        "description": "Hundreds of Claude Code plugins with embedded AI skills. Learn via interactive Jupyter tutorials.",
        "default_branch": "main",
        "pushed_at": "2026-01-11T01:39:29Z",
        "created_at": "2025-10-10T01:01:00Z",
        "language": "Python",
        "license": "NOASSERTION",
        "open_issues": 9,
        "forks": 114
      },
      "skill_md": {
        "found": true,
        "path": "backups/skill-structure-cleanup-20251108-073936/plugins/examples/skills-powerkit/skills/marketplace-manager/SKILL.md",
        "branch": "main",
        "content": "---\nname: marketplace-manager\ndescription: |\n  Automatically manages marketplace catalog updates, syncs marketplace.json, and handles plugin distribution when user mentions marketplace update, sync catalog, or add to marketplace. Specific to claude-code-plugins two-catalog system.\nallowed-tools: Read, Write, Edit, Grep, Bash\nversion: 1.0.0\n---\n\n# Marketplace Manager\n\n## Purpose\nAutomatically manages the claude-code-plugins marketplace catalog system, handling updates to marketplace.extended.json, syncing to marketplace.json, and ensuring catalog integrity.\n\n## Trigger Keywords\n- \"update marketplace\"\n- \"sync marketplace\" or \"sync catalog\"\n- \"add to marketplace\"\n- \"marketplace catalog\"\n- \"update catalog\"\n- \"regenerate marketplace\"\n\n## Two-Catalog System\n\n**Critical Understanding:**\n```\nmarketplace.extended.json (SOURCE OF TRUTH)\nâ”œâ”€â”€ Full metadata\nâ”œâ”€â”€ Extended fields (featured, mcpTools, etc.)\nâ””â”€â”€ Edit THIS file manually\n\nâ†“ npm run sync-marketplace\n\nmarketplace.json (GENERATED)\nâ”œâ”€â”€ CLI-compatible subset\nâ”œâ”€â”€ Sanitized fields\nâ””â”€â”€ NEVER edit directly\n```\n\n## Marketplace Management Tasks\n\n### 1. Add Plugin to Catalog\n\nWhen adding new plugin:\n\n```json\n// Add to marketplace.extended.json\n{\n  \"name\": \"plugin-name\",\n  \"source\": \"./plugins/category/plugin-name\",\n  \"description\": \"Clear one-line description\",\n  \"version\": \"1.0.0\",\n  \"category\": \"productivity\",\n  \"keywords\": [\"keyword1\", \"keyword2\"],\n  \"author\": {\n    \"name\": \"Author Name\",\n    \"email\": \"[email protected]\"\n  },\n  \"repository\": \"https://github.com/user/repo\",\n  \"featured\": false  // true for featured plugins\n}\n```\n\nThen:\n```bash\nnpm run sync-marketplace\n```\n\n### 2. Update Plugin Version\n\nWhen bumping version:\n\n1. Update `plugins/category/plugin-name/.claude-plugin/plugin.json`\n2. Update marketplace.extended.json entry\n3. Run `npm run sync-marketplace`\n4. Validate sync worked: `git diff .claude-plugin/marketplace.json`\n\n### 3. Sync Validation\n\nAfter sync, verify:\n```bash\n# Check marketplace.json was regenerated\ngit status .claude-plugin/marketplace.json\n\n# Validate JSON syntax\njq empty .claude-plugin/marketplace.extended.json\njq empty .claude-plugin/marketplace.json\n\n# Check specific plugin entry\njq '.plugins[] | select(.name == \"plugin-name\")' .claude-plugin/marketplace.json\n```\n\n### 4. Featured Plugin Management\n\nMark plugin as featured:\n```json\n{\n  \"name\": \"plugin-name\",\n  \"featured\": true,  // Add this field\n  // ... rest of fields\n}\n```\n\nFeatured plugins appear first in marketplace.\n\n### 5. Catalog Integrity Checks\n\nI automatically verify:\n- âœ… No duplicate plugin names\n- âœ… All source paths exist\n- âœ… All plugins have required fields\n- âœ… Versions are semantic (x.y.z)\n- âœ… Categories are valid\n- âœ… JSON is valid\n- âœ… Sync is current (no uncommitted changes to marketplace.json)\n\n## Valid Categories\n\n```\nproductivity, security, testing, deployment, documentation,\nanalysis, integration, ai, devops, debugging, code-quality,\ndesign, example, api-development, database, crypto,\nperformance, ai-ml, other\n```\n\n## Sync Process\n\nWhen I sync marketplace:\n\n1. **Backup Current State**\n   ```bash\n   cp .claude-plugin/marketplace.json .claude-plugin/marketplace.json.backup\n   ```\n\n2. **Run Sync Script**\n   ```bash\n   npm run sync-marketplace\n   # or: node scripts/sync-marketplace.cjs\n   ```\n\n3. **Validate Output**\n   ```bash\n   # Check sync success\n   jq empty .claude-plugin/marketplace.json\n\n   # Verify plugins count\n   jq '.plugins | length' .claude-plugin/marketplace.json\n   ```\n\n4. **Check Diff**\n   ```bash\n   git diff .claude-plugin/marketplace.json\n   ```\n\n5. **Commit if Valid**\n   ```bash\n   git add .claude-plugin/marketplace.extended.json .claude-plugin/marketplace.json\n   git commit -m \"chore: Update marketplace catalog\"\n   ```\n\n## Sanitized Fields\n\nThese fields are REMOVED from marketplace.json (CLI):\n- `featured` - Extended metadata\n- `mcpTools` - Extended metadata\n- `pluginCount` - Extended metadata\n- `pricing` - Extended metadata\n- `components` - Extended metadata\n\n**Only add these to marketplace.extended.json**\n\n## Marketplace Schema\n\n**Required fields for every plugin:**\n```json\n{\n  \"name\": \"string (kebab-case)\",\n  \"source\": \"string (relative path from repo root)\",\n  \"description\": \"string (clear, concise)\",\n  \"version\": \"string (semver: x.y.z)\",\n  \"category\": \"string (from valid list)\",\n  \"keywords\": \"array (at least 2)\",\n  \"author\": {\n    \"name\": \"string\",\n    \"email\": \"string (valid email)\"\n  }\n}\n```\n\n**Optional fields:**\n```json\n{\n  \"repository\": \"string (GitHub URL)\",\n  \"homepage\": \"string (docs URL)\",\n  \"license\": \"string (MIT, Apache-2.0, etc.)\",\n  \"featured\": \"boolean (extended only)\",\n  \"mcpTools\": \"number (extended only)\"\n}\n```\n\n## Common Issues & Fixes\n\n### Issue: Sync fails with schema error\n```bash\n# Check marketplace.extended.json syntax\njq empty .claude-plugin/marketplace.extended.json\n\n# Common errors:\n# - Missing comma\n# - Invalid field type\n# - Duplicate plugin name\n```\n\n### Issue: marketplace.json out of sync\n```bash\n# Regenerate from source\nnpm run sync-marketplace\n\n# If still fails, check git status\ngit status .claude-plugin/\n```\n\n### Issue: Plugin not appearing\n```bash\n# Verify entry exists\njq '.plugins[] | select(.name == \"plugin-name\")' .claude-plugin/marketplace.extended.json\n\n# Check source path\nls -la ./plugins/category/plugin-name\n```\n\n## Automation\n\nI can automatically:\n1. Add plugin entries with all required fields\n2. Update version across plugin + catalog\n3. Sync marketplace.json\n4. Validate catalog integrity\n5. Check for duplicates\n6. Fix common issues\n\n## Output Format\n\n```\nğŸ“¦ MARKETPLACE UPDATE REPORT\n\nAction: Add plugin \"new-plugin\"\nLocation: plugins/productivity/new-plugin/\n\nâœ… COMPLETED STEPS:\n1. Added entry to marketplace.extended.json\n2. Ran npm run sync-marketplace\n3. Validated marketplace.json\n4. Checked for duplicates: NONE\n5. Verified source path exists\n\nğŸ“Š MARKETPLACE STATS:\nTotal plugins: 227 (+1)\nCategories: 14\nFeatured: 3\nLatest sync: 2025-10-16 14:30 UTC\n\nâœ¨ Ready to commit:\ngit add .claude-plugin/marketplace.extended.json .claude-plugin/marketplace.json\ngit commit -m \"feat: Add new-plugin to marketplace\"\n```\n\n## Repository-Specific Features\n\n**For claude-code-plugins repo:**\n- Manages `claude-code-plugins-plus` marketplace\n- Handles both extended and CLI catalogs\n- Validates against repository structure\n- Checks plugin count accuracy\n- Ensures featured plugins are quality plugins\n\n## Examples\n\n**User says:** \"Add the new security-scanner plugin to marketplace\"\n\n**I automatically:**\n1. Read plugin.json for metadata\n2. Add entry to marketplace.extended.json\n3. Run npm run sync-marketplace\n4. Validate both catalogs\n5. Check no duplicates\n6. Report success\n\n**User says:** \"Sync the marketplace catalog\"\n\n**I automatically:**\n1. Run npm run sync-marketplace\n2. Validate marketplace.json generated\n3. Check git diff\n4. Report changes\n\n**User says:** \"Update plugin version in marketplace\"\n\n**I automatically:**\n1. Find plugin entry\n2. Update version in marketplace.extended.json\n3. Sync marketplace.json\n4. Validate versions match\n5. Report success\n"
      },
      "discovered_at": "2026-01-11T15:36:19.393826Z",
      "fetch_error": null
    },
    {
      "name": "shioaji",
      "slug": "shioaji",
      "source": "skillsmp",
      "owner": "Sinotrade",
      "repo_name": "Shioaji",
      "repository_url": "https://github.com/Sinotrade/Shioaji",
      "skill_path": "skills/shioaji",
      "github_metadata": {
        "stars": 220,
        "description": "Shioaji all new cross platform api for trading ( è·¨å¹³å°è­‰åˆ¸äº¤æ˜“API )",
        "default_branch": "master",
        "pushed_at": "2026-01-08T02:10:39Z",
        "created_at": "2018-11-21T06:27:12Z",
        "language": "Dockerfile",
        "license": null,
        "open_issues": 12,
        "forks": 18
      },
      "skill_md": {
        "found": true,
        "path": "skills/shioaji/SKILL.md",
        "branch": "master",
        "content": "---\nname: shioaji\ndescription: |\n  Shioaji Taiwan financial trading API guide. Use when trading stocks/futures/options on Taiwan markets, subscribing to real-time market data, querying account info, or building automated trading systems.\n  Shioaji å°ç£é‡‘èäº¤æ˜“ API æŒ‡å—ã€‚é©ç”¨æ–¼ï¼šè‚¡ç¥¨/æœŸè²¨/é¸æ“‡æ¬Šäº¤æ˜“ã€å³æ™‚è¡Œæƒ…è¨‚é–±ã€å¸³å‹™æŸ¥è©¢ã€è‡ªå‹•äº¤æ˜“ç³»çµ±é–‹ç™¼ã€‚\n---\n\n# Shioaji Trading API\n\nShioaji is SinoPac's Python API for trading Taiwan financial markets (stocks, futures, options).\nShioaji æ˜¯æ°¸è±é‡‘è­‰åˆ¸æä¾›çš„ Python äº¤æ˜“ APIï¼Œæ”¯æ´å°ç£è‚¡ç¥¨ã€æœŸè²¨ã€é¸æ“‡æ¬Šå¸‚å ´ã€‚\n\n**Official Docs å®˜æ–¹æ–‡æª”**: https://sinotrade.github.io/\n**LLM Reference**: https://sinotrade.github.io/llms-full.txt\n\n---\n\n## Navigation åŠŸèƒ½å°è¦½\n\n| Topic ä¸»é¡Œ | File æª”æ¡ˆ | Description èªªæ˜ |\n|------------|-----------|------------------|\n| Preparation æº–å‚™ | [PREPARE.md](PREPARE.md) | Account setup, API keys, testing é–‹æˆ¶/é‡‘é‘°ç”³è«‹/æ¸¬è©¦ |\n| Contracts åˆç´„ | [CONTRACTS.md](CONTRACTS.md) | Stocks, Futures, Options contracts è‚¡ç¥¨/æœŸè²¨/é¸æ“‡æ¬Šåˆç´„ |\n| Orders ä¸‹å–® | [ORDERS.md](ORDERS.md) | Place, modify, cancel, combo orders ä¸‹å–®/æ”¹å–®/åˆªå–®/çµ„åˆå–® |\n| Reserve é æ”¶ | [RESERVE.md](RESERVE.md) | Reserve orders for disposition stocks è™•ç½®è‚¡é æ”¶åˆ¸æ¬¾ |\n| Streaming è¡Œæƒ… | [STREAMING.md](STREAMING.md) | Real-time tick & bidask data å³æ™‚ Tick/BidAsk è³‡æ–™ |\n| Market Data å¸‚å ´è³‡æ–™ | [MARKET_DATA.md](MARKET_DATA.md) | Historical, snapshot, credit, scanners æ­·å²è³‡æ–™/å¿«ç…§/è³‡åˆ¸/æƒæå™¨ |\n| Accounting å¸³å‹™ | [ACCOUNTING.md](ACCOUNTING.md) | Balance, margin, P&L, trading limits é¤˜é¡/ä¿è­‰é‡‘/æç›Š/é¡åº¦ |\n| Advanced é€²éš | [ADVANCED.md](ADVANCED.md) | Quote binding, non-blocking, stop orders å ±åƒ¹ç¶å®š/éé˜»å¡/è§¸åƒ¹ |\n| Troubleshooting å•é¡Œæ’è§£ | [TROUBLESHOOTING.md](TROUBLESHOOTING.md) | Common issues and solutions å¸¸è¦‹å•é¡Œèˆ‡è§£æ±º |\n\n---\n\n## Quick Start å¿«é€Ÿå…¥é–€\n\n### Installation å®‰è£\n\n```bash\n# pip\npip install shioaji\n\n# uv (recommended æ¨è–¦)\nuv add shioaji\n\n# with speed optimization é€Ÿåº¦å„ªåŒ–ç‰ˆ\nuv add shioaji --extra speed\n\n# Docker\ndocker run -it sinotrade/shioaji:latest\n```\n\n### Login & Activate CA ç™»å…¥èˆ‡æ†‘è­‰å•Ÿç”¨\n\n```python\nimport shioaji as sj\n\napi = sj.Shioaji()\n\n# Login with API Key ä½¿ç”¨ API Key ç™»å…¥\naccounts = api.login(\n    api_key=\"YOUR_API_KEY\",\n    secret_key=\"YOUR_SECRET_KEY\"\n)\n\n# Activate CA certificate å•Ÿç”¨æ†‘è­‰ (required for placing orders ä¸‹å–®å¿…é ˆ)\napi.activate_ca(\n    ca_path=\"/path/to/Sinopac.pfx\",\n    ca_passwd=\"YOUR_CA_PASSWORD\",\n)\n```\n\n### Simulation Mode æ¨¡æ“¬æ¨¡å¼\n\nTest API without real money. ä½¿ç”¨æ¨¡æ“¬ç’°å¢ƒæ¸¬è©¦ APIã€‚\n\n```python\nimport shioaji as sj\n\napi = sj.Shioaji(simulation=True)\napi.login(api_key=\"YOUR_KEY\", secret_key=\"YOUR_SECRET\")\n```\n\n**Available in simulation æ¨¡æ“¬æ¨¡å¼å¯ç”¨åŠŸèƒ½:**\n- Quote: subscribe, unsubscribe, ticks, kbars, snapshots\n- Order: place_order, update_order, cancel_order, update_status, list_trades\n- Account: list_positions, list_profit_loss\n- Data: short_stock_sources, credit_enquires, scanners\n\n### Simple Order Example ç°¡å–®ä¸‹å–®ç¯„ä¾‹\n\n```python\n# Get contract å–å¾—åˆç´„\ncontract = api.Contracts.Stocks[\"2330\"]  # TSMC å°ç©é›»\n\n# Create order å»ºç«‹è¨‚å–®\norder = api.Order(\n    price=580,\n    quantity=1,\n    action=sj.constant.Action.Buy,\n    price_type=sj.constant.StockPriceType.LMT,\n    order_type=sj.constant.OrderType.ROD,\n    account=api.stock_account,\n)\n\n# Place order ä¸‹å–®\ntrade = api.place_order(contract, order)\n```\n\n---\n\n## Common Constants å¸¸ç”¨å¸¸æ•¸\n\n### Action è²·è³£æ–¹å‘\n```python\nsj.constant.Action.Buy   # è²·é€²\nsj.constant.Action.Sell  # è³£å‡º\n```\n\n### Stock Price Type è‚¡ç¥¨åƒ¹æ ¼é¡å‹\n```python\nsj.constant.StockPriceType.LMT  # Limit é™åƒ¹\nsj.constant.StockPriceType.MKT  # Market å¸‚åƒ¹\nsj.constant.StockPriceType.MKP  # Range Market ç¯„åœå¸‚åƒ¹\n```\n\n### Futures Price Type æœŸè²¨åƒ¹æ ¼é¡å‹\n```python\nsj.constant.FuturesPriceType.LMT  # Limit é™åƒ¹\nsj.constant.FuturesPriceType.MKT  # Market å¸‚åƒ¹\nsj.constant.FuturesPriceType.MKP  # Range Market ç¯„åœå¸‚åƒ¹\n```\n\n### Order Type å§”è¨—æ¢ä»¶\n```python\nsj.constant.OrderType.ROD  # Rest of Day ç•¶æ—¥æœ‰æ•ˆ\nsj.constant.OrderType.IOC  # Immediate or Cancel ç«‹å³æˆäº¤å¦å‰‡å–æ¶ˆ\nsj.constant.OrderType.FOK  # Fill or Kill å…¨éƒ¨æˆäº¤å¦å‰‡å–æ¶ˆ\n```\n\n### Stock Order Lot è‚¡ç¥¨äº¤æ˜“å–®ä½\n```python\nsj.constant.StockOrderLot.Common      # Regular æ•´è‚¡ (1000 shares)\nsj.constant.StockOrderLot.Odd         # After-hours odd lot ç›¤å¾Œé›¶è‚¡\nsj.constant.StockOrderLot.IntradayOdd # Intraday odd lot ç›¤ä¸­é›¶è‚¡\nsj.constant.StockOrderLot.Fixing      # Fixing å®šç›¤\n```\n\n### Order Condition ä¿¡ç”¨äº¤æ˜“æ¢ä»¶\n```python\nsj.constant.StockOrderCond.Cash          # Cash ç¾è‚¡\nsj.constant.StockOrderCond.MarginTrading # Margin èè³‡\nsj.constant.StockOrderCond.ShortSelling  # Short èåˆ¸\n```\n\n### Quote Type å ±åƒ¹é¡å‹\n```python\nsj.constant.QuoteType.Tick    # Tick data é€ç­†æˆäº¤\nsj.constant.QuoteType.BidAsk  # Bid/Ask data äº”æª”å ±åƒ¹\n```\n\n---\n\n## Account Objects å¸³æˆ¶ç‰©ä»¶\n\n```python\n# Stock account è‚¡ç¥¨å¸³æˆ¶\napi.stock_account\n\n# Futures account æœŸè²¨å¸³æˆ¶\napi.futopt_account\n\n# List all accounts åˆ—å‡ºæ‰€æœ‰å¸³æˆ¶\napi.list_accounts()\n```\n\n---\n\n## Rate Limits æµé‡é™åˆ¶\n\n| Category é¡åˆ¥ | Limit é™åˆ¶ |\n|---------------|------------|\n| Daily Traffic æ¯æ—¥æµé‡ | 500MB - 10GB (based on trading volume ä¾äº¤æ˜“é‡) |\n| Quote Query è¡Œæƒ…æŸ¥è©¢ | 50 requests / 5 sec |\n| Accounting Query å¸³å‹™æŸ¥è©¢ | 25 requests / 5 sec |\n| Connections é€£ç·šæ•¸ | 5 per person ID |\n| Daily Logins æ¯æ—¥ç™»å…¥ | 1000 times |\n\n---\n\n## Common Patterns å¸¸ç”¨æ¨¡å¼\n\n### Subscribe Market Data è¨‚é–±è¡Œæƒ…\n\n```python\n# Subscribe tick data è¨‚é–±é€ç­†æˆäº¤\napi.quote.subscribe(\n    api.Contracts.Stocks[\"2330\"],\n    quote_type=sj.constant.QuoteType.Tick\n)\n\n# Subscribe bidask è¨‚é–±äº”æª”\napi.quote.subscribe(\n    api.Contracts.Stocks[\"2330\"],\n    quote_type=sj.constant.QuoteType.BidAsk\n)\n\n# Set callback è¨­å®šå›èª¿\n@api.quote.on_quote\ndef quote_callback(topic, quote):\n    print(f\"Topic: {topic}, Quote: {quote}\")\n```\n\n### Query Positions æŸ¥è©¢æŒå€‰\n\n```python\n# Stock positions è‚¡ç¥¨æŒå€‰\npositions = api.list_positions(api.stock_account)\n\n# Futures positions æœŸè²¨æŒå€‰\npositions = api.list_positions(api.futopt_account)\n```\n\n### Cancel Order åˆªå–®\n\n```python\napi.cancel_order(trade)\n```\n\n### Update Order æ”¹å–®\n\n```python\n# Change price æ”¹åƒ¹\napi.update_order(trade=trade, price=590)\n\n# Reduce quantity æ¸›é‡ (can only reduce åªèƒ½æ¸›å°‘)\napi.update_order(trade=trade, qty=1)\n```\n\n---\n\n## Error Handling éŒ¯èª¤è™•ç†\n\n```python\ntry:\n    trade = api.place_order(contract, order)\nexcept Exception as e:\n    print(f\"Order failed: {e}\")\n\n# Check order status æª¢æŸ¥è¨‚å–®ç‹€æ…‹\napi.update_status(api.stock_account)\nfor trade in api.list_trades():\n    print(trade.status)\n```\n\n---\n\n## Logout ç™»å‡º\n\n```python\napi.logout()\n```\n"
      },
      "discovered_at": "2026-01-11T15:36:19.833191Z",
      "fetch_error": null
    },
    {
      "name": "ecto-thinking",
      "slug": "ecto-thinking",
      "source": "skillsmp",
      "owner": "georgeguimaraes",
      "repo_name": "claude-code-elixir",
      "repository_url": "https://github.com/georgeguimaraes/claude-code-elixir",
      "skill_path": "plugins/elixir/skills/ecto-thinking",
      "github_metadata": {
        "stars": 67,
        "description": "Claude Code plugin marketplace for Elixir development",
        "default_branch": "main",
        "pushed_at": "2026-01-07T23:57:45Z",
        "created_at": "2025-12-26T04:08:18Z",
        "language": "Elixir",
        "license": "Apache-2.0",
        "open_issues": 0,
        "forks": 3
      },
      "skill_md": {
        "found": true,
        "path": "plugins/elixir/skills/ecto-thinking/SKILL.md",
        "branch": "main",
        "content": "---\nname: ecto-thinking\ndescription: This skill should be used when the user asks to \"add a database table\", \"create a new context\", \"query the database\", \"add a field to a schema\", \"validate form input\", \"fix N+1 queries\", \"preload this association\", \"separate these concerns\", or mentions Repo, changesets, migrations, Ecto.Multi, has_many, belongs_to, transactions, query composition, or how contexts should talk to each other.\n---\n\n# Ecto Thinking\n\nMental shifts for Ecto and data layer design. These insights challenge typical ORM patterns.\n\n## Context = Setting That Changes Meaning\n\nContext isn't just a namespaceâ€”it changes what words mean. \"Product\" means different things in Checkout (SKU, name), Billing (SKU, cost), and Fulfillment (SKU, warehouse). Each bounded context may have its OWN Product schema/table.\n\n**Think top-down:** Subdomain â†’ Context â†’ Entity. Not \"What context does Product belong to?\" but \"What is a Product in this business domain?\"\n\n## Cross-Context References: IDs, Not Associations\n\n```elixir\nschema \"cart_items\" do\n  field :product_id, :integer  # Reference by ID\n  # NOT: belongs_to :product, Catalog.Product\nend\n```\n\nQuery through the context, not across associations. Keeps contexts independent and testable.\n\n## DDD Patterns as Pipelines\n\n```elixir\ndef create_product(params) do\n  params\n  |> Products.build()       # Factory: unstructured â†’ domain\n  |> Products.validate()    # Aggregate: enforce invariants\n  |> Products.insert()      # Repository: persist\nend\n```\n\nUse events (as data structs) to compose bounded contexts with minimal coupling.\n\n## Schema â‰  Database Table\n\n| Use Case | Approach |\n|----------|----------|\n| Database table | Standard `schema/2` |\n| Form validation only | `embedded_schema/1` |\n| API request/response | Embedded schema or schemaless |\n\n## Multiple Changesets per Schema\n\n```elixir\ndef registration_changeset(user, attrs)  # Full validation + password\ndef profile_changeset(user, attrs)       # Name, bio only\ndef admin_changeset(user, attrs)         # Role, verified_at\n```\n\nDifferent operations = different changesets.\n\n## Multi-Tenancy: Composite Foreign Keys\n\n```elixir\nadd :post_id, references(:posts, with: [org_id: :org_id], match: :full)\n```\n\nUse `prepare_query/3` for automatic scoping. Raise if `org_id` missing.\n\n## Preload vs Join Trade-offs\n\n| Approach | Best For |\n|----------|----------|\n| Separate preloads | Has-many with many records (less memory) |\n| Join preloads | Belongs-to, has-one (single query) |\n\nJoin preloads can use 10x more memory for has-many.\n\n## CRUD Contexts Are Fine\n\n> \"If you have a CRUD bounded context, go for it. No need to add complexity.\"\n\nUse generators for simple cases. Add DDD patterns only when business logic demands it.\n\n## Gotchas from Core Team\n\n### CTE Queries Don't Inherit Schema Prefix\n\nIn multi-tenant apps, CTEs don't get the parent query's prefix.\n\n**Fix:** Explicitly set prefix: `%{recursive_query | prefix: \"tenant\"}`\n\n### Parameterized Queries â‰  Prepared Statements\n\n- **Parameterized queries:** `WHERE id = $1` â€” always used by Ecto\n- **Prepared statements:** Query plan cached by name â€” can be disabled\n\n**pgbouncer:** Use `prepare: :unnamed` (disables prepared statements, keeps parameterized queries).\n\n### pool_count vs pool_size\n\nMore pools with fewer connections = better for benchmarks. **But** with mixed fast/slow queries, a single larger pool gives better latency.\n\n**Rule:** `pool_count` for uniform workloads, larger `pool_size` for real apps.\n\n### Sandbox Mode Doesn't Work With External Processes\n\nCachex, separate GenServers, or anything outside the test process won't share the sandbox transaction.\n\n**Fix:** Make the external service use the test process, or accept it's not in the same transaction.\n\n### Null Bytes Crash Postgres\n\nPostgreSQL rejects null bytes even though they're valid UTF-8.\n\n**Fix:** Sanitize at boundaries: `String.replace(string, \"\\x00\", \"\")`\n\n### preload_order for Association Sorting\n\n```elixir\nhas_many :comments, Comment, preload_order: [desc: :inserted_at]\n```\n\nNote: Doesn't work for `through` associations.\n\n### Runtime Migrations Use List API\n\n```elixir\nEcto.Migrator.run(Repo, [{0, Migration1}, {1, Migration2}], :up, opts)\n```\n\n## Idioms\n\n- Prefer `Repo.insert/1` over `Repo.insert!/1`â€”handle `{:ok, _}` / `{:error, _}` explicitly\n- Use `Repo.transact/1` (Ecto 3.12+) for simple transactions instead of `Ecto.Multi`\n\n## Red Flags - STOP and Reconsider\n\n- belongs_to pointing to another context's schema\n- Single changeset for all operations\n- Preloading has-many with join\n- CTEs in multi-tenant apps without explicit prefix\n- Using pgbouncer without `prepare: :unnamed`\n- Testing with Cachex/GenServers assuming sandbox shares transactions\n- Accepting user input without null byte sanitization\n\n**Any of these? Re-read the Gotchas section.**\n"
      },
      "discovered_at": "2026-01-11T15:36:20.215985Z",
      "fetch_error": null
    },
    {
      "name": "elixir-thinking",
      "slug": "elixir-thinking",
      "source": "skillsmp",
      "owner": "georgeguimaraes",
      "repo_name": "claude-code-elixir",
      "repository_url": "https://github.com/georgeguimaraes/claude-code-elixir",
      "skill_path": "plugins/elixir/skills/elixir-thinking",
      "github_metadata": {
        "stars": 67,
        "description": "Claude Code plugin marketplace for Elixir development",
        "default_branch": "main",
        "pushed_at": "2026-01-07T23:57:45Z",
        "created_at": "2025-12-26T04:08:18Z",
        "language": "Elixir",
        "license": "Apache-2.0",
        "open_issues": 0,
        "forks": 3
      },
      "skill_md": {
        "found": true,
        "path": "plugins/elixir/skills/elixir-thinking/SKILL.md",
        "branch": "main",
        "content": "---\nname: elixir-thinking\ndescription: This skill should be used when the user asks to \"implement a feature in Elixir\", \"refactor this module\", \"should I use a GenServer here?\", \"how should I structure this?\", \"use the pipe operator\", \"add error handling\", \"make this concurrent\", or mentions protocols, behaviours, pattern matching, with statements, comprehensions, structs, or coming from an OOP background. Contains paradigm-shifting insights.\n---\n\n# Elixir Thinking\n\nMental shifts required before writing Elixir. These contradict conventional OOP patterns.\n\n## The Iron Law\n\n```\nNO PROCESS WITHOUT A RUNTIME REASON\n```\n\nBefore creating a GenServer, Agent, or any process, answer YES to at least one:\n1. Do I need mutable state persisting across calls?\n2. Do I need concurrent execution?\n3. Do I need fault isolation?\n\n**All three are NO?** Use plain functions. Modules organize code; processes manage runtime.\n\n## The Three Decoupled Dimensions\n\nOOP couples behavior, state, and mutability together. Elixir decouples them:\n\n| OOP Dimension | Elixir Equivalent |\n|---------------|-------------------|\n| Behavior | Modules (functions) |\n| State | Data (structs, maps) |\n| Mutability | Processes (GenServer) |\n\nPick only what you need. \"I only need data and functions\" = no process needed.\n\n## \"Let It Crash\" = \"Let It Heal\"\n\nThe misconception: Write careless code.\nThe truth: Supervisors START processes.\n\n- Handle expected errors explicitly (`{:ok, _}` / `{:error, _}`)\n- Let unexpected errors crash â†’ supervisor restarts\n\n## Control Flow\n\n**Pattern matching first:**\n- Match on function heads instead of `if/else` or `case` in bodies\n- `%{}` matches ANY mapâ€”use `map_size(map) == 0` guard for empty maps\n- Avoid nested `case`â€”refactor to single `case`, `with`, or separate functions\n\n**Error handling:**\n- Use `{:ok, result}` / `{:error, reason}` for operations that can fail\n- Avoid raising exceptions for control flow\n- Use `with` for chaining `{:ok, _}` / `{:error, _}` operations\n\n## Polymorphism\n\n| For Polymorphism Over... | Use | Contract |\n|--------------------------|-----|----------|\n| Modules | Behaviors | Upfront callbacks |\n| Data | Protocols | Upfront implementations |\n| Processes | Message passing | Implicit (send/receive) |\n\n**Behaviors** = default for module polymorphism (very cheap at runtime)\n**Protocols** = only when composing data types, especially built-ins\n**Message passing** = only when stateful by design (IO, file handles)\n\nUse the simplest abstraction: pattern matching â†’ anonymous functions â†’ behaviors â†’ protocols â†’ message passing. Each step adds complexity.\n\n**When justified:** Library extensibility, multiple implementations, test swapping.\n**When to stay coupled:** Internal module, single implementation, pattern matching handles all cases.\n\n## Data Modeling Replaces Class Hierarchies\n\nOOP: Complex class hierarchy + visitor pattern.\nElixir: Model as data + pattern matching + recursion.\n\n```elixir\n{:sequence, {:literal, \"rain\"}, {:repeat, {:alternation, \"dogs\", \"cats\"}}}\n\ndef interpret({:literal, text}, input), do: ...\ndef interpret({:sequence, left, right}, input), do: ...\ndef interpret({:repeat, pattern}, input), do: ...\n```\n\n## Defaults and Options\n\nUse `/3` variants (`Keyword.get/3`, `Map.get/3`) instead of case statements branching on `nil`:\n\n```elixir\n# WRONG\ncase Keyword.get(opts, :chunker) do\n  nil -> chunker()\n  config -> parse_chunker_config(config)\nend\n\n# RIGHT\nKeyword.get(opts, :chunker, :default) |> parse_chunker_config()\n```\n\nDon't create helper functions to merge config defaults. Inline the fallback:\n\n```elixir\n# WRONG\ndefp merge_defaults(opts), do: Keyword.merge([repo: Application.get_env(:app, :repo)], opts)\n\n# RIGHT\ndef some_function(opts) do\n  repo = opts[:repo] || Application.get_env(:app, :repo)\nend\n```\n\n## Idioms\n\n- Process dictionary is typically unidiomaticâ€”pass state explicitly\n- Reserve `is_thing` names for guards only\n- Use structs over maps when shape is known: `defstruct [:name, :age]`\n- Prepend to lists `[new | list]` not `list ++ [new]`\n- Use `dbg/1` for debuggingâ€”prints formatted value with context\n- Use built-in `JSON` module (Elixir 1.18+) instead of Jason\n\n## Testing\n\n**Test behavior, not implementation.** Test use cases / public API. Refactoring shouldn't break tests.\n\n**Test your code, not the framework.** If deleting your code doesn't fail the test, it's tautological.\n\n**Keep tests async.** `async: false` means you've coupled to global state. Fix the coupling:\n\n| Problem | Solution |\n|---------|----------|\n| `Application.put_env` | Pass config as function argument |\n| Feature flags | Inject via process dictionary or context |\n| ETS tables | Create per-test tables with unique names |\n| External APIs | Use Mox with explicit allowances |\n\n## Common Rationalizations\n\n| Excuse | Reality |\n|--------|---------|\n| \"I need a process to organize this code\" | Modules organize code. Processes are for runtime. |\n| \"GenServer is the Elixir way\" | Plain functions are also the Elixir way. |\n| \"I'll need state eventually\" | YAGNI. Add process when you need it. |\n| \"It's just a simple wrapper process\" | Simple wrappers become bottlenecks. |\n| \"This is how I'd structure it in OOP\" | Rethink from data flow. |\n\n## Red Flags - STOP and Reconsider\n\n- Creating process without answering the three questions\n- Using GenServer for stateless operations\n- Wrapping a library in a process \"for safety\"\n- One process per entity without runtime justification\n- Reaching for protocols when pattern matching works\n\n**Any of these? Re-read The Iron Law.**\n"
      },
      "discovered_at": "2026-01-11T15:36:20.512124Z",
      "fetch_error": null
    },
    {
      "name": "otp-thinking",
      "slug": "otp-thinking",
      "source": "skillsmp",
      "owner": "georgeguimaraes",
      "repo_name": "claude-code-elixir",
      "repository_url": "https://github.com/georgeguimaraes/claude-code-elixir",
      "skill_path": "plugins/elixir/skills/otp-thinking",
      "github_metadata": {
        "stars": 67,
        "description": "Claude Code plugin marketplace for Elixir development",
        "default_branch": "main",
        "pushed_at": "2026-01-07T23:57:45Z",
        "created_at": "2025-12-26T04:08:18Z",
        "language": "Elixir",
        "license": "Apache-2.0",
        "open_issues": 0,
        "forks": 3
      },
      "skill_md": {
        "found": true,
        "path": "plugins/elixir/skills/otp-thinking/SKILL.md",
        "branch": "main",
        "content": "---\nname: otp-thinking\ndescription: This skill should be used when the user asks to \"add background processing\", \"cache this data\", \"run this async\", \"handle concurrent requests\", \"manage state across requests\", \"process jobs from a queue\", \"this GenServer is slow\", or mentions GenServer, Supervisor, Agent, Task, Registry, DynamicSupervisor, handle_call, handle_cast, supervision trees, fault tolerance, \"let it crash\", or choosing between Broadway and Oban.\n---\n\n# OTP Thinking\n\nParadigm shifts for OTP design. These insights challenge typical concurrency and state management patterns.\n\n## The Iron Law\n\n```\nGENSERVER IS A BOTTLENECK BY DESIGN\n```\n\nA GenServer processes ONE message at a time. Before creating one, ask:\n1. Do I actually need serialized access?\n2. Will this become a throughput bottleneck?\n3. Can reads bypass the GenServer via ETS?\n\n**The ETS pattern:** GenServer owns ETS table, writes serialize through GenServer, reads bypass it entirely with `:read_concurrency`.\n\n**No exceptions:** Don't wrap stateless functions in GenServer. Don't create GenServer \"for organization\".\n\n## GenServer Patterns\n\n| Function | Use For |\n|----------|---------|\n| `call/3` | Synchronous requests expecting replies |\n| `cast/2` | Fire-and-forget messages |\n\n**When in doubt, use `call`** to ensure back-pressure. Set appropriate timeouts for `call/3`.\n\nUse `handle_continue/2` for post-init workâ€”keeps `init/1` fast and non-blocking.\n\n## Task.Supervisor, Not Task.async\n\n`Task.async` spawns a **linked** processâ€”if task crashes, caller crashes too.\n\n| Pattern | On task crash |\n|---------|---------------|\n| `Task.async/1` | Caller crashes (linked, unsupervised) |\n| `Task.Supervisor.async/2` | Caller crashes (linked, supervised) |\n| `Task.Supervisor.async_nolink/2` | Caller survives, can handle error |\n\n**Use Task.Supervisor for:** Production code, graceful shutdown, observability, `async_nolink`.\n**Use Task.async for:** Quick experiments, scripts, when crash-together is acceptable.\n\n## DynamicSupervisor + Registry = Named Dynamic Processes\n\nDynamicSupervisor only supports `:one_for_one` (dynamic children have no ordering). Use Registry for namesâ€”never create atoms dynamically:\n\n```elixir\ndefp via_tuple(id), do: {:via, Registry, {MyApp.Registry, id}}\n```\n\n**PartitionSupervisor** scales DynamicSupervisor for millions of children.\n\n## :pg for Distributed, Registry for Local\n\n| Tool | Scope | Use Case |\n|------|-------|----------|\n| Registry | Single node | Named dynamic processes |\n| :pg | Cluster-wide | Process groups, pub/sub |\n\n`:pg` replaced deprecated `:pg2`. **Horde** provides distributed supervisor/registry with CRDTs.\n\n## Broadway vs Oban: Different Problems\n\n| Tool | Use For |\n|------|---------|\n| Broadway | External queues (SQS, Kafka, RabbitMQ) â€” data ingestion with batching |\n| Oban | Background jobs with database persistence |\n\nBroadway is NOT a job queue.\n\n### Broadway Gotchas\n\n**Processors are for runtime, not code organization.** Dispatch to modules in `handle_message`, don't add processors for different message types.\n\n**one_for_all is for Broadway bugs, not your code.** Your `handle_message` errors are caught and result in failed messages, not supervisor restarts.\n\n**Handle expected failures in the producer** (connection loss, rate limits). Reserve max_restarts for unexpected bugs.\n\n## Supervision Strategies Encode Dependencies\n\n| Strategy | Children Relationship |\n|----------|----------------------|\n| :one_for_one | Independent |\n| :one_for_all | Interdependent (all restart) |\n| :rest_for_one | Sequential dependency |\n\nUse `:max_restarts` and `:max_seconds` to prevent restart loops.\n\nThink about failure cascades BEFORE coding.\n\n## Abstraction Decision Tree\n\n```\nNeed state?\nâ”œâ”€â”€ No â†’ Plain function\nâ””â”€â”€ Yes â†’ Complex behavior?\n    â”œâ”€â”€ No â†’ Agent\n    â””â”€â”€ Yes â†’ Supervision?\n        â”œâ”€â”€ No â†’ spawn_link\n        â””â”€â”€ Yes â†’ Request/response?\n            â”œâ”€â”€ No â†’ Task.Supervisor\n            â””â”€â”€ Yes â†’ Explicit states?\n                â”œâ”€â”€ No â†’ GenServer\n                â””â”€â”€ Yes â†’ GenStateMachine\n```\n\n## Storage Options\n\n| Need | Use |\n|------|-----|\n| Memory cache | ETS (`:read_concurrency` for reads) |\n| Static config | :persistent_term (faster than ETS) |\n| Disk persistence | DETS (2GB limit) |\n| Transactions/Distribution | Mnesia |\n\n## :sys Debugs ANY OTP Process\n\n```elixir\n:sys.get_state(pid)        # Current state\n:sys.trace(pid, true)      # Trace events (TURN OFF when done!)\n```\n\n## Telemetry Is Built Into Everything\n\nPhoenix, Ecto, and most libraries emit telemetry events. Attach handlers:\n\n```elixir\n:telemetry.attach(\"my-handler\", [:phoenix, :endpoint, :stop], &handle/4, nil)\n```\n\nUse `Telemetry.Metrics` + reporters (StatsD, Prometheus, LiveDashboard).\n\n## Red Flags - STOP and Reconsider\n\n- GenServer wrapping stateless computation\n- Task.async in production when you need error handling\n- Creating atoms dynamically for process names\n- Single GenServer becoming throughput bottleneck\n- Using Broadway for background jobs (use Oban)\n- Using Oban for external queue consumption (use Broadway)\n- No supervision strategy reasoning\n\n**Any of these? Re-read The Iron Law and use the Abstraction Decision Tree.**\n"
      },
      "discovered_at": "2026-01-11T15:36:20.903517Z",
      "fetch_error": null
    },
    {
      "name": "phoenix-thinking",
      "slug": "phoenix-thinking",
      "source": "skillsmp",
      "owner": "georgeguimaraes",
      "repo_name": "claude-code-elixir",
      "repository_url": "https://github.com/georgeguimaraes/claude-code-elixir",
      "skill_path": "plugins/elixir/skills/phoenix-thinking",
      "github_metadata": {
        "stars": 67,
        "description": "Claude Code plugin marketplace for Elixir development",
        "default_branch": "main",
        "pushed_at": "2026-01-07T23:57:45Z",
        "created_at": "2025-12-26T04:08:18Z",
        "language": "Elixir",
        "license": "Apache-2.0",
        "open_issues": 0,
        "forks": 3
      },
      "skill_md": {
        "found": true,
        "path": "plugins/elixir/skills/phoenix-thinking/SKILL.md",
        "branch": "main",
        "content": "---\nname: phoenix-thinking\ndescription: This skill should be used when the user asks to \"add a LiveView page\", \"create a form\", \"handle real-time updates\", \"broadcast changes to users\", \"add a new route\", \"create an API endpoint\", \"fix this LiveView bug\", \"why is mount called twice?\", or mentions handle_event, handle_info, handle_params, mount, channels, controllers, components, assigns, sockets, or PubSub. Essential for avoiding duplicate queries in mount.\n---\n\n# Phoenix Thinking\n\nMental shifts for Phoenix applications. These insights challenge typical web framework patterns.\n\n## The Iron Law\n\n```\nNO DATABASE QUERIES IN MOUNT\n```\n\nmount/3 is called TWICE (HTTP request + WebSocket connection). Queries in mount = duplicate queries.\n\n```elixir\ndef mount(_params, _session, socket) do\n  # NO database queries here! Called twice.\n  {:ok, assign(socket, posts: [], loading: true)}\nend\n\ndef handle_params(params, _uri, socket) do\n  # Database queries here - once per navigation\n  posts = Blog.list_posts(socket.assigns.scope)\n  {:noreply, assign(socket, posts: posts, loading: false)}\nend\n```\n\n**mount/3** = setup only (empty assigns, subscriptions, defaults)\n**handle_params/3** = data loading (all database queries, URL-driven state)\n\n**No exceptions:** Don't query \"just this one small thing\" in mount. Don't \"optimize later\". LiveView lifecycle is non-negotiable.\n\n## Scopes: Security-First Pattern (Phoenix 1.8+)\n\nScopes address OWASP #1 vulnerability: Broken Access Control. Authorization context is threaded automaticallyâ€”no more forgetting to scope queries.\n\n```elixir\ndef list_posts(%Scope{user: user}) do\n  Post |> where(user_id: ^user.id) |> Repo.all()\nend\n```\n\n## PubSub Topics Must Be Scoped\n\n```elixir\ndef subscribe(%Scope{organization: org}) do\n  Phoenix.PubSub.subscribe(@pubsub, \"posts:org:#{org.id}\")\nend\n```\n\nUnscoped topics = data leaks between tenants.\n\n## External Polling: GenServer, Not LiveView\n\n**Bad:** Every connected user makes API calls (multiplied by users).\n**Good:** Single GenServer polls, broadcasts to all via PubSub.\n\n## Components Receive Data, LiveViews Own Data\n\n- **Functional components:** Display-only, no internal state\n- **LiveComponents:** Own state, handle own events\n- **LiveViews:** Full page, owns URL, top-level state\n\n## Async Data Loading\n\nUse `assign_async/3` for data that can load after mount:\n\n```elixir\ndef mount(_params, _session, socket) do\n  {:ok, assign_async(socket, :user, fn -> {:ok, %{user: fetch_user()}} end)}\nend\n```\n\n## Gotchas from Core Team\n\n### LiveView terminate/2 Requires trap_exit\n\n`terminate/2` only fires if you're trapping exitsâ€”which you shouldn't do in LiveView.\n\n**Fix:** Use a separate GenServer that monitors the LiveView process via `Process.monitor/1`, then handle `:DOWN` messages to run cleanup.\n\n### start_async Duplicate Names: Later Wins\n\nCalling `start_async` with the same name while a task is in-flight: the **later one wins**, the previous task's result is ignored.\n\n**Fix:** Call `cancel_async/3` first if you want to abort the previous task.\n\n### Channel Intercept Socket State is Stale\n\nThe socket in `handle_out` intercept is a snapshot from subscription time, not current state.\n\n**Why:** Socket is copied into fastlane lookup at subscription time for performance.\n\n**Fix:** Use separate topics per role, or fetch current state explicitly.\n\n### CSS Class Precedence is Stylesheet Order\n\nWhen merging classes on components, precedence is determined by **stylesheet order**, not HTML order. If `btn-primary` appears later in the compiled CSS than `bg-red-500`, it wins regardless of HTML order.\n\n**Fix:** Use variant props instead of class merging.\n\n### Upload Content-Type Can't Be Trusted\n\nThe `:content_type` in `%Plug.Upload{}` is user-provided. Always validate actual file contents (magic bytes) and rewrite filename/extension.\n\n### Read Body Before Plug.Parsers for Webhooks\n\nTo verify webhook signatures, you need the raw body. But Plug.Parsers consumes it.\n\n```elixir\n{:ok, body, conn} = Plug.Conn.read_body(conn)\nverify_signature!(conn, body)\n%{conn | body_params: JSON.decode!(body)}\n```\n\nDon't use `preserve_req_body: true`â€”it keeps the entire body in memory for ALL requests.\n\n## Red Flags - STOP and Reconsider\n\n- Database query in mount/3\n- Unscoped PubSub topics in multi-tenant app\n- LiveView polling external APIs directly\n- Using terminate/2 for cleanup (won't fire without trap_exit)\n- Calling start_async with same name without cancel_async first\n- Relying on socket.assigns in Channel intercepts (stale!)\n- CSS class merging for component customization (use variants)\n- Trusting `%Plug.Upload{}.content_type` for security\n\n**Any of these? Re-read The Iron Law and the Gotchas section.**\n"
      },
      "discovered_at": "2026-01-11T15:36:21.318111Z",
      "fetch_error": null
    },
    {
      "name": "using-elixir-skills",
      "slug": "using-elixir-skills",
      "source": "skillsmp",
      "owner": "georgeguimaraes",
      "repo_name": "claude-code-elixir",
      "repository_url": "https://github.com/georgeguimaraes/claude-code-elixir",
      "skill_path": "plugins/elixir/skills/using-elixir-skills",
      "github_metadata": {
        "stars": 67,
        "description": "Claude Code plugin marketplace for Elixir development",
        "default_branch": "main",
        "pushed_at": "2026-01-07T23:57:45Z",
        "created_at": "2025-12-26T04:08:18Z",
        "language": "Elixir",
        "license": "Apache-2.0",
        "open_issues": 0,
        "forks": 3
      },
      "skill_md": {
        "found": true,
        "path": "plugins/elixir/skills/using-elixir-skills/SKILL.md",
        "branch": "main",
        "content": "---\nname: using-elixir-skills\ndescription: This skill should be used when the user works on any .ex or .exs file, mentions Elixir/Phoenix/Ecto/OTP, the project has a mix.exs, or asks \"which skill should I use\", \"new to Elixir\", \"help with Elixir\". Routes to the correct thinking skill BEFORE exploring code. Triggers on \"implement\", \"add\", \"fix\", \"refactor\" in Elixir projects.\n---\n\n<EXTREMELY-IMPORTANT>\nIf the task involves Elixir, Phoenix, or OTP code, you MUST invoke the relevant skill BEFORE doing ANYTHING elseâ€”including exploring the codebase.\n\nTHIS IS NOT OPTIONAL. Skills tell you HOW to explore and WHAT to look for. You cannot rationalize your way out of this.\n</EXTREMELY-IMPORTANT>\n\n## The Rule\n\n```\nElixir/Phoenix/OTP task â†’ Invoke skill FIRST â†’ Then explore/research â†’ Then write code\n```\n\n**Skills come before exploration.** The skills tell you what patterns to look for, what questions to ask, and what anti-patterns to avoid. Exploring without the skill means you don't know what you're looking for.\n\n## Skill Triggers\n\n| Trigger Phrases | Skill to Invoke |\n|-----------------|-----------------|\n| code, implement, write, design, architecture, structure, pattern | `elixir-thinking` |\n| LiveView, Plug, PubSub, mount, channel, socket, component | `phoenix-thinking` |\n| context, schema, Ecto, changeset, preload, Repo, migration | `ecto-thinking` |\n| GenServer, supervisor, Task, ETS, bottleneck, Broadway | `otp-thinking` |\n| Oban, workflow, job queue, cascade, graft, background job, async job | `oban-thinking` |\n\n## Red Flags\n\nThese thoughts mean STOPâ€”invoke the skill:\n\n| Thought | Reality |\n|---------|---------|\n| \"Let me explore the codebase first\" | Skills tell you WHAT to look for. Invoke first. |\n| \"Let me understand the code first\" | Skills guide understanding. Invoke first. |\n| \"But first, let me...\" | No. Skills come first. Always. |\n| \"I'll add a process to organize this\" | Processes are for runtime, not organization. |\n| \"GenServer is the Elixir way\" | GenServer is a bottleneck by design. |\n| \"I'll query in mount\" | mount is called twice. |\n| \"Task.async is simpler\" | Use Task.Supervisor in production. |\n| \"I know Elixir well enough\" | These skills contain paradigm shifts. Invoke them. |\n"
      },
      "discovered_at": "2026-01-11T15:36:21.747748Z",
      "fetch_error": null
    },
    {
      "name": "oban-thinking",
      "slug": "oban-thinking",
      "source": "skillsmp",
      "owner": "georgeguimaraes",
      "repo_name": "claude-code-elixir",
      "repository_url": "https://github.com/georgeguimaraes/claude-code-elixir",
      "skill_path": "plugins/elixir/skills/oban-thinking",
      "github_metadata": {
        "stars": 67,
        "description": "Claude Code plugin marketplace for Elixir development",
        "default_branch": "main",
        "pushed_at": "2026-01-07T23:57:45Z",
        "created_at": "2025-12-26T04:08:18Z",
        "language": "Elixir",
        "license": "Apache-2.0",
        "open_issues": 0,
        "forks": 3
      },
      "skill_md": {
        "found": true,
        "path": "plugins/elixir/skills/oban-thinking/SKILL.md",
        "branch": "main",
        "content": "---\nname: oban-thinking\ndescription: This skill should be used when the user asks to \"add a background job\", \"process async\", \"schedule a task\", \"retry failed jobs\", \"add email sending\", \"run this later\", \"add a cron job\", \"unique jobs\", \"batch process\", or mentions Oban, Oban Pro, workflows, job queues, cascades, grafting, recorded values, job args, or troubleshooting job failures.\n---\n\n# Oban Thinking\n\nParadigm shifts for Oban job processing. These insights prevent common bugs and guide proper patterns.\n\n---\n\n# Part 1: Oban (Non-Pro)\n\n## The Iron Law: JSON Serialization\n\n```\nJOB ARGS ARE JSON. ATOMS BECOME STRINGS.\n```\n\nThis single fact causes most Oban debugging headaches.\n\n```elixir\n# Creating - atom keys are fine\nMyWorker.new(%{user_id: 123})\n\n# Processing - must use string keys (JSON converted atoms to strings)\ndef perform(%Oban.Job{args: %{\"user_id\" => user_id}}) do\n  # ...\nend\n```\n\n## Error Handling: Let It Crash\n\n**Don't catch errors in Oban jobs.** Let them bubble up to Oban for proper handling.\n\n### Why?\n\n1. **Automatic logging**: Oban logs the full error with stacktrace\n2. **Automatic retries**: Jobs retry with exponential backoff\n3. **Visibility**: Failed jobs appear in Oban Web dashboard\n4. **Consistency**: Error states are tracked in the database\n\n### Anti-Pattern\n\n```elixir\n# Bad: Swallowing errors\ndef perform(%Oban.Job{} = job) do\n  case do_work(job.args) do\n    {:ok, result} -> {:ok, result}\n    {:error, reason} ->\n      Logger.error(\"Failed: #{reason}\")\n      {:ok, :failed}  # Silently marks as complete!\n  end\nend\n```\n\n### Correct Pattern\n\n```elixir\n# Good: Let errors propagate\ndef perform(%Oban.Job{} = job) do\n  result = do_work!(job.args)  # Raises on failure\n  {:ok, result}\nend\n\n# Or return error tuple - Oban treats as failure\ndef perform(%Oban.Job{} = job) do\n  case do_work(job.args) do\n    {:ok, result} -> {:ok, result}\n    {:error, reason} -> {:error, reason}  # Oban will retry\n  end\nend\n```\n\n### When to Catch Errors\n\nOnly catch errors when you need custom retry logic or want to mark a job as permanently failed:\n\n```elixir\ndef perform(%Oban.Job{} = job) do\n  case external_api_call(job.args) do\n    {:ok, result} -> {:ok, result}\n    {:error, :not_found} -> {:cancel, :resource_not_found}  # Don't retry\n    {:error, :rate_limited} -> {:snooze, 60}  # Retry in 60 seconds\n    {:error, _} -> {:error, :will_retry}  # Normal retry\n  end\nend\n```\n\n## Snoozing for Polling\n\nUse `{:snooze, seconds}` for polling external state instead of manual retry logic:\n\n```elixir\ndef perform(%Oban.Job{} = job) do\n  if external_thing_finished?(job.args) do\n    {:ok, :done}\n  else\n    {:snooze, 5}  # Check again in 5 seconds\n  end\nend\n```\n\n## Simple Job Chaining\n\nFor simple sequential chains (JobA â†’ JobB â†’ JobC), have each job enqueue the next:\n\n```elixir\ndef perform(%Oban.Job{} = job) do\n  result = do_work(job.args)\n  # Enqueue next job on success\n  NextWorker.new(%{data: result}) |> Oban.insert()\n  {:ok, result}\nend\n```\n\n**Don't reach for Oban Pro Workflows for linear chains.**\n\n## Unique Jobs\n\nPrevent duplicate jobs with the `unique` option:\n\n```elixir\nuse Oban.Worker,\n  queue: :default,\n  unique: [period: 60]  # Only one job with same args per 60 seconds\n\n# Or scope uniqueness to specific fields\nunique: [period: 300, keys: [:user_id]]\n```\n\n**Gotcha:** Uniqueness is checked on insert, not execution. Two identical jobs inserted 61 seconds apart will both run.\n\n## High Throughput: Chunking\n\nFor millions of records, **chunk work into batches** rather than one job per item:\n\n```elixir\n# Bad: One job per contact (millions of jobs = database strain)\nEnum.each(contacts, &ContactWorker.new(%{id: &1.id}) |> Oban.insert())\n\n# Good: Chunk into batches\ncontacts\n|> Enum.chunk_every(100)\n|> Enum.each(&BatchWorker.new(%{contact_ids: Enum.map(&1, fn c -> c.id end)}) |> Oban.insert())\n```\n\nUse bulk inserts without uniqueness constraints for maximum throughput.\n\n---\n\n# Part 2: Oban Pro\n\n## Cascade Context: Erlang Term Serialization\n\nUnlike regular job args, **cascade context preserves atoms**:\n\n```elixir\n# Creating - atom keys\nWorkflow.put_context(%{score_run_id: id})\n\n# Processing - atom keys still work!\ndef my_cascade(%{score_run_id: id}) do\n  # ...\nend\n\n# Dot notation works too\ndef later_step(context) do\n  context.score_run_id\n  context.previous_result\nend\n```\n\n### Serialization Summary\n\n| | Creating | Processing |\n|-----------------|----------|--------------|\n| Regular jobs | atoms ok | strings only |\n| Cascade context | atoms ok | atoms ok |\n\n## When to Use Workflows\n\nReserve Workflows for:\n- Complex dependency graphs (not just linear chains)\n- Fan-out/fan-in patterns\n- When you need recorded values across steps\n- Conditional branching based on runtime state\n\n**Don't use Workflows for simple A â†’ B â†’ C chains.**\n\n## Workflow Composition with Graft\n\nWhen you need a parent workflow to wait for a sub-workflow to complete before continuing, use `add_graft` instead of `add_workflow`.\n\n### Key Differences\n\n| Method | Sub-workflow completes before deps run? | Output accessible? |\n|--------|----------------------------------------|-------------------|\n| `add_workflow` | No - just inserts jobs | No |\n| `add_graft` | Yes - waits for all jobs | Yes, via recorded values |\n\n### Pattern: Composing Independent Concerns\n\nDon't couple unrelated concerns (e.g., notifications) to domain-specific workflows (e.g., scoring). Instead, create a higher-level orchestrator:\n\n```elixir\n# Bad: Notification logic buried in AggregateScores\ndefmodule AggregateScores do\n  def workflow(score_run_id) do\n    Workflow.new()\n    |> Workflow.add(:aggregate, AggregateJob.new(...))\n    |> Workflow.add(:send_notification, SendEmail.new(...), deps: :aggregate)  # Wrong place!\n  end\nend\n\n# Good: Higher-level workflow composes scoring + notification\ndefmodule FullRunWithNotifications do\n  def workflow(site_url, opts) do\n    notification_opts = build_notification_opts(opts)\n\n    Workflow.new()\n    |> Workflow.put_context(%{notification_opts: notification_opts})\n    |> Workflow.add_graft(:scoring, &graft_full_run/1)\n    |> Workflow.add_cascade(:send_notification, &send_notification/1, deps: :scoring)\n  end\n\n  defp graft_full_run(context) do\n    # Sub-workflow doesn't know about notifications\n    FullRun.workflow(context.site_url, context.opts)\n    |> Workflow.apply_graft()\n    |> Oban.insert_all()\n  end\nend\n```\n\n### Recording Values for Dependent Steps\n\nFor a grafted workflow's output to be available to dependent steps, the final job must use `recorded: true`:\n\n```elixir\ndefmodule FinalJob do\n  use Oban.Pro.Worker, queue: :default, recorded: true\n\n  def perform(%Oban.Job{} = job) do\n    # Return value becomes available in context\n    {:ok, %{score_run_id: score_run_id, composite_score: score}}\n  end\nend\n```\n\n## Dynamic Workflow Appending\n\nAdd jobs to a running workflow with `Workflow.append/2`:\n\n```elixir\ndef perform(%Oban.Job{} = job) do\n  if needs_extra_step?(job.args) do\n    job\n    |> Workflow.append()\n    |> Workflow.add(:extra, ExtraWorker.new(%{}), deps: [:current_step])\n    |> Oban.insert_all()\n  end\n  {:ok, :done}\nend\n```\n\n**Caveat:** Cannot override context or add dependencies to already-running jobs. For complex dynamic scenarios, check external state in the job itself.\n\n## Fan-Out/Fan-In with Batches\n\nTo run a final job after multiple paginated workflows complete, use Batch callbacks:\n\n```elixir\n# Wrap workflows in a shared batch\nbatch_id = \"import-#{import_id}\"\n\npages\n|> Enum.each(fn page ->\n  PageWorkflow.workflow(page)\n  |> Batch.from_workflow(batch_id: batch_id)\n  |> Oban.insert_all()\nend)\n\n# Add completion callback\nBatch.new(batch_id: batch_id)\n|> Batch.add_callback(:completed, CompletionWorker)\n|> Oban.insert()\n```\n\n**Tip:** Include pagination workers in the batch to prevent premature completion.\n\n## Testing Workflows\n\n**Don't use inline testing mode** - workflows need database interaction.\n\n```elixir\n# Use run_workflow/1 for integration tests\nassert %{completed: 3} =\n  Workflow.new()\n  |> Workflow.add(:a, WorkerA.new(%{}))\n  |> Workflow.add(:b, WorkerB.new(%{}), deps: [:a])\n  |> Workflow.add(:c, WorkerC.new(%{}), deps: [:b])\n  |> run_workflow()\n```\n\nFor testing recorded values between workers, insert predecessor jobs with pre-filled metadata.\n\n---\n\n# Red Flags - STOP and Reconsider\n\n**Non-Pro:**\n- Pattern matching on atom keys in `perform/1`\n- Catching all errors and returning `{:ok, _}`\n- Wrapping job logic in try/rescue\n- Creating one job per item when processing millions of records\n\n**Pro:**\n- Using `add_workflow` when you need to wait for completion\n- Coupling notifications/emails to domain workflows\n- Not using `recorded: true` when you need output from grafted workflows\n- Using Workflows for simple linear job chains\n- Testing workflows with inline mode\n\n**Any of these? Re-read the serialization rules.**\n"
      },
      "discovered_at": "2026-01-11T15:36:22.163971Z",
      "fetch_error": null
    },
    {
      "name": "marketplace-release",
      "slug": "marketplace-release",
      "source": "skillsmp",
      "owner": "aiskillstore",
      "repo_name": "marketplace",
      "repository_url": "https://github.com/aiskillstore/marketplace",
      "skill_path": "plugins/emasoft/marketplace-release",
      "github_metadata": {
        "stars": 38,
        "description": "Security-audited skills for Claude, Codex & Claude Code. One-click install, quality verified.",
        "default_branch": "main",
        "pushed_at": "2026-01-11T15:16:05Z",
        "created_at": "2025-12-20T12:00:04Z",
        "language": "Ruby",
        "license": null,
        "open_issues": 0,
        "forks": 0
      },
      "skill_md": {
        "found": true,
        "path": "plugins/emasoft/marketplace-release/SKILL.md",
        "branch": "main",
        "content": "---\nname: marketplace-release\ndescription: Use when creating releases for Claude Code plugin marketplaces. Supports independent plugin versioning - each plugin can be released separately. Triggered by \"release\", \"bump version\", \"create release\", \"publish plugin\".\n---\n\n# Marketplace Release Automation\n\nA portable release script for Claude Code plugin marketplaces with **independent plugin versioning**. Each plugin in a marketplace maintains its own version and can be released separately.\n\n## Prerequisites\n\n1. **GitHub CLI** authenticated: `gh auth status`\n2. **Clean git state** (or acknowledge uncommitted changes)\n3. **marketplace.json** at `.claude-plugin/marketplace.json`\n4. Run from the **marketplace root directory**\n\n## Usage\n\n```bash\n# Release a specific plugin\npython \"${CLAUDE_PLUGIN_ROOT}/scripts/release.py\" <bump-type> <plugin-name> \"<release-notes>\"\n\n# List all plugins and their versions\npython \"${CLAUDE_PLUGIN_ROOT}/scripts/release.py\" --list\n\n# Or copy script to marketplace and run from root\npython scripts/release.py <bump-type> <plugin-name> \"<release-notes>\"\n```\n\n## Examples\n\n```bash\n# Patch release for ghe plugin\npython \"${CLAUDE_PLUGIN_ROOT}/scripts/release.py\" patch ghe \"Fix avatar loading issue\"\n\n# Minor release for marketplace-utils\npython \"${CLAUDE_PLUGIN_ROOT}/scripts/release.py\" minor marketplace-utils \"Add TOC generator\"\n\n# Major release with breaking changes\npython \"${CLAUDE_PLUGIN_ROOT}/scripts/release.py\" major ghe \"Breaking: New API structure\"\n\n# View all plugins and current versions\npython \"${CLAUDE_PLUGIN_ROOT}/scripts/release.py\" --list\n```\n\n## Version Bump Types\n\n| Type | When to Use | Example |\n|------|-------------|---------|\n| `patch` | Bug fixes, minor improvements | 0.5.4 -> 0.5.5 |\n| `minor` | New features, non-breaking changes | 0.5.5 -> 0.6.0 |\n| `major` | Breaking changes, major rewrites | 0.6.0 -> 1.0.0 |\n\n## What It Does\n\n1. **Validates prerequisites** - Checks gh CLI, git repo, uncommitted changes\n2. **Validates plugin** - Runs `claude plugin validate` to ensure plugin is correct\n3. **Bumps plugin version** - In both marketplace.json and the plugin's plugin.json\n4. **Updates script versions** - Automatically updates `__version__` in all scripts (marketplace-utils only)\n5. **Updates READMEs** - Plugin README badges + marketplace README version table\n6. **Creates commit** - With release message\n7. **Creates git tag** - Plugin-specific tag: `<plugin-name>-v<version>`\n8. **Pushes to remote** - Both commit and tag\n9. **Creates GitHub release** - With installation instructions\n\n## Plugin Validation\n\nBefore releasing, validate your plugin to catch errors early:\n\n```bash\n# Validate a specific plugin\npython \"${CLAUDE_PLUGIN_ROOT}/scripts/validate_plugin.py\" ghe\n\n# Validate all plugins\npython \"${CLAUDE_PLUGIN_ROOT}/scripts/validate_plugin.py\" --all\n\n# Show version\npython \"${CLAUDE_PLUGIN_ROOT}/scripts/validate_plugin.py\" --version\n```\n\nThe validation script wraps `claude plugin validate` and provides:\n- Individual plugin validation\n- Batch validation with `--all`\n- Summary report of all results\n\n## Independent Versioning\n\nEach plugin has its own version tracked in marketplace.json:\n\n```json\n{\n  \"name\": \"my-marketplace\",\n  \"plugins\": [\n    {\n      \"name\": \"ghe\",\n      \"source\": \"./plugins/ghe\",\n      \"version\": \"0.5.4\"\n    },\n    {\n      \"name\": \"marketplace-utils\",\n      \"source\": \"./plugins/marketplace-utils\",\n      \"version\": \"1.0.0\"\n    }\n  ]\n}\n```\n\nWhen you release a plugin:\n- **Only that plugin's version** is bumped\n- Tags are plugin-specific: `ghe-v0.5.4`, `marketplace-utils-v1.0.0`\n- Other plugins remain unchanged\n\n## Configuration Files\n\n### marketplace.json (required)\n\nLocated at `.claude-plugin/marketplace.json`:\n\n```json\n{\n  \"name\": \"my-marketplace\",\n  \"plugins\": [\n    {\n      \"name\": \"plugin-a\",\n      \"source\": \"./plugins/plugin-a\",\n      \"version\": \"1.0.0\"\n    },\n    {\n      \"name\": \"plugin-b\",\n      \"source\": \"./plugins/plugin-b\",\n      \"version\": \"2.3.1\"\n    }\n  ]\n}\n```\n\n### plugin.json (auto-detected)\n\nLocated at `plugins/<name>/.claude-plugin/plugin.json`:\n\n```json\n{\n  \"name\": \"plugin-a\",\n  \"version\": \"1.0.0\"\n}\n```\n\nBoth files are updated when releasing that specific plugin.\n\n## Version Suffix Handling\n\nThe script preserves version suffixes like `-alpha`, `-beta`:\n\n- Input version: `0.2.5-alpha`\n- After `patch`: `0.2.6-alpha`\n- Tag created: `ghe-v0.2.6-alpha`\n\n## Generated Release Body\n\n```markdown\n## What's Changed\n\n<your release notes>\n\n## Installation\n\n```bash\n/plugin marketplace update my-marketplace\n/plugin install ghe@my-marketplace\n```\n\n## Full Changelog\nhttps://github.com/owner/repo/compare/ghe-v0.5.3...ghe-v0.5.4\n```\n\n## Confirmation Prompt\n\nThe script prompts for confirmation before making changes:\n\n```\nMarketplace: my-marketplace\nPlugin: ghe\nCurrent version: 0.5.3\nNew version: 0.5.4\n\nProceed with release ghe-v0.5.4? [y/N]\n```\n\n## List Plugins Command\n\nUse `--list` to see all plugins and their current versions:\n\n```bash\n$ python release.py --list\n\nMarketplace: my-marketplace\n\nPlugin                    Version         Source\n----------------------------------------------------------------------\nghe                       0.5.4           ./plugins/ghe\nmarketplace-utils         1.0.0           ./plugins/marketplace-utils\n```\n\n## Marketplace README Version Table\n\nThe release script automatically maintains a version table in the marketplace README.md:\n\n```markdown\n<!-- PLUGIN-VERSIONS-START -->\n## Plugin Versions\n\n| Plugin | Version | Description |\n|--------|---------|-------------|\n| ghe | 0.5.4 | GHE (GitHub-Elements) - Automated project manag... |\n| marketplace-utils | 1.0.0 | Portable utility tools for Claude Code plugin m... |\n\n*Last updated: 2025-01-15*\n\n<!-- PLUGIN-VERSIONS-END -->\n```\n\nThis section is automatically:\n- **Inserted** before the Table of Contents (if no markers exist)\n- **Updated** in place (if markers already exist)\n- **Kept current** with each release\n\nThe main version badge in the README header is also updated to match the first plugin's version.\n\n## Troubleshooting\n\n### \"Plugin validation failed\"\nThe plugin has issues that must be fixed before release. Check the error message and fix the plugin.json or structure.\n\n### \"marketplace.json not found\"\nRun from marketplace root directory, not plugin subdirectory.\n\n### \"Unknown plugin: xyz\"\nCheck plugin name matches exactly what's in marketplace.json. Use `--list` to see available plugins.\n\n### \"Not authenticated with GitHub CLI\"\nRun `gh auth login` and authenticate.\n\n### \"You have uncommitted changes\"\nCommit or stash changes, or proceed and include them in the release.\n\n## Portability\n\nThis script is fully portable:\n- All values read from JSON config files\n- GitHub repo info detected via `gh repo view`\n- No hardcoded paths, names, or user-specific values\n- Can be copied to any Claude Code marketplace project\n"
      },
      "discovered_at": "2026-01-11T15:36:22.589872Z",
      "fetch_error": null
    },
    {
      "name": "marketplace-audit",
      "slug": "marketplace-audit",
      "source": "skillsmp",
      "owner": "robbyt",
      "repo_name": "claude-skills",
      "repository_url": "https://github.com/robbyt/claude-skills",
      "skill_path": ".claude/skills/marketplace-audit",
      "github_metadata": {
        "stars": 35,
        "description": "Skills and Plugins for Claude Code",
        "default_branch": "main",
        "pushed_at": "2025-12-20T21:20:05Z",
        "created_at": "2025-11-20T20:57:51Z",
        "language": "Shell",
        "license": null,
        "open_issues": 0,
        "forks": 2
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/marketplace-audit/SKILL.md",
        "branch": "main",
        "content": "---\nname: marketplace-audit\ndescription: Display plugin versions from marketplace.json. Use when user asks to \"audit versions\", \"show plugin versions\", \"list marketplace versions\", or wants to see the current state of plugin versioning.\n---\n\n# Marketplace Audit\n\nDisplay all plugin versions from the marketplace.\n\n## Usage\n\nRun this jq command to list all plugins and their versions:\n\n```bash\njq '.plugins[] | {name, version}' .claude-plugin/marketplace.json\n```\n\nPresent results in a table format:\n\n| Plugin | Version |\n|--------|---------|\n| plugin-name | x.y.z |\n\n## Notes\n\n- The `version` field in marketplace.json is the marketplace entry version\n- Each plugin also has its own version in `plugins/<name>/.claude-plugin/plugin.json`\n- Skills within plugins do not have separate version fields\n\n## Reference\n\n- [Plugin Marketplaces](https://code.claude.com/docs/en/plugin-marketplaces)\n"
      },
      "discovered_at": "2026-01-11T15:36:22.993590Z",
      "fetch_error": null
    },
    {
      "name": "marketplace-bump",
      "slug": "marketplace-bump",
      "source": "skillsmp",
      "owner": "robbyt",
      "repo_name": "claude-skills",
      "repository_url": "https://github.com/robbyt/claude-skills",
      "skill_path": ".claude/skills/marketplace-bump",
      "github_metadata": {
        "stars": 35,
        "description": "Skills and Plugins for Claude Code",
        "default_branch": "main",
        "pushed_at": "2025-12-20T21:20:05Z",
        "created_at": "2025-11-20T20:57:51Z",
        "language": "Shell",
        "license": null,
        "open_issues": 0,
        "forks": 2
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/marketplace-bump/SKILL.md",
        "branch": "main",
        "content": "---\nname: marketplace-bump\ndescription: Bump a plugin version in marketplace.json using semantic versioning. Use when user asks to \"bump version\", \"increment version\", \"release new version\", or after making changes that warrant a version update.\n---\n\n# Version Bump\n\nBump a plugin version in marketplace.json following semantic versioning.\n\n## Inference Rules\n\nInfer bump type from context:\n- **Major** (X.0.0): Breaking changes, renames, restructuring\n- **Minor** (x.Y.0): New features, new skills\n- **Patch** (x.y.Z): Bug fixes, doc updates\n\n## Commands\n\n```bash\n# Bump patch (e.g., 1.2.3 â†’ 1.2.4)\njq '(.plugins[] | select(.name == \"PLUGIN_NAME\") | .version) |= (split(\".\") | .[2] = ((.[2] | tonumber) + 1 | tostring) | join(\".\"))' .claude-plugin/marketplace.json > /tmp/claude/marketplace.json && mv /tmp/claude/marketplace.json .claude-plugin/marketplace.json\n\n# Bump minor (e.g., 1.2.3 â†’ 1.3.0)\njq '(.plugins[] | select(.name == \"PLUGIN_NAME\") | .version) |= (split(\".\") | .[1] = ((.[1] | tonumber) + 1 | tostring) | .[2] = \"0\" | join(\".\"))' .claude-plugin/marketplace.json > /tmp/claude/marketplace.json && mv /tmp/claude/marketplace.json .claude-plugin/marketplace.json\n\n# Bump major (e.g., 1.2.3 â†’ 2.0.0)\njq '(.plugins[] | select(.name == \"PLUGIN_NAME\") | .version) |= (split(\".\") | .[0] = ((.[0] | tonumber) + 1 | tostring) | .[1] = \"0\" | .[2] = \"0\" | join(\".\"))' .claude-plugin/marketplace.json > /tmp/claude/marketplace.json && mv /tmp/claude/marketplace.json .claude-plugin/marketplace.json\n```\n\nReplace `PLUGIN_NAME` with the actual plugin name.\n\n## Workflow\n\n1. Get current version first:\n   ```bash\n   jq '.plugins[] | select(.name == \"PLUGIN_NAME\") | .version' .claude-plugin/marketplace.json\n   ```\n2. Run the appropriate bump command\n3. Confirm new version to user\n\n## Reference\n\n- [Plugin Marketplaces](https://code.claude.com/docs/en/plugin-marketplaces)\n"
      },
      "discovered_at": "2026-01-11T15:36:23.470856Z",
      "fetch_error": null
    },
    {
      "name": "codex",
      "slug": "codex",
      "source": "skillsmp",
      "owner": "Lucklyric",
      "repo_name": "cc-dev-tools",
      "repository_url": "https://github.com/Lucklyric/cc-dev-tools",
      "skill_path": "plugins/codex/skills/codex",
      "github_metadata": {
        "stars": 26,
        "description": null,
        "default_branch": "main",
        "pushed_at": "2025-12-30T20:53:54Z",
        "created_at": "2025-10-21T01:24:14Z",
        "language": null,
        "license": "Apache-2.0",
        "open_issues": 0,
        "forks": 3
      },
      "skill_md": {
        "found": true,
        "path": "plugins/codex/skills/codex/SKILL.md",
        "branch": "main",
        "content": "---\nname: codex\nversion: 2.1.0\ndescription: Invoke Codex CLI for complex coding tasks requiring high reasoning capabilities. Trigger phrases include \"use codex\", \"ask codex\", \"run codex\", \"call codex\", \"codex cli\", \"GPT-5 reasoning\", \"OpenAI reasoning\", or when users request complex implementation challenges, advanced reasoning, architecture design, or high-reasoning model assistance. Automatically triggers on codex-related requests and supports session continuation for iterative development.\n---\n\n# Codex: High-Reasoning AI Assistant for Claude Code\n\n---\n\n## DEFAULT MODEL: Task-Based Model Selection with Read-Only Default\n\n**Codex uses task-based model selection. Sandbox is `read-only` by default - only use `workspace-write` when user explicitly requests file editing.**\n\n| Task Type | Model | Sandbox (default) | Sandbox (explicit edit) |\n|-----------|-------|-------------------|------------------------|\n| Code-related tasks | `gpt-5.2-codex` | read-only | workspace-write |\n| General tasks | `gpt-5.2` | read-only | workspace-write |\n\n- **Code-related tasks**: Use `gpt-5.2-codex` - optimized for agentic coding (56.4% SWE-Bench Pro)\n- **General tasks**: Use `gpt-5.2` - high-reasoning general model\n- **Sandbox default**: Always `read-only` unless user explicitly requests editing\n- **Explicit editing**: Only when user says \"edit\", \"modify\", \"write changes\", etc., use `workspace-write`\n- Always use `-c model_reasoning_effort=xhigh` for maximum capability\n\n```bash\n# Code task (read-only default)\ncodex exec -m gpt-5.2-codex -s read-only \\\n  -c model_reasoning_effort=xhigh \\\n  \"analyze this function implementation\"\n\n# General task (read-only default)\ncodex exec -m gpt-5.2 -s read-only \\\n  -c model_reasoning_effort=xhigh \\\n  \"explain this architecture\"\n\n# Code task with explicit edit request\ncodex exec -m gpt-5.2-codex -s workspace-write \\\n  -c model_reasoning_effort=xhigh \\\n  \"edit this file to add the feature\"\n\n# General task with explicit edit request\ncodex exec -m gpt-5.2 -s workspace-write \\\n  -c model_reasoning_effort=xhigh \\\n  \"modify the documentation file\"\n```\n\n### Model Fallback Chain\n\nIf the primary model is unavailable, fallback gracefully:\n1. **Code tasks**: `gpt-5.2-codex` â†’ `gpt-5.2` â†’ `gpt-5.1-codex-max`\n2. **General tasks**: `gpt-5.2` â†’ `gpt-5.1` â†’ `gpt-5.1-codex-max`\n3. **Reasoning effort**: `xhigh` â†’ `high` â†’ `medium`\n\n---\n\n## CRITICAL: Always Use `codex exec`\n\n**MUST USE**: `codex exec` for ALL Codex CLI invocations in Claude Code.\n\n**NEVER USE**: `codex` (interactive mode) - will fail with \"stdout is not a terminal\"\n**ALWAYS USE**: `codex exec` (non-interactive mode)\n\n**Examples:**\n- `codex exec -m gpt-5.2 \"prompt\"` (CORRECT)\n- `codex -m gpt-5.2 \"prompt\"` (WRONG - will fail)\n- `codex exec resume --last` (CORRECT)\n- `codex resume --last` (WRONG - will fail)\n\n**Why?** Claude Code's bash environment is non-terminal/non-interactive. Only `codex exec` works in this environment.\n\n---\n\n## IMPORTANT: Interactive vs Exec Mode Flags\n\n**Some Codex CLI flags are ONLY available in interactive mode, NOT in `codex exec`.**\n\n| Flag | Interactive `codex` | `codex exec` | Alternative for exec |\n|------|---------------------|--------------|---------------------|\n| `--search` | âœ… Available | âŒ NOT available | `--enable web_search_request` |\n| `-a/--ask-for-approval` | âœ… Available | âŒ NOT available | `--full-auto` or `-c approval_policy=...` |\n| `--add-dir` | âœ… Available | âœ… Available | N/A |\n| `--full-auto` | âœ… Available | âœ… Available | N/A |\n\n**For web search in exec mode**:\n```bash\n# CORRECT - works in codex exec\ncodex exec --enable web_search_request \"research topic\"\n\n# WRONG - --search only works in interactive mode\ncodex --search \"research topic\"\n```\n\n**For approval control in exec mode**:\n```bash\n# CORRECT - works in codex exec\ncodex exec --full-auto \"task\"\ncodex exec -c approval_policy=on-request \"task\"\n\n# WRONG - -a only works in interactive mode\ncodex -a on-request \"task\"\n```\n\n---\n\n## Trigger Examples\n\nThis skill activates when users say phrases like:\n- \"Use codex to analyze this architecture\"\n- \"Ask codex about this design decision\"\n- \"Run codex on this problem\"\n- \"Call codex for help with this implementation\"\n- \"I need GPT-5 reasoning for this task\"\n- \"Get OpenAI's high-reasoning model on this\"\n- \"Continue with codex\" or \"Resume the codex session\"\n- \"Codex, help me with...\" or simply \"Codex\"\n\n## When to Use This Skill\n\nThis skill should be invoked when:\n- User explicitly mentions \"Codex\" or requests Codex assistance\n- User needs help with complex coding tasks, algorithms, or architecture\n- User requests \"high reasoning\" or \"advanced implementation\" help\n- User needs complex problem-solving or architectural design\n- User wants to continue a previous Codex conversation\n\n## How It Works\n\n### Detecting New Codex Requests\n\nWhen a user makes a request, first determine the task type (code vs general), then determine sandbox based on explicit edit request:\n\n**Step 1: Determine Task Type (Model Selection)**\n- **Code-related tasks**: Use `gpt-5.2-codex` - for implementation, refactoring, code analysis, debugging, etc.\n- **General tasks**: Use `gpt-5.2` - for architecture design, explanations, reviews, documentation, etc.\n\n**Step 2: Determine Sandbox (Edit Permission)**\n- **Default**: `read-only` - safe for all tasks unless user explicitly requests editing\n- **Explicit edit request**: `workspace-write` - ONLY when user explicitly says to edit/modify/write files\n\n**Code-related task examples**:\n- Read-only: \"Analyze this function\", \"Review this implementation\", \"Debug this code\"\n- With editing: \"Edit this file to fix the bug\", \"Modify the function\", \"Refactor and save\"\n\n**General task examples**:\n- Read-only: \"Design a queue data structure\", \"Explain this algorithm\", \"Review the architecture\"\n- With editing: \"Update the documentation file\", \"Modify the README\"\n\n**âš ï¸ Important**: The key distinction for sandbox is whether the user explicitly asks for file modifications. Use `workspace-write` ONLY when user says \"edit\", \"modify\", \"write changes\", \"save\", etc.\n\n### Bash CLI Command Structure\n\n**IMPORTANT**: Always use `codex exec` for non-interactive execution. Claude Code's bash environment is non-terminal, so the interactive `codex` command will fail with \"stdout is not a terminal\" error.\n\n#### Code Task (Read-Only Default)\n\n```bash\ncodex exec -m gpt-5.2-codex -s read-only \\\n  -c model_reasoning_effort=xhigh \\\n  --enable web_search_request \\\n  \"<code-related prompt>\"\n```\n\n#### General Task (Read-Only Default)\n\n```bash\ncodex exec -m gpt-5.2 -s read-only \\\n  -c model_reasoning_effort=xhigh \\\n  --enable web_search_request \\\n  \"<general prompt>\"\n```\n\n#### Code Task with Explicit Edit Request\n\n```bash\ncodex exec -m gpt-5.2-codex -s workspace-write \\\n  -c model_reasoning_effort=xhigh \\\n  --enable web_search_request \\\n  \"<edit code prompt>\"\n```\n\n#### General Task with Explicit Edit Request\n\n```bash\ncodex exec -m gpt-5.2 -s workspace-write \\\n  -c model_reasoning_effort=xhigh \\\n  --enable web_search_request \\\n  \"<edit general files prompt>\"\n```\n\n**Why `codex exec`?**\n- Non-interactive mode required for automation and Claude Code integration\n- Produces clean output suitable for parsing\n- Works in non-TTY environments (like Claude Code's bash)\n\n### Model Selection Logic\n\n**Step 1: Choose Model Based on Task Type**\n\n**Use `gpt-5.2-codex` for code-related tasks:**\n- Implementation, refactoring, code analysis\n- Debugging, fixing bugs, optimization\n- Any task involving code understanding or modification\n\n**Use `gpt-5.2` for general tasks:**\n- Architecture and system design\n- Explanations, documentation, reviews\n- Planning, strategy, general reasoning\n\n**Step 2: Choose Sandbox Based on Edit Intent**\n\n**Use `read-only` (DEFAULT):**\n- Analysis, review, explanation tasks\n- ANY task where user does NOT explicitly request file editing\n\n**Use `workspace-write` (ONLY when explicitly requested):**\n- User explicitly says \"edit this file\", \"modify the code\", \"write changes\"\n- User explicitly asks to \"make edits\" or \"save the changes\"\n- User explicitly requests \"refactor and save\" or \"implement and write\"\n\n**Fallback Models**: `gpt-5.1-codex-max` and `gpt-5.1` are available if primary models are unavailable. See fallback chain in DEFAULT MODEL section.\n\n### Default Configuration\n\nAll Codex invocations use these defaults unless user specifies otherwise:\n\n| Parameter | Default Value | CLI Flag | Notes |\n|-----------|---------------|----------|-------|\n| Model (code tasks) | `gpt-5.2-codex` | `-m gpt-5.2-codex` | For code-related tasks |\n| Model (general tasks) | `gpt-5.2` | `-m gpt-5.2` | For general tasks |\n| Sandbox (default) | `read-only` | `-s read-only` | Safe default for ALL tasks |\n| Sandbox (explicit edit) | `workspace-write` | `-s workspace-write` | Only when user explicitly requests editing |\n| Reasoning Effort | `xhigh` | `-c model_reasoning_effort=xhigh` | Maximum reasoning capability |\n| Verbosity | `medium` | `-c model_verbosity=medium` | Balanced output detail |\n| Web Search | `enabled` | `--enable web_search_request` | Access to up-to-date information |\n\n### CLI Flags Reference\n\n**Codex CLI Version**: 0.72.0+ (requires 0.72.0+ for gpt-5.2-codex and xhigh)\n\n| Flag | Values | Description |\n|------|--------|-------------|\n| `-m, --model` | `gpt-5.2-codex`, `gpt-5.2`, `gpt-5.1-codex-max`, `gpt-5.1` | Model selection |\n| `-s, --sandbox` | `read-only`, `workspace-write`, `danger-full-access` | Sandbox mode |\n| `-c, --config` | `key=value` | Config overrides (e.g., `model_reasoning_effort=high`) |\n| `-C, --cd` | directory path | Working directory |\n| `-p, --profile` | profile name | Use config profile |\n| `--enable` | feature name | Enable a feature (e.g., `web_search_request`) |\n| `--disable` | feature name | Disable a feature |\n| `-i, --image` | file path(s) | Attach image(s) to initial prompt |\n| `--add-dir` | directory path | Additional writable directory (repeatable) |\n| `--full-auto` | flag | Convenience for workspace-write sandbox with on-request approval |\n| `--oss` | flag | Use local open source model provider |\n| `--local-provider` | `lmstudio`, `ollama` | Specify local provider (with --oss) |\n| `--skip-git-repo-check` | flag | Allow running outside Git repository |\n| `--output-schema` | file path | JSON Schema file for response shape |\n| `--color` | `always`, `never`, `auto` | Color settings for output |\n| `--json` | flag | Print events as JSONL |\n| `-o, --output-last-message` | file path | Save last message to file |\n| `--dangerously-bypass-approvals-and-sandbox` | flag | Skip confirmations (DANGEROUS) |\n\n### Configuration Parameters\n\nPass these as `-c key=value`:\n\n- `model_reasoning_effort`: `minimal`, `low`, `medium`, `high`, `xhigh`\n  - **CLI default**: `high` - The Codex CLI defaults to high reasoning\n  - **Skill default**: `xhigh` - This skill explicitly uses xhigh for maximum capability\n  - **`xhigh`**: Extra-high reasoning for maximum capability (supported by gpt-5.2 and gpt-5.1-codex-max)\n  - Use `xhigh` for complex architectural refactoring, long-horizon tasks, or when quality is more important than speed\n- `model_verbosity`: `low`, `medium`, `high` (default: `medium`)\n- `model_reasoning_summary`: `auto`, `concise`, `detailed`, `none` (default: `auto`)\n- `sandbox_workspace_write.writable_roots`: JSON array of additional writable directories (e.g., `[\"/path1\",\"/path2\"]`)\n- `approval_policy`: `untrusted`, `on-failure`, `on-request`, `never` (approval behavior)\n\n**Additional Writable Directories**:\n\nUse `--add-dir` flag (preferred) or config:\n```bash\n# Preferred - simpler syntax (v0.71.0+)\ncodex exec --add-dir /path1 --add-dir /path2 \"task\"\n\n# Alternative - config approach\ncodex exec -c 'sandbox_workspace_write.writable_roots=[\"/path1\",\"/path2\"]' \"task\"\n```\n\n### Model Selection Guide\n\n**Default Models (Codex CLI v0.71.0+)**\n\nThis skill supports the following models:\n- `gpt-5.2` - Latest model with all reasoning levels (NEW in 0.71.0)\n- `gpt-5.1` - General reasoning, architecture, reviews (default)\n- `gpt-5.1-codex-max` - Code editing (legacy, use gpt-5.2 instead)\n- `gpt-5.1-codex` - Standard code editing (available for backward compatibility)\n\n**GPT-5.2 Model (NEW)**:\n- Supports all reasoning effort levels: `low`, `medium`, `high`, `xhigh`\n- Use for cutting-edge tasks requiring latest model capabilities\n- Example: `codex exec -m gpt-5.2 -c model_reasoning_effort=xhigh \"complex task\"`\n\n**Performance Characteristics**:\n- `gpt-5.1-codex-max` is 27-42% faster than `gpt-5.1-codex`\n- Uses ~30% fewer thinking tokens at the same reasoning effort level\n- Supports new `xhigh` reasoning effort for maximum capability\n- Requires Codex CLI 0.71.0+ and ChatGPT Plus/Pro/Business/Edu/Enterprise subscription\n\n**Backward Compatibility**\n\nYou can override to use older models when needed:\n\n```bash\n# Use older gpt-5 model explicitly\ncodex exec -m gpt-5 -s read-only \"Design a data structure\"\n\n# Use older gpt-5-codex model explicitly\ncodex exec -m gpt-5-codex -s workspace-write \"Implement feature X\"\n```\n\n**When to Override**\n\n- **Testing compatibility**: Verify behavior matches older model versions\n- **Specific model requirements**: Project requires specific model version\n- **Model comparison**: Compare outputs between model versions\n\n**Model Override Examples**\n\nOverride via `-m` flag:\n```bash\n# Override to gpt-5 for general task\ncodex exec -m gpt-5 \"Explain algorithm complexity\"\n\n# Override to gpt-5-codex for code task\ncodex exec -m gpt-5-codex -s workspace-write \"Refactor authentication\"\n\n# Override to gpt-4 if available\ncodex exec -m gpt-4 \"Review this code\"\n```\n\n**Default Behavior**\n\nWithout explicit `-m` override:\n- All tasks â†’ `gpt-5.2` (latest model, recommended default)\n- General reasoning â†’ `gpt-5.1` (if explicitly requested)\n- Backward compatibility â†’ `gpt-5.1-codex-max` and `gpt-5.1-codex` still work if explicitly specified\n\n## Session Continuation\n\n### Detecting Continuation Requests\n\nWhen user indicates they want to continue a previous Codex conversation:\n- Keywords: \"continue\", \"resume\", \"keep going\", \"add to that\"\n- Follow-up context referencing previous Codex work\n- Explicit request like \"continue where we left off\"\n\n### Resuming Sessions\n\nFor continuation requests, use the `codex resume` command:\n\n#### Resume Most Recent Session (Recommended)\n\n```bash\ncodex exec resume --last\n```\n\nThis automatically continues the most recent Codex session with all previous context maintained.\n\n#### Resume Specific Session\n\n```bash\ncodex exec resume <session-id>\n```\n\nResume a specific session by providing its UUID. Get session IDs from previous Codex output or by running `codex exec resume --last` to see the most recent session.\n\n**Note**: The interactive session picker (`codex resume` without arguments) is NOT available in non-interactive/Claude Code environments. Always use `--last` or provide explicit session ID.\n\n### Decision Logic: New vs. Continue\n\n**Use `codex exec -m ... \"<prompt>\"`** when:\n- User makes a new, independent request\n- No reference to previous Codex work\n- User explicitly wants a \"fresh\" or \"new\" session\n\n**Use `codex exec resume --last`** when:\n- User indicates continuation (\"continue\", \"resume\", \"add to that\")\n- Follow-up question building on previous Codex conversation\n- Iterative development on same task\n\n### Session History Management\n\n- Codex CLI automatically saves session history\n- No manual session ID tracking needed\n- Sessions persist across Claude Code restarts\n- Use `codex exec resume --last` to access most recent session\n- Use `codex exec resume <session-id>` for specific sessions\n\n## Error Handling\n\n### Simple Error Response Strategy\n\nWhen errors occur, return clear, actionable messages without complex diagnostics:\n\n**Error Message Format:**\n```\nError: [Clear description of what went wrong]\n\nTo fix: [Concrete remediation action]\n\n[Optional: Specific command example]\n```\n\n### Common Errors\n\n#### Command Not Found\n\n```\nError: Codex CLI not found\n\nTo fix: Install Codex CLI and ensure it's available in your PATH\n\nCheck installation: codex --version\n```\n\n#### Authentication Required\n\n```\nError: Not authenticated with Codex\n\nTo fix: Run 'codex login' to authenticate\n\nAfter authentication, try your request again.\n```\n\n#### Invalid Configuration\n\n```\nError: Invalid model specified\n\nTo fix:\n- For coding tasks: Use 'gpt-5.2-codex' with workspace-write sandbox\n- For reasoning tasks: Use 'gpt-5.2' with read-only sandbox\n\nExample (coding): codex exec -m gpt-5.2-codex -s workspace-write -c model_reasoning_effort=xhigh \"implement feature\"\nExample (reasoning): codex exec -m gpt-5.2 -s read-only -c model_reasoning_effort=xhigh \"explain architecture\"\n```\n\n### Troubleshooting\n\n**First Steps for Any Issues:**\n1. Check Codex CLI built-in help: `codex --help`, `codex exec --help`, `codex exec resume --help`\n2. Consult official documentation: [https://github.com/openai/codex/tree/main/docs](https://github.com/openai/codex/tree/main/docs)\n3. Verify skill resources in `references/` directory\n\n**Skill not being invoked?**\n- Check that request matches trigger keywords (Codex, complex coding, high reasoning, etc.)\n- Explicitly mention \"Codex\" in your request\n- Try: \"Use Codex to help me with...\"\n\n**Session not resuming?**\n- Verify you have a previous Codex session (check command output for session IDs)\n- Try: `codex exec resume --last` to resume most recent session\n- If no history exists, start a new session first\n\n**\"stdout is not a terminal\" error?**\n- Always use `codex exec` instead of plain `codex` in Claude Code\n- Claude Code's bash environment is non-interactive/non-terminal\n\n**Errors during execution?**\n- Codex CLI errors are passed through directly\n- Check Codex CLI logs for detailed diagnostics\n- Verify working directory permissions if using workspace-write\n- Check official Codex docs for latest updates and known issues\n\n## Examples\n\n### Example 1: Code Task (Read-Only Default)\n\n**User Request**: \"Analyze this function implementation and suggest improvements\"\n\n**Skill Executes**:\n```bash\ncodex exec -m gpt-5.2-codex -s read-only \\\n  -c model_reasoning_effort=xhigh \\\n  \"Analyze this function implementation and suggest improvements\"\n```\n\n**Result**: Code-related task uses gpt-5.2-codex with read-only sandbox (default). No file modifications.\n\n---\n\n### Example 2: General Task (Read-Only Default)\n\n**User Request**: \"Help me design a binary search tree architecture in Rust\"\n\n**Skill Executes**:\n```bash\ncodex exec -m gpt-5.2 -s read-only \\\n  -c model_reasoning_effort=xhigh \\\n  \"Help me design a binary search tree architecture in Rust\"\n```\n\n**Result**: General task uses gpt-5.2 with read-only sandbox (default). Session automatically saved for continuation.\n\n---\n\n### Example 3: Code Task with Explicit Edit Request\n\n**User Request**: \"Edit this file to implement the BST insert method\"\n\n**Skill Executes**:\n```bash\ncodex exec -m gpt-5.2-codex -s workspace-write \\\n  -c model_reasoning_effort=xhigh \\\n  \"Edit this file to implement the BST insert method\"\n```\n\n**Result**: User explicitly said \"Edit this file\" - code task uses gpt-5.2-codex with workspace-write permissions.\n\n---\n\n### Example 4: Session Continuation\n\n**User Request**: \"Continue with the BST - add a deletion method\"\n\n**Skill Executes**:\n```bash\ncodex exec resume --last\n```\n\n**Result**: Codex resumes the previous BST session and continues with deletion method implementation, maintaining full context.\n\n---\n\n### Example 5: With Web Search (Read-Only Default)\n\n**User Request**: \"Use Codex with web search to research async patterns\"\n\n**Skill Executes**:\n```bash\ncodex exec -m gpt-5.2-codex -s read-only \\\n  -c model_reasoning_effort=xhigh \\\n  --enable web_search_request \\\n  \"Research async patterns\"\n```\n\n**Result**: Code-related research uses gpt-5.2-codex with read-only sandbox (default) and web search enabled.\n\n---\n\n### Example 6: Explicit Refactoring Request\n\n**User Request**: \"Refactor and save the authentication system code\"\n\n**Skill Executes**:\n```bash\ncodex exec -m gpt-5.2-codex -s workspace-write \\\n  -c model_reasoning_effort=xhigh \\\n  \"Refactor and save the authentication system code\"\n```\n\n**Result**: User explicitly said \"Refactor and save\" - code task uses gpt-5.2-codex with workspace-write for file modifications.\n\n---\n\n## Code Review Subcommand (v0.71.0+)\n\nThe `codex review` subcommand provides non-interactive code review capabilities:\n\n```bash\n# Review uncommitted changes (staged, unstaged, untracked)\ncodex review --uncommitted\n\n# Review changes against a base branch\ncodex review --base main\n\n# Review a specific commit\ncodex review --commit abc123\n\n# Review with custom instructions\ncodex review --uncommitted \"Focus on security vulnerabilities\"\n\n# Non-interactive via exec\ncodex exec review --uncommitted\n```\n\n**Review Options**:\n| Flag | Description |\n|------|-------------|\n| `--uncommitted` | Review staged, unstaged, and untracked changes |\n| `--base <BRANCH>` | Review changes against the given base branch |\n| `--commit <SHA>` | Review the changes introduced by a commit |\n| `--title <TITLE>` | Optional commit title for review summary |\n\n---\n\n## CLI Features Reference\n\n### Feature Flags (`--enable` / `--disable`)\nEnable or disable specific Codex features:\n```bash\ncodex exec --enable web_search_request \"Research latest patterns\"\ncodex exec --disable some_feature \"Run without feature\"\n```\n\n### Image Attachment (`-i, --image`)\nAttach images to prompts for visual analysis:\n```bash\ncodex exec -i screenshot.png \"Analyze this UI design\"\ncodex exec -i diagram1.png -i diagram2.png \"Compare these architectures\"\n```\n\n### Additional Directories (`--add-dir`) (v0.71.0+)\nAdd writable directories beyond the primary workspace:\n```bash\ncodex exec --add-dir /shared/libs --add-dir /config \"task\"\n```\n\n### Full Auto Mode (`--full-auto`)\nConvenience flag for low-friction execution:\n```bash\ncodex exec --full-auto \"task\"\n# Equivalent to: -s workspace-write with on-request approval\n```\n\n### Non-Git Environments (`--skip-git-repo-check`)\nRun Codex outside Git repositories:\n```bash\ncodex exec --skip-git-repo-check \"Help with this script\"\n```\n\n### Structured Output (`--output-schema`)\nDefine JSON schema for model responses:\n```bash\ncodex exec --output-schema schema.json \"Generate structured data\"\n```\n\n### Output Coloring (`--color`)\nControl colored output (always, never, auto):\n```bash\ncodex exec --color never \"Run in CI/CD pipeline\"\n```\n\n### Web Search in Exec Mode\n**Note**: `--search` flag is interactive-only. Use `--enable` for exec mode:\n```bash\n# CORRECT for codex exec\ncodex exec --enable web_search_request \"research topic\"\n\n# WRONG - --search only works in interactive mode\ncodex --search \"research topic\"\n```\n\n### Feature Flags (`codex features list`) (v0.71.0+)\nInspect and manage Codex feature flags:\n```bash\n# List all feature flags with their states\ncodex features list\n```\n\n**Current Feature Flags** (as of v0.71.0):\n\n**Stable Features**:\n| Feature | Default | Description |\n|---------|---------|-------------|\n| `web_search_request` | false | Enable web search capability |\n| `parallel` | true | Parallel execution |\n| `shell_tool` | true | Shell command execution |\n| `undo` | true | Undo functionality |\n| `view_image_tool` | true | Image viewing capability |\n| `warnings` | true | Display warnings |\n\n**Experimental/Beta Features**:\n| Feature | Stage | Default | Description |\n|---------|-------|---------|-------------|\n| `exec_policy` | experimental | true | Execution policy control |\n| `remote_compaction` | experimental | true | Remote compaction |\n| `unified_exec` | experimental | false | Unified execution mode |\n| `rmcp_client` | experimental | false | RMCP client support |\n| `apply_patch_freeform` | beta | false | Freeform patch application |\n| `skills` | experimental | false | Skills support |\n| `shell_snapshot` | experimental | false | Shell state snapshots |\n| `remote_models` | experimental | false | Remote model support |\n\nEnable/disable features with `--enable` and `--disable`:\n```bash\ncodex exec --enable web_search_request \"research task\"\ncodex exec --disable parallel \"run sequentially\"\n```\n\n### JSONL Output (`--json`) (v0.71.0+)\nStream events as JSONL for programmatic processing:\n```bash\ncodex exec --json \"task\" > events.jsonl\n```\n\n### Save Last Message (`-o/--output-last-message`) (v0.71.0+)\nWrite the final agent message to a file:\n```bash\ncodex exec -o result.txt \"generate summary\"\n```\n\n---\n\n## When to Use GPT-5.2-Codex vs GPT-5.2\n\n### GPT-5.2-Codex (for code-related tasks):\n- Implementation, refactoring, code analysis\n- Debugging, fixing bugs, optimization\n- Any task involving code understanding\n\n**Read-only (default)**:\n```bash\ncodex exec -m gpt-5.2-codex -s read-only -c model_reasoning_effort=xhigh \"analyze code\"\n```\n\n**Workspace-write (only when user explicitly requests editing)**:\n```bash\ncodex exec -m gpt-5.2-codex -s workspace-write -c model_reasoning_effort=xhigh \"edit this file\"\n```\n\n### GPT-5.2 (for general tasks):\n- Architecture and system design\n- Explanations, documentation, reviews\n- Planning, strategy, general reasoning\n\n**Read-only (default)**:\n```bash\ncodex exec -m gpt-5.2 -s read-only -c model_reasoning_effort=xhigh \"design architecture\"\n```\n\n**Workspace-write (only when user explicitly requests editing)**:\n```bash\ncodex exec -m gpt-5.2 -s workspace-write -c model_reasoning_effort=xhigh \"update the README\"\n```\n\n---\n\n## Fallback Models (Backward Compatibility)\n\n### Use GPT-5.1-Codex-Max When:\n- GPT-5.2-codex is unavailable\n- Explicit requirement for the older codex model\n\n### Use GPT-5.1 When:\n- GPT-5.2 is unavailable\n- Explicit requirement for the older general model\n\n**Default**: Use `gpt-5.2-codex` for coding tasks and `gpt-5.2` for reasoning tasks. Fall back to GPT-5.1 variants only if primary models are unavailable.\n\n## Best Practices\n\n### 1. Use Descriptive Requests\n\n**Good**: \"Help me implement a thread-safe queue with priority support in Python\"\n**Vague**: \"Code help\"\n\nClear, specific requests get better results from high-reasoning models.\n\n### 2. Indicate Continuation Clearly\n\n**Good**: \"Continue with that queue implementation - add unit tests\"\n**Unclear**: \"Add tests\" (might start new session)\n\nExplicit continuation keywords help the skill choose the right command.\n\n### 3. Specify Permissions When Needed\n\n**Good**: \"Refactor this code (allow file writing)\"\n**Risky**: Assuming permissions without specifying\n\nMake your intent clear when you need workspace-write permissions.\n\n### 4. Leverage High Reasoning\n\nThe skill defaults to high reasoning effort - perfect for:\n- Complex algorithms\n- Architecture design\n- Performance optimization\n- Security reviews\n\n## Platform & Capabilities (v0.71.0)\n\n### Windows Sandbox Support\nWindows sandbox is available for filesystem and network access control.\n\n### Interactive Mode Features\nThe `/exit` slash-command alias is available in interactive `codex` mode (not applicable to `codex exec` non-interactive mode used by this skill).\n\n### Model Verbosity Override\nAll models (gpt-5.2, gpt-5.1-codex-max, gpt-5.1-codex) support verbosity override via `-c model_verbosity=<level>` for controlling output detail levels.\n\n### Local/OSS Model Support\nUse `--oss` with `--local-provider` to use local LLM providers:\n```bash\ncodex exec --oss --local-provider ollama \"task\"\ncodex exec --oss --local-provider lmstudio \"task\"\n```\n\n## Pattern References\n\nFor command construction examples and workflow patterns, Claude can reference:\n- `references/command-patterns.md` - Common codex exec usage patterns\n- `references/session-workflows.md` - Session continuation and resume workflows\n- `references/advanced-patterns.md` - Complex configuration and flag combinations\n\nThese files provide detailed examples for constructing valid codex exec commands for various scenarios.\n\n## Additional Resources\n\nFor more details, see:\n- `references/codex-help.md` - Codex CLI command reference\n- `references/codex-config.md` - Full configuration options\n- `README.md` - Installation and quick start guide\n"
      },
      "discovered_at": "2026-01-11T15:36:23.874097Z",
      "fetch_error": null
    },
    {
      "name": "gemini",
      "slug": "gemini",
      "source": "skillsmp",
      "owner": "Lucklyric",
      "repo_name": "cc-dev-tools",
      "repository_url": "https://github.com/Lucklyric/cc-dev-tools",
      "skill_path": "plugins/gemini/skills/gemini",
      "github_metadata": {
        "stars": 26,
        "description": null,
        "default_branch": "main",
        "pushed_at": "2025-12-30T20:53:54Z",
        "created_at": "2025-10-21T01:24:14Z",
        "language": null,
        "license": "Apache-2.0",
        "open_issues": 0,
        "forks": 3
      },
      "skill_md": {
        "found": true,
        "path": "plugins/gemini/skills/gemini/SKILL.md",
        "branch": "main",
        "content": "---\nname: gemini\nversion: 1.2.0\ndescription: Invoke Google Gemini CLI for complex reasoning tasks, research, and AI assistance. Trigger phrases include \"use gemini\", \"ask gemini\", \"run gemini\", \"call gemini\", \"gemini cli\", \"Google AI\", \"Gemini reasoning\", or when users request Google's AI models, need advanced reasoning capabilities, research with web search, or want to continue previous Gemini conversations. Automatically triggers on Gemini-related requests and supports session continuation for iterative development.\n---\n\n# Gemini: Google AI Assistant for Claude Code\n\n---\n\n## DEFAULT MODEL: Gemini 3 Pro\n\n**The default model for ALL Gemini invocations is `gemini-3-pro-preview`.**\n\n- Always use `gemini-3-pro-preview` unless user explicitly requests another model\n- This is the highest reasoning model available\n- Fallback to `gemini-2.5-flash` ONLY on 404/access errors\n\n```bash\n# Default invocation - ALWAYS use gemini-3-pro-preview\ngemini -m gemini-3-pro-preview \"your prompt here\"\n```\n\n---\n\n## CRITICAL: Positional Prompts Required\n\n**REQUIRED**: Use positional prompts for Gemini CLI invocations.\n\n**DEPRECATED**: `-p/--prompt` flag is officially deprecated and will be removed in a future version.\n\n**Examples:**\n- `gemini -m gemini-3-pro-preview \"prompt\"` (CORRECT - positional)\n- `gemini -m gemini-3-pro-preview -p \"prompt\"` (DEPRECATED - avoid using)\n- `gemini -r latest` (CORRECT - session resume)\n\n**Warning from CLI help**: \"[deprecated: Use the positional prompt instead. This flag will be removed in a future version.]\"\n\n**Why?** As of Gemini CLI v0.20.0, the `-p` flag is explicitly marked deprecated. Use positional prompts for forward compatibility.\n\n---\n\n## IMPORTANT: Preview Features & OAuth Free Tier\n\n**For OAuth free tier users in headless mode:**\n\nWhen `previewFeatures: true` in `~/.gemini/settings.json`, the CLI routes ALL requests to Gemini 3 Pro (even `-m gemini-2.5-pro`). Since free tier doesn't have Gemini 3 access, this causes 404 errors.\n\n**Solution**: Disable preview features for reliable headless operation:\n```json\n// ~/.gemini/settings.json\n{\n  \"general\": {\n    \"previewFeatures\": false\n  }\n}\n```\n\n**Plugin Behavior**: This skill automatically falls back to `gemini-2.5-flash` when encountering 404 errors. Flash always works with OAuth free tier.\n\n---\n\n## Trigger Examples\n\nThis skill activates when users say phrases like:\n- \"Use gemini to research this topic\"\n- \"Ask gemini about this design pattern\"\n- \"Run gemini on this analysis\"\n- \"Call gemini for help with this problem\"\n- \"I need Google AI for this task\"\n- \"Get Gemini's reasoning on this\"\n- \"Continue with gemini\" or \"Resume the gemini session\"\n- \"Gemini, help me with...\" or simply \"Gemini\"\n- \"Use Gemini 3\" or \"Use Gemini 2.5\"\n\n## When to Use This Skill\n\nThis skill should be invoked when:\n- User explicitly mentions \"Gemini\" or requests Gemini assistance\n- User needs Google's AI models for reasoning, research, or analysis\n- User requests complex problem-solving or architectural design\n- User needs research capabilities with web search integration\n- User wants to continue a previous Gemini conversation\n- User needs an alternative to Codex or Claude for specific tasks\n\n## How It Works\n\n### Detecting New Gemini Requests\n\nWhen a user makes a request, **default to read-only mode (default approval)** unless they explicitly request file editing:\n\n**Use `gemini-3-pro-preview` for ALL tasks with `default` approval mode:**\n- Architecture, design, reviews, research\n- Explanations, analysis, problem-solving\n- Code analysis and understanding\n- ANY task where user does NOT explicitly request file editing\n\n**Approval Mode Selection:**\n- **`default`** (default): For all tasks - prompts for approval on edits (safe)\n- **`auto_edit`**: ONLY when user explicitly requests file editing\n- **`yolo`**: When user explicitly wants full auto-approval (use with caution)\n\n**âš ï¸ Explicit Edit Request**: If the user explicitly asks to \"edit files\", \"modify code\", \"write changes\", or \"make edits\" - ONLY then use `--approval-mode auto_edit` to enable file modifications.\n\n**Fallback Chain** (if primary unavailable):\n1. `gemini-3-pro-preview` (primary - highest capability)\n2. `gemini-2.5-pro` (stable general reasoning)\n3. `gemini-2.5-flash` (fast, always available)\n\n**Example requests**: \"Design a distributed cache\", \"Explain CQRS pattern\", \"Analyze this code\"\n\n### Bash CLI Command Structure\n\n**IMPORTANT**: Gemini CLI works differently from Codex - no `exec` subcommand needed. Use positional prompts directly.\n\n#### Default Command (Read-Only) - Use for ALL Tasks\n\n```bash\ngemini -m gemini-3-pro-preview \\\n  \"Design a microservices architecture for e-commerce\"\n```\n\n#### Explicit Edit Request Only - When User Asks to Edit Files\n\n```bash\ngemini -m gemini-3-pro-preview \\\n  --approval-mode auto_edit \\\n  \"Edit this file to refactor the function\"\n```\n\n#### For Session Continuation\n\n```bash\n# Resume most recent session\ngemini -r latest\n\n# Resume specific session by index\ngemini -r 3\n\n# Resume and add new prompt\ngemini -r latest \"Continue our discussion about caching strategies\"\n```\n\n**Why positional prompts?**\n- Simpler, more direct syntax\n- Future-proof (recommended by Gemini CLI)\n- Works in non-TTY environments (like Claude Code's bash)\n- No separate `exec` command needed\n\n### Model Selection Logic\n\n**Use `gemini-3-pro-preview` (default for ALL tasks):**\n- Code editing, refactoring, implementation\n- Designing architecture or system design\n- Conducting research or analysis\n- Explaining complex concepts\n- Planning implementation strategies\n- General problem-solving and advanced reasoning\n\n**Fallback to `gemini-2.5-pro` when:**\n- Gemini 3 Pro unavailable or quota exhausted\n- User explicitly requests \"Gemini 2.5\" or \"use 2.5\"\n- Stable, production-ready tasks\n\n**Fallback to `gemini-2.5-flash` when:**\n- Both Gemini 3 Pro and 2.5 Pro unavailable\n- Fast iterations needed (explicit user request)\n- Simple, quick responses (explicit user request)\n\n### Version-Based Model Mapping\n\nWhen users mention a version number, map to the latest model in that family:\n\n| User Request | Maps To | Actual Model ID |\n|--------------|---------|-----------------|\n| \"use 3\" / \"Gemini 3\" | Latest 3.x Pro | `gemini-3-pro-preview` |\n| \"use 2.5\" | 2.5 Pro | `gemini-2.5-pro` |\n| \"use flash\" | 2.5 Flash | `gemini-2.5-flash` |\n| No version specified | Latest Pro (ALL tasks) | `gemini-3-pro-preview` |\n\n**See**: `references/model-selection.md` for detailed model selection guidance and decision tree.\n\n### Default Configuration\n\nAll Gemini invocations use these defaults unless user specifies otherwise:\n\n| Parameter | Default Value | CLI Flag | Notes |\n|-----------|---------------|----------|-------|\n| Model | `gemini-3-pro-preview` | `-m gemini-3-pro-preview` | For ALL tasks (highest capability) |\n| Model (fallback 1) | `gemini-2.5-pro` | `-m gemini-2.5-pro` | If Gemini 3 Pro unavailable |\n| Model (fallback 2) | `gemini-2.5-flash` | `-m gemini-2.5-flash` | Always works on free tier |\n| Approval Mode (default) | `default` | No flag | Safe default - prompts for edits |\n| Approval Mode (editing) | `auto_edit` | `--approval-mode auto_edit` | Only when user explicitly requests editing |\n| Sandbox | `false` (disabled) | No flag | Sandbox disabled by default |\n| Output Format | `text` | No flag | Human-readable text output |\n| Web Search | Enabled when appropriate | `-e web_search` (if needed) | Context-dependent |\n\n**Rationale for Defaults:**\n- **Gemini 3 Pro for ALL tasks**: Highest capability model, optimized for both reasoning and code\n- **Fallback chain**: gemini-3-pro-preview â†’ gemini-2.5-pro â†’ gemini-2.5-flash\n- **default mode**: Safe default that prompts for approval on edits\n- **auto_edit mode**: Only use when user explicitly requests file editing\n- **No sandbox**: Claude Code environment assumed trusted\n- **Text output**: Default for human consumption (use `--output-format json` for parsing)\n\n**Note**: If you have `previewFeatures: true` in settings, disable it for reliable headless operation (see warning above).\n\n### Error Handling\n\nThe skill handles these common errors gracefully:\n\n#### CLI Not Installed\n\n**Error**: `command not found: gemini`\n\n**Message**: \"Gemini CLI not installed. Install from: https://github.com/google-gemini/gemini-cli\"\n\n**Action**: User must install Gemini CLI before using this skill\n\n#### Authentication Required\n\n**Error**: Output contains \"auth\" or \"authentication\"\n\n**Message**: \"Authentication required. Run: `gemini login` to authenticate with your Google account\"\n\n**Action**: User must authenticate via OAuth or API key\n\n#### Rate Limit Exceeded\n\n**Error**: Output contains \"quota\" or \"rate limit\" or status 429\n\n**Message**: \"Rate limit exceeded (60 req/min, 1000 req/day free tier). Retry in X seconds or upgrade account.\"\n\n**Action**: Wait for rate limit reset or upgrade to paid tier\n\n#### Model Unavailable\n\n**Error**: Output contains \"model not found\" or \"404\" or status 403\n\n**Message**: \"Model unavailable. Trying fallback model...\"\n\n**Action**: Automatically retry with fallback:\n- `gemini-3-pro-preview` unavailable â†’ try `gemini-2.5-pro`\n- `gemini-2.5-pro` unavailable â†’ try `gemini-2.5-flash`\n\n#### Session Not Found\n\n**Error**: Using `-r` flag but session doesn't exist\n\n**Message**: \"Session not found. Use `gemini --list-sessions` to see available sessions.\"\n\n**Action**: User should list sessions or start new session\n\n#### Gemini 3 Pro Access Denied\n\n**Error**: Status 403 or \"preview access required\"\n\n**Message**: \"Gemini 3 Pro requires preview access. Enable Preview Features in settings or use `gemini-2.5-pro` instead.\"\n\n**Action**: Either enable preview features, get API key, or use 2.5 models\n\n**See**: `references/gemini-help.md` for complete CLI reference and troubleshooting.\n\n---\n\n## Examples\n\n### Basic Invocation (General Reasoning)\n\n```bash\n# Design system architecture\ngemini -m gemini-3-pro-preview \"Design a scalable payment processing system\"\n\n# Research with web search\ngemini -m gemini-3-pro-preview -e web_search \"Research latest React 19 features\"\n\n# Explain complex concept\ngemini -m gemini-3-pro-preview \"Explain the CAP theorem with real-world examples\"\n```\n\n### Code Editing Tasks\n\n```bash\n# Refactoring (uses gemini-3-pro-preview for all tasks)\ngemini -m gemini-3-pro-preview \"Refactor this function for better readability\"\n\n# Fix syntax errors\ngemini -m gemini-3-pro-preview \"Fix the syntax errors in this JavaScript code\"\n\n# Optimize performance\ngemini -m gemini-3-pro-preview \"Optimize this database query for better performance\"\n```\n\n### Session Management\n\n```bash\n# Start a session (automatic)\ngemini -m gemini-3-pro-preview \"Design an authentication system\"\n\n# List available sessions\ngemini --list-sessions\n\n# Resume most recent\ngemini -r latest\n\n# Resume specific session\ngemini -r 3\n\n# Continue with new prompt\ngemini -r latest \"Now help me implement the login flow\"\n```\n\n### With Output Formatting\n\n```bash\n# JSON output for parsing\ngemini -m gemini-2.5-pro --output-format json \"List top 5 design patterns\"\n\n# Streaming JSON for real-time\ngemini -m gemini-2.5-pro --output-format stream-json \"Explain async patterns\"\n```\n\n### Approval Modes\n\n```bash\n# Default mode (prompt for all)\ngemini -m gemini-2.5-pro --approval-mode default \"Review this code\"\n\n# Auto-edit (auto-approve edits only)\ngemini -m gemini-2.5-pro --approval-mode auto_edit \"Refactor this module\"\n\n# YOLO mode (auto-approve ALL - use with caution)\ngemini -m gemini-2.5-pro --approval-mode yolo \"Deploy to production\"\n```\n\n### Sandbox Mode\n\n```bash\n# Enable sandbox for untrusted code\ngemini -m gemini-2.5-pro -s \"Analyze this suspicious code snippet\"\n\n# Disabled by default (trusted environment)\ngemini -m gemini-2.5-pro \"Review this internal codebase\"\n```\n\n### Extensions & MCP Integration\n\nGemini CLI supports extensions and Model Context Protocol (MCP) servers for enhanced functionality.\n\n```bash\n# List available extensions\ngemini --list-extensions\n\n# Use specific extensions (web search, code analysis, etc.)\ngemini -m gemini-3-pro-preview -e web_search \"Research React 19 features\"\n\n# Use all extensions (default)\ngemini -m gemini-3-pro-preview \"Design system architecture\"\n```\n\n**Note**: This plugin does not implement custom extensions or MCP servers. Users can configure extensions and MCP servers through the Gemini CLI's standard configuration in `~/.gemini/settings.json`. Extensions are enabled by default when appropriate for the task.\n\n### Additional Directories (`--include-directories`) (v0.20.0+)\n\nInclude additional directories in workspace context:\n\n```bash\n# Single directory\ngemini -m gemini-3-pro-preview --include-directories /shared/libs \"task\"\n\n# Multiple directories (comma-separated)\ngemini -m gemini-3-pro-preview --include-directories /path1,/path2 \"task\"\n\n# Multiple directories (repeated flag)\ngemini -m gemini-3-pro-preview --include-directories /path1 --include-directories /path2 \"task\"\n```\n\n**Note**: Disabled in restrictive sandbox profiles.\n\n### Accessibility (`--screen-reader`) (v0.20.0+)\n\nEnable screen reader mode for accessibility:\n\n```bash\ngemini -m gemini-3-pro-preview --screen-reader \"task\"\n```\n\n### Interactive with Prompt (`-i/--prompt-interactive`) (v0.20.0+)\n\nExecute a prompt and continue in interactive mode:\n\n```bash\ngemini -m gemini-3-pro-preview -i \"initial prompt here\"\n```\n\n**Note**: Limited applicability for Claude Code skills which use non-interactive mode.\n\n### Experimental ACP Mode (`--experimental-acp`)\n\nStart agent in Agent Control Protocol mode for programmatic interaction:\n\n```bash\ngemini --experimental-acp \"task\"\n```\n\n**Note**: Experimental feature. Works with `GEMINI_API_KEY` environment variable.\n\n---\n\n## Reference Documentation\n\nFor detailed information, see the references directory:\n\n- **`references/gemini-help.md`** - Complete Gemini CLI help output and flag reference\n- **`references/command-patterns.md`** - Common command templates organized by use case\n- **`references/session-workflows.md`** - Multi-turn conversation patterns and best practices\n- **`references/model-selection.md`** - Model selection decision tree and version mapping\n\n---\n\n## Tips & Best Practices\n\n1. **Always Specify Model**: Use `-m` flag explicitly for predictable behavior\n2. **Use Positional Prompts**: Prefer `gemini \"prompt\"` over deprecated `-p` flag\n3. **Enable Web Search When Needed**: Add `-e web_search` for research tasks\n4. **Resume Sessions for Complex Tasks**: Use `-r latest` for multi-turn conversations\n5. **Start with Gemini 3 Pro**: Default to `gemini-3-pro-preview`, fallback to 2.5 models\n6. **Use Appropriate Approval Mode**: `auto_edit` for code, `default` for untrusted tasks\n7. **Monitor Rate Limits**: 60 req/min, 1000 req/day on free tier\n8. **Check CLI Availability**: Validate `command -v gemini` before invocation\n\n---\n\n## Differences from Codex\n\n| Feature | Codex CLI | Gemini CLI |\n|---------|-----------|------------|\n| Invocation | `codex exec \"prompt\"` | `gemini \"prompt\"` |\n| Subcommand | Required (`exec`) | Not needed |\n| Positional Prompts | Not supported | Preferred |\n| Session Resume | `codex exec resume --last` | `gemini -r latest` |\n| Models | GPT-5.1, GPT-5.1-Codex | Gemini 3 Pro, 2.5 Pro/Flash |\n| Provider | OpenAI (via Codex) | Google |\n\n---\n\n## When to Use Gemini vs Codex vs Claude\n\n**Use Gemini when:**\n- You need Google's latest models\n- Research with web search is important\n- You prefer Google's AI capabilities\n- Codex is unavailable or rate-limited\n- Task benefits from Gemini's strengths\n\n**Use Codex when:**\n- You need GPT-5.1's reasoning capabilities\n- Task requires high-reasoning model\n- Code editing with specific Codex optimizations\n- You're already using Codex workflow\n\n**Use Claude (native) when:**\n- Simple queries within Claude Code's capabilities\n- No external AI needed\n- Quick responses preferred\n- Task doesn't require specialized models\n\n---\n\n## Version Compatibility\n\n- **Minimum Gemini CLI**: v0.20.0\n- **Recommended**: v0.20.x stable (latest)\n- **Preview/Nightly**: Weekly previews available (Tuesdays UTC 2359)\n\n**Changes in v0.20.0:**\n- `-p/--prompt` flag officially deprecated (use positional prompts)\n- New `--include-directories` flag for workspace expansion\n- New `-i/--prompt-interactive` flag for interactive continuation\n- New `--screen-reader` accessibility flag\n- New `--experimental-acp` Agent Control Protocol mode\n- Session management via `-r` flag standard\n\n---\n\nFor questions or issues, consult `references/gemini-help.md` or run `gemini --help`.\n"
      },
      "discovered_at": "2026-01-11T15:36:24.258633Z",
      "fetch_error": null
    },
    {
      "name": "design",
      "slug": "design",
      "source": "skillsmp",
      "owner": "saadshahd",
      "repo_name": "moo.md",
      "repository_url": "https://github.com/saadshahd/moo.md",
      "skill_path": "design/skills/design",
      "github_metadata": {
        "stars": 23,
        "description": "Structured thinking for Claude Code â€” ask before building, search before writing, verify before shipping",
        "default_branch": "main",
        "pushed_at": "2026-01-06T00:32:42Z",
        "created_at": "2025-11-29T15:45:06Z",
        "language": "TypeScript",
        "license": null,
        "open_issues": 1,
        "forks": 0
      },
      "skill_md": {
        "found": true,
        "path": "design/skills/design/SKILL.md",
        "branch": "main",
        "content": "---\nname: design\ndescription: Explore visual design, UI/UX, and design systems. Use when designing visual directions, user journeys, information architecture, color palettes, typography, or reviewing design feedback. NOT for feature planning or technical architecture.\n---\n\n# Design Skill\n\nClaude as collaborative creative partner for research, inspiration, and surfacing unknowns. NOT visual execution.\n\n**Philosophy:** Help designers stay in exploration longer and transition to commitment with earned confidence.\n\n## âš ï¸ CRITICAL: Ask Before Assuming\n\nIf ANY required input is missing or unclear:\n\n1. **STOP**\n2. Use Ask tool to gather missing information\n3. Do NOT proceed with assumptions\n\nFor every input, require:\n\n- **Source**: Research / Stakeholder input / Team assumption\n- **Confidence**: High / Medium / Low\n\nIf >50% inputs are low-confidence assumptions â†’ flag as risk before proceeding.\n\n## Workflow Selection\n\n| Task Type                          | Workflow                 | Reference                   |\n| ---------------------------------- | ------------------------ | --------------------------- |\n| Limits, boundaries, requirements   | Constraints              | `references/constraints.md` |\n| User flow, touchpoints, experience | Journey Mapping          | `references/journey.md`     |\n| Structure, hierarchy, navigation   | Information Architecture | `references/ia.md`          |\n| Color, typography, motion, mood    | Visual Directions        | `references/directions.md`  |\n| Design tokens, principles          | Design System            | `references/system.md`      |\n| UI copy, tone variations           | Microcopy                | `references/copy.md`        |\n| Competitor flows, UX patterns      | UX Comparison            | `references/compare.md`     |\n| Give/receive design feedback       | Design Critique          | `references/critique.md`    |\n\n## Workflow Flow\n\n```\nconstraints â†’ journey â†’ ia â†’ directions â†’ system\n                                 â†“\n                               copy\n\ncompare â†’ (anytime for research)\ncritique â†’ (anytime for feedback)\n```\n\n## Core Principles\n\n### Exploration Mode\n\n- Surface unknowns before constraints\n- Questions over answers early in process\n- No visual execution (no code, no Figma)\n\n### Anti-Convergence\n\n- Always generate **3+ options**\n- Avoid generic defaults (Inter, purple gradients)\n- Include \"what we're NOT doing and why\"\n\n### Evidence-Grounded\n\n- Every input needs Source + Confidence\n- Flag assumptions explicitly\n- Recommend research when confidence is low\n\n### Accessibility-First\n\n- WCAG considerations in every visual workflow\n- Not an afterthought\n\n## Related Thinking Tools\n\n| Tool                                                                            | When to Use                           |\n| ------------------------------------------------------------------------------- | ------------------------------------- |\n| [First Principles](../../hope/skills/soul/references/tools/first-principles.md) | Question assumptions before designing |\n| [Issue Trees](../../hope/skills/soul/references/tools/issue-trees.md)           | Break down complex design problems    |\n| [Decision Matrix](../../hope/skills/soul/references/tools/decision-matrix.md)   | Choose between design directions      |\n\n## Usage\n\n1. Detect which workflow applies\n2. Announce: \"I'm using the design skill for [workflow]\"\n3. **Ask for ALL required inputs before proceeding**\n4. Execute workflow with evidence tracking\n5. Include commitment readiness check\n"
      },
      "discovered_at": "2026-01-11T15:36:24.647878Z",
      "fetch_error": null
    },
    {
      "name": "recall",
      "slug": "recall",
      "source": "skillsmp",
      "owner": "saadshahd",
      "repo_name": "moo.md",
      "repository_url": "https://github.com/saadshahd/moo.md",
      "skill_path": "hope/skills/recall",
      "github_metadata": {
        "stars": 23,
        "description": "Structured thinking for Claude Code â€” ask before building, search before writing, verify before shipping",
        "default_branch": "main",
        "pushed_at": "2026-01-06T00:32:42Z",
        "created_at": "2025-11-29T15:45:06Z",
        "language": "TypeScript",
        "license": null,
        "open_issues": 1,
        "forks": 0
      },
      "skill_md": {
        "found": true,
        "path": "hope/skills/recall/SKILL.md",
        "branch": "main",
        "content": "---\nname: recall\ndescription: Auto-activates at session start to surface relevant learnings. Use when starting work in a domain to recall past insights from ~/.claude/learnings/.\n---\n\n# Recall Skill\n\nSurface relevant learnings from past sessions.\n\n## When This Skill Activates\n\n- Session start (new or resumed)\n- Before substantial work in a domain\n- When soul skill's Silent Audit prompts \"Learnings recalled?\"\n- Explicitly via `/hope:recall [context]`\n\n## Input\n\nOptional context hint (e.g., \"hooks\", \"testing\", \"typescript\"). If empty, infer from current project/conversation.\n\n## Process\n\n1. **Read learnings files** using the Read tool:\n\n   - `~/.claude/learnings/failures.jsonl`\n   - `~/.claude/learnings/discoveries.jsonl`\n   - `~/.claude/learnings/constraints.jsonl`\n\n   If files don't exist, skip silently.\n\n2. **Filter by relevance**:\n\n   - Match `context` field against provided hint or inferred domain\n   - Match `applies_to` tags against current work\n   - Prioritize recent entries (last 30 days)\n   - Prioritize high-confidence discoveries (>= 0.8)\n\n3. **Output format**:\n\n### Relevant Failures\n\n- **[context]**: [failure] â†’ Prevention: [prevention]\n\n### Relevant Discoveries\n\n- **[context]** (confidence: X): [discovery]\n\n### Active Constraints\n\n- **[context]**: [constraint] (permanent: yes/no)\n\n4. **If no relevant learnings**: Report \"No learnings found for [context]\"\n"
      },
      "discovered_at": "2026-01-11T15:36:25.104527Z",
      "fetch_error": null
    },
    {
      "name": "writing",
      "slug": "writing",
      "source": "skillsmp",
      "owner": "saadshahd",
      "repo_name": "moo.md",
      "repository_url": "https://github.com/saadshahd/moo.md",
      "skill_path": "wordsmith/skills/writing",
      "github_metadata": {
        "stars": 23,
        "description": "Structured thinking for Claude Code â€” ask before building, search before writing, verify before shipping",
        "default_branch": "main",
        "pushed_at": "2026-01-06T00:32:42Z",
        "created_at": "2025-11-29T15:45:06Z",
        "language": "TypeScript",
        "license": null,
        "open_issues": 1,
        "forks": 0
      },
      "skill_md": {
        "found": true,
        "path": "wordsmith/skills/writing/SKILL.md",
        "branch": "main",
        "content": "---\nname: writing\ndescription: Precision editing for prose and copy. Use when user says \"edit this\", \"improve this\", \"review my writing\", \"use [name]'s voice\", or provides draft text to refine. Triggers on editing, voice extraction, voice library, narrative structure, microcopy.\n---\n\n# Writing Skill\n\nRouter skill for writing and content workflows. Detects task type and routes to appropriate workflow.\n\n## When This Skill Activates\n\nYou're working on:\n\n- Editing prose or documentation\n- Extracting or matching author voice\n- Managing saved voice profiles (list, apply, delete)\n- Structuring narratives or stories\n- Writing UI microcopy\n- Evaluating content quality\n\n## Workflow Selection\n\nAnnounce which workflow you're using:\n\n| Task Type                                    | Workflow            | Reference                   |\n| -------------------------------------------- | ------------------- | --------------------------- |\n| Analyze writing style, extract voice profile | Voice Extraction    | `references/voice.md`       |\n| List, apply, or delete saved voices          | Voice Library       | `/wordsmith:voices` command |\n| Edit text, cut fluff, tighten prose          | Precision Editing   | `references/editing.md`     |\n| Structure story, build narrative arc         | Narrative Structure | `references/narrative.md`   |\n| Write UI copy, tone variations               | Microcopy Tones     | `references/copy.md`        |\n| Evaluate blog/content quality, score         | Content Evaluation  | `references/eval.md`        |\n| Create RFC, ADR, design doc, or blog         | Document Template   | `../template/SKILL.md`      |\n\n## Strategic Framework\n\n| Framework | Purpose | When to Use |\n|-----------|---------|-------------|\n| [Open Loop](references/open-loop.md) | Make messages memorable via Zeigarnik effect | Copy, presentations, emails that need to stick |\n\n## Related Thinking Tools\n\nFrom `hope/skills/soul/references/tools/`:\n\n| Tool                                                                      | When to Use                                |\n| ------------------------------------------------------------------------- | ------------------------------------------ |\n| [Minto Pyramid](../../hope/skills/soul/references/tools/minto-pyramid.md) | Structure executive summaries, SCQA format |\n| [Productive Thinking](../../hope/skills/soul/references/tools/productive-thinking.md) | Multi-perspective content review |\n\n## Usage\n\n1. Detect which workflow applies based on user's task\n2. Announce: \"I'm using the writing skill for [workflow]\"\n3. Load the appropriate reference file\n4. Execute the workflow exactly as written\n\n## Rules\n\n- Use Ask tool to gather input before proceeding\n- Preserve author voice when editing\n- Be specific about changes and rationale\n- For evaluations, provide exact replacement text for fixes\n"
      },
      "discovered_at": "2026-01-11T15:36:25.397104Z",
      "fetch_error": null
    },
    {
      "name": "counsel",
      "slug": "counsel",
      "source": "skillsmp",
      "owner": "saadshahd",
      "repo_name": "moo.md",
      "repository_url": "https://github.com/saadshahd/moo.md",
      "skill_path": "counsel/skills/counsel",
      "github_metadata": {
        "stars": 23,
        "description": "Structured thinking for Claude Code â€” ask before building, search before writing, verify before shipping",
        "default_branch": "main",
        "pushed_at": "2026-01-06T00:32:42Z",
        "created_at": "2025-11-29T15:45:06Z",
        "language": "TypeScript",
        "license": null,
        "open_issues": 1,
        "forks": 0
      },
      "skill_md": {
        "found": true,
        "path": "counsel/skills/counsel/SKILL.md",
        "branch": "main",
        "content": "---\nname: counsel\ndescription: Expert simulation for code guidance and style. Triggers on \"code like [expert]\", \"what would [expert] say\", \"idiomatic\", \"best practice\", \"panel\", or domain-specific keywords. Channels documented expert perspectives with explicit confidence.\n---\n\n# counsel\n\nSimulate expert perspectives for code guidance, style, and debates.\n\n---\n\n## When This Activates\n\n- \"code like [expert name]\", \"write like [expert]\"\n- \"what would [expert] say\", \"ask [expert]\"\n- \"review\", \"audit\", \"panel\", \"guidance\"\n- \"idiomatic\", \"best practice\", \"clean code\"\n- Domain keywords from curated profiles (see [inference.md](references/inference.md))\n\n---\n\n## Core Constraint\n\nYou are NOT the expert. You are simulating their perspective based on documented work.\n\n**Required behaviors:**\n- State confidence explicitly (X/10)\n- Cite prior work when giving opinions\n- Use \"would likely\" not \"would\"\n- Flag when simulation confidence is low\n- Check calibrations before generating\n\n---\n\n## Process\n\n### Step 0: Load Calibrations\n\nRead `.claude/logs/counsel-calibrations.jsonl` if it exists.\nApply all calibrations to matching expert simulations.\n\n### Step 0.5: Load Blocklist\n\nRead `~/.claude/counsel-blocklist.json` if it exists. Build excluded set from blocked profile names.\n\nThese profiles are invisible to detection, paneling, and summoning.\n\nIf user explicitly requests a blocked profile by name, refuse with:\n> \"âš ï¸ [profile] is on your blocklist. Use `/counsel:unblock [name]` to remove.\"\n\n### Step 1: Detect Expert\n\nFollow [inference.md](references/inference.md) detection order:\n\n1. Explicit name mention â†’ direct match\n2. Trigger keywords â†’ match to curated profile\n3. File context â†’ infer from extensions/imports\n4. Domain signals â†’ topic-based routing\n5. No match â†’ ask user or provide generic guidance\n\n### Step 2: Load Profile\n\n**CRITICAL: Lazy loading only.** After Step 1 detection, load ONLY the matched profile. Never preload multiple profiles. For panels, load max 3-4 profiles.\n\nIf curated profile exists in `references/profiles/`:\n- Read full profile\n- Apply confidence rules from [confidence.md](references/confidence.md)\n- Note: base 6/10, apply modifiers\n\nIf no curated profile:\n- Use dynamic simulation (base 4/10)\n- Add low-confidence warning\n- Suggest adding curated profile\n\n### Step 3: Generate Response\n\nApply expert's philosophy, voice pattern, typical concerns, and would-never-say guardrails. Display confidence in header, offer calibration at end. See [confidence.md](references/confidence.md) for display format.\n\n---\n\n## Output Modes\n\n### Single Expert (default)\n\nOne expert perspective on the query.\n\n### Panel\n\nMultiple experts debate. Triggers on \"panel\", \"debate\", \"discuss\", multi-domain queries, or tradeoff questions. See `/counsel:panel` for format.\n\n### Style Modifier\n\nWhen \"code like [expert]\" or \"style of [expert]\": generate code in expert's documented style with citations and confidence.\n\n---\n\n## Curated Profiles\n\n20 experts available. See [inference.md](references/inference.md) for the complete catalog with domain routing.\n\n---\n\n## Commands\n\n| Command | Purpose |\n|---------|---------|\n| `/counsel:summon [expert]` | Explicit single-expert invocation |\n| `/counsel:panel [question]` | Multi-expert debate |\n| `/counsel:calibrate [correction]` | Correct simulation errors |\n| `/counsel:block [name]` | Block a profile from simulations |\n| `/counsel:unblock [name]` | Remove a profile from blocklist |\n| `/counsel:blocked` | List blocked profiles |\n\n---\n\n## Guardrails\n\n### Refuse When\n\n- Confidence would be < 30%\n- Expert has no documented public positions\n- Topic requires personal opinions not documented views\n\n### Never\n\n- Claim certainty about what expert \"would\" say (use \"would likely\")\n- Invent positions not in documented work\n- Simulate without stating confidence\n- Skip calibration check\n\n---\n\n## Output Anonymization\n\n**Never use expert names in output.** Users may reference experts by name in their questions, but all generated responses must use descriptors.\n\n**Process:**\n1. User mentions expert (by name or description)\n2. Identify: \"Why is this expert relevant to this question?\"\n3. Generate descriptor from that relevance (e.g., \"an immutability advocate\")\n4. Use descriptor in all output â€” headers, panel labels, citations\n\n**Allowed in input:** \"What would Rich Hickey say about my Redux state?\"\n**Required in output:** \"**Channeling an immutability advocate** (7/10 confidence)...\"\n\nSee [confidence.md](references/confidence.md#descriptor-generation) for descriptor examples.\n\n---\n\n## Calibration Protocol\n\nIf user says \"[Expert] wouldn't say that\": acknowledge, ask for correction, log to `.claude/logs/counsel-calibrations.jsonl`, apply in future. See `/counsel:calibrate` for details.\n"
      },
      "discovered_at": "2026-01-11T15:36:25.691257Z",
      "fetch_error": null
    },
    {
      "name": "gate",
      "slug": "gate",
      "source": "skillsmp",
      "owner": "saadshahd",
      "repo_name": "moo.md",
      "repository_url": "https://github.com/saadshahd/moo.md",
      "skill_path": "hope/skills/gate",
      "github_metadata": {
        "stars": 23,
        "description": "Structured thinking for Claude Code â€” ask before building, search before writing, verify before shipping",
        "default_branch": "main",
        "pushed_at": "2026-01-06T00:32:42Z",
        "created_at": "2025-11-29T15:45:06Z",
        "language": "TypeScript",
        "license": null,
        "open_issues": 1,
        "forks": 0
      },
      "skill_md": {
        "found": true,
        "path": "hope/skills/gate/SKILL.md",
        "branch": "main",
        "content": "---\nname: gate\ndescription: Verification before completion claims. Use when about to say \"done\", \"fixed\", or \"complete\". Runs checklist by workflow type with evidence requirements.\n---\n\n# gate\n\nVerify before claiming completion.\n\n## Trigger\n\nBefore claiming: \"done\", \"fixed\", \"complete\", \"working\", \"ready\"\n\n## Workflow A: Build\n\n```\nâ–¡ Feature executes without errors (show output)\nâ–¡ Edge cases tested (empty, null, boundary)\nâ–¡ Rollback tested if Type 2B/1\nâ–¡ Dependencies verified\n```\n\n## Workflow B: Debug\n\n```\nâ–¡ Root cause identified with evidence\nâ–¡ Fix tested and resolves symptom\nâ–¡ Prevention added (test/automation/guard)\nâ–¡ Related bugs checked (same class)\n```\n\n## Workflow C: Refactor\n\n```\nâ–¡ Existing tests pass unchanged\nâ–¡ Behavior identical (output comparison)\nâ–¡ Deletion complete (no orphans)\nâ–¡ No new abstraction without justification\n```\n\n## Verification Types\n\n| Type | Description | Sufficient for SHIP? |\n|------|-------------|---------------------|\n| `execution output` | Ran command, showed result | âœ“ Yes |\n| `observation` | Screenshot, debugger session | âœ“ Yes |\n| `measurement` | Metrics, benchmark data | âœ“ Yes |\n| `code review` | Inspection only | âš ï¸ Weak |\n| `assumption` | Not verified | âœ— Blocks SHIP |\n\nRequire `execution output`, `observation`, or `measurement` before completion claims.\n\n## Anti-Patterns\n\n| Claim                      | Problem         | Required      |\n| -------------------------- | --------------- | ------------- |\n| \"Should work\"              | Speculation     | Actual output |\n| \"Looks good\"               | No verification | Test results  |\n| \"Fixed the issue\"          | No proof        | Before/after  |\n| \"I think this resolves it\" | No confidence % | X-Y% + basis  |\n\n## Incomplete Work\n\nWhen blocked, state:\n\n- What's done (with evidence)\n- What's blocking (specific)\n- What's remaining\n\n## Type 2A Exception\n\nTrivial changes (< 1 min rollback): completion allowed without full gate.\nDocument undo command.\n\n## Common Rationalizations (All Wrong)\n\n| Thought | Reality |\n|---------|---------|\n| \"The tests passed\" | Tests â‰  verification. Did you run the ACTUAL command? |\n| \"It should work\" | \"Should\" = assumption. Show evidence. |\n| \"I already checked\" | When? Show the output. |\n| \"The user is waiting\" | Rushed verification = rework later. |\n| \"It's a simple change\" | Simple changes break production too. |\n| \"I'm pretty sure it works\" | Pretty sure â‰  evidence. Run it. |\n"
      },
      "discovered_at": "2026-01-11T15:36:26.226538Z",
      "fetch_error": null
    },
    {
      "name": "product",
      "slug": "product",
      "source": "skillsmp",
      "owner": "saadshahd",
      "repo_name": "moo.md",
      "repository_url": "https://github.com/saadshahd/moo.md",
      "skill_path": "product/skills/product",
      "github_metadata": {
        "stars": 23,
        "description": "Structured thinking for Claude Code â€” ask before building, search before writing, verify before shipping",
        "default_branch": "main",
        "pushed_at": "2026-01-06T00:32:42Z",
        "created_at": "2025-11-29T15:45:06Z",
        "language": "TypeScript",
        "license": null,
        "open_issues": 1,
        "forks": 0
      },
      "skill_md": {
        "found": true,
        "path": "product/skills/product/SKILL.md",
        "branch": "main",
        "content": "---\nname: product\ndescription: Product workflows router. Use when user mentions \"PRD\", \"competitive analysis\", \"metrics\", \"OKRs\", \"cohort\", \"requirements\", or \"technical debt\". Triggers on product management and strategy tasks.\n---\n\n# Product Skill\n\nRouter skill for product management workflows. Detects task type and routes to appropriate workflow.\n\n## When This Skill Activates\n\nYou're working on:\n\n- Competitive analysis or market positioning\n- Product requirements documentation\n- Goal setting and metrics definition\n- User research synthesis\n- Cohort and retention analysis\n- PRD quality evaluation\n- Technical debt prioritization\n\n## Workflow Selection\n\nAnnounce which workflow you're using:\n\n| Task Type                                   | Workflow             | Reference                |\n| ------------------------------------------- | -------------------- | ------------------------ |\n| Competitive analysis, market gaps, win/loss | Competitive Analysis | `references/compete.md`  |\n| Feature specs, requirements, MVP scoping    | PRD Generation       | `references/prd.md`      |\n| Goals, OKRs, KPIs, tracking systems         | Metrics & Goals      | `references/metrics.md`  |\n| User interviews, qualitative data, insights | Research Synthesis   | `references/research.md` |\n| Retention, LTV, churn, cohort data          | Cohort Analysis      | `references/cohort.md`   |\n| PRD review, completeness check, scoring     | PRD Evaluation       | `references/prd-eval.md` |\n| Tech debt triage, remediation planning      | Debt Prioritization  | `references/debt.md`     |\n\n## Related Thinking Tools\n\nFrom `hope/skills/soul/references/tools/`:\n\n| Tool                                                                                  | When to Use                               |\n| ------------------------------------------------------------------------------------- | ----------------------------------------- |\n| [Second-Order Thinking](../../hope/skills/soul/references/tools/second-order.md)      | Predict consequences of product decisions |\n| [Pre-Mortem](../../hope/skills/soul/references/tools/pre-mortem.md)                   | Anticipate launch failures                |\n| [Impact-Effort](../../hope/skills/soul/references/tools/impact-effort.md)             | Focus on high-impact, low-effort features |\n\nFrom this skill's `references/`:\n\n| Tool                                              | When to Use                             |\n| ------------------------------------------------- | --------------------------------------- |\n| [Jobs To Be Done](references/jobs-to-be-done.md)  | Understand what customers hire products for |\n| [Systems Archetypes](references/systems-archetypes.md) | Recognize \"limits to growth\", \"shifting burden\" patterns |\n\n## Usage\n\n1. Detect which workflow applies based on user's task\n2. Announce: \"I'm using the product skill for [workflow]\"\n3. Load the appropriate reference file\n4. Execute the workflow exactly as written\n\n## Rules\n\n- Use Ask tool to gather input before proceeding\n- Ground recommendations in evidence\n- Use story points, never time estimates\n- Challenge assumptions and cut scope by default\n"
      },
      "discovered_at": "2026-01-11T15:36:26.605030Z",
      "fetch_error": null
    },
    {
      "name": "trace",
      "slug": "trace",
      "source": "skillsmp",
      "owner": "saadshahd",
      "repo_name": "moo.md",
      "repository_url": "https://github.com/saadshahd/moo.md",
      "skill_path": "hope/skills/trace",
      "github_metadata": {
        "stars": 23,
        "description": "Structured thinking for Claude Code â€” ask before building, search before writing, verify before shipping",
        "default_branch": "main",
        "pushed_at": "2026-01-06T00:32:42Z",
        "created_at": "2025-11-29T15:45:06Z",
        "language": "TypeScript",
        "license": null,
        "open_issues": 1,
        "forks": 0
      },
      "skill_md": {
        "found": true,
        "path": "hope/skills/trace/SKILL.md",
        "branch": "main",
        "content": "---\nname: trace\ndescription: Root cause analysis for complex bugs. Use when initial fix fails or incident is severe. Traces Effect â†’ Cause â†’ Root with confidence levels and prevention hierarchy.\n---\n\n# trace\n\nRoot cause analysis when surface fixes fail.\n\n## When to Use\n\n| Trigger                            | Action    |\n| ---------------------------------- | --------- |\n| Bug persists after initial fix     | Run trace |\n| Production incident (SEV 1-2)      | Run trace |\n| Complex failure (multiple sources) | Run trace |\n| Trivial bug (< 10 min fix)         | Skip      |\n\n## 1. Timeline\n\n```\nHH:MM - [Event] - [System state] - [Action taken]\n```\n\nNote: detection time vs. start time (how long hidden?)\n\n## 2. Five Whys\n\n```\nEffect: [What users/systems experienced]\n\nWhy 1: [Immediate cause] (X-Y% confident)\nWhy 2: [Underlying mechanism] (X-Y% confident)\nWhy 3: [System/process gap] (X-Y% confident)\nWhy 4: [Organizational factor] (X-Y% confident)\nWhy 5: [Root cause] (X-Y% confident)\n```\n\n**Gates**: < 70% any level â†’ request logs/reproduction\nRoot cause = deepest answer with â‰¥70% confidence\n\n## 3. Contributing Factors\n\nBeyond root cause, what amplified impact?\n\n**Process**: Monitoring gaps, testing gaps, review gaps\n**People**: Unclear ownership, missing runbooks\n**Technical**: Dependency failures, capacity limits, config drift\n**Context**: Traffic patterns, deployment timing, external factors\n\nList 2-4 factors with specific mechanisms.\n\n**Tools:** [Ishikawa](../soul/references/tools/ishikawa.md) for categorization, [Iceberg](../soul/references/tools/iceberg.md) for deep structure analysis.\n\n## 4. Impact\n\n**Users**: Count, experience, business cost (quantified)\n**Systems**: Downstream effects, data integrity, security\n\n## 5. Prevention Hierarchy\n\n### Immediate (< 1 week)\n\n```\n1. [Code/config change]\n   File: [path:line]\n   Verification: [how to confirm]\n   Owner: [who]\n```\n\n### Short-Term (< 1 month)\n\n```\n1. [Alert/test/automation]\n   Trigger: [when it fires]\n   Owner: [who]\n```\n\n### Long-Term (< 1 quarter)\n\n```\n1. [Architectural change]\n   Problem class: [what it prevents]\n   Effort: [story points]\n   Owner: [who]\n```\n\nEach tier needs â‰¥1 item.\n\n## 6. Blameless\n\nSee `soul/references/blameless.md`\n\nFocus on system gaps, not individual mistakes.\n\n## Output\n\n```\n# Incident: [Title]\n\n## Timeline\n[Detection â†’ Resolution]\n\n## Five Whys\n[With confidence per level]\n\n## Contributing Factors\n[2-4 items]\n\n## Impact\n[Quantified]\n\n## Prevention\n[Immediate / Short-Term / Long-Term]\n\n## Top 3 Actions\n1. [Task] | Owner: [Name] | Due: [Date]\n2. ...\n3. ...\n```\n\n## Anti-Patterns\n\n| Bad                     | Good                                   |\n| ----------------------- | -------------------------------------- |\n| \"Human error\"           | Identify automation gap                |\n| \"Communication failure\" | Identify process gap                   |\n| \"Be more careful\"       | Add system safeguard                   |\n| \"Performance issue\"     | Specific: \"Pool exhausted at 1K req/s\" |\n"
      },
      "discovered_at": "2026-01-11T15:36:26.871147Z",
      "fetch_error": null
    },
    {
      "name": "template",
      "slug": "template",
      "source": "skillsmp",
      "owner": "saadshahd",
      "repo_name": "moo.md",
      "repository_url": "https://github.com/saadshahd/moo.md",
      "skill_path": "wordsmith/skills/template",
      "github_metadata": {
        "stars": 23,
        "description": "Structured thinking for Claude Code â€” ask before building, search before writing, verify before shipping",
        "default_branch": "main",
        "pushed_at": "2026-01-06T00:32:42Z",
        "created_at": "2025-11-29T15:45:06Z",
        "language": "TypeScript",
        "license": null,
        "open_issues": 1,
        "forks": 0
      },
      "skill_md": {
        "found": true,
        "path": "wordsmith/skills/template/SKILL.md",
        "branch": "main",
        "content": "---\nname: template\ndescription: Scaffold structured documents (RFC, ADR, Blog) using industry best practices. Produces draft for refinement with /wordsmith:edit.\n---\n\n# Template Skill\n\nScaffold structured documents using industry best practices. Produces a draft; use `/wordsmith:edit` to refine.\n\n## When This Skill Activates\n\nYou're working on:\n\n- Writing an RFC or design document\n- Creating an Architecture Decision Record (ADR)\n- Structuring a blog post or technical article\n- Applying or creating custom templates\n\n## Workflow Selection\n\nAnnounce which template you're using:\n\n| Request Pattern | Action | Reference |\n|-----------------|--------|-----------|\n| \"RFC\", \"request for comments\", \"design doc\", \"proposal\" | Apply RFC template | `references/templates/rfc.md` |\n| \"ADR\", \"architecture decision\", \"decision record\" | Apply ADR template | `references/templates/adr.md` |\n| \"blog\", \"blog post\", \"article\", \"technical post\" | Apply Blog template | `references/templates/blog.md` |\n| \"[custom name]\" template | Apply user template | `~/.claude/wordsmith/templates.jsonl` |\n| \"list templates\", \"show my templates\" | List all templates | See Template Management below |\n| \"create custom template\", \"save as template\" | Create user template | See Template Management below |\n| \"delete template [name]\" | Remove user template | See Template Management below |\n\n## Usage\n\n1. Detect template type from user request\n2. Announce: \"I'm using the template skill for [type] document\"\n3. Ask for required inputs (topic, context, audience)\n4. Check for custom template in `~/.claude/wordsmith/templates.jsonl` first\n5. Fall back to built-in templates if no custom match\n6. Generate scaffolded document with guidance\n7. Prompt: **\"Draft ready. Use `/wordsmith:edit` to refine prose, or continue iterating.\"**\n\n## Post-Scaffold Actions\n\nAfter generating draft:\n\n1. Offer to save modifications as custom template\n2. Suggest `/wordsmith:edit` for prose refinement\n3. Highlight any sections needing user input\n\n## Template Management\n\nUser templates stored at: `~/.claude/wordsmith/templates.jsonl`\n\n### List Templates\n\n**Goal:** Show all available templates (built-in + user) so user can choose.\n\nBuilt-in templates: `rfc`, `adr`, `blog`\n\n### Create Template\n\n**Goal:** Persist user's template definition for reuse.\n\n**Required information:**\n- Template name (must be unique)\n- Sections with guidance (at minimum)\n- Base template if extending existing\n\n**Constraints:**\n- Validate name uniqueness before saving\n- Confirm with user before overwriting existing\n\n**JSONL Schema:**\n\n```json\n{\n  \"ts\": \"ISO-8601\",\n  \"name\": \"template-name\",\n  \"base\": \"rfc|adr|blog|null\",\n  \"description\": \"One-line description\",\n  \"sections\": [{\"name\": \"...\", \"required\": true, \"guidance\": \"...\"}],\n  \"header_fields\": [\"field1\", \"field2\"],\n  \"quality_checks\": [\"Check 1\", \"Check 2\"],\n  \"source\": \"user\"\n}\n```\n\n### Delete Template\n\n**Goal:** Remove user template from storage.\n\n**Constraints:**\n- Cannot delete built-in templates\n- Confirm before deleting\n\n## Rules\n\n- Always check for custom templates before using built-ins\n- Use Ask tool for required inputs before scaffolding\n- Include quality checks at end of generated document\n- Prompt for `/wordsmith:edit` after scaffolding\n- Preserve user's existing content if iterating on a draft\n"
      },
      "discovered_at": "2026-01-11T15:36:27.174361Z",
      "fetch_error": null
    },
    {
      "name": "founder",
      "slug": "founder",
      "source": "skillsmp",
      "owner": "saadshahd",
      "repo_name": "moo.md",
      "repository_url": "https://github.com/saadshahd/moo.md",
      "skill_path": "founder/skills/founder",
      "github_metadata": {
        "stars": 23,
        "description": "Structured thinking for Claude Code â€” ask before building, search before writing, verify before shipping",
        "default_branch": "main",
        "pushed_at": "2026-01-06T00:32:42Z",
        "created_at": "2025-11-29T15:45:06Z",
        "language": "TypeScript",
        "license": null,
        "open_issues": 1,
        "forks": 0
      },
      "skill_md": {
        "found": true,
        "path": "founder/skills/founder/SKILL.md",
        "branch": "main",
        "content": "---\nname: founder\ndescription: Use when validating ideas, sizing markets, building pitch decks, preparing for investors, modeling financials, planning launches, or creating board reports. Auto-activates on fundraising, pitch, investor, TAM/SAM/SOM, unit economics, runway, or board deck tasks.\n---\n\n# Founder Skill\n\nRouter skill for startup workflows. Detects task type and routes to appropriate workflow that produces usable artifacts.\n\n## When This Skill Activates\n\nYou're working on:\n\n- Validating a product idea or value proposition\n- Calculating market size (TAM/SAM/SOM)\n- Analyzing competitive landscape or threats\n- Building or evaluating a pitch deck\n- Preparing for investor meetings\n- Modeling unit economics, projections, or cash flow\n- Planning a product launch\n- Creating board reports or updates\n\n## Workflow Selection\n\nAnnounce which workflow you're using before starting:\n\n| Task Type                         | Workflow            | Reference                     | Output Artifact               |\n| --------------------------------- | ------------------- | ----------------------------- | ----------------------------- |\n| Idea validation, stress testing   | Validate Idea       | `references/validate.md`      | JSON scores + GO/ITERATE/KILL |\n| TAM/SAM/SOM, market opportunity   | Size Market         | `references/market-size.md`   | Tables + Marp slide           |\n| Competition, threats, positioning | Analyze Competition | `references/compete.md`       | Threat matrix + heat map      |\n| Pitch deck creation or eval       | Build Pitch Deck    | `references/pitch.md`         | Marp deck (10-12 slides)      |\n| Investor Q&A, meeting prep        | Prep for Investors  | `references/investor-prep.md` | Q&A document                  |\n| Unit economics, projections, cash | Model Financials    | `references/financials.md`    | Spreadsheet-ready tables      |\n| Launch planning, 90-day roadmap   | Plan Launch         | `references/launch.md`        | Phased execution plan         |\n| Board deck, metrics summary       | Report to Board     | `references/board.md`         | Marp deck + summary           |\n\n## Related Thinking Tools\n\nFrom `hope/skills/soul/references/tools/`:\n\n| Tool                                                                                | When to Use                                  |\n| ----------------------------------------------------------------------------------- | -------------------------------------------- |\n| [Abstraction Ladder](../../hope/skills/soul/references/tools/abstraction-ladder.md) | Reframe pivot decisions                      |\n| [Hard Choice](../../hope/skills/soul/references/tools/hard-choice.md)               | GO/KILL verdicts with no clear winner        |\n| [Zwicky Box](../../hope/skills/soul/references/tools/zwicky-box.md)                 | Generate creative business model variations  |\n| [First Principles](../../hope/skills/soul/references/tools/first-principles.md)     | Challenge \"that's how it's done\" assumptions |\n| [Pre-Mortem](../../hope/skills/soul/references/tools/pre-mortem.md)                 | Anticipate launch/funding failures           |\n| [Circle of Competence](../../hope/skills/soul/references/tools/circle-of-competence.md) | Know when to hire vs build yourself      |\n\nFrom this skill's `references/`:\n\n| Tool                                              | When to Use                             |\n| ------------------------------------------------- | --------------------------------------- |\n| [Regret Minimization](references/regret-minimization.md) | Major founder decisions (quit job, pivot, shut down) |\n\n## Usage\n\n1. Detect which workflow applies based on user's task\n2. Announce: \"I'm using the founder skill for [workflow]\"\n3. Load the appropriate reference file\n4. Execute the workflow exactly as written\n5. Produce the specified artifact\n\n## Artifact Tooling\n\nAfter generating markdown artifacts, users can convert them:\n\n| Artifact      | Tool        | Command                                        |\n| ------------- | ----------- | ---------------------------------------------- |\n| Slides (Marp) | Marp CLI    | `npx @marp-team/marp-cli slides.md --pptx`     |\n| Documents     | md-to-pdf   | `npx md-to-pdf document.md`                    |\n| Spreadsheets  | Copy tables | Paste markdown tables into Google Sheets/Excel |\n\n## Rules\n\n- Always ask clarifying questions before generating artifacts\n- Produce complete, usable outputs (not partial drafts)\n- Use Marp format for all slide decks\n- Use markdown tables for spreadsheet data (easy paste)\n- Be brutally honest in evaluations (2% YC acceptance rate mindset)\n- Include confidence levels and key assumptions\n\n## Quality Footer (Required for High-Stakes Outputs)\n\nAll validation, pitch, and financial outputs MUST end with:\n\n```\n---\n| Confidence | X-Y% |\n| Key Assumption | [What would change this verdict] |\n| Reversibility | Type 2A/2B/1 |\n```\n\n**Verdict rules:**\n- GO verdict requires â‰¥70% confidence\n- ITERATE requires identifying specific unknowns to resolve\n- KILL must cite specific evidence, not intuition\n\n## Common Rationalizations (All Wrong)\n\n| Thought | Reality |\n|---------|---------|\n| \"The market is huge\" | TAM without SAM/SOM is meaningless. |\n| \"Nobody's doing this\" | If nobody's doing it, ask why. |\n| \"We just need 1% of the market\" | That's not a strategy, it's wishful math. |\n| \"First mover advantage\" | First movers usually lose. Execution wins. |\n| \"Build it and they will come\" | Distribution is harder than product. |\n| \"We're different\" | Every founder says this. Prove it with evidence. |\n"
      },
      "discovered_at": "2026-01-11T15:36:27.579286Z",
      "fetch_error": null
    },
    {
      "name": "career",
      "slug": "career",
      "source": "skillsmp",
      "owner": "saadshahd",
      "repo_name": "moo.md",
      "repository_url": "https://github.com/saadshahd/moo.md",
      "skill_path": "career/skills/career",
      "github_metadata": {
        "stars": 23,
        "description": "Structured thinking for Claude Code â€” ask before building, search before writing, verify before shipping",
        "default_branch": "main",
        "pushed_at": "2026-01-06T00:32:42Z",
        "created_at": "2025-11-29T15:45:06Z",
        "language": "TypeScript",
        "license": null,
        "open_issues": 1,
        "forks": 0
      },
      "skill_md": {
        "found": true,
        "path": "career/skills/career/SKILL.md",
        "branch": "main",
        "content": "---\nname: career\ndescription: Use when preparing for interviews, assessing skills, analyzing job opportunities, navigating stakeholder politics, or developing professional capabilities. Auto-activates on interview prep, career assessment, job search, skill gaps, feedback interpretation, leadership development, or professional growth tasks.\n---\n\n# Career Skill\n\nRouter skill for career development workflows. Detects task type and routes to appropriate workflow.\n\n## When This Skill Activates\n\nYou're working on:\n\n- Interview preparation or simulation\n- Career/skill assessment and gap analysis\n- Job posting analysis or opportunity evaluation\n- STAR narrative building for behavioral interviews\n- Stakeholder navigation and political situations\n- Executive communication evaluation\n- Professional skill development and practice drills\n- Focus capacity and meeting ROI analysis\n- Perspective shifting on career challenges\n\n## Workflow Selection\n\nAnnounce which workflow you're using:\n\n| Task Type                                  | Workflow              | Reference                   |\n| ------------------------------------------ | --------------------- | --------------------------- |\n| AI fluency evaluation, skill assessment    | AI Fluency Assessment | `references/assess.md`      |\n| Interview practice, scenario simulation    | Interview Simulator   | `references/simulate.md`    |\n| Behavioral stories, achievement narratives | STAR-C Narrative      | `references/star.md`        |\n| Weakness patterns, skill gap analysis      | Gap Analysis          | `references/gap.md`         |\n| Practice drills, situation-to-skill        | Practice Drill        | `references/drill.md`       |\n| Executive updates, leadership emails       | Communication Eval    | `references/eval-comm.md`   |\n| Political situations, stakeholder dynamics | Stakeholder Navigator | `references/stakeholder.md` |\n| Mental ruts, alternative viewpoints        | Perspective Shift     | `references/reframe.md`     |\n| Meeting costs, deep work capacity          | Focus Capacity        | `references/focus.md`       |\n| Job posting OSINT, company intelligence    | Job Intel             | `references/osint.md`       |\n\n## Related Thinking Tools\n\nFrom `hope/skills/soul/references/tools/`:\n\n| Tool                                                                                  | When to Use                               |\n| ------------------------------------------------------------------------------------- | ----------------------------------------- |\n| [SBI](../../hope/skills/soul/references/tools/sbi.md)                                 | Give or receive feedback without judgment |\n| [Conflict Resolution](../../hope/skills/soul/references/tools/conflict-resolution.md) | Navigate stakeholder disagreements        |\n| [Ladder of Inference](../../hope/skills/soul/references/tools/ladder-inference.md)    | Check assumptions in political situations |\n| [Circle of Competence](../../hope/skills/soul/references/tools/circle-of-competence.md) | Know your strengths and limits           |\n\nFrom this skill's `references/`:\n\n| Tool                                      | When to Use                             |\n| ----------------------------------------- | --------------------------------------- |\n| [10/10/10 Rule](../../hope/skills/soul/references/tools/10-10-10.md) | Daily career decisions with time clarity |\n| [Feynman Technique](references/feynman-technique.md) | Deep learning, interview prep, verify understanding |\n\n## Usage\n\n1. Detect which workflow applies based on user's task\n2. Announce: \"I'm using the career skill for [workflow]\"\n3. Load the appropriate reference file\n4. Execute the workflow exactly as written\n\n## Rules\n\n- Use Ask tool to gather input before proceeding\n- Be direct and honestâ€”career growth requires uncomfortable feedback\n- Focus on actionable improvements, not encouragement\n- Ground recommendations in evidence from user responses\n- Use story points for effort estimates, never time\n\n## Quality Footer (Required for Assessments)\n\nAll assessment, simulation, and stakeholder navigation outputs MUST end with:\n\n```\n---\n| Confidence | X-Y% |\n| Key Assumption | [What would change this assessment] |\n| Reversibility | Type 2A/2B/1 |\n```\n\n**Evidence requirements:**\n- Assessments must cite specific user responses\n- Simulations must ground feedback in observable patterns\n- Stakeholder analysis must distinguish [FACT] from [INFERENCE]\n"
      },
      "discovered_at": "2026-01-11T15:36:28.022066Z",
      "fetch_error": null
    },
    {
      "name": "hope",
      "slug": "hope",
      "source": "skillsmp",
      "owner": "saadshahd",
      "repo_name": "moo.md",
      "repository_url": "https://github.com/saadshahd/moo.md",
      "skill_path": "hope/skills/soul",
      "github_metadata": {
        "stars": 23,
        "description": "Structured thinking for Claude Code â€” ask before building, search before writing, verify before shipping",
        "default_branch": "main",
        "pushed_at": "2026-01-06T00:32:42Z",
        "created_at": "2025-11-29T15:45:06Z",
        "language": "TypeScript",
        "license": null,
        "open_issues": 1,
        "forks": 0
      },
      "skill_md": {
        "found": true,
        "path": "hope/skills/soul/SKILL.md",
        "branch": "main",
        "content": "---\nname: hope\ndescription: moo hope â€” cognitive operating system. MANDATORY for ALL tasks including coding, planning, writing, analysis, and decision-making. Run silent audit, clarify intent. Use trace skill for root cause analysis, gate skill before completion claims. Triggers on any request requiring structured thinking.\n---\n\n<EXTREMELY-IMPORTANT>\nThis skill applies to EVERY task. No exceptions.\nRun Silent Audit before responding.\nUse confidence gates.\nClarify intent using /hope:intent before building.\n\n**DEFER TO SPECIFIC SKILLS:** If user request clearly matches a domain-specific skill, invoke that skill FIRST:\n- \"edit\", \"improve prose\", \"review writing\" â†’ Use `wordsmith:writing` skill\n- \"PRD\", \"competitive analysis\", \"metrics\", \"OKRs\" â†’ Use `product:product` skill\n- \"interview\", \"career\", \"skill assessment\" â†’ Use `career:career` skill\n- \"validate idea\", \"pitch\", \"fundraising\" â†’ Use `founder:founder` skill\n\nDomain skills handle their workflows; soul provides the thinking framework underneath.\n</EXTREMELY-IMPORTANT>\n\n# moo\n\nmind on output. Stay present with AI.\n\nCognitive operating system for structured thinking.\n\nApplies to: coding, planning, writing, analysis, decision-making, and any task requiring clarity.\n\n---\n\n## Silent Audit (Run Before Every Response)\n\n```\nâ–¡ Inversion applied? (failure modes identified)\nâ–¡ Library searched? (production solution exists?)\nâ–¡ Learnings recalled? (past failures/discoveries for this domain?)\nâ–¡ Verification type known? (execution output > assumption)\nâ–¡ Subjective estimate stated? (~X% with evidence)\nâ–¡ Alternative provided? (different approach)\nâ–¡ Reversibility checked? (Type 2A/2B/1)\nâ–¡ Story points estimated? (complexity, never time)\nâ–¡ Intent clarified? (â‰¥85% confident I understand)\n```\n\n**Forbidden without percentage**: \"probably\", \"likely\", \"maybe\", \"might\", \"could\"\n\n---\n\n## Strategic Frameworks\n\nHigher-level frameworks for complex situations. Use before diving into tactical tools.\n\n| Framework                                        | Purpose                               | When to Use                                   |\n| ------------------------------------------------ | ------------------------------------- | --------------------------------------------- |\n| [Handshake](references/handshake.md)             | Drive action from communication       | Meetings, negotiations, getting buy-in        |\n| [SCOPE](references/scope.md)                     | Right-size analysis before starting   | Research, investigation, any analysis work    |\n| [Leverage Points](references/leverage-points.md) | Find where to intervene in systems    | Complex system change, choosing interventions |\n| [SPOT](references/spot.md)                       | Surface and act on recurring patterns | Retrospectives, debugging recurring issues    |\n\n---\n\n## Default Tools\n\nFor most situations, use these first:\n\n| Situation              | Default                                                | When to Use                            |\n| ---------------------- | ------------------------------------------------------ | -------------------------------------- |\n| Prioritizing work      | [Impact-Effort](references/tools/impact-effort.md)     | Backlog grooming, what to do next      |\n| Breaking down problems | [Issue Trees](references/tools/issue-trees.md)         | Complex problems, exhaustive analysis  |\n| Finding root cause     | [Ishikawa](references/tools/ishikawa.md)               | Debugging, incidents, postmortems      |\n| Making decisions       | [Decision Matrix](references/tools/decision-matrix.md) | Multi-option choices with tradeoffs    |\n| Understanding systems  | [Feedback Loops](references/tools/feedback-loops.md)   | Architecture, metrics, consequences    |\n| Communicating clearly  | [Minto Pyramid](references/tools/minto-pyramid.md)     | Writing, presentations, exec summaries |\n\n## All Tools (when default doesn't fit)\n\n| Category          | Tools                                                                                                                                                                                                 | When to Use                                        |\n| ----------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------- |\n| Root Cause        | [Ishikawa](references/tools/ishikawa.md), [Iceberg](references/tools/iceberg.md)                                                                                                                      | Debugging, incidents, Five Whys extension          |\n| Domain            | [Cynefin](references/tools/cynefin.md)                                                                                                                                                                | Choosing approach before diving in                 |\n| Decision          | [Decision Matrix](references/tools/decision-matrix.md), [Hard Choice](references/tools/hard-choice.md), [OODA](references/tools/ooda.md), [Ladder of Inference](references/tools/ladder-inference.md), [Grey Thinking](references/tools/grey-thinking.md), [10-10-10](references/tools/10-10-10.md) | Multi-option choices, fast decisions, avoid binary traps, time perspective |\n| Prioritization    | [Eisenhower](references/tools/eisenhower.md), [Impact-Effort](references/tools/impact-effort.md), [Opportunity Cost](references/tools/opportunity-cost.md), [Systems Over Goals](references/tools/systems-over-goals.md) | Backlog grooming, debt triage, tradeoffs, habits   |\n| Systems           | [Feedback Loops](references/tools/feedback-loops.md), [Connection Circles](references/tools/connection-circles.md), [Second-Order](references/tools/second-order.md), [Incentives](references/tools/incentives.md), [Bottlenecks](references/tools/bottlenecks.md) | Architecture, metrics, behavior, constraints       |\n| Creative          | [Zwicky Box](references/tools/zwicky-box.md), [Abstraction Ladder](references/tools/abstraction-ladder.md), [Productive Thinking](references/tools/productive-thinking.md), [Deliberate Practice](references/tools/deliberate-practice.md) | Brainstorming, reframing, innovation, skill building |\n| Communication     | [Minto Pyramid](references/tools/minto-pyramid.md), [SBI](references/tools/sbi.md), [Conflict Resolution](references/tools/conflict-resolution.md), [Steel Man](references/tools/steel-man.md) | Writing, feedback, negotiation, argumentation      |\n| Problem Structure | [Issue Trees](references/tools/issue-trees.md), [First Principles](references/tools/first-principles.md), [Concept Map](references/tools/concept-map.md)                                              | Decomposition, exhaustive breakdown                |\n| Risk              | [Pre-Mortem](references/tools/pre-mortem.md)                                                                                                                                                          | Anticipate failure before starting                 |\n| Boundaries        | [Circle of Competence](references/tools/circle-of-competence.md), [Chesterton's Fence](references/tools/chestertons-fence.md)                                                                         | Know limits, understand before changing            |\n| Probability       | [Bayesian Thinking](references/tools/bayesian-thinking.md)                                                                                                                                            | Update beliefs with evidence, calibrate confidence |\n| Abstraction       | [Map vs Territory](references/tools/map-territory.md)                                                                                                                                                 | Models â‰  reality, question assumptions             |\n| Biases            | [Munger's 25](references/tools/munger-biases.md)                                                                                                                                                      | Pre-decision bias check, high-stakes decisions     |\n\n## Tool Pairings\n\nCommon combinations for complex problems:\n\n| Primary Tool | Pairs With | Use Case |\n|-------------|------------|----------|\n| Pre-Mortem | Deliberate Practice | Practice drills for failure modes |\n| Pre-Mortem | Feedback Loops | Learn from drill outcomes |\n| Bayesian Thinking | Pre-Mortem | Update priors from failure analysis |\n| Circle of Competence | Sunk Cost | Know when to exit outside expertise |\n| Grey Thinking | Steel Man + Decision Matrix | Multi-perspective evaluation |\n| Systems Over Goals | Feedback Loops | Design habit systems with measurement |\n| Munger's 25 | Confidence Gates | Run bias check before claiming â‰¥85% |\n| Opportunity Cost | Eisenhower + Impact-Effort | Weigh hidden costs when prioritizing |\n| Chesterton's Fence | Second-Order Thinking | Understand before removing |\n\n---\n\n## Common Rationalizations (All Wrong)\n\n| Thought | Reality |\n|---------|---------|\n| \"This is just a simple question\" | Run Silent Audit anyway. |\n| \"I already know the answer\" | State confidence percentage. |\n| \"This doesn't need a library search\" | Search anyway. Every library not written = 1000 bugs avoided. |\n| \"The user wants me to just do it\" | Clarify intent first. Wrong fast = waste. |\n| \"This is too small for workflows\" | Workflow B for any fix. |\n| \"I can skip the inversion\" | Inversion catches failures cheaper than debugging. |\n| \"The pattern is obvious\" | Document it anyway. Future you will forget. |\n| \"I'll add tests later\" | \"Later\" = never. Test now or don't claim done. |\n\n**Every rationalization = skipped step = compounding failure.**\n\n---\n\n## Available Hope Skills\n\nWhen task matches, use the appropriate skill:\n\n| Task Type                                      | Skill                    | Trigger                                  |\n| ---------------------------------------------- | ------------------------ | ---------------------------------------- |\n| Root cause analysis (bugs, failures, problems) | `hope:trace`             | \"why did this fail\", incident, debugging |\n| Before claiming done/fixed/complete            | `hope:gate`              | Verification checkpoint                  |\n| Foundation for ALL thinking                    | `hope:soul` (this skill) | Default for everything                   |\n\nAnnounce skill usage: \"I'm using hope:[skill] for [purpose]\"\n\n---\n\n## Verification Gates\n\nDecisions use a **dual-signal** system: verification type (primary) + subjective estimate (secondary).\n\n### Verification Types (Primary Signal)\n\n| Type | Description | Sufficient for SHIP? |\n|------|-------------|---------------------|\n| `execution output` | Ran command, showed result | âœ“ Yes |\n| `observation` | Screenshot, debugger | âœ“ Yes |\n| `measurement` | Metrics, benchmark | âœ“ Yes |\n| `code review` | Inspection only | âš ï¸ Weak |\n| `assumption` | Not verified | âœ— Blocks SHIP |\n\n### Subjective Estimates (Secondary Signal)\n\n| Estimate | Action |\n| -------- | ------ |\n| **< 70%** | Research first. Surface unknowns. |\n| **70-85%** | Ship with monitoring and fallback plan. |\n| **â‰¥ 85%** | Ship immediately. |\n\n**Note:** Subjective percentages are Claude's estimates, not calibrated accuracy. Weight verification type higher.\n\n---\n\n## Intent Clarification Protocol\n\nBefore building ANYTHING, reach â‰¥85% confidence you understand the request.\n\n**If uncertain, ask about:**\n\n- Purpose (why does this need to exist?)\n- Success criteria (how do we know it works?)\n- Constraints (tech stack, performance, compatibility)\n- Edge cases (what inputs break it?)\n- Must-include facts (non-negotiables)\n\n**Surface unknowns with questions like:**\n\n- What problem does this solve today (not hypothetically)?\n- Who's the user and what's their journey?\n- What's the simplest version that would work?\n- What would make this fail catastrophically?\n- What have you already tried?\n\n**Only proceed when:**\n\n- Intent is crystal clear\n- Constraints are known\n- Success criteria defined\n- OR user says \"proceed anyway\"\n\n---\n\n## Workflow Selection\n\n| Task                    | Workflow | Gate                          |\n| ----------------------- | -------- | ----------------------------- |\n| Build / Feature         | A        | Intent clear + Library search |\n| Debug / Fix             | B        | Root cause before workaround  |\n| Refactor / Architecture | C        | Deletion before redesign      |\n\n---\n\n## Workflow A: Build\n\n### 0. Intent Check\n\nAm I â‰¥85% confident I understand what's needed?\n\n- No â†’ Ask clarifying questions (see Intent Clarification Protocol)\n- Yes â†’ Proceed\n\n### 1. Inversion\n\nList 3-5 failure modes with impact:\n\n```\n## Failure Analysis\n- [Mode 1]: [CATASTROPHIC/HIGH/MEDIUM/LOW]\n- [Mode 2]: [Impact]\n- [Mode 3]: [Impact]\n```\n\n### 2. Library Search\n\nFind â‰¥2 production libraries OR state \"No library exists because [reason]\"\n\nEvaluate: downloads, maintenance, security, learning curve.\n\n**Building custom without search = automatic failure.**\n\n### 3. Layer 0 (Simplest Working Version)\n\n- Production library + minimal config\n- Deployable in < 1 hour\n- Easy rollback (Type 2A)\n\n```\n## Layer 0: [Library] (X-Y% confident)\nInstall: `[command]`\nConfig: [minimal setup]\nWhy: [evidence for confidence]\n```\n\n### 4. Progressive Disclosure\n\n- **Layer 1** (Production): Only if Layer 0 proven insufficient by metrics\n- **Layer 2** (Scale): Only if Layer 1 shows specific bottleneck\n\nEach layer requires metric-based justification.\n\n### 5. Quality Footer\n\nSee [Quality Footer](references/quality-footer.md) for format and verdict rules.\n\n---\n\n## Workflow B: Debug\n\n### 0. Intent Check\n\nDo I understand the symptom clearly?\n\n- No â†’ Ask for error messages, reproduction steps, context\n- Yes â†’ Proceed\n\n### 1. Effect â†’ Cause â†’ Root\n\nList 3-5 potential root causes with confidence:\n\n```\n- [Cause 1]: X-Y% confident\n- [Cause 2]: X-Y% confident\n- [Cause 3]: X-Y% confident\n```\n\n**All < 70%?** â†’ Add instrumentation, request more context.\n\n### 2. Verify Root Cause\n\n- Minimal reproduction\n- Evidence (logs, debugger, profiling)\n- Proceed only when â‰¥70% confident\n\n### 3. Fix + Prevention\n\n```\n## Root Cause (X-Y% confident)\n[Explanation with evidence]\n\n## Fix\n[file:line changes]\n\n## Prevention\n[Structural change to prevent class of bugs]\n```\n\n**Workarounds = forbidden.** Fix root cause or escalate.\n\n### 4. Correctness Protocol\n\n| Situation              | Action                           |\n| ---------------------- | -------------------------------- |\n| Fixable now (< 30 min) | Fix immediately                  |\n| Complex (> 30 min)     | TODO contract with deadline      |\n| Unclear                | Escalate with reproduction steps |\n\n---\n\n## Workflow C: Refactor / Architecture\n\n### 0. Musashi Test\n\n\"Do nothing which is of no use.\"\n\nAsk: Can we **delete** this instead of refactor?\n\n- Yes â†’ Propose deletion with migration path\n- No â†’ Justify why it must exist\n\n**Deletion > refactor > rebuild (always)**\n\n### 1. Journey-Centric Design\n\n```\nâœ— /components + /services + /utils\nâœ“ /journeys/checkout/[everything]\n```\n\nTest: Can one developer understand entire journey on one screen?\n\n### 2. Illegal States Unrepresentable\n\n```typescript\n// âœ— Boolean soup (2^n states, few valid)\n{ isLoggedIn: boolean; isLoading: boolean; error?: string }\n\n// âœ“ Discriminated union (n states, all valid)\ntype State =\n  | { type: \"anonymous\" }\n  | { type: \"loading\" }\n  | { type: \"authenticated\"; user: User }\n  | { type: \"error\"; message: string }\n```\n\n### 3. Atomic Migration\n\nNo v2 interfaces. No versions. No parallel implementations.\n\nWhen changing boundaries: migrate EVERYTHING atomically or nothing.\n\nOne truth only.\n\n---\n\n## Decision Framework\n\n### Reversibility\n\n| Type   | Rollback | Examples             | Action                  |\n| ------ | -------- | -------------------- | ----------------------- |\n| **2A** | < 1 min  | Config, rename       | Execute immediately     |\n| **2B** | < 5 min  | Dependency, refactor | Execute with monitoring |\n| **1**  | Hours+   | Schema, public API   | Deep analysis required  |\n\n### Story Points\n\n| Pts | Complexity   | Characteristics              |\n| --- | ------------ | ---------------------------- |\n| 1   | Trivial      | < 10 lines, obvious          |\n| 3   | Standard     | Existing patterns            |\n| 5   | Complex      | Some unknowns, design needed |\n| 8   | Architecture | Multiple subsystems          |\n| 13+ | Too Big      | Break down further           |\n\n**Never estimate time.** Complexity is objective; velocity varies.\n\n### Library-First Protocol\n\n```\n1. Search production libraries (npm, PyPI, crates.io)\n2. Evaluate â‰¥2 options\n3. If none suitable: explicitly justify custom code\n4. Default: use library\n```\n\nEvery library you don't write = 1000 bugs you don't have.\n\n---\n\n## Subagent Usage\n\n**Delegate**: doc retrieval, codebase search, library evaluation, debugging research\n\n**Never delegate**: implementation decisions, architecture choices, plan approval\n\n---\n\n## Learnings System\n\n`~/.claude/learnings/`:\n\n| File                | Schema                                             |\n| ------------------- | -------------------------------------------------- |\n| `failures.jsonl`    | `{ts, context, failure, root_cause, prevention}`   |\n| `discoveries.jsonl` | `{ts, context, discovery, confidence, applies_to}` |\n| `constraints.jsonl` | `{ts, context, constraint, source, permanent}`     |\n\n**Commands:**\n\n- `/hope:learn` - Extract learnings from session or transcript\n- `/hope:recall` - Surface relevant learnings for current context\n\n**When to recall:** Before starting substantial work in a domain, run `/hope:recall [domain]` to surface past insights and avoid repeating mistakes.\n\n---\n\n## Quality Footer (Required)\n\nEvery non-trivial response ends with a verdict box. See [Quality Footer](references/quality-footer.md) for format, verdict rules, and examples.\n"
      },
      "discovered_at": "2026-01-11T15:36:28.331082Z",
      "fetch_error": null
    },
    {
      "name": "marketplace-publishing",
      "slug": "marketplace-publishing",
      "source": "skillsmp",
      "owner": "anton-abyzov",
      "repo_name": "specweave",
      "repository_url": "https://github.com/anton-abyzov/specweave",
      "skill_path": "plugins/specweave-plugin-dev/skills/marketplace-publishing",
      "github_metadata": {
        "stars": 19,
        "description": "Autonomous AI Development Framework. Build production software with specs, tests, and docs that write themselves. Works with Claude, Cursor, Copilot.",
        "default_branch": "develop",
        "pushed_at": "2026-01-11T06:03:55Z",
        "created_at": "2025-10-25T21:31:34Z",
        "language": "TypeScript",
        "license": "MIT",
        "open_issues": 4,
        "forks": 3
      },
      "skill_md": {
        "found": true,
        "path": "plugins/specweave-plugin-dev/skills/marketplace-publishing/SKILL.md",
        "branch": "develop",
        "content": "---\nname: marketplace-publishing\ndescription: Expert Claude Code marketplace publishing covering npm publishing, GitHub releases, semantic versioning, plugin packaging, README documentation, CHANGELOG management, marketplace submission, and plugin distribution. Activates for publish plugin, npm publish, marketplace, release plugin, semantic versioning, semver, plugin distribution, publish to npm, github release.\n---\n\n# Marketplace Publishing Expert\n\nExpert guidance for publishing Claude Code plugins to npm and marketplace.\n\n## Publishing Platforms\n\n**1. GitHub** (Recommended):\n```bash\n# Install from GitHub\nclaude plugin add github:username/plugin-name\n\n# Pros:\n- Free hosting\n- Version control\n- Issue tracking\n- Easy updates\n\n# Requirements:\n- Public repository\n- Proper directory structure\n- README with installation\n```\n\n**2. npm**:\n```bash\n# Install from npm\nclaude plugin add plugin-name\n\n# Pros:\n- Centralized registry\n- Semantic versioning\n- Easy discovery\n\n# Requirements:\n- npm account\n- package.json\n- Unique name (prefix: claude-plugin-)\n```\n\n**3. Marketplace**:\n```bash\n# Official Claude Code marketplace\n# PR to marketplace repository\n\n# Requirements:\n- Quality standards\n- Complete documentation\n- No security issues\n- Proper licensing\n```\n\n## Semantic Versioning\n\n**Version Format**: `MAJOR.MINOR.PATCH`\n\n**Rules**:\n```yaml\nMAJOR (1.0.0 â†’ 2.0.0):\n  - Breaking changes\n  - Remove commands\n  - Change skill keywords\n  - Incompatible API changes\n\nMINOR (1.0.0 â†’ 1.1.0):\n  - New features\n  - Add commands\n  - Add skills\n  - Backward compatible\n\nPATCH (1.0.0 â†’ 1.0.1):\n  - Bug fixes\n  - Documentation updates\n  - Performance improvements\n  - No API changes\n```\n\n**Examples**:\n```bash\n# Bug fix\nnpm version patch  # 1.0.0 â†’ 1.0.1\n\n# New feature\nnpm version minor  # 1.0.1 â†’ 1.1.0\n\n# Breaking change\nnpm version major  # 1.1.0 â†’ 2.0.0\n```\n\n## package.json Setup\n\n**Minimum**:\n```json\n{\n  \"name\": \"claude-plugin-my-plugin\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Expert [domain] plugin for Claude Code\",\n  \"keywords\": [\"claude-code\", \"plugin\", \"keyword1\"],\n  \"author\": \"Your Name\",\n  \"license\": \"MIT\",\n  \"files\": [\n    \".claude-plugin\",\n    \"commands\",\n    \"skills\",\n    \"agents\",\n    \"README.md\",\n    \"LICENSE\"\n  ]\n}\n```\n\n**Full**:\n```json\n{\n  \"name\": \"claude-plugin-my-plugin\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Expert [domain] plugin with [features]\",\n  \"main\": \"index.js\",\n  \"scripts\": {\n    \"test\": \"echo \\\"No tests yet\\\"\",\n    \"validate\": \"bash validate.sh\"\n  },\n  \"keywords\": [\n    \"claude-code\",\n    \"plugin\",\n    \"development-tools\",\n    \"keyword1\",\n    \"keyword2\"\n  ],\n  \"author\": \"Your Name <you@example.com>\",\n  \"license\": \"MIT\",\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"https://github.com/username/my-plugin\"\n  },\n  \"homepage\": \"https://github.com/username/my-plugin#readme\",\n  \"bugs\": {\n    \"url\": \"https://github.com/username/my-plugin/issues\"\n  },\n  \"files\": [\n    \".claude-plugin/**/*\",\n    \"commands/**/*\",\n    \"skills/**/*\",\n    \"agents/**/*\",\n    \"README.md\",\n    \"LICENSE\"\n  ]\n}\n```\n\n## Publishing Workflow\n\n**GitHub Release**:\n```bash\n# 1. Update version\nnpm version patch\n\n# 2. Commit changes\ngit add .\ngit commit -m \"Release v1.0.1\"\n\n# 3. Create tag\ngit tag v1.0.1\n\n# 4. Push\ngit push && git push --tags\n\n# 5. Create GitHub release\ngh release create v1.0.1 \\\n  --title \"v1.0.1\" \\\n  --notes \"Bug fixes and improvements\"\n```\n\n**npm Publish**:\n```bash\n# 1. Login\nnpm login\n\n# 2. Validate package\nnpm pack --dry-run\n\n# 3. Publish\nnpm publish\n\n# 4. Verify\nnpm view claude-plugin-my-plugin\n```\n\n## Documentation Requirements\n\n**README.md**:\n```markdown\n# Plugin Name\n\n> One-line tagline\n\nBrief description.\n\n## Features\n\n- Feature 1\n- Feature 2\n\n## Installation\n\n\\```bash\nclaude plugin add github:user/plugin\n\\```\n\n## Commands\n\n### /plugin:command\n\nDescription.\n\n## Examples\n\n[Working examples]\n\n## License\n\nMIT\n```\n\n**CHANGELOG.md**:\n```markdown\n# Changelog\n\n## [1.0.1] - 2025-01-15\n\n### Fixed\n- Bug fix 1\n- Bug fix 2\n\n## [1.0.0] - 2025-01-01\n\n### Added\n- Initial release\n```\n\n## Quality Checklist\n\n**Pre-publish**:\n- âœ… All commands working\n- âœ… Skills activate correctly\n- âœ… No hardcoded secrets\n- âœ… README with examples\n- âœ… LICENSE file\n- âœ… Semantic versioning\n- âœ… CHANGELOG updated\n- âœ… Git tag created\n\n**Post-publish**:\n- âœ… Test installation\n- âœ… Verify on npm (if published)\n- âœ… Check GitHub release\n- âœ… Update marketplace (if applicable)\n\nPublish professional Claude Code plugins!\n"
      },
      "discovered_at": "2026-01-11T15:36:28.740547Z",
      "fetch_error": null
    },
    {
      "name": "toolscript",
      "slug": "toolscript",
      "source": "skillsmp",
      "owner": "mKeRix",
      "repo_name": "toolscript",
      "repository_url": "https://github.com/mKeRix/toolscript",
      "skill_path": "plugins/toolscript/skills/toolscript",
      "github_metadata": {
        "stars": 19,
        "description": "Efficient MCP tool calling in code mode for Claude Code",
        "default_branch": "main",
        "pushed_at": "2025-12-12T09:46:22Z",
        "created_at": "2025-11-23T15:12:35Z",
        "language": "TypeScript",
        "license": null,
        "open_issues": 0,
        "forks": 0
      },
      "skill_md": {
        "found": true,
        "path": "plugins/toolscript/skills/toolscript/SKILL.md",
        "branch": "main",
        "content": "---\nname: toolscript\ndescription: Discover and execute MCP tools via gateway. Use when user asks to \"call tool\", \"list tools\", or before performing tasks that might have specialized MCP capabilities.\n---\n\n# Toolscript Skill\n\nDiscover and execute MCP tools through the toolscript gateway.\n\n**Use proactively:** Before operations, search for specialized MCP tools.\n\n## Quick Start\n\n```bash\n# 1. Search for tools and get TypeScript code\ntoolscript search \"what you need\" --output types\n\n# 2. Execute - single line\ntoolscript exec 'import {tools} from \"toolscript\"; console.log(await tools.server.toolName({param: \"value\"}))'\n\n# 3. Execute - multi-line (use Write tool for /tmp/<filename>.ts)\ntoolscript exec -f /tmp/<filename>.ts\n```\n\n## Toolscript Format\n\n```typescript\nimport { tools } from \"toolscript\";\nconst result = await tools.serverName.toolName({param: \"value\"});\nconsole.log(result)\n```\n\n## Alternative Workflows\n\n- **Direct access:** Use `toolscript get-types --filter <tool-name>,<2nd-tool-name>` if you know the tools\n- **Browse discovery:** Use `toolscript list-servers` and `toolscript list-tools <server>`\n\n## References\n\n- `references/commands.md` - All commands and options\n- `references/examples.md` - Working examples and workflows\n- `references/configuration.md` - Gateway and server setup\n- `references/troubleshooting.md` - Diagnostics and fixes\n"
      },
      "discovered_at": "2026-01-11T15:36:29.032870Z",
      "fetch_error": null
    },
    {
      "name": "update-marketplace-stars",
      "slug": "update-marketplace-stars",
      "source": "skillsmp",
      "owner": "NikiforovAll",
      "repo_name": "lazyclaude",
      "repository_url": "https://github.com/NikiforovAll/lazyclaude",
      "skill_path": ".claude/skills/update-marketplace-stars",
      "github_metadata": {
        "stars": 17,
        "description": " A lazygit-style TUI for visualizing Claude Code customizations.",
        "default_branch": "main",
        "pushed_at": "2026-01-01T15:45:13Z",
        "created_at": "2025-12-06T20:40:15Z",
        "language": "Python",
        "license": "MIT",
        "open_issues": 9,
        "forks": 3
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/update-marketplace-stars/SKILL.md",
        "branch": "main",
        "content": "---\nname: update-marketplace-stars\ndescription: Update GitHub star counts for suggested marketplaces in DEFAULT_SUGGESTED_MARKETPLACES. Use this skill when asked to \"update stars\", \"refresh marketplace stars\", or \"sync star counts\".\n---\n\n# Update Marketplace Stars\n\nUpdate the GitHub star counts for suggested marketplaces defined in `src/lazyclaude/services/settings.py`.\n\n## Location\n\nThe star counts are defined in:\n\n```\nsrc/lazyclaude/services/settings.py\n```\n\nLook for the `DEFAULT_SUGGESTED_MARKETPLACES` dictionary near the top of the file.\n\n## Fetch Current Stars\n\nUse GitHub CLI to fetch current star counts for each repository:\n\n```bash\ngh api repos/{owner}/{repo} --jq '.stargazers_count'\n```\n\nExample for all current marketplaces:\n\n```bash\ngh api repos/anthropics/claude-plugins-official --jq '.stargazers_count'\ngh api repos/NikiforovAll/claude-code-rules --jq '.stargazers_count'\ngh api repos/SawyerHood/dev-browser --jq '.stargazers_count'\ngh api repos/Piebald-AI/claude-code-lsps --jq '.stargazers_count'\ngh api repos/wshobson/agents --jq '.stargazers_count'\ngh api repos/davila7/claude-code-templates --jq '.stargazers_count'\ngh api repos/ComposioHQ/awesome-claude-skills --jq '.stargazers_count'\ngh api repos/steveyegge/beads --jq '.stargazers_count'\ngh api repos/ccplugins/awesome-claude-code-plugins --jq '.stargazers_count'\n```\n\n## Workflow\n\n1. Read `src/lazyclaude/services/settings.py` to get current marketplace repos\n2. Run `gh api` commands in parallel to fetch star counts\n3. Update the `stars` values in `DEFAULT_SUGGESTED_MARKETPLACES`\n4. Present summary of changes (old vs new star counts)\n\n## Notes\n\n- Star counts are approximate and change frequently\n- Run this periodically before releases to keep counts fresh\n- If a repo is not found (404), keep the existing value and notify user\n"
      },
      "discovered_at": "2026-01-11T15:36:29.303216Z",
      "fetch_error": null
    },
    {
      "name": "agent-prompt-evolution",
      "slug": "agent-prompt-evolution",
      "source": "skillsmp",
      "owner": "yaleh",
      "repo_name": "meta-cc",
      "repository_url": "https://github.com/yaleh/meta-cc",
      "skill_path": ".claude/skills/agent-prompt-evolution",
      "github_metadata": {
        "stars": 15,
        "description": "Meta-Cognition tool for Claude Code - analyze session history for workflow optimization.",
        "default_branch": "main",
        "pushed_at": "2025-12-13T10:31:07Z",
        "created_at": "2025-10-08T01:58:30Z",
        "language": "Go",
        "license": "MIT",
        "open_issues": 0,
        "forks": 1
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/agent-prompt-evolution/SKILL.md",
        "branch": "main",
        "content": "---\nname: Agent Prompt Evolution\ndescription: Track and optimize agent specialization during methodology development. Use when agent specialization emerges (generic agents show >5x performance gap), multi-experiment comparison needed, or methodology transferability analysis required. Captures agent set evolution (Aâ‚™ tracking), meta-agent evolution (Mâ‚™ tracking), specialization decisions (when/why to create specialized agents), and reusability assessment (universal vs domain-specific vs task-specific). Enables systematic cross-experiment learning and optimized Mâ‚€ evolution. 2-3 hours overhead per experiment.\nallowed-tools: Read, Grep, Glob, Edit, Write\n---\n\n# Agent Prompt Evolution\n\n**Systematically track how agents specialize during methodology development.**\n\n> Specialized agents emerge from need, not prediction. Track their evolution to understand when specialization adds value.\n\n---\n\n## When to Use This Skill\n\nUse this skill when:\n- ğŸ”„ **Agent specialization emerges**: Generic agents show >5x performance gap\n- ğŸ“Š **Multi-experiment comparison**: Want to learn across experiments\n- ğŸ§© **Methodology transferability**: Analyzing what's reusable vs domain-specific\n- ğŸ“ˆ **Mâ‚€ optimization**: Want to evolve base Meta-Agent capabilities\n- ğŸ¯ **Specialization decisions**: Deciding when to create new agents\n- ğŸ“š **Agent library**: Building reusable agent catalog\n\n**Don't use when**:\n- âŒ Single experiment with no specialization\n- âŒ Generic agents sufficient throughout\n- âŒ No cross-experiment learning goals\n- âŒ Tracking overhead not worth insights\n\n---\n\n## Quick Start (10 minutes per iteration)\n\n### Track Agent Evolution in Each Iteration\n\n**iteration-N.md template**:\n\n```markdown\n## Agent Set Evolution\n\n### Current Agent Set (Aâ‚™)\n1. **coder** (generic) - Write code, implement features\n2. **doc-writer** (generic) - Documentation\n3. **data-analyst** (generic) - Data analysis\n4. **coverage-analyzer** (specialized, created iteration 3) - Analyze test coverage gaps\n\n### Changes from Previous Iteration\n- Added: coverage-analyzer (10x speedup for coverage analysis)\n- Removed: None\n- Modified: None\n\n### Specialization Decision\n**Why coverage-analyzer?**\n- Generic data-analyst took 45 min for coverage analysis\n- Identified 10x performance gap\n- Coverage analysis is recurring task (every iteration)\n- Domain knowledge: Go coverage tools, gap identification patterns\n- **ROI**: 3 hours creation cost, saves 40 min/iteration Ã— 3 remaining iterations = 2 hours saved\n\n### Agent Reusability Assessment\n- **coder**: Universal (100% transferable)\n- **doc-writer**: Universal (100% transferable)\n- **data-analyst**: Universal (100% transferable)\n- **coverage-analyzer**: Domain-specific (testing methodology, 70% transferable to other languages)\n\n### System State\n- Aâ‚™ â‰  Aâ‚™â‚‹â‚ (new agent added)\n- System UNSTABLE (need iteration N+1 to confirm stability)\n```\n\n---\n\n## Four Tracking Dimensions\n\n### 1. Agent Set Evolution (Aâ‚™)\n\n**Track changes iteration-to-iteration**:\n\n```\nAâ‚€ = {coder, doc-writer, data-analyst}\nAâ‚ = {coder, doc-writer, data-analyst} (unchanged)\nAâ‚‚ = {coder, doc-writer, data-analyst} (unchanged)\nAâ‚ƒ = {coder, doc-writer, data-analyst, coverage-analyzer} (new specialist)\nAâ‚„ = {coder, doc-writer, data-analyst, coverage-analyzer, test-generator} (new specialist)\nAâ‚… = {coder, doc-writer, data-analyst, coverage-analyzer, test-generator} (stable)\n```\n\n**Stability**: Aâ‚™ == Aâ‚™â‚‹â‚ for convergence\n\n### 2. Meta-Agent Evolution (Mâ‚™)\n\n**Standard Mâ‚€ capabilities**:\n1. **observe**: Pattern observation\n2. **plan**: Iteration planning\n3. **execute**: Agent orchestration\n4. **reflect**: Value assessment\n5. **evolve**: System evolution\n\n**Track enhancements**:\n\n```\nMâ‚€ = {observe, plan, execute, reflect, evolve}\nMâ‚ = {observe, plan, execute, reflect, evolve, gap-identify} (new capability)\nMâ‚‚ = {observe, plan, execute, reflect, evolve, gap-identify} (stable)\n```\n\n**Finding** (from 8 experiments): Mâ‚€ sufficient in all cases (no evolution needed)\n\n### 3. Specialization Decision Tree\n\n**When to create specialized agent**:\n\n```\nDecision tree:\n1. Is generic agent sufficient? (performance within 2x)\n   YES â†’ No specialization\n   NO â†’ Continue\n\n2. Is task recurring? (happens â‰¥3 times)\n   NO â†’ One-off, tolerate slowness\n   YES â†’ Continue\n\n3. Is performance gap >5x?\n   NO â†’ Tolerate moderate slowness\n   YES â†’ Continue\n\n4. Is creation cost <ROI?\n   Creation cost < (Time saved per use Ã— Remaining uses)\n   NO â†’ Not worth it\n   YES â†’ Create specialized agent\n```\n\n**Example** (Bootstrap-002):\n\n```\nTask: Test coverage gap analysis\nGeneric agent (data-analyst): 45 min\nPotential specialist (coverage-analyzer): 4.5 min (10x faster)\n\nRecurring: YES (every iteration, 3 remaining)\nPerformance gap: 10x (>5x threshold)\nCreation cost: 3 hours\nROI: (45-4.5) min Ã— 3 = 121.5 min = 2 hours saved\nDecision: CREATE (positive ROI)\n```\n\n### 4. Reusability Assessment\n\n**Three categories**:\n\n**Universal** (90-100% transferable):\n- Generic agents (coder, doc-writer, data-analyst)\n- No domain knowledge required\n- Applicable across all domains\n\n**Domain-Specific** (60-80% transferable):\n- Requires domain knowledge (testing, CI/CD, error handling)\n- Patterns apply within domain\n- Needs adaptation for other domains\n\n**Task-Specific** (10-30% transferable):\n- Highly specialized for particular task\n- One-off creation\n- Unlikely to reuse\n\n**Examples**:\n\n```\nAgent: coverage-analyzer\nDomain: Testing methodology\nTransferability: 70%\n- Go coverage tools (language-specific, 30% adaptation)\n- Gap identification patterns (universal, 100%)\n- Overall: 70% transferable to Python/Rust/TypeScript testing\n\nAgent: test-generator\nDomain: Testing methodology\nTransferability: 40%\n- Go test syntax (language-specific, 0% to other languages)\n- Test pattern templates (moderately transferable, 60%)\n- Overall: 40% transferable\n\nAgent: log-analyzer\nDomain: Observability\nTransferability: 85%\n- Log parsing (universal, 95%)\n- Pattern recognition (universal, 100%)\n- Structured logging concepts (universal, 100%)\n- Go slog specifics (language-specific, 20%)\n- Overall: 85% transferable\n```\n\n---\n\n## Evolution Log Template\n\nCreate `agents/EVOLUTION-LOG.md`:\n\n```markdown\n# Agent Evolution Log\n\n## Experiment Overview\n- Domain: Testing Strategy\n- Baseline agents: 3 (coder, doc-writer, data-analyst)\n- Final agents: 5 (+coverage-analyzer, +test-generator)\n- Specialization count: 2\n\n---\n\n## Iteration-by-Iteration Evolution\n\n### Iteration 0\n**Agent Set**: {coder, doc-writer, data-analyst}\n**Changes**: None (baseline)\n**Observations**: Generic agents sufficient for baseline establishment\n\n### Iteration 3\n**Agent Set**: {coder, doc-writer, data-analyst, coverage-analyzer}\n**Changes**: +coverage-analyzer\n**Reason**: 10x performance gap (45 min â†’ 4.5 min)\n**Creation Cost**: 3 hours\n**ROI**: Positive (2 hours saved over 3 iterations)\n**Reusability**: 70% (domain-specific, testing)\n\n### Iteration 4\n**Agent Set**: {coder, doc-writer, data-analyst, coverage-analyzer, test-generator}\n**Changes**: +test-generator\n**Reason**: 200x performance gap (manual test writing too slow)\n**Creation Cost**: 4 hours\n**ROI**: Massive (saved 10+ hours)\n**Reusability**: 40% (task-specific, Go testing)\n\n### Iteration 5\n**Agent Set**: {coder, doc-writer, data-analyst, coverage-analyzer, test-generator}\n**Changes**: None\n**System**: STABLE (Aâ‚™ == Aâ‚™â‚‹â‚)\n\n---\n\n## Specialization Analysis\n\n### coverage-analyzer\n**Purpose**: Analyze test coverage, identify gaps\n**Performance**: 10x faster than generic data-analyst\n**Domain**: Testing methodology\n**Transferability**: 70%\n**Lessons**: Coverage gap identification patterns are universal, tool integration is language-specific\n\n### test-generator\n**Purpose**: Generate test boilerplate from coverage gaps\n**Performance**: 200x faster than manual\n**Domain**: Testing methodology (Go-specific)\n**Transferability**: 40%\n**Lessons**: High speedup justified low transferability, patterns reusable but syntax is not\n\n---\n\n## Cross-Experiment Reuse\n\n### From Previous Experiments\n- **validation-builder** (from API design experiment) â†’ Used for smoke test validation\n- Reusability: Excellent (validation patterns are universal)\n- Adaptation: Minimal (10 min to adapt from API to CI/CD context)\n\n### To Future Experiments\n- **coverage-analyzer** â†’ Reusable for Python/Rust/TypeScript testing (70% transferable)\n- **test-generator** â†’ Less reusable (40% transferable, needs rewrite for other languages)\n\n---\n\n## Meta-Agent Evolution\n\n### Mâ‚€ Capabilities\n{observe, plan, execute, reflect, evolve}\n\n### Changes\nNone (Mâ‚€ sufficient throughout)\n\n### Observations\n- Mâ‚€'s \"evolve\" capability successfully identified need for specialization\n- No Meta-Agent evolution required\n- Convergence: Mâ‚™ == Mâ‚€ for all iterations\n\n---\n\n## Lessons Learned\n\n### Specialization Decisions\n- **10x performance gap** is good threshold (< 5x not worth it, >10x clear win)\n- **Positive ROI required**: Creation cost must be justified by time savings\n- **Recurring tasks only**: One-off tasks don't justify specialization\n\n### Reusability Patterns\n- **Generic agents always reusable**: coder, doc-writer, data-analyst (100%)\n- **Domain agents moderately reusable**: coverage-analyzer (70%)\n- **Task agents rarely reusable**: test-generator (40%)\n\n### When NOT to Specialize\n- Performance gap <5x (tolerable slowness)\n- Task is one-off (no recurring benefit)\n- Creation cost >ROI (not worth time investment)\n- Generic agent will improve with practice (learning curve)\n```\n\n---\n\n## Cross-Experiment Analysis\n\nAfter 3+ experiments, create `agents/CROSS-EXPERIMENT-ANALYSIS.md`:\n\n```markdown\n# Cross-Experiment Agent Analysis\n\n## Agent Reuse Matrix\n\n| Agent | Exp1 | Exp2 | Exp3 | Reuse Rate | Transferability |\n|-------|------|------|------|------------|-----------------|\n| coder | âœ“ | âœ“ | âœ“ | 100% | Universal |\n| doc-writer | âœ“ | âœ“ | âœ“ | 100% | Universal |\n| data-analyst | âœ“ | âœ“ | âœ“ | 100% | Universal |\n| coverage-analyzer | âœ“ | - | âœ“ | 67% | Domain (testing) |\n| test-generator | âœ“ | - | - | 33% | Task-specific |\n| validation-builder | - | âœ“ | âœ“ | 67% | Domain (validation) |\n| log-analyzer | - | - | âœ“ | 33% | Domain (observability) |\n\n## Specialization Patterns\n\n### Universal Agents (100% reuse)\n- Generic capabilities (coder, doc-writer, data-analyst)\n- No domain knowledge\n- Always included in Aâ‚€\n\n### Domain Agents (50-80% reuse)\n- Require domain knowledge (testing, CI/CD, observability)\n- Reusable within domain\n- Examples: coverage-analyzer, validation-builder, log-analyzer\n\n### Task Agents (10-40% reuse)\n- Highly specialized\n- One-off or rare reuse\n- Examples: test-generator (Go-specific)\n\n## Mâ‚€ Sufficiency\n\n**Finding**: Mâ‚€ = {observe, plan, execute, reflect, evolve} sufficient in ALL experiments\n\n**Implications**:\n- No Meta-Agent evolution needed\n- Base capabilities handle all domains\n- Specialization occurs at Agent layer, not Meta-Agent layer\n\n## Specialization Threshold\n\n**Data** (from 3 experiments):\n- Average performance gap for specialization: 15x (range: 5x-200x)\n- Average creation cost: 3.5 hours (range: 2-5 hours)\n- Average ROI: Positive in 8/9 cases (89% success rate)\n\n**Recommendation**: Use 5x performance gap as threshold\n\n---\n\n**Updated**: After each new experiment\n```\n\n---\n\n## Success Criteria\n\nAgent evolution tracking succeeded when:\n\n1. **Complete tracking**: All agent changes documented each iteration\n2. **Specialization justified**: Each specialized agent has clear ROI\n3. **Reusability assessed**: Each agent categorized (universal/domain/task)\n4. **Cross-experiment learning**: Patterns identified across 2+ experiments\n5. **Mâ‚€ stability documented**: Meta-Agent evolution (or lack thereof) tracked\n\n---\n\n## Related Skills\n\n**Parent framework**:\n- [methodology-bootstrapping](../methodology-bootstrapping/SKILL.md) - Core OCA cycle\n\n**Complementary**:\n- [rapid-convergence](../rapid-convergence/SKILL.md) - Agent stability criterion\n\n---\n\n## References\n\n**Core guide**:\n- [Evolution Tracking](reference/tracking.md) - Detailed tracking process\n- [Specialization Decisions](reference/specialization.md) - Decision tree\n- [Reusability Framework](reference/reusability.md) - Assessment rubric\n\n**Examples**:\n- [Bootstrap-002 Evolution](examples/testing-strategy-agent-evolution.md) - 2 specialists\n- [Bootstrap-007 No Evolution](examples/ci-cd-no-specialization.md) - Generic sufficient\n\n---\n\n**Status**: âœ… Formalized | 2-3 hours overhead | Enables systematic learning\n"
      },
      "discovered_at": "2026-01-11T15:36:29.595831Z",
      "fetch_error": null
    },
    {
      "name": "api-design",
      "slug": "api-design",
      "source": "skillsmp",
      "owner": "yaleh",
      "repo_name": "meta-cc",
      "repository_url": "https://github.com/yaleh/meta-cc",
      "skill_path": ".claude/skills/api-design",
      "github_metadata": {
        "stars": 15,
        "description": "Meta-Cognition tool for Claude Code - analyze session history for workflow optimization.",
        "default_branch": "main",
        "pushed_at": "2025-12-13T10:31:07Z",
        "created_at": "2025-10-08T01:58:30Z",
        "language": "Go",
        "license": "MIT",
        "open_issues": 0,
        "forks": 1
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/api-design/SKILL.md",
        "branch": "main",
        "content": "---\nname: API Design\ndescription: Systematic API design methodology with 6 validated patterns covering parameter categorization, safe refactoring, audit-first approach, automated validation, quality gates, and example-driven documentation. Use when designing new APIs, improving API consistency, implementing breaking change policies, or building API quality enforcement. Provides deterministic decision trees (5-tier parameter system), validation tool architecture, pre-commit hook patterns. Validated with 82.5% cross-domain transferability, 37.5% efficiency gains through audit-first refactoring.\nallowed-tools: Read, Write, Edit, Bash, Grep, Glob\n---\n\n# API Design\n\n**Systematic API design with validated patterns and automated quality enforcement.**\n\n> Good APIs are designed, not discovered. 82.5% of patterns transfer across domains.\n\n---\n\n## When to Use This Skill\n\nUse this skill when:\n- ğŸ¯ **Designing new API**: Need systematic parameter organization and naming conventions\n- ğŸ”„ **Refactoring existing API**: Improving consistency without breaking changes\n- ğŸ“Š **API quality enforcement**: Building validation tools and quality gates\n- ğŸ“ **API documentation**: Writing clear, example-driven documentation\n- ğŸš€ **API evolution**: Implementing versioning, deprecation, and migration policies\n- ğŸ” **API consistency**: Standardizing conventions across multiple endpoints\n\n**Don't use when**:\n- âŒ API has <5 endpoints (overhead not justified)\n- âŒ No team collaboration (conventions only valuable for teams)\n- âŒ Prototype/throwaway code (skip formalization)\n- âŒ Non-REST/non-JSON APIs without adaptation (patterns assume JSON-based APIs)\n\n---\n\n## Prerequisites\n\n### Tools\n- **API framework** (language-specific): Go, Python, TypeScript, etc.\n- **Validation tools** (optional): Linters, schema validators\n- **Version control**: Git (for pre-commit hooks)\n\n### Concepts\n- **REST principles**: Resource-based design, HTTP methods\n- **JSON specification**: Object property ordering (unordered), schema design\n- **Semantic Versioning**: Major.Minor.Patch versioning (if using Pattern 1)\n- **Pre-commit hooks**: Git hooks for quality gates\n\n### Background Knowledge\n- API design basics (endpoints, parameters, responses)\n- Backward compatibility principles\n- Testing strategies (integration tests, contract tests)\n\n---\n\n## Quick Start (30 minutes)\n\nThis skill was extracted using systematic knowledge extraction methodology from Bootstrap-006 experiment.\n\n**Status**: PARTIAL EXTRACTION (demonstration of methodology, not complete skill)\n\n**Note**: This is a minimal viable skill created to validate the knowledge extraction methodology. A complete skill would include:\n- Detailed pattern descriptions with code examples\n- Step-by-step walkthroughs for each pattern\n- Templates for API specifications\n- Scripts for validation and quality gates\n- Comprehensive reference documentation\n\n**Extraction Evidence**:\n- Source experiment: Bootstrap-006 (V_instance=0.87, V_meta=0.786)\n- Patterns extracted: 6/6 identified (not yet fully documented here)\n- Principles extracted: 8/8 identified (not yet fully documented here)\n- Extraction time: 30 minutes (partial, demonstration only)\n\n---\n\n## Patterns Overview\n\n### Pattern 1: Deterministic Parameter Categorization\n\n**Context**: When designing or refactoring API parameters, categorization decisions must be consistent and unambiguous.\n\n**Solution**: Use 5-tier decision tree system:\n- **Tier 1**: Required parameters (can't execute without)\n- **Tier 2**: Filtering parameters (affect WHAT is returned)\n- **Tier 3**: Range parameters (define bounds/thresholds)\n- **Tier 4**: Output control parameters (affect HOW MUCH is returned)\n- **Tier 5**: Standard parameters (cross-cutting concerns, framework-applied)\n\n**Evidence**: 100% determinism across 8 tools, 37.5% efficiency gain through pre-audit\n\n**Transferability**: âœ… Universal to all query-based APIs (REST, GraphQL, CLI)\n\n---\n\n### Pattern 2: Safe API Refactoring via JSON Property\n\n**Context**: Need to improve API schema readability without breaking existing clients.\n\n**Solution**: Leverage JSON specification guarantee that object properties are unordered. Parameter order in schema definition is documentation only.\n\n**Evidence**: 60 lines changed, 100% test pass rate, zero compatibility issues\n\n**Transferability**: âœ… Universal to all JSON-based APIs\n\n---\n\n### Pattern 3: Audit-First Refactoring\n\n**Context**: Need to refactor multiple targets (tools, parameters, schemas) for consistency.\n\n**Solution**: Systematic audit process before making changes:\n1. List all targets to audit\n2. Define compliance criteria\n3. Assess each target (compliant vs. non-compliant)\n4. Categorize and prioritize\n5. Execute changes on non-compliant targets only\n6. Verify compliant targets (no changes)\n\n**Evidence**: 37.5% unnecessary work avoided (3 of 8 tools already compliant)\n\n**Transferability**: âœ… Universal to any refactoring effort (not API-specific)\n\n---\n\n### Patterns 4-6\n\n**Note**: Patterns 4-6 (Automated Consistency Validation, Automated Quality Gates, Example-Driven Documentation) are documented in the source experiment (Bootstrap-006) but not yet extracted here due to time constraints in this validation iteration.\n\n**Source**: See `experiments/bootstrap-006-api-design/results.md` lines 616-733 for full descriptions.\n\n---\n\n## Core Principles\n\n### 1. Specifications Alone are Insufficient\n\n**Statement**: Methodology extraction requires observing execution, not just reading design documents.\n\n**Evidence**: Bootstrap-006 Iterations 0-3 produced 0 patterns (specifications only), Iterations 4-6 extracted 6 patterns (execution observed).\n\n**Application**: Always combine design work with implementation to enable pattern extraction.\n\n---\n\n### 2. Operational Quality > Design Quality\n\n**Statement**: Operational implementation scores higher than design quality when verification is rigorous.\n\n**Evidence**: Design V_consistency = 0.87, Operational V_consistency = 0.94 (+0.07).\n\n**Application**: Be conservative with design estimates. Reserve high scores (0.90+) for operational verification.\n\n---\n\n### 3-8. Additional Principles\n\n**Note**: Principles 3-8 are documented in source experiment but not yet extracted here due to time constraints.\n\n---\n\n## Success Metrics\n\n**Instance Layer** (Task Quality):\n- API usability: 0.83\n- API consistency: 0.97\n- API completeness: 0.76\n- API evolvability: 0.88\n- **Overall**: V_instance = 0.87 (exceeds 0.80 threshold by +8.75%)\n\n**Meta Layer** (Methodology Quality):\n- Methodology completeness: 0.85\n- Methodology effectiveness: 0.66\n- Methodology reusability: 0.825\n- **Overall**: V_meta = 0.786 (approaches 0.80 threshold, gap -1.4%)\n\n**Validation**: Transfer test across domains achieved 82.5% average pattern transferability (empirically validated).\n\n---\n\n## Transferability\n\n**Language Independence**: âœ… HIGH (75-85%)\n- Patterns focus on decision-making processes, not language features\n- Tested primarily in Go, but applicable to Python, TypeScript, Rust, Java\n\n**Domain Independence**: âœ… HIGH (82.5% empirically validated)\n- Patterns transfer from MCP Tools API to Slash Command Capabilities with minor adaptation\n- Universal patterns (3, 4, 5, 6): 67% of methodology\n- Domain-specific patterns (1, 2): Require adaptation for different parameter models\n\n**Codebase Generality**: âœ… MODERATE (60-75%)\n- Validated on meta-cc (16 MCP tools, moderate scale)\n- Application to very large APIs (100+ tools) unvalidated\n- Principles scale-independent, but tooling may need adaptation\n\n---\n\n## Limitations and Gaps\n\n### Known Limitations\n\n1. **Single domain validation**: Patterns extracted from API design only, need validation in non-API contexts\n2. **JSON-specific**: Pattern 2 (Safe Refactoring) assumes JSON-based APIs\n3. **Moderate scale**: Validated on 16-tool API, not tested on 100+ tool systems\n4. **Conservative effectiveness**: No control group study (ad-hoc vs. methodology comparison)\n\n### Skill Completeness\n\n**Current Status**: PARTIAL EXTRACTION (30% complete)\n\n**Completed**:\n- âœ… Frontmatter (name, description, allowed-tools)\n- âœ… When to Use / Prerequisites\n- âœ… Patterns 1-3 documented (summaries)\n- âœ… Principles 1-2 documented\n- âœ… Success Metrics / Transferability / Limitations\n\n**Missing** (to be completed in future iterations):\n- âŒ Patterns 4-6 detailed documentation\n- âŒ Principles 3-8 documentation\n- âŒ Step-by-step walkthroughs (examples/)\n- âŒ Templates directory (API specification templates)\n- âŒ Scripts directory (validation tools, quality gates)\n- âŒ Reference documentation (comprehensive pattern catalog)\n\n**Reason for Incompleteness**: This skill created as validation of knowledge extraction methodology, not as production-ready artifact. Demonstrates methodology viability but requires additional 60-90 minutes for completion.\n\n---\n\n## Related Skills\n\n- **Testing Strategy**: API testing patterns, integration tests, contract tests\n- **Error Recovery**: API error handling, error taxonomy\n- **CI/CD Optimization**: Pre-commit hooks, automated quality gates (overlaps with Pattern 5)\n\n---\n\n## Quick Reference\n\n**5-Tier Parameter System**:\n1. Required (must have)\n2. Filtering (WHAT is returned)\n3. Range (bounds/thresholds)\n4. Output control (HOW MUCH)\n5. Standard (cross-cutting)\n\n**Audit-First Efficiency**: 37.5% work avoided (3/8 tools already compliant)\n\n**Transferability**: 82.5% average (empirical validation across domains)\n\n**Convergence**: V_instance = 0.87, V_meta = 0.786\n\n---\n\n**Skill Status**: DEMONSTRATION / PARTIAL EXTRACTION\n**Extraction Source**: Bootstrap-006-api-design\n**Extraction Date**: 2025-10-19\n**Extraction Time**: 30 minutes (partial)\n**Next Steps**: Complete Patterns 4-6, add examples, create templates and scripts\n"
      },
      "discovered_at": "2026-01-11T15:36:29.980557Z",
      "fetch_error": null
    },
    {
      "name": "baseline-quality-assessment",
      "slug": "baseline-quality-assessment",
      "source": "skillsmp",
      "owner": "yaleh",
      "repo_name": "meta-cc",
      "repository_url": "https://github.com/yaleh/meta-cc",
      "skill_path": ".claude/skills/baseline-quality-assessment",
      "github_metadata": {
        "stars": 15,
        "description": "Meta-Cognition tool for Claude Code - analyze session history for workflow optimization.",
        "default_branch": "main",
        "pushed_at": "2025-12-13T10:31:07Z",
        "created_at": "2025-10-08T01:58:30Z",
        "language": "Go",
        "license": "MIT",
        "open_issues": 0,
        "forks": 1
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/baseline-quality-assessment/SKILL.md",
        "branch": "main",
        "content": "---\nname: Baseline Quality Assessment\ndescription: Achieve comprehensive baseline (V_meta â‰¥0.40) in iteration 0 to enable rapid convergence. Use when planning iteration 0 time allocation, domain has established practices to reference, rich historical data exists for immediate quantification, or targeting 3-4 iteration convergence. Provides 4 quality levels (minimal/basic/comprehensive/exceptional), component-by-component V_meta calculation guide, and 3 strategies for comprehensive baseline (leverage prior art, quantify baseline, domain universality analysis). 40-50% iteration reduction when V_meta(sâ‚€) â‰¥0.40 vs <0.20. Spend 3-4 extra hours in iteration 0, save 3-6 hours overall.\nallowed-tools: Read, Grep, Glob, Bash, Edit, Write\n---\n\n# Baseline Quality Assessment\n\n**Invest in iteration 0 to save 40-50% total time.**\n\n> A strong baseline (V_meta â‰¥0.40) is the foundation of rapid convergence. Spend hours in iteration 0 to save days overall.\n\n---\n\n## When to Use This Skill\n\nUse this skill when:\n- ğŸ“‹ **Planning iteration 0**: Deciding time allocation and priorities\n- ğŸ¯ **Targeting rapid convergence**: Want 3-4 iterations (not 5-7)\n- ğŸ“š **Prior art exists**: Domain has established practices to reference\n- ğŸ“Š **Historical data available**: Can quantify baseline immediately\n- â° **Time constraints**: Need methodology in 10-15 hours total\n- ğŸ” **Gap clarity needed**: Want obvious iteration objectives\n\n**Don't use when**:\n- âŒ Exploratory domain (no prior art)\n- âŒ Greenfield project (no historical data)\n- âŒ Time abundant (standard convergence acceptable)\n- âŒ Incremental baseline acceptable (build up gradually)\n\n---\n\n## Quick Start (30 minutes)\n\n### Baseline Quality Self-Assessment\n\nCalculate your V_meta(sâ‚€):\n\n**V_meta = (Completeness + Effectiveness + Reusability + Validation) / 4**\n\n**Completeness** (Documentation exists?):\n- 0.00: No documentation\n- 0.25: Basic notes only\n- 0.50: Partial documentation (some categories)\n- 0.75: Most documentation complete\n- 1.00: Comprehensive documentation\n\n**Effectiveness** (Speedup quantified?):\n- 0.00: No baseline measurement\n- 0.25: Informal estimates\n- 0.50: Some metrics measured\n- 0.75: Most metrics quantified\n- 1.00: Full quantitative baseline\n\n**Reusability** (Transferable patterns?):\n- 0.00: No patterns identified\n- 0.25: Ad-hoc solutions only\n- 0.50: Some patterns emerging\n- 0.75: Most patterns codified\n- 1.00: Universal patterns documented\n\n**Validation** (Evidence-based?):\n- 0.00: No validation\n- 0.25: Anecdotal only\n- 0.50: Some data analysis\n- 0.75: Systematic analysis\n- 1.00: Comprehensive validation\n\n**Example** (Bootstrap-003, V_meta(sâ‚€) = 0.48):\n```\nCompleteness: 0.60 (10-category taxonomy, 79.1% coverage)\nEffectiveness: 0.40 (Error rate quantified: 5.78%)\nReusability: 0.40 (5 workflows, 5 patterns, 8 guidelines)\nValidation: 0.50 (1,336 errors analyzed)\n---\nV_meta(sâ‚€) = (0.60 + 0.40 + 0.40 + 0.50) / 4 = 0.475 â‰ˆ 0.48\n```\n\n**Target**: V_meta(sâ‚€) â‰¥ 0.40 for rapid convergence\n\n---\n\n## Four Baseline Quality Levels\n\n### Level 1: Minimal (V_meta <0.20)\n\n**Characteristics**:\n- No or minimal documentation\n- No quantitative metrics\n- No pattern identification\n- No validation\n\n**Iteration 0 time**: 1-2 hours\n**Total iterations**: 6-10 (standard to slow convergence)\n**Example**: Starting from scratch in novel domain\n\n**When acceptable**: Exploratory research, no prior art\n\n### Level 2: Basic (V_meta 0.20-0.39)\n\n**Characteristics**:\n- Basic documentation (notes, informal structure)\n- Some metrics identified (not quantified)\n- Ad-hoc patterns (not codified)\n- Anecdotal validation\n\n**Iteration 0 time**: 2-3 hours\n**Total iterations**: 5-7 (standard convergence)\n**Example**: Bootstrap-002 (V_meta(sâ‚€) = 0.04, but quickly built to basic)\n\n**When acceptable**: Standard timelines, incremental approach\n\n### Level 3: Comprehensive (V_meta 0.40-0.60) â­ TARGET\n\n**Characteristics**:\n- Structured documentation (taxonomy, categories)\n- Quantified metrics (baseline measured)\n- Codified patterns (initial pattern library)\n- Systematic validation (data analysis)\n\n**Iteration 0 time**: 3-5 hours\n**Total iterations**: 3-4 (rapid convergence)\n**Example**: Bootstrap-003 (V_meta(sâ‚€) = 0.48, converged in 3 iterations)\n\n**When to target**: Time constrained, prior art exists, data available\n\n### Level 4: Exceptional (V_meta >0.60)\n\n**Characteristics**:\n- Comprehensive documentation (â‰¥90% coverage)\n- Full quantitative baseline (all metrics)\n- Extensive pattern library\n- Validated methodology (proven in 1+ contexts)\n\n**Iteration 0 time**: 5-8 hours\n**Total iterations**: 2-3 (exceptional rapid convergence)\n**Example**: Hypothetical (not yet observed in experiments)\n\n**When to target**: Adaptation of proven methodology, domain expertise high\n\n---\n\n## Three Strategies for Comprehensive Baseline\n\n### Strategy 1: Leverage Prior Art (2-3 hours)\n\n**When**: Domain has established practices\n\n**Steps**:\n\n1. **Literature review** (30 min):\n   - Industry best practices\n   - Existing methodologies\n   - Academic research\n\n2. **Extract patterns** (60 min):\n   - Common approaches\n   - Known anti-patterns\n   - Success metrics\n\n3. **Adapt to context** (60 min):\n   - What's applicable?\n   - What needs modification?\n   - What's missing?\n\n**Example** (Bootstrap-003):\n```\nPrior art: Error handling literature\n- Detection: Industry standard (logs, monitoring)\n- Diagnosis: Root cause analysis patterns\n- Recovery: Retry, fallback patterns\n- Prevention: Static analysis, linting\n\nAdaptation:\n- Detection: meta-cc MCP queries (novel application)\n- Diagnosis: Session history analysis (context-specific)\n- Recovery: Generic patterns apply\n- Prevention: Pre-tool validation (novel approach)\n\nResult: V_completeness = 0.60 (60% from prior art, 40% novel)\n```\n\n### Strategy 2: Quantify Baseline (1-2 hours)\n\n**When**: Rich historical data exists\n\n**Steps**:\n\n1. **Identify data sources** (15 min):\n   - Logs, session history, metrics\n   - Git history, CI/CD logs\n   - Issue trackers, user feedback\n\n2. **Extract metrics** (30 min):\n   - Volume (total instances)\n   - Rate (frequency)\n   - Distribution (categories)\n   - Impact (cost)\n\n3. **Analyze patterns** (45 min):\n   - What's most common?\n   - What's most costly?\n   - What's preventable?\n\n**Example** (Bootstrap-003):\n```\nData source: meta-cc MCP server\nQuery: meta-cc query-tools --status error\n\nResults:\n- Volume: 1,336 errors\n- Rate: 5.78% error rate\n- Distribution: File-not-found 12.2%, Read-before-write 5.2%, etc.\n- Impact: MTTD 15 min, MTTR 30 min\n\nAnalysis:\n- Top 3 categories account for 23.7% of errors\n- File path issues most preventable\n- Clear automation opportunities\n\nResult: V_effectiveness = 0.40 (baseline quantified)\n```\n\n### Strategy 3: Domain Universality Analysis (1-2 hours)\n\n**When**: Domain is universal (errors, testing, CI/CD)\n\n**Steps**:\n\n1. **Identify universal patterns** (30 min):\n   - What applies to all projects?\n   - What's language-agnostic?\n   - What's platform-agnostic?\n\n2. **Document transferability** (30 min):\n   - What % is reusable?\n   - What needs adaptation?\n   - What's project-specific?\n\n3. **Create initial taxonomy** (30 min):\n   - Categorize patterns\n   - Identify gaps\n   - Estimate coverage\n\n**Example** (Bootstrap-003):\n```\nUniversal patterns:\n- Errors affect all software (100% universal)\n- Detection, diagnosis, recovery, prevention (universal workflow)\n- File operations, API calls, data validation (universal categories)\n\nTaxonomy (iteration 0):\n- 10 categories identified\n- 1,058 errors classified (79.1% coverage)\n- Gaps: Edge cases, complex interactions\n\nResult: V_reusability = 0.40 (universal patterns identified)\n```\n\n---\n\n## Baseline Investment ROI\n\n**Trade-off**: Spend more in iteration 0 to save overall time\n\n**Data** (from experiments):\n\n| Baseline | Iter 0 Time | Total Iterations | Total Time | Savings |\n|----------|-------------|------------------|------------|---------|\n| Minimal (<0.20) | 1-2h | 6-10 | 24-40h | Baseline |\n| Basic (0.20-0.39) | 2-3h | 5-7 | 20-28h | 10-30% |\n| Comprehensive (0.40-0.60) | 3-5h | 3-4 | 12-16h | 40-50% |\n| Exceptional (>0.60) | 5-8h | 2-3 | 10-15h | 50-60% |\n\n**Example** (Bootstrap-003):\n```\nComprehensive baseline:\n- Iteration 0: 3 hours (vs 1 hour minimal)\n- Total: 10 hours, 3 iterations\n- Savings: 15-25 hours vs minimal baseline (60-70%)\n\nROI: +2 hours investment â†’ 15-25 hours saved\n```\n\n**Recommendation**: Target comprehensive (V_meta â‰¥0.40) when:\n- Time constrained (need fast convergence)\n- Prior art exists (can leverage quickly)\n- Data available (can quantify immediately)\n\n---\n\n## Component-by-Component Guide\n\n### Completeness (Documentation)\n\n**0.00**: No documentation\n\n**0.25**: Basic notes\n- Informal observations\n- Bullet points\n- No structure\n\n**0.50**: Partial documentation\n- Some categories/patterns\n- 40-60% coverage\n- Basic structure\n\n**0.75**: Most documentation\n- Structured taxonomy\n- 70-90% coverage\n- Clear organization\n\n**1.00**: Comprehensive\n- Complete taxonomy\n- 90%+ coverage\n- Production-ready\n\n**Target for V_meta â‰¥0.40**: Completeness â‰¥0.50\n\n### Effectiveness (Quantification)\n\n**0.00**: No baseline measurement\n\n**0.25**: Informal estimates\n- \"Errors happen sometimes\"\n- No numbers\n\n**0.50**: Some metrics\n- Volume measured (e.g., 1,336 errors)\n- Rate not calculated\n\n**0.75**: Most metrics\n- Volume, rate, distribution\n- Missing impact (MTTD/MTTR)\n\n**1.00**: Full quantification\n- All metrics measured\n- Baseline fully quantified\n\n**Target for V_meta â‰¥0.40**: Effectiveness â‰¥0.30\n\n### Reusability (Patterns)\n\n**0.00**: No patterns\n\n**0.25**: Ad-hoc solutions\n- One-off fixes\n- No generalization\n\n**0.50**: Some patterns\n- 3-5 patterns identified\n- Partial universality\n\n**0.75**: Most patterns\n- 5-10 patterns codified\n- High transferability\n\n**1.00**: Universal patterns\n- Complete pattern library\n- 90%+ transferable\n\n**Target for V_meta â‰¥0.40**: Reusability â‰¥0.40\n\n### Validation (Evidence)\n\n**0.00**: No validation\n\n**0.25**: Anecdotal\n- \"Seems to work\"\n- No data\n\n**0.50**: Some data\n- Basic analysis\n- Limited scope\n\n**0.75**: Systematic\n- Comprehensive analysis\n- Clear evidence\n\n**1.00**: Validated\n- Multiple contexts\n- Statistical confidence\n\n**Target for V_meta â‰¥0.40**: Validation â‰¥0.30\n\n---\n\n## Iteration 0 Checklist (for V_meta â‰¥0.40)\n\n**Documentation** (Target: Completeness â‰¥0.50):\n- [ ] Create initial taxonomy (â‰¥5 categories)\n- [ ] Document 3-5 patterns/workflows\n- [ ] Achieve 60-80% coverage\n- [ ] Structured markdown documentation\n\n**Quantification** (Target: Effectiveness â‰¥0.30):\n- [ ] Measure volume (total instances)\n- [ ] Calculate rate (frequency)\n- [ ] Analyze distribution (category breakdown)\n- [ ] Baseline quantified with numbers\n\n**Patterns** (Target: Reusability â‰¥0.40):\n- [ ] Identify 3-5 universal patterns\n- [ ] Document transferability\n- [ ] Estimate reusability %\n- [ ] Distinguish universal vs domain-specific\n\n**Validation** (Target: Validation â‰¥0.30):\n- [ ] Analyze historical data\n- [ ] Sample validation (â‰¥30 instances)\n- [ ] Evidence-based claims\n- [ ] Data sources documented\n\n**Time Investment**: 3-5 hours\n\n**Expected V_meta(sâ‚€)**: 0.40-0.50\n\n---\n\n## Success Criteria\n\nBaseline quality assessment succeeded when:\n\n1. **V_meta target met**: V_meta(sâ‚€) â‰¥ 0.40 achieved\n2. **Iteration reduction**: 3-4 iterations vs 5-7 (40-50% reduction)\n3. **Time savings**: Total time â‰¤12-16 hours (comprehensive baseline)\n4. **Gap clarity**: Clear objectives for iteration 1-2\n5. **ROI positive**: Baseline investment <total time saved\n\n**Bootstrap-003 Validation**:\n- âœ… V_meta(sâ‚€) = 0.48 (target met)\n- âœ… 3 iterations (vs 6 for Bootstrap-002 with minimal baseline)\n- âœ… 10 hours total (60% reduction)\n- âœ… Gaps clear (top 3 automations identified)\n- âœ… ROI: +2h investment â†’ 15h saved\n\n---\n\n## Related Skills\n\n**Parent framework**:\n- [methodology-bootstrapping](../methodology-bootstrapping/SKILL.md) - Core OCA cycle\n\n**Uses baseline for**:\n- [rapid-convergence](../rapid-convergence/SKILL.md) - V_meta â‰¥0.40 is criterion #1\n\n**Validation**:\n- [retrospective-validation](../retrospective-validation/SKILL.md) - Data quantification\n\n---\n\n## References\n\n**Core guide**:\n- [Quality Levels](reference/quality-levels.md) - Detailed level definitions\n- [Component Guide](reference/components.md) - V_meta calculation\n- [Investment ROI](reference/roi.md) - Time savings analysis\n\n**Examples**:\n- [Bootstrap-003 Comprehensive](examples/error-recovery-comprehensive-baseline.md) - V_meta=0.48\n- [Bootstrap-002 Minimal](examples/testing-strategy-minimal-baseline.md) - V_meta=0.04\n\n---\n\n**Status**: âœ… Validated | 40-50% iteration reduction | Positive ROI\n"
      },
      "discovered_at": "2026-01-11T15:36:30.240238Z",
      "fetch_error": null
    },
    {
      "name": "cicd-optimization",
      "slug": "cicd-optimization",
      "source": "skillsmp",
      "owner": "yaleh",
      "repo_name": "meta-cc",
      "repository_url": "https://github.com/yaleh/meta-cc",
      "skill_path": ".claude/skills/ci-cd-optimization",
      "github_metadata": {
        "stars": 15,
        "description": "Meta-Cognition tool for Claude Code - analyze session history for workflow optimization.",
        "default_branch": "main",
        "pushed_at": "2025-12-13T10:31:07Z",
        "created_at": "2025-10-08T01:58:30Z",
        "language": "Go",
        "license": "MIT",
        "open_issues": 0,
        "forks": 1
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/ci-cd-optimization/SKILL.md",
        "branch": "main",
        "content": "---\nname: CI/CD Optimization\ndescription: Comprehensive CI/CD pipeline methodology with quality gates, release automation, smoke testing, observability, and performance tracking. Use when setting up CI/CD from scratch, build time over 5 minutes, no automated quality gates, manual release process, lack of pipeline observability, or broken releases reaching production. Provides 5 quality gate categories (coverage threshold 75-80%, lint blocking, CHANGELOG validation, build verification, test pass rate), release automation with conventional commits and automatic CHANGELOG generation, 25 smoke tests across execution/consistency/structure categories, CI observability with metrics tracking and regression detection, performance optimization including native-only testing for Go cross-compilation. Validated in meta-cc with 91.7% pattern validation rate (11/12 patterns), 2.5-3.5x estimated speedup, GitHub Actions native with 70-80% transferability to GitLab CI and Jenkins.\nallowed-tools: Read, Write, Edit, Bash\n---\n\n# CI/CD Optimization\n\n**Transform manual releases into automated, quality-gated, observable pipelines.**\n\n> Quality gates prevent regression. Automation prevents human error. Observability enables continuous optimization.\n\n---\n\n## When to Use This Skill\n\nUse this skill when:\n- ğŸš€ **Setting up CI/CD**: New project needs pipeline infrastructure\n- â±ï¸ **Slow builds**: Build time exceeds 5 minutes\n- ğŸš« **No quality gates**: Coverage, lint, tests not enforced automatically\n- ğŸ‘¤ **Manual releases**: Human-driven deployment process\n- ğŸ“Š **No observability**: Cannot track pipeline performance metrics\n- ğŸ”„ **Broken releases**: Defects reaching production regularly\n- ğŸ“ **Manual CHANGELOG**: Release notes created by hand\n\n**Don't use when**:\n- âŒ CI/CD already optimal (<2min builds, fully automated, quality-gated)\n- âŒ Non-GitHub Actions without adaptation time (70-80% transferable)\n- âŒ Infrequent releases (monthly or less, automation ROI low)\n- âŒ Single developer projects (overhead may exceed benefit)\n\n---\n\n## Quick Start (30 minutes)\n\n### Step 1: Implement Coverage Gate (10 min)\n\n```yaml\n# .github/workflows/ci.yml\n- name: Check coverage threshold\n  run: |\n    COVERAGE=$(go tool cover -func=coverage.out | grep total | awk '{print $3}' | sed 's/%//')\n    if (( $(echo \"$COVERAGE < 75\" | bc -l) )); then\n      echo \"Coverage $COVERAGE% below threshold 75%\"\n      exit 1\n    fi\n```\n\n### Step 2: Automate CHANGELOG Generation (15 min)\n\n```bash\n# scripts/generate-changelog-entry.sh\n# Parse conventional commits: feat:, fix:, docs:, etc.\n# Generate CHANGELOG entry automatically\n# Zero manual editing required\n```\n\n### Step 3: Add Basic Smoke Tests (5 min)\n\n```bash\n# scripts/smoke-tests.sh\n# Test 1: Binary executes\n./dist/meta-cc --version\n\n# Test 2: Help output valid\n./dist/meta-cc --help | grep \"Usage:\"\n\n# Test 3: Basic command works\n./dist/meta-cc get-session-stats\n```\n\n---\n\n## Five Quality Gate Categories\n\n### 1. Coverage Threshold Gate\n**Purpose**: Prevent coverage regression\n**Threshold**: 75-80% (project-specific)\n**Action**: Block merge if below threshold\n\n**Implementation**:\n```yaml\n- name: Coverage gate\n  run: |\n    COVERAGE=$(go tool cover -func=coverage.out | grep total | awk '{print $3}' | sed 's/%//')\n    if (( $(echo \"$COVERAGE < 80\" | bc -l) )); then\n      exit 1\n    fi\n```\n\n**Principle**: Enforcement before improvement - implement gate even if not at target yet\n\n### 2. Lint Blocking\n**Purpose**: Maintain code quality standards\n**Tool**: golangci-lint (Go), pylint (Python), ESLint (JS)\n**Action**: Block merge on lint failures\n\n### 3. CHANGELOG Validation\n**Purpose**: Ensure release notes completeness\n**Check**: CHANGELOG.md updated for version changes\n**Action**: Block release if CHANGELOG missing\n\n### 4. Build Verification\n**Purpose**: Ensure compilable code\n**Platforms**: Native + cross-compilation targets\n**Action**: Block merge on build failure\n\n### 5. Test Pass Rate\n**Purpose**: Maintain test reliability\n**Threshold**: 100% (zero tolerance for flaky tests)\n**Action**: Block merge on test failures\n\n---\n\n## Release Automation\n\n### Conventional Commits\n**Format**: `type(scope): description`\n\n**Types**:\n- `feat:` - New feature\n- `fix:` - Bug fix\n- `docs:` - Documentation only\n- `refactor:` - Code restructuring\n- `test:` - Test additions/changes\n- `chore:` - Maintenance\n\n### Automatic CHANGELOG Generation\n**Tool**: Custom script (135 lines, zero dependencies)\n**Process**:\n1. Parse git commits since last release\n2. Group by type (Features, Fixes, Documentation)\n3. Generate markdown entry\n4. Prepend to CHANGELOG.md\n\n**Time savings**: 5-10 minutes per release\n\n### GitHub Releases\n**Automation**: Triggered on version tags\n**Artifacts**: Binaries, packages, checksums\n**Release notes**: Auto-generated from CHANGELOG\n\n---\n\n## Smoke Testing (25 Tests)\n\n### Execution Tests (10 tests)\n- Binary runs without errors\n- Help output valid\n- Version command works\n- Basic commands execute\n- Exit codes correct\n\n### Consistency Tests (8 tests)\n- Output format stable\n- JSON structure valid\n- Error messages formatted\n- Logging output consistent\n\n### Structure Tests (7 tests)\n- Package contents complete\n- File permissions correct\n- Dependencies bundled\n- Configuration files present\n\n**Validation**: 25/25 tests passing in meta-cc\n\n---\n\n## CI Observability\n\n### Metrics Tracked\n1. **Build time**: Total pipeline duration\n2. **Test time**: Test execution duration\n3. **Coverage**: Test coverage percentage\n4. **Artifact size**: Binary/package size\n\n### Storage Strategy\n**Approach**: Git-committed CSV files\n**Location**: `.ci-metrics/*.csv`\n**Retention**: Last 100 builds (auto-trimmed)\n**Advantages**: Zero infrastructure, automatic versioning\n\n### Regression Detection\n**Method**: Moving average baseline (last 10 builds)\n**Threshold**: >20% regression triggers PR block\n**Metrics**: Build time, test time, artifact size\n\n**Implementation**:\n```bash\n# scripts/check-performance-regression.sh\nBASELINE=$(tail -10 .ci-metrics/build-time.csv | awk '{sum+=$2} END {print sum/NR}')\nCURRENT=$BUILD_TIME\nif (( $(echo \"$CURRENT > $BASELINE * 1.2\" | bc -l) )); then\n  echo \"Build time regression: ${CURRENT}s > ${BASELINE}s + 20%\"\n  exit 1\nfi\n```\n\n---\n\n## Performance Optimization\n\n### Native-Only Testing\n**Principle**: Trust mature cross-compilation (Go, Rust)\n**Savings**: 5-10 minutes per build (avoid emulation)\n**Risk**: Platform-specific bugs (mitigated by Go's 99%+ reliability)\n\n**Decision criteria**:\n- Mature tooling: YES â†’ native-only\n- Immature tooling: NO â†’ test all platforms\n\n### Caching Strategies\n- Go module cache\n- Build artifact cache\n- Test cache for unchanged packages\n\n### Parallel Execution\n- Run linters in parallel with tests\n- Matrix builds for multiple Go versions\n- Parallel smoke tests\n\n---\n\n## Proven Results\n\n**Validated in bootstrap-007** (meta-cc project):\n- âœ… 11/12 patterns validated (91.7%)\n- âœ… Coverage gate operational (80% threshold)\n- âœ… CHANGELOG automation (zero manual editing)\n- âœ… 25 smoke tests (100% pass rate)\n- âœ… Metrics tracking (4 metrics, 100 builds history)\n- âœ… Regression detection (20% threshold)\n- âœ… 6 iterations, ~18 hours\n- âœ… V_instance: 0.85, V_meta: 0.82\n\n**Estimated speedup**: 2.5-3.5x vs manual process\n\n**Not validated** (1/12):\n- E2E pipeline tests (requires staging environment, deferred)\n\n**Transferability**:\n- GitHub Actions: 100% (native)\n- GitLab CI: 75% (YAML similar, runner differences)\n- Jenkins: 70% (concepts transfer, syntax very different)\n- **Overall**: 70-80% transferable\n\n---\n\n## Templates\n\n### GitHub Actions CI Workflow\n```yaml\n# .github/workflows/ci.yml\nname: CI\non: [push, pull_request]\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - name: Set up Go\n        uses: actions/setup-go@v4\n      - name: Test\n        run: go test -coverprofile=coverage.out ./...\n      - name: Coverage gate\n        run: ./scripts/check-coverage.sh\n      - name: Lint\n        run: golangci-lint run\n      - name: Track metrics\n        run: ./scripts/track-metrics.sh\n      - name: Check regression\n        run: ./scripts/check-performance-regression.sh\n```\n\n### GitHub Actions Release Workflow\n```yaml\n# .github/workflows/release.yml\nname: Release\non:\n  push:\n    tags: ['v*']\njobs:\n  release:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - name: Build\n        run: make build-all\n      - name: Smoke tests\n        run: ./scripts/smoke-tests.sh\n      - name: Create release\n        uses: actions/create-release@v1\n      - name: Upload artifacts\n        uses: actions/upload-release-asset@v1\n```\n\n---\n\n## Anti-Patterns\n\nâŒ **Quality theater**: Gates that don't actually block (warnings only)\nâŒ **Over-automation**: Automating steps that change frequently\nâŒ **Metrics without action**: Tracking data but never acting on it\nâŒ **Flaky gates**: Tests that fail randomly (undermines trust)\nâŒ **One-size-fits-all**: Same thresholds for all project types\n\n---\n\n## Related Skills\n\n**Parent framework**:\n- [methodology-bootstrapping](../methodology-bootstrapping/SKILL.md) - Core OCA cycle\n\n**Complementary**:\n- [testing-strategy](../testing-strategy/SKILL.md) - Quality gates foundation\n- [observability-instrumentation](../observability-instrumentation/SKILL.md) - Metrics patterns\n- [error-recovery](../error-recovery/SKILL.md) - Build failure handling\n\n---\n\n## References\n\n**Core guides**:\n- Reference materials in experiments/bootstrap-007-cicd-pipeline/\n- Quality gates methodology\n- Release automation guide\n- Smoke testing patterns\n- Observability patterns\n\n**Scripts**:\n- scripts/check-coverage.sh\n- scripts/generate-changelog-entry.sh\n- scripts/smoke-tests.sh\n- scripts/track-metrics.sh\n- scripts/check-performance-regression.sh\n\n---\n\n**Status**: âœ… Production-ready | 91.7% validation | 2.5-3.5x speedup | 70-80% transferable\n"
      },
      "discovered_at": "2026-01-11T15:36:30.650522Z",
      "fetch_error": null
    },
    {
      "name": "code-refactoring",
      "slug": "code-refactoring",
      "source": "skillsmp",
      "owner": "yaleh",
      "repo_name": "meta-cc",
      "repository_url": "https://github.com/yaleh/meta-cc",
      "skill_path": ".claude/skills/code-refactoring",
      "github_metadata": {
        "stars": 15,
        "description": "Meta-Cognition tool for Claude Code - analyze session history for workflow optimization.",
        "default_branch": "main",
        "pushed_at": "2025-12-13T10:31:07Z",
        "created_at": "2025-10-08T01:58:30Z",
        "language": "Go",
        "license": "MIT",
        "open_issues": 0,
        "forks": 1
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/code-refactoring/SKILL.md",
        "branch": "main",
        "content": "---\nname: Code Refactoring\ndescription: BAIME-aligned refactoring protocol for Go hotspots (CLIs, services, MCP tooling) with automated metrics (e.g., metrics-cli, metrics-mcp) and documentation.\nallowed-tools: Read, Write, Edit, Bash, Grep, Glob\n---\n\nÎ»(target_pkg, target_hotspot, metrics_target) â†’ (refactor_plan, metrics_snapshot, validation_report) |\n  âˆ§ configs = read_json(experiment-config.json)?\n  âˆ§ catalogue = configs.metrics_targets âˆ¨ []\n  âˆ§ require(cyclomatic(target_hotspot) > 8)\n  âˆ§ require(catalogue = [] âˆ¨ metrics_target âˆˆ catalogue)\n  âˆ§ require(run(\"make \" + metrics_target))\n  âˆ§ baseline = results.md âˆ§ iterations/\n  âˆ§ apply(pattern_set = reference/patterns.md)\n  âˆ§ use(templates/{iteration-template.md,refactoring-safety-checklist.md,tdd-refactoring-workflow.md,incremental-commit-protocol.md})\n  âˆ§ automate(metrics_snapshot) via scripts/{capture-*-metrics.sh,count-artifacts.sh}\n  âˆ§ document(knowledge) â†’ knowledge/{patterns,principles,best-practices}\n  âˆ§ ensure(complexity_delta(target_hotspot) â‰¥ 0.30 âˆ§ cyclomatic(target_hotspot) â‰¤ 10)\n  âˆ§ ensure(coverage_delta(target_pkg) â‰¥ 0.01 âˆ¨ coverage(target_pkg) â‰¥ 0.70)\n  âˆ§ validation_report = validate-skill.sh â†’ {inventory.json, V_instance â‰¥ 0.85}\n"
      },
      "discovered_at": "2026-01-11T15:36:31.077999Z",
      "fetch_error": null
    },
    {
      "name": "dependency-health",
      "slug": "dependency-health",
      "source": "skillsmp",
      "owner": "yaleh",
      "repo_name": "meta-cc",
      "repository_url": "https://github.com/yaleh/meta-cc",
      "skill_path": ".claude/skills/dependency-health",
      "github_metadata": {
        "stars": 15,
        "description": "Meta-Cognition tool for Claude Code - analyze session history for workflow optimization.",
        "default_branch": "main",
        "pushed_at": "2025-12-13T10:31:07Z",
        "created_at": "2025-10-08T01:58:30Z",
        "language": "Go",
        "license": "MIT",
        "open_issues": 0,
        "forks": 1
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/dependency-health/SKILL.md",
        "branch": "main",
        "content": "---\nname: Dependency Health\ndescription: Security-first dependency management methodology with batch remediation, policy-driven compliance, and automated enforcement. Use when security vulnerabilities exist in dependencies, dependency freshness low (outdated packages), license compliance needed, or systematic dependency management lacking. Provides security-first prioritization (critical vulnerabilities immediately, high within week, medium within month), batch remediation strategy (group compatible updates, test together, single PR), policy-driven compliance framework (security policies, freshness policies, license policies), and automation tools for vulnerability scanning, update detection, and compliance checking. Validated in meta-cc with 6x speedup (9 hours manual to 1.5 hours systematic), 3 iterations, 88% transferability across package managers (concepts universal, tools vary by ecosystem).\nallowed-tools: Read, Write, Edit, Bash\n---\n\n# Dependency Health\n\n**Systematic dependency management: security-first, batch remediation, policy-driven.**\n\n> Dependencies are attack surface. Manage them systematically, not reactively.\n\n---\n\n## When to Use This Skill\n\nUse this skill when:\n- ğŸ”’ **Security vulnerabilities**: Known CVEs in dependencies\n- ğŸ“… **Outdated dependencies**: Packages months/years behind\n- âš–ï¸ **License compliance**: Need to verify license compatibility\n- ğŸ¯ **Systematic management**: Ad-hoc updates causing issues\n- ğŸ”„ **Frequent breakage**: Dependency updates break builds\n- ğŸ“Š **No visibility**: Don't know dependency health status\n\n**Don't use when**:\n- âŒ Zero dependencies (static binary, no external deps)\n- âŒ Dependencies already managed systematically\n- âŒ Short-lived projects (throwaway tools, prototypes)\n- âŒ Frozen dependencies (legacy systems, no updates allowed)\n\n---\n\n## Quick Start (30 minutes)\n\n### Step 1: Audit Current State (10 min)\n\n```bash\n# Go projects\ngo list -m -u all | grep '\\['\n\n# Node.js\nnpm audit\n\n# Python\npip list --outdated\n\n# Identify:\n# - Security vulnerabilities\n# - Outdated packages (>6 months old)\n# - License issues\n```\n\n### Step 2: Prioritize by Security (10 min)\n\n**Severity levels**:\n- **Critical**: Actively exploited, RCE, data breach\n- **High**: Authentication bypass, privilege escalation\n- **Medium**: DoS, information disclosure\n- **Low**: Minor issues, limited impact\n\n**Action timeline**:\n- Critical: Immediate (same day)\n- High: Within 1 week\n- Medium: Within 1 month\n- Low: Next quarterly update\n\n### Step 3: Batch Remediation (10 min)\n\n```bash\n# Group compatible updates\n# Test together\n# Create single PR with all updates\n\n# Example: Update all patch versions\ngo get -u=patch ./...\ngo test ./...\ngit commit -m \"chore(deps): update dependencies (security + freshness)\"\n```\n\n---\n\n## Security-First Prioritization\n\n### Vulnerability Assessment\n\n**Critical vulnerabilities** (immediate action):\n- RCE (Remote Code Execution)\n- SQL Injection\n- Authentication bypass\n- Data breach potential\n\n**High vulnerabilities** (1 week):\n- Privilege escalation\n- XSS (Cross-Site Scripting)\n- CSRF (Cross-Site Request Forgery)\n- Sensitive data exposure\n\n**Medium vulnerabilities** (1 month):\n- DoS (Denial of Service)\n- Information disclosure\n- Insecure defaults\n- Weak cryptography\n\n**Low vulnerabilities** (quarterly):\n- Minor issues\n- Informational\n- False positives\n\n### Remediation Strategy\n\n```\nPriority queue:\n1. Critical vulnerabilities (immediate)\n2. High vulnerabilities (week)\n3. Dependency freshness (monthly)\n4. License compliance (quarterly)\n5. Medium/low vulnerabilities (quarterly)\n```\n\n---\n\n## Batch Remediation Strategy\n\n### Why Batch Updates?\n\n**Problems with one-at-a-time**:\n- Update fatigue (100+ dependencies)\n- Test overhead (N tests for N updates)\n- PR overhead (N reviews)\n- Potential conflicts (update A breaks with update B)\n\n**Benefits of batching**:\n- Single test run for all updates\n- Single PR review\n- Detect incompatibilities early\n- 6x faster (validated in meta-cc)\n\n### Batching Strategies\n\n**Strategy 1: By Severity**\n```bash\n# Batch 1: All security patches\n# Batch 2: All minor/patch updates\n# Batch 3: All major updates (breaking changes)\n```\n\n**Strategy 2: By Compatibility**\n```bash\n# Batch 1: Compatible updates (no breaking changes)\n# Batch 2: Breaking changes (one at a time)\n```\n\n**Strategy 3: By Timeline**\n```bash\n# Batch 1: Immediate (critical vulnerabilities)\n# Batch 2: Weekly (high vulnerabilities + freshness)\n# Batch 3: Monthly (medium vulnerabilities)\n# Batch 4: Quarterly (low vulnerabilities + license)\n```\n\n---\n\n## Policy-Driven Compliance\n\n### Security Policies\n\n```yaml\n# .dependency-policy.yml\nsecurity:\n  critical_vulnerabilities:\n    action: block_merge\n    max_age: 0 days\n  high_vulnerabilities:\n    action: block_merge\n    max_age: 7 days\n  medium_vulnerabilities:\n    action: warn\n    max_age: 30 days\n```\n\n### Freshness Policies\n\n```yaml\nfreshness:\n  max_age:\n    major: 12 months\n    minor: 6 months\n    patch: 3 months\n  exceptions:\n    - package: legacy-lib\n      reason: \"No maintained alternative\"\n```\n\n### License Policies\n\n```yaml\nlicenses:\n  allowed:\n    - MIT\n    - Apache-2.0\n    - BSD-3-Clause\n  denied:\n    - GPL-3.0  # Copyleft issues\n    - AGPL-3.0\n  review_required:\n    - Custom\n    - Proprietary\n```\n\n---\n\n## Automation Tools\n\n### Vulnerability Scanning\n\n```bash\n# Go: govulncheck\ngo install golang.org/x/vuln/cmd/govulncheck@latest\ngovulncheck ./...\n\n# Node.js: npm audit\nnpm audit --audit-level=moderate\n\n# Python: safety\npip install safety\nsafety check\n\n# Rust: cargo-audit\ncargo install cargo-audit\ncargo audit\n```\n\n### Automated Updates\n\n```bash\n# Dependabot (GitHub)\n# .github/dependabot.yml\nversion: 2\nupdates:\n  - package-ecosystem: \"gomod\"\n    directory: \"/\"\n    schedule:\n      interval: \"weekly\"\n    open-pull-requests-limit: 5\n    groups:\n      security:\n        patterns:\n          - \"*\"\n        update-types:\n          - \"patch\"\n          - \"minor\"\n```\n\n### License Checking\n\n```bash\n# Go: go-licenses\ngo install github.com/google/go-licenses@latest\ngo-licenses check ./...\n\n# Node.js: license-checker\nnpx license-checker --summary\n\n# Python: pip-licenses\npip install pip-licenses\npip-licenses\n```\n\n---\n\n## Proven Results\n\n**Validated in bootstrap-010** (meta-cc project):\n- âœ… Security-first prioritization implemented\n- âœ… Batch remediation (5 dependencies updated together)\n- âœ… 6x speedup: 9 hours manual â†’ 1.5 hours systematic\n- âœ… 3 iterations (rapid convergence)\n- âœ… V_instance: 0.92 (highest among experiments)\n- âœ… V_meta: 0.85\n\n**Metrics**:\n- Vulnerabilities: 2 critical â†’ 0 (resolved immediately)\n- Freshness: 45% outdated â†’ 15% outdated\n- License compliance: 100% (all MIT/Apache-2.0/BSD)\n\n**Transferability**:\n- Go (gomod): 100% (native)\n- Node.js (npm): 90% (npm audit similar)\n- Python (pip): 85% (safety similar)\n- Rust (cargo): 90% (cargo audit similar)\n- Java (Maven): 85% (OWASP dependency-check)\n- **Overall**: 88% transferable\n\n---\n\n## Common Patterns\n\n### Pattern 1: Security Update Workflow\n\n```bash\n# 1. Scan for vulnerabilities\ngovulncheck ./...\n\n# 2. Review severity\n# Critical/High â†’ immediate\n# Medium/Low â†’ batch\n\n# 3. Update dependencies\ngo get -u github.com/vulnerable/package@latest\n\n# 4. Test\ngo test ./...\n\n# 5. Commit\ngit commit -m \"fix(deps): resolve CVE-XXXX-XXXXX in package X\"\n```\n\n### Pattern 2: Monthly Freshness Update\n\n```bash\n# 1. Check for updates\ngo list -m -u all\n\n# 2. Batch updates (patch/minor)\ngo get -u=patch ./...\n\n# 3. Test\ngo test ./...\n\n# 4. Commit\ngit commit -m \"chore(deps): monthly dependency freshness update\"\n```\n\n### Pattern 3: Major Version Upgrade\n\n```bash\n# One at a time (breaking changes)\n# 1. Update single package\ngo get package@v2\n\n# 2. Fix breaking changes\n# ... code modifications ...\n\n# 3. Test extensively\ngo test ./...\n\n# 4. Commit\ngit commit -m \"feat(deps): upgrade package to v2\"\n```\n\n---\n\n## Anti-Patterns\n\nâŒ **Ignoring security advisories**: \"We'll update later\"\nâŒ **One-at-a-time updates**: 100 separate PRs for 100 dependencies\nâŒ **Automatic merging**: Dependabot auto-merge without testing\nâŒ **Dependency pinning forever**: Never updating to avoid breakage\nâŒ **License ignorance**: Not checking license compatibility\nâŒ **No testing after updates**: Assuming updates won't break anything\n\n---\n\n## Related Skills\n\n**Parent framework**:\n- [methodology-bootstrapping](../methodology-bootstrapping/SKILL.md) - Core OCA cycle\n\n**Complementary**:\n- [ci-cd-optimization](../ci-cd-optimization/SKILL.md) - Automated dependency checks in CI\n- [error-recovery](../error-recovery/SKILL.md) - Dependency failure handling\n\n**Acceleration**:\n- [rapid-convergence](../rapid-convergence/SKILL.md) - 3 iterations achieved\n\n---\n\n## References\n\n**Core guides**:\n- Reference materials in experiments/bootstrap-010-dependency-health/\n- Security-first prioritization framework\n- Batch remediation strategies\n- Policy-driven compliance\n\n**Tools**:\n- govulncheck (Go)\n- npm audit (Node.js)\n- safety (Python)\n- cargo-audit (Rust)\n- go-licenses (license checking)\n\n---\n\n**Status**: âœ… Production-ready | 6x speedup | 88% transferable | V_instance 0.92 (highest)\n"
      },
      "discovered_at": "2026-01-11T15:36:31.509901Z",
      "fetch_error": null
    },
    {
      "name": "error-recovery",
      "slug": "error-recovery",
      "source": "skillsmp",
      "owner": "yaleh",
      "repo_name": "meta-cc",
      "repository_url": "https://github.com/yaleh/meta-cc",
      "skill_path": ".claude/skills/error-recovery",
      "github_metadata": {
        "stars": 15,
        "description": "Meta-Cognition tool for Claude Code - analyze session history for workflow optimization.",
        "default_branch": "main",
        "pushed_at": "2025-12-13T10:31:07Z",
        "created_at": "2025-10-08T01:58:30Z",
        "language": "Go",
        "license": "MIT",
        "open_issues": 0,
        "forks": 1
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/error-recovery/SKILL.md",
        "branch": "main",
        "content": "---\nname: Error Recovery\ndescription: Comprehensive error handling methodology with 13-category taxonomy, diagnostic workflows, recovery patterns, and prevention guidelines. Use when error rate >5%, MTTD/MTTR too high, errors recurring, need systematic error prevention, or building error handling infrastructure. Provides error taxonomy (file operations, API calls, data validation, resource management, concurrency, configuration, dependency, network, parsing, state management, authentication, timeout, edge cases - 95.4% coverage), 8 diagnostic workflows, 5 recovery patterns, 8 prevention guidelines, 3 automation tools (file path validation, read-before-write check, file size validation - 23.7% error prevention). Validated with 1,336 historical errors, 85-90% transferability across languages/platforms, 0.79 confidence retrospective validation.\nallowed-tools: Read, Write, Edit, Bash, Grep, Glob\n---\n\n# Error Recovery\n\n**Systematic error handling: detection, diagnosis, recovery, and prevention.**\n\n> Errors are not failures - they're opportunities for systematic improvement. 95% of errors fall into 13 predictable categories.\n\n---\n\n## When to Use This Skill\n\nUse this skill when:\n- ğŸ“Š **High error rate**: >5% of operations fail\n- â±ï¸ **Slow recovery**: MTTD (Mean Time To Detect) or MTTR (Mean Time To Resolve) too high\n- ğŸ”„ **Recurring errors**: Same errors happen repeatedly\n- ğŸ¯ **Building error infrastructure**: Need systematic error handling\n- ğŸ“ˆ **Prevention focus**: Want to prevent errors, not just handle them\n- ğŸ” **Root cause analysis**: Need diagnostic frameworks\n\n**Don't use when**:\n- âŒ Error rate <1% (handling ad-hoc sufficient)\n- âŒ Errors are truly random (no patterns)\n- âŒ No historical data (can't establish taxonomy)\n- âŒ Greenfield project (no errors yet)\n\n---\n\n## Quick Start (20 minutes)\n\n### Step 1: Quantify Baseline (10 min)\n\n```bash\n# For meta-cc projects\nmeta-cc query-tools --status error | jq '. | length'\n# Output: Total error count\n\n# Calculate error rate\nmeta-cc get-session-stats | jq '.total_tool_calls'\necho \"Error rate: errors / total * 100\"\n\n# Analyze distribution\nmeta-cc query-tools --status error | \\\n  jq -r '.error_message' | \\\n  sed 's/:.*//' | sort | uniq -c | sort -rn | head -10\n# Output: Top 10 error types\n```\n\n### Step 2: Classify Errors (5 min)\n\nMap errors to 13 categories (see taxonomy below):\n- File operations (12.2%)\n- API calls, Data validation, Resource management, etc.\n\n### Step 3: Apply Top 3 Prevention Tools (5 min)\n\nBased on bootstrap-003 validation:\n1. **File path validation** (prevents 12.2% of errors)\n2. **Read-before-write check** (prevents 5.2%)\n3. **File size validation** (prevents 6.3%)\n\n**Total prevention**: 23.7% of errors\n\n---\n\n## 13-Category Error Taxonomy\n\nValidated with 1,336 errors (95.4% coverage):\n\n### 1. File Operations (12.2%)\n- File not found, permission denied, path validation\n- **Prevention**: Validate paths before use, check existence\n\n### 2. API Calls (8.7%)\n- HTTP errors, timeouts, invalid responses\n- **Recovery**: Retry with exponential backoff\n\n### 3. Data Validation (7.5%)\n- Invalid format, missing fields, type mismatches\n- **Prevention**: Schema validation, type checking\n\n### 4. Resource Management (6.3%)\n- File handles, memory, connections not cleaned up\n- **Prevention**: Defer cleanup, use resource pools\n\n### 5. Concurrency (5.8%)\n- Race conditions, deadlocks, channel errors\n- **Recovery**: Timeout mechanisms, panic recovery\n\n### 6. Configuration (5.4%)\n- Missing config, invalid values, env var issues\n- **Prevention**: Config validation at startup\n\n### 7. Dependency Errors (5.2%)\n- Missing dependencies, version conflicts\n- **Prevention**: Dependency validation in CI\n\n### 8. Network Errors (4.9%)\n- Connection refused, DNS failures, proxy issues\n- **Recovery**: Retry, fallback to alternative endpoints\n\n### 9. Parsing Errors (4.3%)\n- JSON/XML parse failures, malformed input\n- **Prevention**: Validate before parsing\n\n### 10. State Management (3.7%)\n- Invalid state transitions, missing initialization\n- **Prevention**: State machine validation\n\n### 11. Authentication (2.8%)\n- Invalid credentials, expired tokens\n- **Recovery**: Token refresh, re-authentication\n\n### 12. Timeout Errors (2.4%)\n- Operation exceeded time limit\n- **Prevention**: Set appropriate timeouts\n\n### 13. Edge Cases (1.2%)\n- Boundary conditions, unexpected inputs\n- **Prevention**: Comprehensive test coverage\n\n**Uncategorized**: 4.6% (edge cases, unique errors)\n\n---\n\n## Eight Diagnostic Workflows\n\n### 1. File Operation Diagnosis\n1. Check file existence\n2. Verify permissions\n3. Validate path format\n4. Check disk space\n\n### 2. API Call Diagnosis\n1. Verify endpoint availability\n2. Check network connectivity\n3. Validate request format\n4. Review response codes\n\n### 3-8. (See reference/diagnostic-workflows.md for complete workflows)\n\n---\n\n## Five Recovery Patterns\n\n### 1. Retry with Exponential Backoff\n**Use for**: Transient errors (network, API timeouts)\n```go\nfor i := 0; i < maxRetries; i++ {\n    err := operation()\n    if err == nil {\n        return nil\n    }\n    time.Sleep(time.Duration(math.Pow(2, float64(i))) * time.Second)\n}\nreturn fmt.Errorf(\"operation failed after %d retries\", maxRetries)\n```\n\n### 2. Fallback to Alternative\n**Use for**: Service unavailability\n\n### 3. Graceful Degradation\n**Use for**: Non-critical functionality failures\n\n### 4. Circuit Breaker\n**Use for**: Cascading failures prevention\n\n### 5. Panic Recovery\n**Use for**: Unhandled runtime errors\n\nSee [reference/recovery-patterns.md](reference/recovery-patterns.md) for complete patterns.\n\n---\n\n## Eight Prevention Guidelines\n\n1. **Validate inputs early**: Check before processing\n2. **Use type-safe APIs**: Leverage static typing\n3. **Implement pre-conditions**: Assert expectations\n4. **Defensive programming**: Handle unexpected cases\n5. **Fail fast**: Detect errors immediately\n6. **Log comprehensively**: Capture error context\n7. **Test error paths**: Don't just test happy paths\n8. **Monitor error rates**: Track trends over time\n\nSee [reference/prevention-guidelines.md](reference/prevention-guidelines.md).\n\n---\n\n## Three Automation Tools\n\n### 1. File Path Validator\n**Prevents**: 12.2% of errors (163/1,336)\n**Usage**: Validate file paths before Read/Write operations\n**Confidence**: 93.3% (sample validation)\n\n### 2. Read-Before-Write Checker\n**Prevents**: 5.2% of errors (70/1,336)\n**Usage**: Verify file readable before writing\n**Confidence**: 90%+\n\n### 3. File Size Validator\n**Prevents**: 6.3% of errors (84/1,336)\n**Usage**: Check file size before processing\n**Confidence**: 95%+\n\n**Total prevention**: 317 errors (23.7%) with 0.79 overall confidence\n\nSee [scripts/](scripts/) for implementation.\n\n---\n\n## Proven Results\n\n**Validated in bootstrap-003** (meta-cc project):\n- âœ… 1,336 errors analyzed\n- âœ… 13-category taxonomy (95.4% coverage)\n- âœ… 23.7% error prevention validated\n- âœ… 3 iterations, 10 hours (rapid convergence)\n- âœ… V_instance: 0.83\n- âœ… V_meta: 0.85\n- âœ… Confidence: 0.79 (high)\n\n**Transferability**:\n- Error taxonomy: 95% (errors universal across languages)\n- Diagnostic workflows: 90% (process universal, tools vary)\n- Recovery patterns: 85% (patterns universal, syntax varies)\n- Prevention guidelines: 90% (principles universal)\n- **Overall**: 85-90% transferable\n\n---\n\n## Related Skills\n\n**Parent framework**:\n- [methodology-bootstrapping](../methodology-bootstrapping/SKILL.md) - Core OCA cycle\n\n**Acceleration used**:\n- [rapid-convergence](../rapid-convergence/SKILL.md) - 3 iterations achieved\n- [retrospective-validation](../retrospective-validation/SKILL.md) - 1,336 historical errors\n\n**Complementary**:\n- [testing-strategy](../testing-strategy/SKILL.md) - Error path testing\n- [observability-instrumentation](../observability-instrumentation/SKILL.md) - Error logging\n\n---\n\n## References\n\n**Core methodology**:\n- [Error Taxonomy](reference/taxonomy.md) - 13 categories detailed\n- [Diagnostic Workflows](reference/diagnostic-workflows.md) - 8 workflows\n- [Recovery Patterns](reference/recovery-patterns.md) - 5 patterns\n- [Prevention Guidelines](reference/prevention-guidelines.md) - 8 guidelines\n\n**Automation**:\n- [Validation Tools](scripts/) - 3 prevention tools\n\n**Examples**:\n- [File Operation Errors](examples/file-operation-errors.md) - Common patterns\n- [API Error Handling](examples/api-error-handling.md) - Retry strategies\n\n---\n\n**Status**: âœ… Production-ready | 1,336 errors validated | 23.7% prevention | 85-90% transferable\n"
      },
      "discovered_at": "2026-01-11T15:36:32.023968Z",
      "fetch_error": null
    },
    {
      "name": "knowledge-transfer",
      "slug": "knowledge-transfer",
      "source": "skillsmp",
      "owner": "yaleh",
      "repo_name": "meta-cc",
      "repository_url": "https://github.com/yaleh/meta-cc",
      "skill_path": ".claude/skills/knowledge-transfer",
      "github_metadata": {
        "stars": 15,
        "description": "Meta-Cognition tool for Claude Code - analyze session history for workflow optimization.",
        "default_branch": "main",
        "pushed_at": "2025-12-13T10:31:07Z",
        "created_at": "2025-10-08T01:58:30Z",
        "language": "Go",
        "license": "MIT",
        "open_issues": 0,
        "forks": 1
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/knowledge-transfer/SKILL.md",
        "branch": "main",
        "content": "---\nname: Knowledge Transfer\ndescription: Progressive learning methodology for structured onboarding using time-boxed learning paths (Day-1, Week-1, Month-1), validation checkpoints, and scaffolding principles. Use when onboarding new contributors, reducing ramp-up time from weeks to days, creating self-service learning paths, systematizing ad-hoc knowledge sharing, or building institutional knowledge preservation. Provides 3 learning path templates (Day-1: 4-8h setupâ†’contribution, Week-1: 20-40h architectureâ†’feature, Month-1: 40-160h expertiseâ†’mentoring), progressive disclosure pattern, validation checkpoint principle, module mastery best practice. Validated with 3-8x onboarding speedup (structured vs. unstructured), 95%+ transferability to any software project (Go, Rust, Python, TypeScript). Learning theory principles applied: progressive disclosure, scaffolding, validation checkpoints, time-boxing.\nallowed-tools: Read, Write, Edit, Grep, Glob\n---\n\n# Knowledge Transfer\n\n**Reduce onboarding time by 3-8x with structured learning paths.**\n\n> Progressive disclosure, scaffolding, and validation checkpoints transform weeks of confusion into days of productive learning.\n\n---\n\n## When to Use This Skill\n\nUse this skill when:\n- ğŸ‘¥ **Onboarding contributors**: New developers joining project\n- â° **Slow ramp-up**: Weeks to first meaningful contribution\n- ğŸ“š **Ad-hoc knowledge sharing**: Unstructured, mentor-dependent learning\n- ğŸ“ˆ **Scaling teams**: Can't rely on 1-on-1 mentoring\n- ğŸ”„ **Knowledge preservation**: Institutional knowledge at risk\n- ğŸ¯ **Clear learning paths**: Need structured Day-1, Week-1, Month-1 plans\n\n**Don't use when**:\n- âŒ Single contributor projects (no onboarding needed)\n- âŒ Onboarding already optimal (<1 week to productivity)\n- âŒ Non-software projects without adaptation\n- âŒ No time to create learning paths (requires 4-8h investment)\n\n---\n\n## Quick Start (30 minutes)\n\n### Step 1: Assess Current Onboarding (10 min)\n\n**Questions to answer**:\n- How long does it take for new contributors to make their first meaningful contribution?\n- What documentation exists? (README, architecture docs, development guides)\n- What do contributors struggle with most? (setup, architecture, workflows)\n\n**Baseline**: Unstructured onboarding typically takes 4-12 weeks to productivity.\n\n### Step 2: Create Day-1 Learning Path (15 min)\n\n**Structure**:\n1. **Environment Setup** (1-2h): Installation, build, test\n2. **Project Understanding** (1-2h): Purpose, structure, core concepts\n3. **Code Navigation** (1-2h): Find files, search code, read docs\n4. **First Contribution** (1-2h): Trivial fix (typo, comment)\n\n**Validation**: PR submitted, tests passing, CI green\n\n### Step 3: Plan Week-1 and Month-1 Paths (5 min)\n\n**Week-1 Focus**: Architecture understanding, module mastery, meaningful contribution (20-40h)\n\n**Month-1 Focus**: Domain expertise, significant feature, code ownership, mentoring (40-160h)\n\n---\n\n## Three Learning Path Templates\n\n### 1. Day-1 Learning Path (4-8 hours)\n\n**Purpose**: Get contributor from zero to first contribution in one day\n\n**Four Sections**:\n\n**Section 1: Environment Setup** (1-2h)\n- Prerequisites documented (Go 1.21+, git, make)\n- Step-by-step installation instructions\n- Build verification (`make all`)\n- Test suite execution (`make test`)\n- **Validation**: Can build and test successfully\n\n**Section 2: Project Understanding** (1-2h)\n- Project purpose and value proposition\n- Repository structure overview (cmd/, internal/, docs/)\n- Core concepts (3-5 key ideas)\n- User personas and use cases\n- **Validation**: Can explain project purpose in 2-3 sentences\n\n**Section 3: Code Navigation** (1-2h)\n- File finding strategies (grep, find, IDE navigation)\n- Code search techniques (function definitions, usage sites)\n- Documentation navigation (README, docs/, code comments)\n- Development workflows (TDD, git flow)\n- **Validation**: Can find specific function in codebase within 2 minutes\n\n**Section 4: First Contribution** (1-2h)\n- Good first issues identified (typo fixes, comment improvements)\n- Contribution process (fork, branch, PR)\n- Code review expectations\n- CI/CD validation\n- **Validation**: PR submitted with tests passing\n\n**Success Criteria**:\n- âœ… Environment working (built, tested)\n- âœ… Basic understanding (can explain purpose)\n- âœ… Code navigation skills (can find files/functions)\n- âœ… First PR submitted (trivial contribution)\n\n**Transferability**: 80% (environment setup is project-specific)\n\n---\n\n### 2. Week-1 Learning Path (20-40 hours)\n\n**Purpose**: Deep architecture understanding and first meaningful contribution\n\n**Four Sections**:\n\n**Section 1: Architecture Deep Dive** (5-10h)\n- System design overview (components, data flow)\n- Integration points (APIs, databases, external services)\n- Design patterns used (MVC, dependency injection)\n- Architectural decisions (ADRs)\n- **Validation**: Can draw architecture diagram, explain data flow\n\n**Section 2: Module Mastery** (8-15h)\n- Core modules identified (3-5 critical modules)\n- Dependency-ordered learning (foundational â†’ higher-level)\n- Module APIs and interfaces\n- Integration between modules\n- **Best Practice**: Study modules in dependency order\n- **Validation**: Can explain each module's purpose and key functions\n\n**Section 3: Development Workflows** (3-5h)\n- TDD workflow (write tests first)\n- Debugging techniques (debugger, logging)\n- Git workflows (feature branches, rebasing)\n- Code review process (standards, checklist)\n- **Validation**: Can follow TDD cycle, submit quality PR\n\n**Section 4: Meaningful Contribution** (4-10h)\n- \"Good first issue\" selection (small feature, bug fix)\n- Feature implementation (with tests)\n- Code review iteration\n- Feature merged\n- **Validation**: Feature merged, code review feedback incorporated\n\n**Success Criteria**:\n- âœ… Architecture understanding (can explain design)\n- âœ… Module mastery (know 3-5 core modules)\n- âœ… Development workflows (TDD, git, code review)\n- âœ… Meaningful contribution (feature merged)\n\n**Transferability**: 75% (module names and architecture are project-specific)\n\n---\n\n### 3. Month-1 Learning Path (40-160 hours)\n\n**Purpose**: Build deep expertise, deliver significant feature, enable mentoring\n\n**Four Sections**:\n\n**Section 1: Domain Selection & Deep Dive** (10-40h)\n- Domain areas identified (e.g., Parser, Analyzer, Query, MCP, CLI)\n- Domain selection (choose based on interest and project need)\n- Deep dive resources (docs, code, architecture)\n- Domain patterns and anti-patterns\n- **Validation**: Deep dive deliverable (design doc, refactoring proposal)\n\n**Section 2: Significant Feature Development** (15-60h)\n- Feature definition (200+ lines, multi-module, complex logic)\n- Design document creation\n- Implementation with comprehensive tests\n- Performance considerations\n- **Validation**: Significant feature merged (200+ lines)\n\n**Section 3: Code Ownership & Expertise** (10-40h)\n- Reviewer role for domain\n- Issue triaging and assignment\n- Architecture improvement proposals\n- Performance optimization\n- **Validation**: Reviewed 3+ PRs, triaged 5+ issues\n\n**Section 4: Community & Mentoring** (5-20h)\n- Mentoring new contributors (guide through first PR)\n- Documentation improvements (based on learning experience)\n- Knowledge sharing (internal presentations, blog posts)\n- Community engagement (discussions, issue responses)\n- **Validation**: Mentored 1+ contributor, improved documentation\n\n**Success Criteria**:\n- âœ… Deep domain expertise (go-to expert in one area)\n- âœ… Significant feature delivered (200+ lines, merged)\n- âœ… Code ownership (reviewer, triager)\n- âœ… Mentoring capability (guided new contributor)\n\n**Transferability**: 85% (domain specialization framework is universal)\n\n---\n\n## Learning Theory Principles\n\n### 1. Progressive Disclosure âœ…\n\n**Definition**: Reveal complexity gradually to avoid overwhelming learners\n\n**Application**:\n- Day-1: Basic setup and understanding (minimal complexity)\n- Week-1: Architecture and module mastery (medium complexity)\n- Month-1: Expertise and mentoring (high complexity)\n\n**Evidence**: Each path builds on previous, complexity increases systematically\n\n---\n\n### 2. Scaffolding âœ…\n\n**Definition**: Provide support that reduces over time as learner gains independence\n\n**Application**:\n- Day-1: Highly guided (step-by-step instructions, explicit prerequisites)\n- Week-1: Semi-guided (structured sections, some autonomy)\n- Month-1: Mostly independent (domain selection choice, self-directed deep dives)\n\n**Evidence**: Support level decreases across paths (guided â†’ semi-independent â†’ independent)\n\n---\n\n### 3. Validation Checkpoints âœ…\n\n**Principle**: \"Every learning stage needs clear, actionable validation criteria that enable self-assessment without external dependency\"\n\n**Rationale**:\n- Self-directed learning requires confidence in progress\n- External validation doesn't scale (maintainer bottleneck)\n- Clear checkpoints prevent confusion and false confidence\n\n**Implementation**:\n- Checklists with specific items (not vague \"understand X\")\n- Success criteria with measurable outcomes (PR merged, tests passing)\n- Self-assessment questions (can you explain Y? can you implement Z?)\n\n**Universality**: 95%+ (applies to any learning context)\n\n---\n\n### 4. Time-Boxing âœ…\n\n**Definition**: Realistic time estimates help learners plan and avoid frustration\n\n**Application**:\n- Day-1: 4-8 hours (clear boundary)\n- Week-1: 20-40 hours (flexible but bounded)\n- Month-1: 40-160 hours (wide range for depth variation)\n\n**Evidence**: All paths have explicit time estimates with min-max ranges\n\n---\n\n## Module Mastery Best Practice\n\n**Context**: Week-1 contributor learning complex codebase with multiple interconnected modules\n\n**Problem**: Without structure, contributors randomly jump between modules, missing critical dependencies\n\n**Solution**: Architecture-first, sequential module deep dives\n\n**Approach**:\n1. **Architecture Overview First**: Understand system design before diving into modules\n2. **Dependency-Ordered Sequence**: Study modules in dependency order (foundational â†’ higher-level)\n3. **Deliberate Practice**: Build small examples after each module to validate understanding\n4. **Integration Understanding**: After individual modules, understand how they interact\n\n**Example** (meta-cc):\n- Architecture: Two-layer (CLI + MCP), 3 core packages (parser, analyzer, query)\n- Sequence: Parser (foundation) â†’ Analyzer (uses parser) â†’ Query (uses both)\n- Practice: Write small programs using each module's API\n- Integration: Understand MCP server coordination of all 3 modules\n\n**Transferability**: 80% (applies to modular architectures)\n\n---\n\n## Proven Results\n\n**Validated in bootstrap-011 (meta-cc project)**:\n- âœ… Meta layer: V_meta = 0.877 (CONVERGED)\n- âœ… 3 learning path templates complete (Day-1, Week-1, Month-1)\n- âœ… 6 knowledge artifacts created (3 templates, 1 pattern, 1 principle, 1 best practice)\n- âœ… Duration: 4 iterations, ~8 hours\n- âœ… 3-8x onboarding speedup demonstrated (structured vs. unstructured)\n\n**Onboarding Time Comparison**:\n- Traditional unstructured: 4-12 weeks to productivity\n- Structured methodology: 1.5-5 weeks to same outcome\n- **Speedup**: 3-8x faster âœ…\n\n**Transferability Validation**:\n- Go projects: 95-97% transferable\n- Rust projects: 90-95% transferable (6-8h adaptation)\n- Python projects: 85-90% transferable (8-10h adaptation)\n- TypeScript projects: 80-85% transferable (10-12h adaptation)\n- **Overall**: 95%+ transferable âœ…\n\n---\n\n## Complete Onboarding Lifecycle\n\n**Total Time**: 64-208 hours (1.5-5 weeks @ 40h/week)\n\n**Day-1 (4-8 hours)**:\n- Environment setup â†’ Project understanding â†’ Code navigation â†’ First contribution\n- **Outcome**: PR submitted, tests passing\n\n**Week-1 (20-40 hours)** (requires Day-1 completion):\n- Architecture deep dive â†’ Module mastery â†’ Development workflows â†’ Meaningful contribution\n- **Outcome**: Feature merged, architecture understanding validated\n\n**Month-1 (40-160 hours)** (requires Week-1 completion):\n- Domain deep dive â†’ Significant feature â†’ Code ownership â†’ Mentoring\n- **Outcome**: Domain expert status, significant feature merged, mentored contributor\n\n**Progressive Complexity**: Simple â†’ Medium â†’ Complex\n**Progressive Independence**: Guided â†’ Semi-independent â†’ Independent\n**Progressive Impact**: Trivial fix â†’ Small feature â†’ Significant feature\n\n---\n\n## Common Anti-Patterns\n\nâŒ **Information overload**: Dumping all knowledge on Day-1 (overwhelms learner)\nâŒ **No validation**: Missing self-assessment checkpoints (learner uncertain of progress)\nâŒ **Vague success criteria**: \"Understand architecture\" (not measurable)\nâŒ **No time estimates**: Undefined time commitment (causes frustration)\nâŒ **Dependency violations**: Teaching advanced concepts before fundamentals\nâŒ **External validation dependency**: Requiring mentor approval for every step (doesn't scale)\n\n---\n\n## Templates and Examples\n\n### Templates\n- [Day-1 Learning Path Template](templates/day1-learning-path-template.md) - First-day onboarding\n- [Week-1 Learning Path Template](templates/week1-learning-path-template.md) - First-week architecture and modules\n- [Month-1 Learning Path Template](templates/month1-learning-path-template.md) - First-month expertise building\n\n### Examples\n- [Progressive Learning Path Pattern](examples/progressive-learning-path-pattern.md) - Time-boxed learning structure\n- [Validation Checkpoint Principle](examples/validation-checkpoint-principle.md) - Self-assessment criteria\n- [Module Mastery Onboarding](examples/module-mastery-best-practice.md) - Architecture-first learning\n\n---\n\n## Related Skills\n\n**Parent framework**:\n- [methodology-bootstrapping](../methodology-bootstrapping/SKILL.md) - Core OCA cycle\n\n**Complementary domains**:\n- [cross-cutting-concerns](../cross-cutting-concerns/SKILL.md) - Pattern extraction for learning materials\n- [technical-debt-management](../technical-debt-management/SKILL.md) - Documentation debt prioritization\n\n---\n\n## References\n\n**Core methodology**:\n- [Progressive Learning Path](reference/progressive-learning-path.md) - Full pattern documentation\n- [Validation Checkpoints](reference/validation-checkpoints.md) - Self-assessment guide\n- [Module Mastery](reference/module-mastery.md) - Dependency-ordered learning\n- [Learning Theory](reference/learning-theory.md) - Principles and evidence\n\n**Quick guides**:\n- [Creating Day-1 Path](reference/create-day1-path.md) - 15-minute guide\n- [Adaptation Guide](reference/adaptation-guide.md) - Transfer to other projects\n\n---\n\n**Status**: âœ… Production-ready | Validated in meta-cc | 3-8x speedup | 95%+ transferable\n"
      },
      "discovered_at": "2026-01-11T15:36:32.343956Z",
      "fetch_error": null
    },
    {
      "name": "methodology-bootstrapping",
      "slug": "methodology-bootstrapping",
      "source": "skillsmp",
      "owner": "yaleh",
      "repo_name": "meta-cc",
      "repository_url": "https://github.com/yaleh/meta-cc",
      "skill_path": ".claude/skills/methodology-bootstrapping",
      "github_metadata": {
        "stars": 15,
        "description": "Meta-Cognition tool for Claude Code - analyze session history for workflow optimization.",
        "default_branch": "main",
        "pushed_at": "2025-12-13T10:31:07Z",
        "created_at": "2025-10-08T01:58:30Z",
        "language": "Go",
        "license": "MIT",
        "open_issues": 0,
        "forks": 1
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/methodology-bootstrapping/SKILL.md",
        "branch": "main",
        "content": "---\nname: Methodology Bootstrapping\ndescription: Apply Bootstrapped AI Methodology Engineering (BAIME) to develop project-specific methodologies through systematic Observe-Codify-Automate cycles with dual-layer value functions (instance quality + methodology quality). Use when creating testing strategies, CI/CD pipelines, error handling patterns, observability systems, or any reusable development methodology. Provides structured framework with convergence criteria, agent coordination, and empirical validation. Validated in 8 experiments with 100% success rate, 4.9 avg iterations, 10-50x speedup vs ad-hoc. Works for testing, CI/CD, error recovery, dependency management, documentation systems, knowledge transfer, technical debt, cross-cutting concerns.\nallowed-tools: Read, Grep, Glob, Edit, Write, Bash\n---\n\n# Methodology Bootstrapping\n\n**Apply Bootstrapped AI Methodology Engineering (BAIME) to systematically develop and validate software engineering methodologies through observation, codification, and automation.**\n\n> The best methodologies are not designed but evolved through systematic observation, codification, and automation of successful practices.\n\n---\n\n## What is BAIME?\n\n**BAIME (Bootstrapped AI Methodology Engineering)** is a unified framework that integrates three complementary methodologies optimized for LLM-based development:\n\n1. **OCA Cycle** (Observe-Codify-Automate) - Core iterative framework\n2. **Empirical Validation** - Scientific method and data-driven decisions\n3. **Value Optimization** - Dual-layer value functions for quantitative evaluation\n\nThis skill provides the complete BAIME framework for systematic methodology development. The methodology is especially powerful when combined with AI agents (like Claude Code) that can execute the OCA cycle, coordinate specialized agents, and calculate value functions automatically.\n\n**Key Innovation**: BAIME treats methodology development like software developmentâ€”with empirical observation, automated testing, continuous iteration, and quantitative metrics.\n\n---\n\n## When to Use This Skill\n\nUse this skill when you need to:\n- ğŸ¯ **Create systematic methodologies** for testing, CI/CD, error handling, observability, etc.\n- ğŸ“Š **Validate methodologies empirically** with data-driven evidence\n- ğŸ”„ **Evolve practices iteratively** using OCA (Observe-Codify-Automate) cycle\n- ğŸ“ˆ **Measure methodology quality** with dual-layer value functions\n- ğŸš€ **Achieve rapid convergence** (typically 3-7 iterations, 6-15 hours)\n- ğŸŒ **Create transferable methodologies** (70-95% reusable across projects)\n\n**Don't use this skill for**:\n- âŒ One-time ad-hoc tasks without reusability goals\n- âŒ Trivial processes (<100 lines of code/docs)\n- âŒ When established industry standards fully solve your problem\n\n---\n\n## Quick Start with BAIME (10 minutes)\n\n### 1. Define Your Domain\nChoose what methodology you want to develop using BAIME:\n- Testing strategy (15x speedup example)\n- CI/CD pipeline (2.5-3.5x speedup example)\n- Error recovery patterns (80% error reduction example)\n- Observability system (23-46x speedup example)\n- Dependency management (6x speedup example)\n- Documentation system (47% token cost reduction example)\n- Knowledge transfer (3-8x speedup example)\n- Technical debt management\n- Cross-cutting concerns\n\n### 2. Establish Baseline\nMeasure current state:\n```bash\n# Example: Testing domain\n- Current coverage: 65%\n- Test quality: Ad-hoc\n- No systematic approach\n- Bug rate: Baseline\n\n# Example: CI/CD domain\n- Build time: 5 minutes\n- No quality gates\n- Manual releases\n```\n\n### 3. Set Dual Goals\nDefine both layers:\n- **Instance goal** (domain-specific): \"Reach 80% test coverage\"\n- **Meta goal** (methodology): \"Create reusable testing strategy with 85%+ transferability\"\n\n### 4. Start Iteration 0\nFollow the OCA cycle (see [reference/observe-codify-automate.md](reference/observe-codify-automate.md))\n\n---\n\n## Specialized Subagents\n\nBAIME provides two specialized Claude Code subagents to streamline experiment execution:\n\n### iteration-prompt-designer\n\n**When to use**: At experiment start, to create comprehensive ITERATION-PROMPTS.md\n\n**What it does**:\n- Designs iteration templates tailored to your domain\n- Incorporates modular Meta-Agent architecture\n- Provides domain-specific guidance for each iteration\n- Creates structured prompts for baseline and subsequent iterations\n\n**How to invoke**:\n```\nUse the Task tool with subagent_type=\"iteration-prompt-designer\"\n\nExample:\n\"Design ITERATION-PROMPTS.md for refactoring methodology experiment\"\n```\n\n**Benefits**:\n- âœ… Comprehensive iteration prompts (saves 2-3 hours setup time)\n- âœ… Domain-specific value function design\n- âœ… Proper baseline iteration structure\n- âœ… Evidence-driven evolution guidance\n\n---\n\n### iteration-executor\n\n**When to use**: For each iteration execution (Iteration 0, 1, 2, ...)\n\n**What it does**:\n- Executes iteration through lifecycle phases (Observe â†’ Codify â†’ Automate â†’ Evaluate)\n- Coordinates Meta-Agent capabilities and agent invocations\n- Tracks state transitions (M_{n-1} â†’ M_n, A_{n-1} â†’ A_n, s_{n-1} â†’ s_n)\n- Calculates dual-layer value functions (V_instance, V_meta) systematically\n- Evaluates convergence criteria rigorously\n- Generates complete iteration documentation\n\n**How to invoke**:\n```\nUse the Task tool with subagent_type=\"iteration-executor\"\n\nExample:\n\"Execute Iteration 2 of testing methodology experiment using iteration-executor\"\n```\n\n**Benefits**:\n- âœ… Consistent iteration structure across experiments\n- âœ… Systematic value calculation (reduces bias, improves honesty)\n- âœ… Proper convergence evaluation (prevents premature convergence)\n- âœ… Complete artifact generation (data, knowledge, reflections)\n- âœ… Reduced iteration time (structured execution vs ad-hoc)\n\n**Important**: iteration-executor reads capability files fresh each iteration (no caching) to ensure latest guidance is applied.\n\n---\n\n### knowledge-extractor\n\n**When to use**: After experiment converges, to extract and transform knowledge into reusable artifacts\n\n**What it does**:\n- Extracts patterns, principles, templates from converged BAIME experiment\n- Transforms experiment artifacts into production-ready Claude Code skills\n- Creates knowledge base entries (patterns/*.md, principles/*.md)\n- Validates output quality with structured criteria (V_instance â‰¥ 0.85)\n- Achieves 195x speedup (2 min vs 390 min manual extraction)\n- Produces distributable, reusable artifacts for the community\n\n**How to invoke**:\n```\nUse the Task tool with subagent_type=\"knowledge-extractor\"\n\nExample:\n\"Extract knowledge from Bootstrap-004 refactoring experiment and create code-refactoring skill using knowledge-extractor\"\n```\n\n**Benefits**:\n- âœ… Systematic knowledge preservation (vs ad-hoc documentation)\n- âœ… Reusable Claude Code skills (ready for distribution)\n- âœ… Quality validation (95% content equivalence to hand-crafted)\n- âœ… Fast extraction (2-5 min, 195x speedup)\n- âœ… Knowledge base population (patterns, principles, templates)\n- âœ… Automated artifact generation (43% workflow automation with 4 tools)\n\n**Lifecycle position**: Post-Convergence phase\n```\nExperiment Design â†’ iteration-prompt-designer â†’ ITERATION-PROMPTS.md\n       â†“\nIterate â†’ iteration-executor (x N) â†’ iteration-0..N.md\n       â†“\nConverge â†’ Create results.md\n       â†“\nExtract â†’ knowledge-extractor â†’ .claude/skills/ + knowledge/\n       â†“\nDistribute â†’ Claude Code users\n```\n\n**Validated performance** (Bootstrap-005):\n- Speedup: 195x (390 min â†’ 2 min)\n- Quality: V_instance = 0.87, 95% content equivalence\n- Reliability: 100% success across 3 experiments\n- Automation: 43% of workflow (6/14 steps)\n\n---\n\n## Core Framework\n\n### The OCA Cycle\n\n```\nObserve â†’ Codify â†’ Automate\n   â†‘                    â†“\n   â””â”€â”€â”€â”€â”€â”€ Evolve â”€â”€â”€â”€â”€â”€â”˜\n```\n\n**Observe**: Collect empirical data about current practices\n- Use meta-cc MCP tools to analyze session history\n- Git analysis for commit patterns\n- Code metrics (coverage, complexity)\n- Access pattern tracking\n- Error rate monitoring\n\n**Codify**: Extract patterns and document methodologies\n- Pattern recognition from data\n- Hypothesis formation\n- Documentation as markdown\n- Validation with real scenarios\n\n**Automate**: Convert methodologies to automated checks\n- Detection: Identify when pattern applies\n- Validation: Check compliance\n- Enforcement: CI/CD gates\n- Suggestion: Automated fix recommendations\n\n**Evolve**: Apply methodology to itself for continuous improvement\n- Use tools on development process\n- Discover meta-patterns\n- Optimize methodology\n\n**Detailed guide**: [reference/observe-codify-automate.md](reference/observe-codify-automate.md)\n\n### Dual-Layer Value Functions\n\nEvery iteration calculates two scores:\n\n**V_instance(s)**: Domain-specific task quality\n- Example (testing): coverage Ã— quality Ã— stability Ã— performance\n- Example (CI/CD): speed Ã— reliability Ã— automation Ã— observability\n- Target: â‰¥0.80\n\n**V_meta(s)**: Methodology transferability quality\n- Components: completeness Ã— effectiveness Ã— reusability Ã— validation\n- Completeness: Is methodology fully documented?\n- Effectiveness: What speedup does it provide?\n- Reusability: What % transferable across projects?\n- Validation: Is it empirically validated?\n- Target: â‰¥0.80\n\n**Detailed guide**: [reference/dual-value-functions.md](reference/dual-value-functions.md)\n\n### Convergence Criteria\n\nMethodology complete when:\n1. âœ… **System stable**: Agent set unchanged for 2+ iterations\n2. âœ… **Dual threshold**: V_instance â‰¥ 0.80 AND V_meta â‰¥ 0.80\n3. âœ… **Objectives complete**: All planned work finished\n4. âœ… **Diminishing returns**: Î”V < 0.02 for 2+ iterations\n\n**Alternative patterns**:\n- **Meta-Focused Convergence**: V_meta â‰¥ 0.80, V_instance â‰¥ 0.55 (when methodology is primary goal)\n- **Practical Convergence**: Combined quality exceeds metrics, justified partial criteria\n\n**Detailed guide**: [reference/convergence-criteria.md](reference/convergence-criteria.md)\n\n---\n\n## Iteration Documentation Structure\n\nEvery BAIME iteration must produce a comprehensive iteration report following a standardized 10-section structure. This ensures consistent quality, complete knowledge capture, and reproducible methodology development.\n\n### Required Sections\n\n**See complete example**: [examples/iteration-documentation-example.md](examples/iteration-documentation-example.md)\n\n**Use blank template**: [examples/iteration-structure-template.md](examples/iteration-structure-template.md)\n\n1. **Executive Summary** (2-3 paragraphs)\n   - Iteration focus and objectives\n   - Key achievements\n   - Key learnings\n   - Value scores (V_instance, V_meta)\n\n2. **Pre-Execution Context**\n   - Previous state: M_{n-1}, A_{n-1}, s_{n-1}\n   - Previous values: V_instance(s_{n-1}), V_meta(s_{n-1}) with component breakdowns\n   - Primary objectives for this iteration\n\n3. **Work Executed** (organized by BAIME phases)\n   - **Phase 1: OBSERVE** - Data collection, measurements, gap identification\n   - **Phase 2: CODIFY** - Pattern extraction, documentation, knowledge creation\n   - **Phase 3: AUTOMATE** - Tool creation, script development, enforcement\n   - **Phase 4: EVALUATE** - Metric calculation, value assessment\n\n4. **Value Calculations** (detailed, evidence-based)\n   - **V_instance(s_n)** with component breakdowns\n     - Each component score with concrete evidence\n     - Formula application with arithmetic\n     - Final score calculation\n     - Change from previous iteration (Î”V)\n   - **V_meta(s_n)** with rubric assessments\n     - Completeness score (checklist-based, with evidence)\n     - Effectiveness score (speedup, quality gains, with evidence)\n     - Reusability score (transferability estimate, with evidence)\n     - Final score calculation\n     - Change from previous iteration (Î”V)\n\n5. **Gap Analysis**\n   - **Instance layer gaps** (what's needed to reach V_instance â‰¥ 0.80)\n     - Prioritized list with estimated effort\n   - **Meta layer gaps** (what's needed to reach V_meta â‰¥ 0.80)\n     - Prioritized list with estimated effort\n   - Estimated work remaining\n\n6. **Convergence Check** (systematic criteria evaluation)\n   - **Dual threshold**: V_instance â‰¥ 0.80 AND V_meta â‰¥ 0.80\n   - **System stability**: M_n == M_{n-1} AND A_n == A_{n-1}\n   - **Objectives completeness**: All planned work finished\n   - **Diminishing returns**: Î”V < 0.02 for 2+ iterations\n   - **Convergence decision**: YES/NO with detailed rationale\n\n7. **Evolution Decisions** (evidence-driven)\n   - **Agent sufficiency analysis** (A_n vs A_{n-1})\n     - Each agent's performance assessment\n     - Decision: evolution needed or not\n     - Rationale with evidence\n   - **Meta-Agent sufficiency analysis** (M_n vs M_{n-1})\n     - Each capability's effectiveness assessment\n     - Decision: evolution needed or not\n     - Rationale with evidence\n\n8. **Artifacts Created**\n   - Data files (coverage reports, metrics, measurements)\n   - Knowledge files (patterns, principles, methodology documents)\n   - Code changes (implementation, tests, tools)\n   - Other deliverables\n\n9. **Reflections**\n   - **What worked well** (successes to repeat)\n   - **What didn't work** (failures to avoid)\n   - **Learnings** (insights from this iteration)\n   - **Insights for methodology** (meta-level learnings)\n\n10. **Conclusion**\n    - Iteration summary\n    - Key metrics and improvements\n    - Critical decisions made\n    - Next steps\n    - Confidence assessment\n\n### File Naming Convention\n\n```\niterations/iteration-N.md\n```\n\nWhere N = 0, 1, 2, 3, ... (starting from 0 for baseline)\n\n### Documentation Quality Standards\n\n**Evidence-based scores**:\n- Every value component score must have concrete evidence\n- Avoid vague assessments (\"seems good\" âŒ, \"72.3% coverage, +5% from baseline\" âœ…)\n- Show arithmetic for all calculations\n\n**Honest assessment**:\n- Low scores early are expected and acceptable (baseline V_meta often 0.15-0.25)\n- Don't inflate scores to meet targets\n- Document gaps explicitly\n- Acknowledge when objectives are not met\n\n**Complete coverage**:\n- All 10 sections must be present\n- Don't skip reflections (valuable for meta-learning)\n- Don't skip gap analysis (critical for planning)\n- Don't skip convergence check (prevents premature convergence)\n\n### Tools for Iteration Documentation\n\n**Recommended workflow**:\n1. Copy [examples/iteration-structure-template.md](examples/iteration-structure-template.md) to `iterations/iteration-N.md`\n2. Invoke `iteration-executor` subagent to execute iteration with structured documentation\n3. Review [examples/iteration-documentation-example.md](examples/iteration-documentation-example.md) for quality reference\n\n**Automated generation**: Use `iteration-executor` subagent to ensure consistent structure and systematic value calculation.\n\n---\n\n## Three-Layer Architecture\n\n**BAIME** integrates three complementary methodologies into a unified framework:\n\n**Layer 1: Core Framework (OCA Cycle)**\n- Observe â†’ Codify â†’ Automate â†’ Evolve\n- Three-tuple output: (O, Aâ‚™, Mâ‚™)\n- Self-referential feedback loop\n- Agent coordination\n\n**Layer 2: Scientific Foundation (Empirical Methodology)**\n- Empirical observation tools\n- Data-driven pattern extraction\n- Hypothesis testing\n- Scientific validation\n\n**Layer 3: Quantitative Evaluation (Value Optimization)**\n- Dual-layer value functions (V_instance + V_meta)\n- Convergence mathematics\n- Agent as gradient, Meta-Agent as Hessian\n- Optimization perspective\n\n**Why \"BAIME\"?** The framework bootstraps itselfâ€”methodologies developed using BAIME can be applied to improve BAIME itself. This self-referential property, combined with AI-agent coordination, makes it uniquely suited for LLM-based development tools.\n\n**Detailed guide**: [reference/three-layer-architecture.md](reference/three-layer-architecture.md)\n\n---\n\n## Proven Results\n\n**Validated in 8 experiments**:\n- âœ… 100% success rate (8/8 converged)\n- â±ï¸ Average: 4.9 iterations, 9.1 hours\n- ğŸ“ˆ V_instance average: 0.784 (range: 0.585-0.92)\n- ğŸ“ˆ V_meta average: 0.840 (range: 0.83-0.877)\n- ğŸŒ Transferability: 70-95%+\n- ğŸš€ Speedup: 3-46x vs ad-hoc\n\n**Example applications**:\n- **Testing strategy**: 15x speedup, 75%â†’86% coverage ([examples/testing-methodology.md](examples/testing-methodology.md))\n- **CI/CD pipeline**: 2.5-3.5x speedup, 91.7% pattern validation ([examples/ci-cd-optimization.md](examples/ci-cd-optimization.md))\n- **Error recovery**: 80% error reduction, 85% transferability\n- **Observability**: 23-46x speedup, 90-95% transferability\n- **Dependency health**: 6x speedup (9hâ†’1.5h), 88% transferability\n- **Knowledge transfer**: 3-8x onboarding speedup, 95%+ transferability\n- **Documentation**: 47% token cost reduction, 85% transferability\n- **Technical debt**: SQALE quantification, 85% transferability\n\n---\n\n## Usage Templates\n\n### Experiment Template\nUse [templates/experiment-template.md](templates/experiment-template.md) to structure your methodology development:\n- README.md structure\n- Iteration prompts\n- Knowledge extraction format\n- Results documentation\n\n### Iteration Prompt Template\nUse [templates/iteration-prompts-template.md](templates/iteration-prompts-template.md) to guide each iteration:\n- Iteration N objectives\n- OCA cycle execution steps\n- Value calculation rubrics\n- Convergence checks\n\n**Automated generation**: Use `iteration-prompt-designer` subagent to create domain-specific iteration prompts.\n\n### Iteration Documentation Template\n\n**Structure template**: [examples/iteration-structure-template.md](examples/iteration-structure-template.md)\n- 10-section standardized structure\n- Blank template ready to copy and fill\n- Includes all required components\n\n**Complete example**: [examples/iteration-documentation-example.md](examples/iteration-documentation-example.md)\n- Real iteration from test strategy experiment\n- Shows proper value calculations with evidence\n- Demonstrates honest assessment and gap analysis\n- Illustrates quality reflections and insights\n\n**Automated execution**: Use `iteration-executor` subagent to ensure consistent structure and systematic value calculation.\n\n**Quality standards**:\n- Evidence-based scoring (concrete data, not vague assessments)\n- Honest evaluation (low scores acceptable, inflation harmful)\n- Complete coverage (all 10 sections required)\n- Arithmetic shown (all value calculations with steps)\n\n---\n\n## Common Pitfalls\n\nâŒ **Don't**:\n- Use only one methodology layer in isolation (except quick prototyping)\n- Predetermine agent evolution path (let specialization emerge from data)\n- Force convergence at target iteration count (trust the criteria)\n- Inflate value metrics to meet targets (honest assessment critical)\n- Skip empirical validation (data-driven decisions only)\n\nâœ… **Do**:\n- Start with OCA cycle, add evaluation and validation\n- Let agent specialization emerge from domain needs\n- Trust the convergence criteria (system knows when done)\n- Calculate V(s) honestly based on actual state\n- Complete all analysis thoroughly before codifying\n\n### Iteration Documentation Pitfalls\n\nâŒ **Don't**:\n- Skip iteration documentation (every iteration needs iteration-N.md)\n- Calculate V-scores without component breakdowns and evidence\n- Use vague assessments (\"seems good\", \"probably 0.7\")\n- Omit gap analysis or convergence checks\n- Document only successes (failures provide valuable learnings)\n- Assume convergence without systematic criteria evaluation\n- Inflate scores to meet targets (honesty is critical)\n- Skip reflections section (meta-learning opportunity)\n\nâœ… **Do**:\n- Use `iteration-executor` subagent for consistent structure\n- Provide concrete evidence for each value component\n- Show arithmetic for all calculations\n- Document both instance and meta layer gaps explicitly\n- Include reflections (what worked, didn't work, learnings, insights)\n- Be honest about scores (baseline V_meta of 0.20 is normal and acceptable)\n- Follow the 10-section structure for every iteration\n- Reference iteration documentation example for quality standards\n\n---\n\n## Related Skills\n\n**Acceleration techniques** (achieve 3-4 iteration convergence):\n- [rapid-convergence](../rapid-convergence/SKILL.md) - Fast convergence patterns\n- [retrospective-validation](../retrospective-validation/SKILL.md) - Historical data validation\n- [baseline-quality-assessment](../baseline-quality-assessment/SKILL.md) - Strong iteration 0\n\n**Supporting skills**:\n- [agent-prompt-evolution](../agent-prompt-evolution/SKILL.md) - Track agent specialization\n\n**Domain applications** (ready-to-use methodologies):\n- [testing-strategy](../testing-strategy/SKILL.md) - TDD, coverage-driven, fixtures\n- [error-recovery](../error-recovery/SKILL.md) - Error taxonomy, recovery patterns\n- [ci-cd-optimization](../ci-cd-optimization/SKILL.md) - Quality gates, automation\n- [observability-instrumentation](../observability-instrumentation/SKILL.md) - Logging, metrics, tracing\n- [dependency-health](../dependency-health/SKILL.md) - Security, freshness, compliance\n- [knowledge-transfer](../knowledge-transfer/SKILL.md) - Onboarding, learning paths\n- [technical-debt-management](../technical-debt-management/SKILL.md) - SQALE, prioritization\n- [cross-cutting-concerns](../cross-cutting-concerns/SKILL.md) - Pattern extraction, enforcement\n\n---\n\n## References\n\n**Core documentation**:\n- [Overview](reference/overview.md) - Architecture and philosophy\n- [OCA Cycle](reference/observe-codify-automate.md) - Detailed process\n- [Value Functions](reference/dual-value-functions.md) - Evaluation framework\n- [Convergence Criteria](reference/convergence-criteria.md) - When to stop\n- [Three-Layer Architecture](reference/three-layer-architecture.md) - Framework layers\n\n**Quick start**:\n- [Quick Start Guide](reference/quick-start-guide.md) - Step-by-step tutorial\n\n**Examples**:\n- [Testing Methodology](examples/testing-methodology.md) - Complete walkthrough\n- [CI/CD Optimization](examples/ci-cd-optimization.md) - Pipeline example\n- [Error Recovery](examples/error-recovery.md) - Error handling example\n\n**Templates**:\n- [Experiment Template](templates/experiment-template.md) - Structure your experiment\n- [Iteration Prompts](templates/iteration-prompts-template.md) - Guide each iteration\n\n---\n\n**Status**: âœ… Production-ready | BAIME Framework | 8 experiments | 100% success rate | 95% transferable\n\n**Terminology**: This skill implements the **Bootstrapped AI Methodology Engineering (BAIME)** framework. Use \"BAIME\" when referring to this methodology in documentation, research, or when asking Claude Code for assistance with methodology development.\n"
      },
      "discovered_at": "2026-01-11T15:36:32.774879Z",
      "fetch_error": null
    },
    {
      "name": "observability-instrumentation",
      "slug": "observability-instrumentation",
      "source": "skillsmp",
      "owner": "yaleh",
      "repo_name": "meta-cc",
      "repository_url": "https://github.com/yaleh/meta-cc",
      "skill_path": ".claude/skills/observability-instrumentation",
      "github_metadata": {
        "stars": 15,
        "description": "Meta-Cognition tool for Claude Code - analyze session history for workflow optimization.",
        "default_branch": "main",
        "pushed_at": "2025-12-13T10:31:07Z",
        "created_at": "2025-10-08T01:58:30Z",
        "language": "Go",
        "license": "MIT",
        "open_issues": 0,
        "forks": 1
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/observability-instrumentation/SKILL.md",
        "branch": "main",
        "content": "---\nname: Observability Instrumentation\ndescription: Comprehensive observability methodology implementing three pillars (logs, metrics, traces) with structured logging using Go slog, Prometheus-style metrics, and distributed tracing patterns. Use when adding observability from scratch, logs unstructured or inadequate, no metrics collection, debugging production issues difficult, or need performance monitoring. Provides structured logging patterns (contextual logging, log levels DEBUG/INFO/WARN/ERROR, request ID propagation), metrics instrumentation (counter/gauge/histogram patterns, Prometheus exposition), tracing setup (span creation, context propagation, sampling strategies), and Go slog best practices (JSON formatting, attribute management, handler configuration). Validated in meta-cc with 23-46x speedup vs ad-hoc logging, 90-95% transferability across languages (slog specific to Go but patterns universal).\nallowed-tools: Read, Write, Edit, Bash, Grep, Glob\n---\n\n# Observability Instrumentation\n\n**Implement three pillars of observability: logs, metrics, and traces.**\n\n> You can't improve what you can't measure. You can't debug what you can't observe.\n\n---\n\n## When to Use This Skill\n\nUse this skill when:\n- ğŸ“Š **No observability**: Starting from scratch\n- ğŸ“ **Unstructured logs**: Printf debugging, no context\n- ğŸ“ˆ **No metrics**: Can't measure performance or errors\n- ğŸ› **Hard to debug**: Production issues take hours to diagnose\n- ğŸ” **Performance unknown**: No visibility into bottlenecks\n- ğŸ¯ **SLO/SLA tracking**: Need to measure reliability\n\n**Don't use when**:\n- âŒ Observability already comprehensive\n- âŒ Non-production code (development scripts, throwaway tools)\n- âŒ Performance not critical (batch jobs, admin tools)\n- âŒ No logging infrastructure available\n\n---\n\n## Quick Start (20 minutes)\n\n### Step 1: Add Structured Logging (10 min)\n\n```go\n// Initialize slog\nimport \"log/slog\"\n\nlogger := slog.New(slog.NewJSONHandler(os.Stdout, &slog.HandlerOptions{\n    Level: slog.LevelInfo,\n}))\n\n// Use structured logging\nlogger.Info(\"operation completed\",\n    slog.String(\"user_id\", userID),\n    slog.Int(\"count\", count),\n    slog.Duration(\"duration\", elapsed))\n```\n\n### Step 2: Add Basic Metrics (5 min)\n\n```go\n// Counters\nrequestCount.Add(1)\nerrorCount.Add(1)\n\n// Gauges\nactiveConnections.Set(float64(count))\n\n// Histograms\nrequestDuration.Observe(elapsed.Seconds())\n```\n\n### Step 3: Add Request ID Propagation (5 min)\n\n```go\n// Generate request ID\nrequestID := uuid.New().String()\n\n// Add to context\nctx = context.WithValue(ctx, requestIDKey, requestID)\n\n// Log with request ID\nlogger.InfoContext(ctx, \"processing request\",\n    slog.String(\"request_id\", requestID))\n```\n\n---\n\n## Three Pillars of Observability\n\n### 1. Logs (Structured Logging)\n\n**Purpose**: Record discrete events with context\n\n**Go slog patterns**:\n```go\n// Contextual logging\nlogger.InfoContext(ctx, \"user authenticated\",\n    slog.String(\"user_id\", userID),\n    slog.String(\"method\", authMethod),\n    slog.Duration(\"elapsed\", elapsed))\n\n// Error logging with stack trace\nlogger.ErrorContext(ctx, \"database query failed\",\n    slog.String(\"query\", query),\n    slog.Any(\"error\", err))\n\n// Debug logging (disabled in production)\nlogger.DebugContext(ctx, \"cache hit\",\n    slog.String(\"key\", cacheKey))\n```\n\n**Log levels**:\n- **DEBUG**: Detailed diagnostic information\n- **INFO**: General informational messages\n- **WARN**: Warning messages (potential issues)\n- **ERROR**: Error messages (failures)\n\n**Best practices**:\n- Always use structured logging (not printf)\n- Include request ID in all logs\n- Log both successes and failures\n- Include timing information\n- Don't log sensitive data (passwords, tokens)\n\n### 2. Metrics (Quantitative Measurements)\n\n**Purpose**: Track aggregate statistics over time\n\n**Three metric types**:\n\n**Counter** (monotonically increasing):\n```go\nhttpRequestsTotal.Add(1)\nhttpErrorsTotal.Add(1)\n```\n\n**Gauge** (can go up or down):\n```go\nactiveConnections.Set(float64(connCount))\nqueueLength.Set(float64(len(queue)))\n```\n\n**Histogram** (distributions):\n```go\nrequestDuration.Observe(elapsed.Seconds())\nresponseSize.Observe(float64(size))\n```\n\n**Prometheus exposition**:\n```go\nhttp.Handle(\"/metrics\", promhttp.Handler())\n```\n\n### 3. Traces (Distributed Request Tracking)\n\n**Purpose**: Track requests across services\n\n**Span creation**:\n```go\nctx, span := tracer.Start(ctx, \"database.query\")\ndefer span.End()\n\n// Add attributes\nspan.SetAttributes(\n    attribute.String(\"db.query\", query),\n    attribute.Int(\"db.rows\", rowCount))\n\n// Record error\nif err != nil {\n    span.RecordError(err)\n    span.SetStatus(codes.Error, err.Error())\n}\n```\n\n**Context propagation**:\n```go\n// Extract from HTTP headers\nctx = otel.GetTextMapPropagator().Extract(ctx, propagation.HeaderCarrier(req.Header))\n\n// Inject into HTTP headers\notel.GetTextMapPropagator().Inject(ctx, propagation.HeaderCarrier(req.Header))\n```\n\n---\n\n## Go slog Best Practices\n\n### Handler Configuration\n\n```go\n// Production: JSON handler\nlogger := slog.New(slog.NewJSONHandler(os.Stdout, &slog.HandlerOptions{\n    Level: slog.LevelInfo,\n    AddSource: true, // Include file:line\n}))\n\n// Development: Text handler\nlogger := slog.New(slog.NewTextHandler(os.Stdout, &slog.HandlerOptions{\n    Level: slog.LevelDebug,\n}))\n```\n\n### Attribute Management\n\n```go\n// Reusable attributes\nattrs := []slog.Attr{\n    slog.String(\"service\", \"api\"),\n    slog.String(\"version\", version),\n}\n\n// Child logger with default attributes\napiLogger := logger.With(attrs...)\n\n// Use child logger\napiLogger.Info(\"request received\") // Includes service and version automatically\n```\n\n### Performance Optimization\n\n```go\n// Lazy evaluation (expensive operations)\nlogger.Info(\"operation completed\",\n    slog.Group(\"stats\",\n        slog.Int(\"count\", count),\n        slog.Any(\"details\", func() interface{} {\n            return computeExpensiveStats() // Only computed if logged\n        })))\n```\n\n---\n\n## Implementation Patterns\n\n### Pattern 1: Request ID Propagation\n\n```go\ntype contextKey string\nconst requestIDKey contextKey = \"request_id\"\n\n// Generate and store\nrequestID := uuid.New().String()\nctx = context.WithValue(ctx, requestIDKey, requestID)\n\n// Extract and log\nif reqID, ok := ctx.Value(requestIDKey).(string); ok {\n    logger.InfoContext(ctx, \"processing\",\n        slog.String(\"request_id\", reqID))\n}\n```\n\n### Pattern 2: Operation Timing\n\n```go\nfunc instrumentOperation(ctx context.Context, name string, fn func() error) error {\n    start := time.Now()\n    logger.InfoContext(ctx, \"operation started\", slog.String(\"operation\", name))\n\n    err := fn()\n    elapsed := time.Since(start)\n\n    if err != nil {\n        logger.ErrorContext(ctx, \"operation failed\",\n            slog.String(\"operation\", name),\n            slog.Duration(\"elapsed\", elapsed),\n            slog.Any(\"error\", err))\n        operationErrors.Add(1)\n    } else {\n        logger.InfoContext(ctx, \"operation completed\",\n            slog.String(\"operation\", name),\n            slog.Duration(\"elapsed\", elapsed))\n    }\n\n    operationDuration.Observe(elapsed.Seconds())\n    return err\n}\n```\n\n### Pattern 3: Error Rate Monitoring\n\n```go\n// Track error rates\ntotalRequests.Add(1)\nif err != nil {\n    errorRequests.Add(1)\n}\n\n// Calculate error rate (in monitoring system)\n// error_rate = rate(errorRequests[5m]) / rate(totalRequests[5m])\n```\n\n---\n\n## Proven Results\n\n**Validated in bootstrap-009** (meta-cc project):\n- âœ… Structured logging with slog (100% coverage)\n- âœ… Metrics instrumentation (Prometheus-compatible)\n- âœ… Distributed tracing setup (OpenTelemetry)\n- âœ… 23-46x speedup vs ad-hoc logging\n- âœ… 7 iterations, ~21 hours\n- âœ… V_instance: 0.87, V_meta: 0.83\n\n**Speedup breakdown**:\n- Debug time: 46x faster (context immediately available)\n- Performance analysis: 23x faster (metrics pre-collected)\n- Error diagnosis: 30x faster (structured logs + traces)\n\n**Transferability**:\n- Go slog: 100% (Go-specific)\n- Structured logging patterns: 100% (universal)\n- Metrics patterns: 95% (Prometheus standard)\n- Tracing patterns: 95% (OpenTelemetry standard)\n- **Overall**: 90-95% transferable\n\n**Language adaptations**:\n- Python: structlog, prometheus_client, opentelemetry-python\n- Java: SLF4J, Micrometer, OpenTelemetry Java\n- Node.js: winston, prom-client, @opentelemetry/api\n- Rust: tracing, prometheus, opentelemetry\n\n---\n\n## Anti-Patterns\n\nâŒ **Log spamming**: Logging everything (noise overwhelms signal)\nâŒ **Unstructured logs**: String concatenation instead of structured fields\nâŒ **Synchronous logging**: Blocking on log writes (use async handlers)\nâŒ **Missing context**: Logs without request ID or user context\nâŒ **Metrics explosion**: Too many unique label combinations (cardinality issues)\nâŒ **Trace everything**: 100% sampling in production (performance impact)\n\n---\n\n## Related Skills\n\n**Parent framework**:\n- [methodology-bootstrapping](../methodology-bootstrapping/SKILL.md) - Core OCA cycle\n\n**Complementary**:\n- [error-recovery](../error-recovery/SKILL.md) - Error logging patterns\n- [ci-cd-optimization](../ci-cd-optimization/SKILL.md) - Build metrics\n- [testing-strategy](../testing-strategy/SKILL.md) - Test instrumentation\n\n---\n\n## References\n\n**Core guides**:\n- Reference materials in experiments/bootstrap-009-observability-methodology/\n- Three pillars methodology\n- Go slog patterns\n- Metrics instrumentation guide\n- Tracing setup guide\n\n**Templates**:\n- templates/logger-setup.go - Logger initialization\n- templates/metrics-instrumentation.go - Metrics patterns\n- templates/tracing-setup.go - OpenTelemetry configuration\n\n---\n\n**Status**: âœ… Production-ready | 23-46x speedup | 90-95% transferable | Validated in meta-cc\n"
      },
      "discovered_at": "2026-01-11T15:36:33.062945Z",
      "fetch_error": null
    },
    {
      "name": "rapid-convergence",
      "slug": "rapid-convergence",
      "source": "skillsmp",
      "owner": "yaleh",
      "repo_name": "meta-cc",
      "repository_url": "https://github.com/yaleh/meta-cc",
      "skill_path": ".claude/skills/rapid-convergence",
      "github_metadata": {
        "stars": 15,
        "description": "Meta-Cognition tool for Claude Code - analyze session history for workflow optimization.",
        "default_branch": "main",
        "pushed_at": "2025-12-13T10:31:07Z",
        "created_at": "2025-10-08T01:58:30Z",
        "language": "Go",
        "license": "MIT",
        "open_issues": 0,
        "forks": 1
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/rapid-convergence/SKILL.md",
        "branch": "main",
        "content": "---\nname: Rapid Convergence\ndescription: Achieve 3-4 iteration methodology convergence (vs standard 5-7) when clear baseline metrics exist, domain scope is focused, and direct validation is possible. Use when you have V_meta baseline â‰¥0.40, quantifiable success criteria, retrospective validation data, and generic agents are sufficient. Enables 40-60% time reduction (10-15 hours vs 20-30 hours) without sacrificing quality. Prediction model helps estimate iteration count during experiment planning. Validated in error recovery (3 iterations, 10 hours, V_instance=0.83, V_meta=0.85).\nallowed-tools: Read, Grep, Glob\n---\n\n# Rapid Convergence\n\n**Achieve methodology convergence in 3-4 iterations through structural optimization, not rushing.**\n\n> Rapid convergence is not about moving fast - it's about recognizing when structural factors naturally enable faster progress without sacrificing quality.\n\n---\n\n## When to Use This Skill\n\nUse this skill when:\n- ğŸ¯ **Planning new experiment**: Want to estimate iteration count and timeline\n- ğŸ“Š **Clear baseline exists**: Can quantify current state with V_meta(sâ‚€) â‰¥ 0.40\n- ğŸ” **Focused domain**: Can describe scope in <3 sentences without ambiguity\n- âœ… **Direct validation**: Can validate with historical data or single context\n- âš¡ **Time constraints**: Need methodology in 10-15 hours vs 20-30 hours\n- ğŸ§© **Generic agents sufficient**: No complex specialization needed\n\n**Don't use when**:\n- âŒ Exploratory research (no established metrics)\n- âŒ Multi-context validation required (cross-language, cross-domain testing)\n- âŒ Complex specialization needed (>10x speedup from specialists)\n- âŒ Incremental pattern discovery (patterns emerge gradually, not upfront)\n\n---\n\n## Quick Start (5 minutes)\n\n### Rapid Convergence Self-Assessment\n\nAnswer these 5 questions:\n\n1. **Baseline metrics exist**: Can you quantify current state objectively? (YES/NO)\n2. **Domain is focused**: Can you describe scope in <3 sentences? (YES/NO)\n3. **Validation is direct**: Can you validate without multi-context deployment? (YES/NO)\n4. **Prior art exists**: Are there established practices to reference? (YES/NO)\n5. **Success criteria clear**: Do you know what \"done\" looks like? (YES/NO)\n\n**Scoring**:\n- **4-5 YES**: âš¡ Rapid convergence (3-4 iterations) likely\n- **2-3 YES**: ğŸ“Š Standard convergence (5-7 iterations) expected\n- **0-1 YES**: ğŸ”¬ Exploratory (6-10 iterations), establish baseline first\n\n---\n\n## Five Rapid Convergence Criteria\n\n### Criterion 1: Clear Baseline Metrics (CRITICAL)\n\n**Indicator**: V_meta(sâ‚€) â‰¥ 0.40\n\n**What it means**:\n- Domain has established metrics (error rate, test coverage, build time)\n- Baseline can be measured objectively in iteration 0\n- Success criteria can be quantified before starting\n\n**Example (Bootstrap-003)**:\n```\nâœ… Clear baseline:\n- 1,336 errors quantified via MCP queries\n- 5.78% error rate calculated\n- Clear MTTD/MTTR targets\n- Result: V_meta(sâ‚€) = 0.48\n\nOutcome: 3 iterations, 10 hours\n```\n\n**Counter-example (Bootstrap-002)**:\n```\nâŒ No baseline:\n- No existing test coverage data\n- Had to establish metrics first\n- Fuzzy success criteria initially\n- Result: V_meta(sâ‚€) = 0.04\n\nOutcome: 6 iterations, 25.5 hours\n```\n\n**Impact**: High V_meta baseline means:\n- Fewer iterations to reach 0.80 threshold (+0.40 vs +0.76)\n- Clearer iteration objectives (gaps are obvious)\n- Faster validation (metrics already exist)\n\nSee [reference/baseline-metrics.md](reference/baseline-metrics.md) for achieving V_meta â‰¥ 0.40.\n\n### Criterion 2: Focused Domain Scope (IMPORTANT)\n\n**Indicator**: Domain described in <3 sentences without ambiguity\n\n**What it means**:\n- Single cross-cutting concern\n- Clear boundaries (what's in vs out of scope)\n- Well-established practices (prior art)\n\n**Examples**:\n```\nâœ… Focused (Bootstrap-003):\n\"Reduce error rate through detection, diagnosis, recovery, prevention\"\n\nâŒ Broad (Bootstrap-002):\n\"Develop test strategy\" (requires scoping: what tests? which patterns? how much coverage?)\n```\n\n**Impact**: Focused scope means:\n- Less exploration needed\n- Clearer convergence criteria\n- Lower risk of scope creep\n\n### Criterion 3: Direct Validation (IMPORTANT)\n\n**Indicator**: Can validate without multi-context deployment\n\n**What it means**:\n- Retrospective validation possible (use historical data)\n- Single-context validation sufficient\n- Proxy metrics strongly correlate with value\n\n**Examples**:\n```\nâœ… Direct (Bootstrap-003):\nRetrospective validation via 1,336 historical errors\nNo deployment needed\nConfidence: 0.79\n\nâŒ Indirect (Bootstrap-002):\nMulti-context validation required (3 project archetypes)\nDeploy and test in each context\nAdds 2-3 iterations\n```\n\n**Impact**: Direct validation means:\n- Faster iteration cycles\n- Less complexity\n- Easier V_meta calculation\n\nSee [../retrospective-validation](../retrospective-validation/SKILL.md) for retrospective validation technique.\n\n### Criterion 4: Generic Agent Sufficiency (MODERATE)\n\n**Indicator**: Generic agents (data-analyst, doc-writer, coder) sufficient\n\n**What it means**:\n- No specialized domain knowledge required\n- Tasks are analysis + documentation + simple automation\n- Pattern extraction is straightforward\n\n**Examples**:\n```\nâœ… Generic sufficient (Bootstrap-003):\nGeneric agents analyzed errors, documented taxonomy, created scripts\nNo specialization overhead\n3 iterations\n\nâš ï¸ Specialization needed (Bootstrap-002):\ncoverage-analyzer (10x speedup)\ntest-generator (200x speedup)\n6 iterations (specialization added 1-2 iterations)\n```\n\n**Impact**: No specialization means:\n- No iteration delay for agent design\n- Simpler coordination\n- Faster execution\n\n### Criterion 5: Early High-Impact Automation (MODERATE)\n\n**Indicator**: Top 3 automation opportunities identified by iteration 1\n\n**What it means**:\n- Pareto principle applies (20% patterns â†’ 80% impact)\n- High-frequency, high-impact patterns obvious\n- Automation feasibility clear (no R&D risk)\n\n**Examples**:\n```\nâœ… Early identification (Bootstrap-003):\n3 tools preventing 23.7% of errors identified in iteration 0-1\nClear automation path\nRapid V_instance improvement\n\nâš ï¸ Gradual discovery (Bootstrap-002):\n8 test patterns emerged gradually over 6 iterations\nPattern library built incrementally\n```\n\n**Impact**: Early automation means:\n- Faster V_instance improvement\n- Clearer path to convergence\n- Less trial-and-error\n\n---\n\n## Convergence Speed Prediction Model\n\n### Formula\n\n```\nPredicted Iterations = Base(4) + Î£ penalties\n\nPenalties:\n- V_meta(sâ‚€) < 0.40: +2 iterations\n- Domain scope fuzzy: +1 iteration\n- Multi-context validation: +2 iterations\n- Specialization needed: +1 iteration\n- Automation unclear: +1 iteration\n```\n\n### Worked Examples\n\n**Bootstrap-003 (Error Recovery)**:\n```\nBase: 4\nV_meta(sâ‚€) = 0.48 â‰¥ 0.40: +0 âœ“\nDomain scope clear: +0 âœ“\nRetrospective validation: +0 âœ“\nGeneric agents sufficient: +0 âœ“\nAutomation identified early: +0 âœ“\n---\nPredicted: 4 iterations\nActual: 3 iterations âœ…\n```\n\n**Bootstrap-002 (Test Strategy)**:\n```\nBase: 4\nV_meta(sâ‚€) = 0.04 < 0.40: +2 âœ—\nDomain scope broad: +1 âœ—\nMulti-context validation: +2 âœ—\nSpecialization needed: +1 âœ—\nAutomation unclear: +0 âœ“\n---\nPredicted: 10 iterations\nActual: 6 iterations âœ… (model conservative)\n```\n\n**Interpretation**: Model predicts upper bound. Actual often faster due to efficient execution.\n\nSee [examples/prediction-examples.md](examples/prediction-examples.md) for more cases.\n\n---\n\n## Rapid Convergence Strategy\n\nIf criteria indicate 3-4 iteration potential, optimize:\n\n### Pre-Iteration 0: Planning (1-2 hours)\n\n**1. Establish Baseline Metrics**\n- Identify existing data sources\n- Define quantifiable success criteria\n- Ensure automatic measurement\n\n**Example**: `meta-cc query-tools --status error` â†’ 1,336 errors immediately\n\n**2. Scope Domain Tightly**\n- Write 1-sentence definition\n- List explicit in/out boundaries\n- Identify prior art\n\n**Example**: \"Error detection, diagnosis, recovery, prevention for meta-cc\"\n\n**3. Plan Validation Approach**\n- Prefer retrospective (historical data)\n- Minimize multi-context overhead\n- Identify proxy metrics\n\n**Example**: Retrospective validation with 1,336 historical errors\n\n### Iteration 0: Comprehensive Baseline (3-5 hours)\n\n**Target: V_meta(sâ‚€) â‰¥ 0.40**\n\n**Tasks**:\n1. Quantify current state thoroughly\n2. Create initial taxonomy (â‰¥70% coverage)\n3. Document existing practices\n4. Identify top 3 automations\n\n**Example (Bootstrap-003)**:\n- Analyzed all 1,336 errors\n- Created 10-category taxonomy (79.1% coverage)\n- Documented 5 workflows, 5 patterns, 8 guidelines\n- Identified 3 tools preventing 23.7% errors\n- Result: V_meta(sâ‚€) = 0.48 âœ…\n\n**Time**: Spend 3-5 hours here (saves 6-10 hours overall)\n\n### Iteration 1: High-Impact Automation (3-4 hours)\n\n**Tasks**:\n1. Implement top 3 tools\n2. Expand taxonomy (â‰¥90% coverage)\n3. Validate with data (if possible)\n4. Target: Î”V_instance = +0.20-0.30\n\n**Example (Bootstrap-003)**:\n- Built 3 tools (515 LOC, ~150-180 lines each)\n- Expanded taxonomy: 10 â†’ 12 categories (92.3%)\n- Result: V_instance = 0.55 (+0.27) âœ…\n\n### Iteration 2: Validate and Converge (3-4 hours)\n\n**Tasks**:\n1. Test automation (real/historical data)\n2. Complete taxonomy (â‰¥95% coverage)\n3. Check convergence:\n   - V_instance â‰¥ 0.80?\n   - V_meta â‰¥ 0.80?\n   - System stable?\n\n**Example (Bootstrap-003)**:\n- Validated 23.7% error prevention\n- Taxonomy: 95.4% coverage\n- Result: V_instance = 0.83, V_meta = 0.85 âœ… CONVERGED\n\n**Total time**: 10-13 hours (3 iterations)\n\n---\n\n## Anti-Patterns\n\n### 1. Premature Convergence\n\n**Symptom**: Declare convergence at iteration 2 with V â‰ˆ 0.75\n\n**Problem**: Rushed without meeting 0.80 threshold\n\n**Solution**: Rapid convergence = 3-4 iterations (not 2). Respect quality threshold.\n\n### 2. Scope Creep\n\n**Symptom**: Adding categories/patterns in iterations 3-4\n\n**Problem**: Poorly scoped domain\n\n**Solution**: Tight scoping in README. If scope grows, re-plan or accept slower convergence.\n\n### 3. Over-Engineering Automation\n\n**Symptom**: Spending 8+ hours on complex tools\n\n**Problem**: Complexity delays convergence\n\n**Solution**: Keep tools simple (1-2 hours, 150-200 lines). Complex tools are iteration 3-4 work.\n\n### 4. Unnecessary Multi-Context Validation\n\n**Symptom**: Testing 3+ contexts despite obvious generalizability\n\n**Problem**: Validation overhead delays convergence\n\n**Solution**: Use judgment. Error recovery is universal. Test strategy may need multi-context.\n\n---\n\n## Comparison Table\n\n| Aspect | Standard | Rapid |\n|--------|----------|-------|\n| **Iterations** | 5-7 | 3-4 |\n| **Duration** | 20-30h | 10-15h |\n| **V_meta(sâ‚€)** | 0.00-0.30 | 0.40-0.60 |\n| **Domain** | Broad/exploratory | Focused |\n| **Validation** | Multi-context often | Direct/retrospective |\n| **Specialization** | Likely (1-3 agents) | Often unnecessary |\n| **Discovery** | Incremental | Most patterns early |\n| **Risk** | Scope creep | Premature convergence |\n\n**Key**: Rapid convergence is about **recognizing structural factors**, not rushing.\n\n---\n\n## Success Criteria\n\nRapid convergence pattern successfully applied when:\n\n1. **Accurate prediction**: Actual iterations within Â±1 of predicted\n2. **Quality maintained**: V_instance â‰¥ 0.80, V_meta â‰¥ 0.80\n3. **Time efficiency**: Duration â‰¤50% of standard convergence\n4. **Artifact completeness**: Deliverables production-ready\n5. **Reusability validated**: â‰¥80% transferability achieved\n\n**Bootstrap-003 Validation**:\n- âœ… Predicted: 3-4, Actual: 3\n- âœ… Quality: V_instance=0.83, V_meta=0.85\n- âœ… Efficiency: 10h (39% of Bootstrap-002's 25.5h)\n- âœ… Artifacts: 13 categories, 8 workflows, 3 tools\n- âœ… Reusability: 85-90%\n\n---\n\n## Related Skills\n\n**Parent framework**:\n- [methodology-bootstrapping](../methodology-bootstrapping/SKILL.md) - Core OCA cycle\n\n**Complementary acceleration**:\n- [retrospective-validation](../retrospective-validation/SKILL.md) - Fast validation\n- [baseline-quality-assessment](../baseline-quality-assessment/SKILL.md) - Strong iteration 0\n\n**Supporting**:\n- [agent-prompt-evolution](../agent-prompt-evolution/SKILL.md) - Agent stability\n\n---\n\n## References\n\n**Core guide**:\n- [Rapid Convergence Criteria](reference/criteria.md) - Detailed criteria explanation\n- [Prediction Model](reference/prediction-model.md) - Formula and examples\n- [Strategy Guide](reference/strategy.md) - Iteration-by-iteration tactics\n\n**Examples**:\n- [Bootstrap-003 Case Study](examples/error-recovery-3-iterations.md) - Rapid convergence\n- [Bootstrap-002 Comparison](examples/test-strategy-6-iterations.md) - Standard convergence\n\n---\n\n**Status**: âœ… Validated | Bootstrap-003 | 40-60% time reduction | No quality sacrifice\n"
      },
      "discovered_at": "2026-01-11T15:36:33.458793Z",
      "fetch_error": null
    },
    {
      "name": "retrospective-validation",
      "slug": "retrospective-validation",
      "source": "skillsmp",
      "owner": "yaleh",
      "repo_name": "meta-cc",
      "repository_url": "https://github.com/yaleh/meta-cc",
      "skill_path": ".claude/skills/retrospective-validation",
      "github_metadata": {
        "stars": 15,
        "description": "Meta-Cognition tool for Claude Code - analyze session history for workflow optimization.",
        "default_branch": "main",
        "pushed_at": "2025-12-13T10:31:07Z",
        "created_at": "2025-10-08T01:58:30Z",
        "language": "Go",
        "license": "MIT",
        "open_issues": 0,
        "forks": 1
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/retrospective-validation/SKILL.md",
        "branch": "main",
        "content": "---\nname: Retrospective Validation\ndescription: Validate methodology effectiveness using historical data without live deployment. Use when rich historical data exists (100+ instances), methodology targets observable patterns (error prevention, test strategy, performance optimization), pattern matching is feasible with clear detection rules, and live deployment has high friction (CI/CD integration effort, user study time, deployment risk). Enables 40-60% time reduction vs prospective validation, 60-80% cost reduction. Confidence calculation model provides statistical rigor. Validated in error recovery (1,336 errors, 23.7% prevention, 0.79 confidence).\nallowed-tools: Read, Grep, Glob, Bash\n---\n\n# Retrospective Validation\n\n**Validate methodologies with historical data, not live deployment.**\n\n> When you have 1,000 past errors, you don't need to wait for 1,000 future errors to prove your methodology works.\n\n---\n\n## When to Use This Skill\n\nUse this skill when:\n- ğŸ“Š **Rich historical data**: 100+ instances (errors, test failures, performance issues)\n- ğŸ¯ **Observable patterns**: Methodology targets detectable issues\n- ğŸ” **Pattern matching feasible**: Clear detection heuristics, measurable false positive rate\n- âš¡ **High deployment friction**: CI/CD integration costly, user studies time-consuming\n- ğŸ“ˆ **Statistical rigor needed**: Want confidence intervals, not just hunches\n- â° **Time constrained**: Need validation in hours, not weeks\n\n**Don't use when**:\n- âŒ Insufficient data (<50 instances)\n- âŒ Emergent effects (human behavior change, UX improvements)\n- âŒ Pattern matching unreliable (>20% false positive rate)\n- âŒ Low deployment friction (1-2 hour CI/CD integration)\n\n---\n\n## Quick Start (30 minutes)\n\n### Step 1: Check Historical Data (5 min)\n\n```bash\n# Example: Error data for meta-cc\nmeta-cc query-tools --status error | jq '. | length'\n# Output: 1336 errors âœ… (>100 threshold)\n\n# Example: Test failures from CI logs\ngrep \"FAILED\" ci-logs/*.txt | wc -l\n# Output: 427 failures âœ…\n```\n\n**Threshold**: â‰¥100 instances for statistical confidence\n\n### Step 2: Define Detection Rule (10 min)\n\n```yaml\nTool: validate-path.sh\nPrevents: \"File not found\" errors\nDetection:\n  - Error message matches: \"no such file or directory\"\n  - OR \"cannot read file\"\n  - OR \"file does not exist\"\nConfidence: High (90%+) - deterministic check\n```\n\n### Step 3: Apply Rule to Historical Data (10 min)\n\n```bash\n# Count matches\ngrep -E \"(no such file|cannot read|does not exist)\" errors.log | wc -l\n# Output: 163 errors (12.2% of total)\n\n# Sample manual validation (30 errors)\n# True positives: 28/30 (93.3%)\n# Adjusted: 163 * 0.933 = 152 preventable âœ…\n```\n\n### Step 4: Calculate Confidence (5 min)\n\n```\nConfidence = Data Quality Ã— Accuracy Ã— Logical Correctness\n           = 0.85 Ã— 0.933 Ã— 1.0\n           = 0.79 (High confidence)\n```\n\n**Result**: Tool would have prevented 152 errors with 79% confidence.\n\n---\n\n## Four-Phase Process\n\n### Phase 1: Data Collection\n\n**1. Identify Data Sources**\n\nFor Claude Code / meta-cc:\n```bash\n# Error history\nmeta-cc query-tools --status error\n\n# User pain points\nmeta-cc query-user-messages --pattern \"error|fail|broken\"\n\n# Error context\nmeta-cc query-context --error-signature \"...\"\n```\n\nFor other projects:\n- Git history (commits, diffs, blame)\n- CI/CD logs (test failures, build errors)\n- Application logs (runtime errors)\n- Issue trackers (bug reports)\n\n**2. Quantify Baseline**\n\nMetrics needed:\n- **Volume**: Total instances (e.g., 1,336 errors)\n- **Rate**: Frequency (e.g., 5.78% error rate)\n- **Distribution**: Category breakdown (e.g., file-not-found: 12.2%)\n- **Impact**: Cost (e.g., MTTD: 15 min, MTTR: 30 min)\n\n### Phase 2: Pattern Definition\n\n**1. Create Detection Rules**\n\nFor each tool/methodology:\n```yaml\nwhat_it_prevents: Error type or failure mode\ndetection_rule: Pattern matching heuristic\nconfidence: Estimated accuracy (high/medium/low)\n```\n\n**2. Define Success Criteria**\n\n```yaml\nprevention: Message matches AND tool would catch it\nspeedup: Tool faster than manual debugging\nreliability: No false positives/negatives in sample\n```\n\n### Phase 3: Validation Execution\n\n**1. Apply Rules to Historical Data**\n\n```bash\n# Pseudo-code\nfor instance in historical_data:\n  category = classify(instance)\n  tool = find_applicable_tool(category)\n  if would_have_prevented(tool, instance):\n    count_prevented++\n\nprevention_rate = count_prevented / total * 100\n```\n\n**2. Sample Manual Validation**\n\n```\nSample size: 30 instances (95% confidence)\nFor each: \"Would tool have prevented this?\"\nCalculate: True positive rate, False positive rate\nAdjust: prevention_claim * true_positive_rate\n```\n\n**Example** (Bootstrap-003):\n```\nSample: 30/317 claimed prevented\nTrue positives: 28 (93.3%)\nAdjusted: 317 * 0.933 = 296 errors\nConfidence: High (93%+)\n```\n\n**3. Measure Performance**\n\n```bash\n# Tool time\ntime tool.sh < test_input\n# Output: 0.05s\n\n# Manual time (estimate from historical data)\n# Average debug time: 15 min = 900s\n\n# Speedup: 900 / 0.05 = 18,000x\n```\n\n### Phase 4: Confidence Assessment\n\n**Confidence Formula**:\n\n```\nConfidence = D Ã— A Ã— L\n\nWhere:\nD = Data Quality (0.5-1.0)\nA = Accuracy (True Positive Rate, 0.5-1.0)\nL = Logical Correctness (0.5-1.0)\n```\n\n**Data Quality** (D):\n- 1.0: Complete, accurate, representative\n- 0.8-0.9: Minor gaps or biases\n- 0.6-0.7: Significant gaps\n- <0.6: Unreliable data\n\n**Accuracy** (A):\n- 1.0: 100% true positive rate (verified)\n- 0.8-0.95: High (sample validation 80-95%)\n- 0.6-0.8: Medium (60-80%)\n- <0.6: Low (unreliable pattern matching)\n\n**Logical Correctness** (L):\n- 1.0: Deterministic (tool directly addresses root cause)\n- 0.8-0.9: High correlation (strong evidence)\n- 0.6-0.7: Moderate correlation\n- <0.6: Weak or speculative\n\n**Example** (Bootstrap-003):\n```\nD = 0.85 (Complete error logs, minor gaps in context)\nA = 0.933 (93.3% true positive rate from sample)\nL = 1.0 (File validation is deterministic)\n\nConfidence = 0.85 Ã— 0.933 Ã— 1.0 = 0.79 (High)\n```\n\n**Interpretation**:\n- â‰¥0.75: High confidence (publishable)\n- 0.60-0.74: Medium confidence (needs caveats)\n- 0.45-0.59: Low confidence (suggestive, not conclusive)\n- <0.45: Insufficient confidence (need prospective validation)\n\n---\n\n## Comparison: Retrospective vs Prospective\n\n| Aspect | Retrospective | Prospective |\n|--------|--------------|-------------|\n| **Time** | Hours-days | Weeks-months |\n| **Cost** | Low (queries) | High (deployment) |\n| **Risk** | Zero | May introduce issues |\n| **Confidence** | 0.60-0.95 | 0.90-1.0 |\n| **Data** | Historical | New |\n| **Scope** | Full history | Limited window |\n| **Bias** | Hindsight | None |\n\n**When to use each**:\n- **Retrospective**: Fast validation, high data volume, observable patterns\n- **Prospective**: Behavioral effects, UX, emergent properties\n- **Hybrid**: Retrospective first, limited prospective for edge cases\n\n---\n\n## Success Criteria\n\nRetrospective validation succeeded when:\n\n1. **Sufficient data**: â‰¥100 instances analyzed\n2. **High confidence**: â‰¥0.75 overall confidence score\n3. **Sample validated**: â‰¥80% true positive rate\n4. **Impact quantified**: Prevention % or speedup measured\n5. **Time savings**: 40-60% faster than prospective validation\n\n**Bootstrap-003 Validation**:\n- âœ… Data: 1,336 errors analyzed\n- âœ… Confidence: 0.79 (high)\n- âœ… Sample: 93.3% true positive rate\n- âœ… Impact: 23.7% error prevention\n- âœ… Time: 3 hours vs 2+ weeks (prospective)\n\n---\n\n## Related Skills\n\n**Parent framework**:\n- [methodology-bootstrapping](../methodology-bootstrapping/SKILL.md) - Core OCA cycle\n\n**Complementary acceleration**:\n- [rapid-convergence](../rapid-convergence/SKILL.md) - Fast iteration (uses retrospective)\n- [baseline-quality-assessment](../baseline-quality-assessment/SKILL.md) - Strong iteration 0\n\n---\n\n## References\n\n**Core guide**:\n- [Four-Phase Process](reference/process.md) - Detailed methodology\n- [Confidence Calculation](reference/confidence.md) - Statistical rigor\n- [Detection Rules](reference/detection-rules.md) - Pattern matching guide\n\n**Examples**:\n- [Error Recovery Validation](examples/error-recovery-1336-errors.md) - Bootstrap-003\n\n---\n\n**Status**: âœ… Validated | Bootstrap-003 | 0.79 confidence | 40-60% time reduction\n"
      },
      "discovered_at": "2026-01-11T15:36:33.870834Z",
      "fetch_error": null
    },
    {
      "name": "subagent-prompt-construction",
      "slug": "subagent-prompt-construction",
      "source": "skillsmp",
      "owner": "yaleh",
      "repo_name": "meta-cc",
      "repository_url": "https://github.com/yaleh/meta-cc",
      "skill_path": ".claude/skills/subagent-prompt-construction",
      "github_metadata": {
        "stars": 15,
        "description": "Meta-Cognition tool for Claude Code - analyze session history for workflow optimization.",
        "default_branch": "main",
        "pushed_at": "2025-12-13T10:31:07Z",
        "created_at": "2025-10-08T01:58:30Z",
        "language": "Go",
        "license": "MIT",
        "open_issues": 0,
        "forks": 1
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/subagent-prompt-construction/SKILL.md",
        "branch": "main",
        "content": "---\nname: subagent-prompt-construction\ndescription: Systematic methodology for constructing compact (<150 lines), expressive, Claude Code-integrated subagent prompts using lambda contracts and symbolic logic. Use when creating new specialized subagents for Claude Code with agent composition, MCP tool integration, or skill references. Validated with phase-planner-executor (V_instance=0.895).\nversion: 1.0\nstatus: validated\nv_meta: 0.709\nv_instance: 0.895\ntransferability: 95%\n---\n\nÎ»(use_case, complexity) â†’ subagent_prompt |\n  âˆ§ require(need_orchestration(use_case) âˆ¨ need_mcp_integration(use_case))\n  âˆ§ complexity âˆˆ {simple, moderate, complex}\n  âˆ§ line_target = {simple: 30-60, moderate: 60-120, complex: 120-150}\n  âˆ§ template = read(templates/subagent-template.md)\n  âˆ§ patterns = read(reference/patterns.md)\n  âˆ§ integration = read(reference/integration-patterns.md)\n  âˆ§ apply(template, use_case, patterns, integration) â†’ draft\n  âˆ§ validate(|draft| â‰¤ 150 âˆ§ integration_score â‰¥ 0.50 âˆ§ clarity â‰¥ 0.80)\n  âˆ§ examples/{phase-planner-executor.md} demonstrates orchestration\n  âˆ§ reference/case-studies/* provides detailed analysis\n  âˆ§ scripts/ provide validation and metrics automation\n  âˆ§ output = {prompt: draft, metrics: validation_report}\n\n**Artifacts**:\n- **templates/**: Reusable subagent template (lambda contract structure)\n- **examples/**: Compact validated examples (â‰¤150 lines each)\n- **reference/patterns.md**: Core patterns (orchestration, analysis, enhancement)\n- **reference/integration-patterns.md**: Claude Code feature integration (agents, MCP, skills)\n- **reference/symbolic-language.md**: Formal syntax reference (logic operators, quantifiers)\n- **reference/case-studies/**: Detailed analysis and design rationale\n- **scripts/**: Automation tools (validation, metrics, pattern extraction)\n\n**Usage**: See templates/subagent-template.md for structure. Apply integration patterns for Claude Code features. Validate compactness (â‰¤150 lines), integration (â‰¥1 feature), clarity. Reference examples/ for compact demonstrations and case-studies/ for detailed analysis.\n\n**Constraints**: Max 150 lines per prompt | Use symbolic logic for compactness | Explicit dependencies section | Integration score â‰¥0.50 | Test coverage â‰¥80% for generated artifacts\n\n**Validation**: V_instance=0.895 (phase-planner-executor: 92 lines, 2 agents, 2 MCP tools) | V_meta=0.709 (compactness=0.65, integration=0.857, maintainability=0.85) | Transferability=95%\n"
      },
      "discovered_at": "2026-01-11T15:36:34.315279Z",
      "fetch_error": null
    },
    {
      "name": "technical-debt-management",
      "slug": "technical-debt-management",
      "source": "skillsmp",
      "owner": "yaleh",
      "repo_name": "meta-cc",
      "repository_url": "https://github.com/yaleh/meta-cc",
      "skill_path": ".claude/skills/technical-debt-management",
      "github_metadata": {
        "stars": 15,
        "description": "Meta-Cognition tool for Claude Code - analyze session history for workflow optimization.",
        "default_branch": "main",
        "pushed_at": "2025-12-13T10:31:07Z",
        "created_at": "2025-10-08T01:58:30Z",
        "language": "Go",
        "license": "MIT",
        "open_issues": 0,
        "forks": 1
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/technical-debt-management/SKILL.md",
        "branch": "main",
        "content": "---\nname: Technical Debt Management\ndescription: Systematic technical debt quantification and management using SQALE methodology with value-effort prioritization, phased paydown roadmaps, and prevention strategies. Use when technical debt unmeasured or subjective, need objective prioritization, planning refactoring work, establishing debt prevention practices, or tracking debt trends over time. Provides 6 methodology components (measurement with SQALE index, categorization with code smell taxonomy, prioritization with value-effort matrix, phased paydown roadmap, trend tracking system, prevention guidelines), 3 patterns (SQALE-based quantification, code smell taxonomy mapping, value-effort prioritization), 3 principles (high-value low-effort first, SQALE provides objective baseline, complexity drives maintainability debt). Validated with 4.5x speedup vs manual approach, 85% transferability across languages (Go, Python, JavaScript, Java, Rust), SQALE industry-standard methodology.\nallowed-tools: Read, Write, Edit, Bash, Grep, Glob\n---\n\n# Technical Debt Management\n\n**Transform subjective debt assessment into objective, data-driven paydown strategy with 4.5x speedup.**\n\n> Measure what matters. Prioritize by value. Pay down strategically. Prevent proactively.\n\n---\n\n## When to Use This Skill\n\nUse this skill when:\n- ğŸ“Š **Unmeasured debt**: Technical debt unknown or subjectively assessed\n- ğŸ¯ **Need prioritization**: Many debt items, unclear which to tackle first\n- ğŸ“ˆ **Planning refactoring**: Need objective justification and ROI analysis\n- ğŸš¨ **Debt accumulation**: Debt growing but no tracking system\n- ğŸ”„ **Prevention lacking**: Reactive debt management, no proactive practices\n- ğŸ“‹ **Objective reporting**: Stakeholders need quantified debt metrics\n\n**Don't use when**:\n- âŒ Debt already well-quantified with SQALE or similar methodology\n- âŒ Codebase very small (<1K LOC, minimal debt accumulation)\n- âŒ No refactoring capacity (debt measurement without action is wasteful)\n- âŒ Tools unavailable (need complexity, coverage, duplication analysis tools)\n\n---\n\n## Quick Start (30 minutes)\n\n### Step 1: Calculate SQALE Index (15 min)\n\n**SQALE Formula**:\n```\nDevelopment Cost = LOC / 30  (30 LOC/hour productivity)\nTechnical Debt = Remediation Cost (hours)\nTD Ratio = Technical Debt / Development Cost Ã— 100%\n```\n\n**SQALE Ratings**:\n- A (Excellent): â‰¤5% TD ratio\n- B (Good): 6-10%\n- C (Moderate): 11-20%\n- D (Poor): 21-50%\n- E (Critical): >50%\n\n**Example** (meta-cc):\n```\nLOC: 12,759\nDevelopment Cost: 425.3 hours\nTechnical Debt: 66.0 hours\nTD Ratio: 15.52% (Rating: C - Moderate)\n```\n\n### Step 2: Categorize Debt (10 min)\n\n**SQALE Code Smell Taxonomy**:\n1. **Bloaters**: Long methods, large classes (complexity debt)\n2. **Change Preventers**: Shotgun surgery, divergent change (flexibility debt)\n3. **Reliability Issues**: Test coverage gaps, error handling (quality debt)\n4. **Couplers**: Feature envy, inappropriate intimacy (coupling debt)\n5. **Dispensables**: Duplicate code, dead code (maintainability debt)\n\n**Example Breakdown**:\n- Complexity: 54.5 hours (82.6%)\n- Coverage: 10.0 hours (15.2%)\n- Duplication: 1.0 hours (1.5%)\n\n### Step 3: Prioritize with Value-Effort Matrix (5 min)\n\n**Four Quadrants**:\n```\nHigh Value, Low Effort  â†’ Quick Wins (do first)\nHigh Value, High Effort â†’ Strategic (plan carefully)\nLow Value, Low Effort   â†’ Opportunistic (do when convenient)\nLow Value, High Effort  â†’ Avoid (skip unless critical)\n```\n\n**Quick Wins Example**:\n- Fix error capitalization (0.5 hours)\n- Increase test coverage for small module (2.0 hours)\n\n---\n\n## Six Methodology Components\n\n### 1. Measurement Framework (SQALE)\n\n**Objective**: Quantify technical debt objectively using industry-standard SQALE methodology\n\n**Three Calculations**:\n\n**A. Development Cost**:\n```\nDevelopment Cost = LOC / Productivity\nProductivity = 30 LOC/hour (SQALE standard)\n```\n\n**B. Remediation Cost** (Complexity Example):\n```\nGraduated Thresholds:\n- Low complexity (â‰¤10): 0 hours\n- Medium complexity (11-15): 0.5 hours per function\n- High complexity (16-25): 1.0 hours per function\n- Very high (26-50): 2.0 hours per function\n- Extreme (>50): 4.0 hours per function\n```\n\n**C. Technical Debt Ratio**:\n```\nTD Ratio = (Total Remediation Cost / Development Cost) Ã— 100%\nSQALE Rating = Map TD Ratio to A-E scale\n```\n\n**Tools**:\n- Go: gocyclo, gocov, golangci-lint\n- Python: radon, pylint, pytest-cov\n- JavaScript: eslint, jscpd, nyc\n- Java: PMD, JaCoCo, CheckStyle\n- Rust: cargo-geiger, clippy\n\n**Output**: SQALE Index Report (total debt, TD ratio, rating, breakdown by category)\n\n**Transferability**: 100% (SQALE formulas language-agnostic)\n\n---\n\n### 2. Categorization Framework (Code Smells)\n\n**Objective**: Map metrics to SQALE code smell taxonomy for prioritization\n\n**Five SQALE Categories**:\n\n**1. Bloaters** (Complexity Debt):\n- Long methods (cyclomatic complexity >10)\n- Large classes (>500 LOC)\n- Long parameter lists (>5 parameters)\n- **Remediation**: Extract method, split class, introduce parameter object\n\n**2. Change Preventers** (Flexibility Debt):\n- Shotgun surgery (change requires touching multiple files)\n- Divergent change (class changes for multiple reasons)\n- **Remediation**: Consolidate logic, introduce abstraction layer\n\n**3. Reliability Issues** (Quality Debt):\n- Test coverage gaps (<80% target)\n- Missing error handling\n- **Remediation**: Add tests, implement error handling\n\n**4. Couplers** (Coupling Debt):\n- Feature envy (method uses data from another class more than own)\n- Inappropriate intimacy (high coupling between modules)\n- **Remediation**: Move method, reduce coupling\n\n**5. Dispensables** (Maintainability Debt):\n- Duplicate code (>3% duplication ratio)\n- Dead code (unreachable functions)\n- **Remediation**: Extract common code, remove dead code\n\n**Output**: Code Smell Report (smell type, instances, files, remediation cost)\n\n**Transferability**: 80-90% (OO smells apply to OO languages only, others universal)\n\n---\n\n### 3. Prioritization Framework (Value-Effort Matrix)\n\n**Objective**: Rank debt items by ROI (business value / remediation effort)\n\n**Business Value Assessment** (3 factors):\n1. **User Impact**: Does debt affect user experience? (0-10)\n2. **Change Frequency**: How often is this code changed? (0-10)\n3. **Error Risk**: Does debt cause bugs? (0-10)\n4. **Total Value**: Sum of 3 factors (0-30)\n\n**Effort Estimation**:\n- Use SQALE remediation cost model\n- Factor in testing, code review, deployment time\n\n**Value-Effort Quadrants**:\n```\n         High Value\n         |\n Quick   |   Strategic\n  Wins   |\n---------|------------- Effort\nOpportun-|   Avoid\n  istic  |\n         |\n       Low Value\n```\n\n**Priority Ranking**:\n1. Quick Wins (high value, low effort)\n2. Strategic (high value, high effort) - plan carefully\n3. Opportunistic (low value, low effort) - when convenient\n4. Avoid (low value, high effort) - skip unless critical\n\n**Output**: Prioritization Matrix (debt items ranked by quadrant)\n\n**Transferability**: 95% (value-effort concept universal, specific values vary)\n\n---\n\n### 4. Paydown Framework (Phased Roadmap)\n\n**Objective**: Create actionable, phased plan for debt reduction\n\n**Four Phases**:\n\n**Phase 1: Quick Wins** (0-2 hours)\n- Highest ROI items\n- Build momentum, demonstrate value\n- Example: Fix lint issues, error capitalization\n\n**Phase 2: Coverage Gaps** (2-12 hours)\n- Test coverage improvements\n- Prevent regressions, enable refactoring confidence\n- Example: Add integration tests, increase coverage to â‰¥80%\n\n**Phase 3: Strategic Complexity** (12-30 hours)\n- High-value, high-effort refactoring\n- Address architectural debt\n- Example: Consolidate duplicated logic, refactor high-complexity functions\n\n**Phase 4: Opportunistic** (as time allows)\n- Low-priority items tackled when working nearby\n- Example: Refactor during feature development in same area\n\n**Expected Improvements** (calculate per phase):\n```\nPhase TD Reduction = Sum of remediation costs in phase\nNew TD Ratio = (Total Debt - Phase TD Reduction) / Development Cost Ã— 100%\nNew SQALE Rating = Map new TD ratio to A-E scale\n```\n\n**Output**: Paydown Roadmap (4 phases, time estimates, expected TD ratio improvements)\n\n**Transferability**: 100% (phased approach universal)\n\n---\n\n### 5. Tracking Framework (Trend Analysis)\n\n**Objective**: Continuous debt monitoring with early warning alerts\n\n**Five Tracking Components**:\n\n**1. Automated Data Collection**:\n- Weekly metrics collection (complexity, coverage, duplication)\n- CI/CD integration (collect on every build)\n\n**2. Baseline Storage**:\n- Quarterly SQALE snapshots\n- Historical comparison (track delta)\n\n**3. Trend Tracking**:\n- Time series: TD ratio, complexity, coverage, hotspots\n- Identify trends (increasing, decreasing, stable)\n\n**4. Visualization Dashboard**:\n- TD ratio over time\n- Debt by category (stacked area chart)\n- Coverage trends\n- Complexity heatmap\n- Hotspot analysis (files with most debt)\n\n**5. Alerting Rules**:\n- TD ratio increase >5% in 1 month\n- Coverage drop >5%\n- New high-complexity functions (>25 complexity)\n- Duplication spike >3%\n\n**Expected Impact**:\n- Visibility: Point-in-time â†’ continuous trends\n- Decision making: Reactive â†’ data-driven proactive\n- Early warning: Alert before debt spikes\n\n**Output**: Tracking System Design (automation plan, dashboard mockups, alert rules)\n\n**Transferability**: 95% (tracking concept universal, tools vary)\n\n---\n\n### 6. Prevention Framework (Proactive Practices)\n\n**Objective**: Prevent new debt accumulation through gates and practices\n\n**Six Prevention Strategies**:\n\n**1. Pre-Commit Complexity Gates**:\n```bash\n# Reject commits with functions >15 complexity\ngocyclo -over 15 .\n```\n\n**2. Test Coverage Requirements**:\n- Overall: â‰¥80%\n- New code: â‰¥90%\n- CI/CD gate: Fail build if coverage drops\n\n**3. Static Analysis Enforcement**:\n- Zero tolerance for critical issues\n- Warning threshold (fail if >10 warnings)\n\n**4. Code Review Checklist** (6 debt prevention items):\n- [ ] No functions >15 complexity\n- [ ] Test coverage â‰¥90% for new code\n- [ ] No duplicate code (DRY principle)\n- [ ] Error handling complete\n- [ ] No dead code\n- [ ] Architecture consistency maintained\n\n**5. Refactoring Time Budget**:\n- Allocate 20% sprint capacity for refactoring\n- Opportunistic paydown during feature work\n\n**6. Architecture Review**:\n- Quarterly health checks\n- Identify architectural debt early\n- Plan strategic refactoring\n\n**Expected Impact**:\n- TD accumulation: 2%/quarter â†’ <0.5%/quarter\n- ROI: 4 days saved per quarter (prevention time << paydown time)\n\n**Output**: Prevention Guidelines (pre-commit hooks, CI/CD gates, code review checklist)\n\n**Transferability**: 85% (specific thresholds vary, practices universal)\n\n---\n\n## Three Extracted Patterns\n\n### Pattern 1: SQALE-Based Debt Quantification\n\n**Problem**: Subjective debt assessment leads to inconsistent prioritization\n\n**Solution**: Use SQALE methodology for objective, reproducible measurement\n\n**Structure**:\n1. Calculate development cost (LOC / 30)\n2. Calculate remediation cost (graduated thresholds)\n3. Calculate TD ratio (remediation / development Ã— 100%)\n4. Assign SQALE rating (A-E)\n\n**Benefits**:\n- Objective (same methodology, same results)\n- Reproducible (industry standard)\n- Comparable (across projects, over time)\n\n**Transferability**: 90% (formulas universal, threshold calibration language-specific)\n\n---\n\n### Pattern 2: Code Smell Taxonomy Mapping\n\n**Problem**: Metrics (complexity, duplication) don't directly translate to actionable insights\n\n**Solution**: Map metrics to SQALE code smell taxonomy for clear remediation strategies\n\n**Structure**:\n```\nMetric â†’ Code Smell â†’ Remediation Strategy\nComplexity >10 â†’ Long Method (Bloater) â†’ Extract Method\nDuplication >3% â†’ Duplicate Code (Dispensable) â†’ Extract Common Code\nCoverage <80% â†’ Test Gap (Reliability Issue) â†’ Add Tests\n```\n\n**Benefits**:\n- Actionable (smell â†’ remediation)\n- Prioritizable (smell severity)\n- Educational (developers learn smell patterns)\n\n**Transferability**: 80% (OO smells require adaptation for non-OO languages)\n\n---\n\n### Pattern 3: Value-Effort Prioritization Matrix\n\n**Problem**: Too many debt items, unclear which to tackle first\n\n**Solution**: Rank by ROI using value-effort matrix\n\n**Structure**:\n1. Assess business value (user impact + change frequency + error risk)\n2. Estimate remediation effort (SQALE model)\n3. Plot on matrix (4 quadrants)\n4. Prioritize: Quick Wins â†’ Strategic â†’ Opportunistic â†’ Avoid\n\n**Benefits**:\n- ROI-driven (maximize value per hour)\n- Transparent (stakeholders understand prioritization)\n- Flexible (adjust value weights per project)\n\n**Transferability**: 95% (concept universal, specific values vary)\n\n---\n\n## Three Principles\n\n### Principle 1: Pay High-Value Low-Effort Debt First\n\n**Statement**: \"Maximize ROI by prioritizing high-value low-effort debt (quick wins) before tackling strategic debt\"\n\n**Rationale**:\n- Build momentum (early wins)\n- Demonstrate value (stakeholder buy-in)\n- Free up capacity (small wins compound)\n\n**Evidence**: Quick wins phase (0.5-2 hours) enables larger strategic work\n\n**Application**: Always start paydown roadmap with quick wins\n\n---\n\n### Principle 2: SQALE Provides Objective Baseline\n\n**Statement**: \"Use SQALE methodology for objective, reproducible debt measurement to enable data-driven decisions\"\n\n**Rationale**:\n- Subjective assessment varies by developer\n- Objective measurement enables comparison (projects, time periods)\n- Industry standard (validated across thousands of projects)\n\n**Evidence**: 4.5x speedup vs manual approach, objective vs subjective\n\n**Application**: Calculate SQALE index before any debt work\n\n---\n\n### Principle 3: Complexity Drives Maintainability Debt\n\n**Statement**: \"Complexity debt dominates technical debt (often 70-90%), focus refactoring on high-complexity functions\"\n\n**Rationale**:\n- High complexity â†’ hard to understand â†’ slow changes â†’ bugs\n- Complexity compounds (high complexity attracts more complexity)\n- Refactoring complexity has highest impact\n\n**Evidence**: 82.6% of meta-cc debt from complexity (54.5/66 hours)\n\n**Application**: Prioritize complexity reduction in paydown roadmaps\n\n---\n\n## Proven Results\n\n**Validated in bootstrap-012 (meta-cc project)**:\n- âœ… SQALE Index: 66 hours debt, 15.52% TD ratio, rating C (Moderate)\n- âœ… Methodology: 6/6 components complete (measurement, categorization, prioritization, paydown, tracking, prevention)\n- âœ… Convergence: V_instance = 0.805, V_meta = 0.855 (both >0.80)\n- âœ… Duration: 4 iterations, ~7 hours\n- âœ… Paydown roadmap: 31.5 hours â†’ rating B (8.23%, -47.7% debt reduction)\n\n**Effectiveness Validation**:\n- Manual approach: 9 hours (ad-hoc review, subjective prioritization)\n- Methodology approach: 2 hours (tool-based, SQALE calculation)\n- **Speedup**: 4.5x âœ…\n- **Accuracy**: Subjective â†’ Objective (SQALE standard)\n- **Reproducibility**: Low â†’ High\n\n**Transferability Validation** (5 languages analyzed):\n- Go: 90% transferable (native)\n- Python: 85% (tools: radon, pylint, pytest-cov)\n- JavaScript: 85% (tools: eslint, jscpd, nyc)\n- Java: 90% (tools: PMD, JaCoCo, CheckStyle)\n- Rust: 80% (tools: cargo-geiger, clippy, skip OO smells)\n- **Overall**: 85% transferable âœ…\n\n**Universal Components** (13/16, 81%):\n- SQALE formulas (100%)\n- Prioritization matrix (100%)\n- Paydown roadmap (100%)\n- Code smell taxonomy (90%, OO smells excluded)\n- Tracking approach (95%)\n- Prevention practices (85%)\n\n---\n\n## Common Anti-Patterns\n\nâŒ **Measurement without action**: Calculating debt but not creating paydown plan\nâŒ **Strategic-only focus**: Skipping quick wins, tackling only big refactoring (low momentum)\nâŒ **No prevention**: Paying down debt without gates (debt re-accumulates)\nâŒ **Subjective prioritization**: \"This code is bad\" without quantified impact\nâŒ **Tool-free assessment**: Manual review instead of automated metrics (4.5x slower)\nâŒ **No tracking**: Point-in-time snapshot instead of continuous monitoring (reactive)\n\n---\n\n## Templates and Examples\n\n### Templates\n- [SQALE Index Report Template](templates/sqale-index-report-template.md) - Standard debt measurement report\n- [Code Smell Categorization Template](templates/code-smell-categorization-template.md) - Map metrics to smells\n- [Remediation Cost Breakdown Template](templates/remediation-cost-breakdown-template.md) - Estimate paydown effort\n- [Transfer Guide Template](templates/transfer-guide-template.md) - Adapt methodology to new language\n\n### Examples\n- [SQALE Calculation Walkthrough](examples/sqale-calculation-example.md) - Step-by-step meta-cc example\n- [Value-Effort Prioritization](examples/value-effort-matrix-example.md) - Prioritization matrix with real debt items\n- [Phased Paydown Roadmap](examples/paydown-roadmap-example.md) - 4-phase plan with TD ratio improvements\n\n---\n\n## Related Skills\n\n**Parent framework**:\n- [methodology-bootstrapping](../methodology-bootstrapping/SKILL.md) - Core OCA cycle\n\n**Complementary domains**:\n- [testing-strategy](../testing-strategy/SKILL.md) - Coverage debt reduction\n- [ci-cd-optimization](../ci-cd-optimization/SKILL.md) - Prevention gates\n- [cross-cutting-concerns](../cross-cutting-concerns/SKILL.md) - Architectural debt patterns\n\n---\n\n## References\n\n**Core methodology**:\n- [SQALE Methodology](reference/sqale-methodology.md) - Complete SQALE guide\n- [Code Smell Taxonomy](reference/code-smell-taxonomy.md) - SQALE categories with examples\n- [Prioritization Framework](reference/prioritization-framework.md) - Value-effort matrix guide\n- [Transfer Guide](reference/transfer-guide.md) - Language-specific adaptations\n\n**Quick guides**:\n- [15-Minute SQALE Analysis](reference/quick-sqale-analysis.md) - Fast debt measurement\n- [Remediation Cost Estimation](reference/remediation-cost-guide.md) - Effort calculation\n\n---\n\n**Status**: âœ… Production-ready | Validated in meta-cc | 4.5x speedup | 85% transferable\n"
      },
      "discovered_at": "2026-01-11T15:36:34.595961Z",
      "fetch_error": null
    },
    {
      "name": "testing-strategy",
      "slug": "testing-strategy",
      "source": "skillsmp",
      "owner": "yaleh",
      "repo_name": "meta-cc",
      "repository_url": "https://github.com/yaleh/meta-cc",
      "skill_path": ".claude/skills/testing-strategy",
      "github_metadata": {
        "stars": 15,
        "description": "Meta-Cognition tool for Claude Code - analyze session history for workflow optimization.",
        "default_branch": "main",
        "pushed_at": "2025-12-13T10:31:07Z",
        "created_at": "2025-10-08T01:58:30Z",
        "language": "Go",
        "license": "MIT",
        "open_issues": 0,
        "forks": 1
      },
      "skill_md": {
        "found": true,
        "path": ".claude/skills/testing-strategy/SKILL.md",
        "branch": "main",
        "content": "---\nname: Testing Strategy\ndescription: Systematic testing methodology for Go projects using TDD, coverage-driven gap closure, fixture patterns, and CLI testing. Use when establishing test strategy from scratch, improving test coverage from 60-75% to 80%+, creating test infrastructure with mocks and fixtures, building CLI test suites, or systematizing ad-hoc testing. Provides 8 documented patterns (table-driven, golden file, fixture, mocking, CLI testing, integration, helper utilities, coverage-driven gap closure), 3 automation tools (coverage analyzer 186x speedup, test generator 200x speedup, methodology guide 7.5x speedup). Validated across 3 project archetypes with 3.1x average speedup, 5.8% adaptation effort, 89% transferability to Python/Rust/TypeScript.\nallowed-tools: Read, Write, Edit, Bash, Grep, Glob\n---\n\n# Testing Strategy\n\n**Transform ad-hoc testing into systematic, coverage-driven strategy with 15x speedup.**\n\n> Coverage is a means, quality is the goal. Systematic testing beats heroic testing.\n\n---\n\n## When to Use This Skill\n\nUse this skill when:\n- ğŸ¯ **Starting new project**: Need systematic testing from day 1\n- ğŸ“Š **Coverage below 75%**: Want to reach 80%+ systematically\n- ğŸ”§ **Test infrastructure**: Building fixtures, mocks, test helpers\n- ğŸ–¥ï¸ **CLI applications**: Need CLI-specific testing patterns\n- ğŸ”„ **Refactoring legacy**: Adding tests to existing code\n- ğŸ“ˆ **Quality gates**: Implementing CI/CD coverage enforcement\n\n**Don't use when**:\n- âŒ Coverage already >90% with good quality\n- âŒ Non-Go projects without adaptation (89% transferable, needs language-specific adjustments)\n- âŒ No CI/CD infrastructure (automation tools require CI integration)\n- âŒ Time budget <10 hours (methodology requires investment)\n\n---\n\n## Quick Start (30 minutes)\n\n### Step 1: Measure Baseline (10 min)\n\n```bash\n# Run tests with coverage\ngo test -coverprofile=coverage.out ./...\ngo tool cover -func=coverage.out\n\n# Identify gaps\n# - Total coverage %\n# - Packages below 75%\n# - Critical paths uncovered\n```\n\n### Step 2: Apply Coverage-Driven Gap Closure (15 min)\n\n**Priority algorithm**:\n1. **Critical paths first**: Core business logic, error handling\n2. **Low-hanging fruit**: Pure functions, simple validators\n3. **Complex integrations**: File I/O, external APIs, CLI commands\n\n### Step 3: Use Test Pattern (5 min)\n\n```go\n// Table-driven test pattern\nfunc TestFunction(t *testing.T) {\n    tests := []struct {\n        name    string\n        input   InputType\n        want    OutputType\n        wantErr bool\n    }{\n        {\"happy path\", validInput, expectedOutput, false},\n        {\"error case\", invalidInput, zeroValue, true},\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            got, err := Function(tt.input)\n            if (err != nil) != tt.wantErr {\n                t.Errorf(\"error = %v, wantErr %v\", err, tt.wantErr)\n            }\n            if !reflect.DeepEqual(got, tt.want) {\n                t.Errorf(\"got %v, want %v\", got, tt.want)\n            }\n        })\n    }\n}\n```\n\n---\n\n## Eight Test Patterns\n\n### 1. Table-Driven Tests (Universal)\n\n**Use for**: Multiple input/output combinations\n**Transferability**: 100% (works in all languages)\n\n**Benefits**:\n- Comprehensive coverage with minimal code\n- Easy to add new test cases\n- Clear separation of data vs logic\n\nSee [reference/patterns.md#table-driven](reference/patterns.md) for detailed examples.\n\n### 2. Golden File Testing (Complex Outputs)\n\n**Use for**: Large outputs (JSON, HTML, formatted text)\n**Transferability**: 95% (concept universal, tools vary)\n\n**Pattern**:\n```go\ngolden := filepath.Join(\"testdata\", \"golden\", \"output.json\")\nif *update {\n    os.WriteFile(golden, got, 0644)\n}\nwant, _ := os.ReadFile(golden)\nassert.Equal(t, want, got)\n```\n\n### 3. Fixture Patterns (Integration Tests)\n\n**Use for**: Complex setup (DB, files, configurations)\n**Transferability**: 90%\n\n**Pattern**:\n```go\nfunc LoadFixture(t *testing.T, name string) *Model {\n    data, _ := os.ReadFile(fmt.Sprintf(\"testdata/fixtures/%s.json\", name))\n    var model Model\n    json.Unmarshal(data, &model)\n    return &model\n}\n```\n\n### 4. Mocking External Dependencies\n\n**Use for**: APIs, databases, file systems\n**Transferability**: 85% (Go-specific interfaces, patterns universal)\n\nSee [reference/patterns.md#mocking](reference/patterns.md) for detailed strategies.\n\n### 5. CLI Testing\n\n**Use for**: Command-line applications\n**Transferability**: 80% (subprocess testing varies by language)\n\n**Strategies**:\n- Capture stdout/stderr\n- Mock os.Exit\n- Test flag parsing\n- End-to-end subprocess testing\n\nSee [templates/cli-test-template.go](templates/cli-test-template.go).\n\n### 6. Integration Test Patterns\n\n**Use for**: Multi-component interactions\n**Transferability**: 90%\n\n### 7. Test Helper Utilities\n\n**Use for**: Reduce boilerplate, improve readability\n**Transferability**: 95%\n\n### 8. Coverage-Driven Gap Closure\n\n**Use for**: Systematic improvement from 60% to 80%+\n**Transferability**: 100% (methodology universal)\n\n**Algorithm**:\n```\nWHILE coverage < threshold:\n  1. Run coverage analysis\n  2. Identify file with lowest coverage\n  3. Analyze uncovered lines\n  4. Prioritize: critical > easy > complex\n  5. Write tests\n  6. Re-measure\n```\n\n---\n\n## Three Automation Tools\n\n### 1. Coverage Gap Analyzer (186x speedup)\n\n**What it does**: Analyzes go tool cover output, identifies gaps by priority\n\n**Speedup**: 15 min manual â†’ 5 sec automated (186x)\n\n**Usage**:\n```bash\n./scripts/analyze-coverage.sh coverage.out\n# Output: Priority-ranked list of files needing tests\n```\n\nSee [reference/automation-tools.md#coverage-analyzer](reference/automation-tools.md).\n\n### 2. Test Generator (200x speedup)\n\n**What it does**: Generates table-driven test boilerplate from function signatures\n\n**Speedup**: 10 min manual â†’ 3 sec automated (200x)\n\n**Usage**:\n```bash\n./scripts/generate-test.sh pkg/parser/parse.go ParseTools\n# Output: Complete table-driven test scaffold\n```\n\n### 3. Methodology Guide Generator (7.5x speedup)\n\n**What it does**: Creates project-specific testing guide from patterns\n\n**Speedup**: 6 hours manual â†’ 48 min automated (7.5x)\n\n---\n\n## Proven Results\n\n**Validated in bootstrap-002 (meta-cc project)**:\n- âœ… Coverage: 72.1% â†’ 72.5% (maintained above target)\n- âœ… Test count: 590 â†’ 612 tests (+22)\n- âœ… Test reliability: 100% pass rate\n- âœ… Duration: 6 iterations, 25.5 hours\n- âœ… V_instance: 0.80 (converged iteration 3)\n- âœ… V_meta: 0.80 (converged iteration 5)\n\n**Multi-context validation** (3 project archetypes):\n- âœ… Context A (CLI tool): 2.8x speedup, 5% adaptation\n- âœ… Context B (Library): 3.5x speedup, 3% adaptation\n- âœ… Context C (Web service): 3.0x speedup, 9% adaptation\n- âœ… Average: 3.1x speedup, 5.8% adaptation effort\n\n**Cross-language transferability**:\n- Go: 100% (native)\n- Python: 90% (pytest patterns similar)\n- Rust: 85% (cargo test compatible)\n- TypeScript: 85% (Jest patterns similar)\n- Java: 82% (JUnit compatible)\n- **Overall**: 89% transferable\n\n---\n\n## Quality Criteria\n\n### Coverage Thresholds\n- **Minimum**: 75% (gate enforcement)\n- **Target**: 80%+ (comprehensive)\n- **Excellence**: 90%+ (critical packages only)\n\n### Quality Metrics\n- Zero flaky tests (deterministic)\n- Test execution <2min (unit + integration)\n- Clear failure messages (actionable)\n- Independent tests (no ordering dependencies)\n\n### Pattern Adoption\n- âœ… Table-driven: 80%+ of test functions\n- âœ… Fixtures: All integration tests\n- âœ… Mocks: All external dependencies\n- âœ… Golden files: Complex output verification\n\n---\n\n## Common Anti-Patterns\n\nâŒ **Coverage theater**: 95% coverage but testing getters/setters\nâŒ **Integration-heavy**: Slow test suite (>5min) due to too many integration tests\nâŒ **Flaky tests**: Ignored failures undermine trust\nâŒ **Coupled tests**: Dependencies on execution order\nâŒ **Missing assertions**: Tests that don't verify behavior\nâŒ **Over-mocking**: Mocking internal functions (test implementation, not interface)\n\n---\n\n## Templates and Examples\n\n### Templates\n- [Unit Test Template](templates/unit-test-template.go) - Table-driven pattern\n- [Integration Test Template](templates/integration-test-template.go) - With fixtures\n- [CLI Test Template](templates/cli-test-template.go) - Stdout/stderr capture\n- [Mock Template](templates/mock-template.go) - Interface-based mocking\n\n### Examples\n- [Coverage-Driven Gap Closure](examples/gap-closure-walkthrough.md) - Step-by-step 60%â†’80%\n- [CLI Testing Strategy](examples/cli-testing-example.md) - Complete CLI test suite\n- [Fixture Patterns](examples/fixture-examples.md) - Integration test fixtures\n\n---\n\n## Related Skills\n\n**Parent framework**:\n- [methodology-bootstrapping](../methodology-bootstrapping/SKILL.md) - Core OCA cycle\n\n**Complementary domains**:\n- [ci-cd-optimization](../ci-cd-optimization/SKILL.md) - Quality gates, coverage enforcement\n- [error-recovery](../error-recovery/SKILL.md) - Error handling test patterns\n\n**Acceleration**:\n- [rapid-convergence](../rapid-convergence/SKILL.md) - Fast methodology development\n- [baseline-quality-assessment](../baseline-quality-assessment/SKILL.md) - Strong iteration 0\n\n---\n\n## References\n\n**Core methodology**:\n- [Test Patterns](reference/patterns.md) - All 8 patterns detailed\n- [Automation Tools](reference/automation-tools.md) - Tool usage guides\n- [Quality Criteria](reference/quality-criteria.md) - Standards and thresholds\n- [Cross-Language Transfer](reference/cross-language-guide.md) - Adaptation guides\n\n**Quick guides**:\n- [TDD Workflow](reference/tdd-workflow.md) - Red-Green-Refactor cycle\n- [Coverage-Driven Gap Closure](reference/gap-closure.md) - Algorithm and examples\n\n---\n\n**Status**: âœ… Production-ready | Validated in meta-cc + 3 contexts | 3.1x speedup | 89% transferable\n"
      },
      "discovered_at": "2026-01-11T15:36:34.871005Z",
      "fetch_error": null
    },
    {
      "name": "mcp-skill-creator",
      "slug": "mcp-skill-creator",
      "source": "skillsmp",
      "owner": "nemori-ai",
      "repo_name": "skills",
      "repository_url": "https://github.com/nemori-ai/skills",
      "skill_path": "mcp-skill-creator",
      "github_metadata": {
        "stars": 11,
        "description": "A skill for Claude that enables you to fork and iteratively improve existing skills based on your specific preferences and workflows.",
        "default_branch": "main",
        "pushed_at": "2025-11-11T08:39:06Z",
        "created_at": "2025-10-21T10:30:32Z",
        "language": "Python",
        "license": null,
        "open_issues": 0,
        "forks": 0
      },
      "skill_md": {
        "found": true,
        "path": "mcp-skill-creator/SKILL.md",
        "branch": "main",
        "content": "---\nname: mcp-skill-creator\ndescription: Meta-skill for creating workflow-optimized skills from MCP servers. Use when users want to create a custom skill that integrates one or more MCP servers into a specialized workflow. The user provides MCP server configurations and describes their work scenario (workflow, preferences, SOPs), and this skill generates a new skill with optimized scripts following Anthropic's MCP + code execution best practices.\n---\n\n# MCP-Powered Skill Creator\n\nThis meta-skill creates workflow-optimized skills from MCP servers using code execution patterns inspired by [Anthropic's MCP engineering practices](https://www.anthropic.com/engineering/code-execution-with-mcp).\n\n## Core Concept\n\nTransform MCP servers into specialized, personalized workflow skills by:\n\n1. **Progressive Disclosure**: Generate code APIs for MCP tools, loaded on-demand (not all upfront)\n2. **Context Efficiency**: Process data in execution environment, minimize token usage\n3. **Workflow Optimization**: Combine MCP calls with parallel execution, filtering, control flow\n4. **Personalization**: Embed user preferences, SOPs, and domain knowledge into the skill\n\n## When to Use This Skill\n\nUse this skill when a user wants to:\n- Create a custom skill from one or more MCP servers\n- Optimize a workflow that involves multiple MCP tool calls\n- Build reusable automation scripts for specific work scenarios\n- Capture personal SOPs and preferences into a skill\n\n## âš ï¸ IMPORTANT: Before You Start\n\n**ALWAYS check and install dependencies FIRST before doing anything else:**\n\n```bash\npython3 -c \"import mcp; print('âœ“ MCP SDK is installed')\" 2>/dev/null || pip3 install mcp --break-system-packages\n```\n\n**Automatic Installation Process:**\n1. First, check if MCP SDK is installed\n2. If not installed, **automatically install it** using `pip3 install mcp --break-system-packages`\n3. Verify installation succeeded before continuing\n4. Then proceed with skill creation\n\n**DO NOT ask the user to manually install dependencies** - you should handle this automatically as part of the skill creation process.\n\n**Why this matters**: The introspector and generated scripts require the `mcp` package. Installing it upfront ensures a smooth workflow.\n\n## Skill Creation Process\n\nFollow these steps to create an MCP-powered skill. This process combines programmatic MCP infrastructure generation with LLM-driven skill design, following skill-creator principles.\n\n### Overview of Steps\n\n0. **Prerequisites** - Install required dependencies\n1. **Gather Input** - Collect MCP servers and workflow description from user\n2. **Generate MCP Infrastructure** - Use scripts to introspect servers and create wrappers (programmatic)\n3. **Understand the Workflow** - Analyze user's scenario with concrete examples (LLM-driven)\n4. **Plan Skill Contents** - Determine what scripts, references, and guidance to include (LLM-driven)\n5. **Implement the Skill** - Write workflow scripts and SKILL.md with embedded preferences (LLM-driven)\n6. **Package and Deliver** - Create distributable .skill file\n\n### Step 0: Prerequisites (Automatic)\n\n**You should automatically check and install the MCP SDK if needed:**\n\n```bash\npython3 -c \"import mcp; print('âœ“ MCP SDK is installed')\" 2>/dev/null || pip3 install mcp --break-system-packages\n```\n\n**Process:**\n1. Check if MCP SDK is already installed\n2. If not, install it automatically with `pip3 install mcp --break-system-packages`\n3. Verify installation succeeded\n4. Inform the user that dependencies have been installed\n\n**Why needed**: The introspector and generated scripts use the `mcp` package to connect to MCP servers.\n\n**DO NOT ask the user to manually install** - handle this automatically as part of the workflow.\n\n### Step 1: Gather Input\n\nBefore starting, collect the following from the user:\n\n**MCP Server Configurations** (required):\n```json\n{\n  \"mcp_servers\": [\n    {\n      \"name\": \"server-name\",\n      \"command\": [\"npx\", \"-y\", \"@modelcontextprotocol/server-...\"]\n    }\n  ]\n}\n```\n\n**Workflow Description** (required):\n- Clear description of the workflow steps\n- Can be numbered list, sequential narrative, or structured steps\n- Example: \"First I visit the official website, then check ProductHunt, then search Twitter/Reddit, finally generate a report\"\n\n**User Preferences** (optional):\n- How they like to work\n- What data they prioritize\n- Quality standards\n- Example: \"I prefer quantitative metrics over qualitative descriptions\"\n\n**Standard Operating Procedures** (optional):\n- Company-specific practices\n- Domain knowledge\n- Best practices\n- Example: \"Always verify information from at least 3 sources\"\n\nIf user provides a single configuration file, parse it to extract these components.\n\n### Step 2: Generate MCP Infrastructure (Programmatic)\n\nThis step generates the MCP client infrastructure and tool discovery utilities.\n\n#### 2.1 Introspect MCP Servers\n\nUse `scripts/mcp_introspector.py` to discover available tools:\n\n```bash\n# Create MCP config file in skill directory\necho '{\n  \"servers\": [\n    {\n      \"name\": \"filesystem\",\n      \"command\": [\"npx\", \"-y\", \"@modelcontextprotocol/server-filesystem\", \"/path/to/dir\"]\n    }\n  ]\n}' > <skill-dir>/mcp_config.json\n\n# Run introspection\npython scripts/mcp_introspector.py <skill-dir>/mcp_config.json introspection.json\n```\n\nThis produces a JSON file with all available tools, their parameters, and descriptions.\n\n#### 2.2 Generate MCP Client and Tool Discovery\n\nUse `scripts/generate_mcp_wrappers.py` to create the infrastructure:\n\n```bash\npython scripts/generate_mcp_wrappers.py introspection.json <skill-dir>\n```\n\nThis creates:\n- `scripts/mcp_client.py` - **Working** MCP client with proper connection management\n- `scripts/list_mcp_tools.py` - **Dynamic tool discovery** (Progressive Disclosure)\n- `scripts/tools/<server>/` - (Optional) Type-safe wrappers for each tool\n\n**Generated structure**:\n```\n<skill-dir>/\nâ”œâ”€â”€ mcp_config.json           # Server configuration\nâ”œâ”€â”€ scripts/\nâ”‚   â”œâ”€â”€ mcp_client.py         # âœ… Working implementation\nâ”‚   â”œâ”€â”€ list_mcp_tools.py     # ğŸ†• View tool docs on-demand\nâ”‚   â””â”€â”€ workflows/            # (You'll create these)\nâ”‚       â””â”€â”€ your_workflow.py\n```\n\n#### 2.3 How to View MCP Tool Documentation\n\n**Progressive Disclosure** means tools are discovered on-demand, not pre-loaded. Three ways to view docs:\n\n1. **Dynamic Query** (Recommended):\n   ```bash\n   cd <skill-dir>/scripts\n   python list_mcp_tools.py\n   ```\n   Shows all available tools with parameters and descriptions.\n\n2. **Generate Static Reference**:\n   ```bash\n   python list_mcp_tools.py > references/mcp_tools_reference.txt\n   ```\n   Save for offline reference.\n\n3. **In SKILL.md**:\n   List only the most commonly used tools, full docs available via method 1 or 2.\n\n**Key Insight**: You don't need wrapper files for each tool. Just use `call_mcp_tool()` directly:\n```python\nfrom mcp_client import call_mcp_tool\n\nresult = await call_mcp_tool('filesystem', 'search_files', {\n    'path': '/path',\n    'pattern': 'myfile'\n})\n```\n\n### Step 3: Understand the Workflow (LLM-Driven)\n\nNow analyze the user's workflow description to understand what this skill needs to accomplish. Similar to skill-creator's Step 1.\n\n**Ask clarifying questions if needed**:\n- \"What specific data sources do you use?\"\n- \"How do you handle cases where data is missing?\"\n- \"What does the final output look like?\"\n- \"Are there any steps that must happen sequentially vs in parallel?\"\n\n**Identify workflow characteristics**:\n- Which steps are data fetching operations (candidates for parallelization)\n- Which steps are data processing (candidates for execution environment filtering)\n- Which steps have complex control flow (loops, conditionals, polling)\n- What intermediate state needs to be preserved\n\n**Example Analysis**:\n\nUser says: \"I research products by checking the official site, ProductHunt, Twitter, and Reddit, then create a report\"\n\nAnalysis:\n- 4 data fetch operations (parallel opportunity)\n- 1 aggregation step (data filtering opportunity)\n- 1 output generation (report creation)\n- Sequential dependency: Fetch all â†’ Aggregate â†’ Generate report\n\n### Step 4: Plan Skill Contents (LLM-Driven)\n\nBased on the workflow analysis, determine what to include in the skill. Follow skill-creator principles.\n\n#### 4.1 Decide on Scripts vs Guidance\n\n**Create scripts when**:\n- Same code would be rewritten repeatedly\n- Complex workflow with multiple MCP calls\n- Parallel execution can improve performance\n- Data filtering reduces context usage significantly\n- Polling/monitoring patterns\n\n**Use text guidance when**:\n- Workflow varies significantly each time\n- Simple single-tool operations\n- User needs flexibility in approach\n- Context helps more than code\n\n#### 4.2 Plan Script Structure\n\nFor each workflow script to create, determine:\n\n**Script purpose**: What part of the workflow does it handle?\n\n**MCP tools needed**: Which tools from which servers?\n\n**Optimization patterns**: \n- Parallel execution: `asyncio.gather()` for independent fetches\n- Data filtering: Process in execution environment before returning\n- Control flow: Loops, conditionals, error handling\n- State persistence: Save intermediate results to filesystem\n\n**Parameters**: What inputs does the script need?\n\n**Output**: What does it return? (Prefer summaries over full data)\n\n#### 4.3 Plan SKILL.md Structure\n\nDetermine what goes in SKILL.md:\n\n**Essential**:\n- Workflow overview (user's mental model)\n- When to use each script\n- User preferences (embedded as guidance)\n- SOPs (embedded as procedural instructions)\n- Available MCP tools (reference, not full docs)\n\n**Optional references/**:\n- Detailed MCP tool catalog\n- Complex schemas or API documentation  \n- Additional examples\n- Troubleshooting guides\n\n### Step 5: Implement the Skill (LLM-Driven)\n\nNow create the actual skill files. This is where you write code and documentation.\n\n#### 5.1 Write Workflow Scripts\n\nFor each planned script, create `scripts/workflows/<script_name>.py`:\n\n**Follow these patterns from Anthropic's MCP best practices**:\n\n**Pattern 1: Parallel Fetch + Aggregate**\n```python\nasync def research_pipeline(product_url: str, product_name: str) -> dict:\n    \"\"\"Complete research workflow with parallel data gathering\"\"\"\n    \n    # Parallel fetch from multiple sources\n    official_task = google_devtools.fetch_page(product_url)\n    twitter_task = x_com.search_tweets(f'\"{product_name}\"')\n    reddit_task = reddit.search_discussions(product_name)\n    \n    # Execute concurrently (3x faster than sequential)\n    official, twitter, reddit = await asyncio.gather(\n        official_task, twitter_task, reddit_task\n    )\n    \n    # Filter and aggregate in execution environment\n    # (keeps raw data out of context)\n    key_features = extract_features(official, top_n=10)\n    sentiment = analyze_sentiment([twitter, reddit])\n    highlights = extract_highlights(twitter + reddit, top_n=5)\n    \n    # Return summary (not full data)\n    return {\n        'key_features': key_features,\n        'sentiment': sentiment,\n        'highlights': highlights,\n        'source_count': len(twitter) + len(reddit)\n    }\n```\n\n**Pattern 2: Polling/Monitoring**\n```python\nasync def wait_for_deployment(channel: str, keyword: str, timeout: int = 300):\n    \"\"\"Poll Slack channel for deployment completion\"\"\"\n    start = time.time()\n    \n    while time.time() - start < timeout:\n        messages = await slack.get_channel_history(channel, limit=10)\n        \n        if any(keyword in m['text'].lower() for m in messages):\n            return {'status': 'complete', 'message': messages[0]}\n        \n        await asyncio.sleep(10)\n    \n    return {'status': 'timeout'}\n```\n\n**Pattern 3: Bulk Processing**\n```python\nasync def sync_contacts(sheet_id: str, crm_object: str):\n    \"\"\"Sync contacts from sheet to CRM (privacy-preserving)\"\"\"\n    \n    # Load data once\n    contacts = await google_sheets.get_sheet(sheet_id)\n    \n    # Filter in execution environment (not in context)\n    valid = [c for c in contacts if validate_email(c['email'])]\n    \n    # Batch update (PII never enters model context)\n    results = []\n    for batch in chunked(valid, batch_size=50):\n        batch_results = await asyncio.gather(*[\n            crm.update_record(crm_object, contact)\n            for contact in batch\n        ])\n        results.extend(batch_results)\n    \n    # Return summary only\n    return {\n        'processed': len(valid),\n        'successful': sum(1 for r in results if r['success'])\n    }\n```\n\n**Key Principles for Scripts**:\n- Use `async`/`await` for IO-bound MCP calls\n- Combine related operations into single scripts\n- Filter/aggregate data before returning to model\n- Return summaries, not raw data\n- Include type hints and docstrings\n- Add helper functions for data processing\n\n#### 5.2 Write SKILL.md\n\nCreate the SKILL.md following skill-creator structure, with MCP-specific additions.\n\n**YAML Frontmatter**:\n```yaml\n---\nname: <skill-name>\ndescription: <Brief description of workflow + when to use + MCP servers involved>\n---\n```\n\n**Body Structure**:\n\n```markdown\n# [Skill Name]\n\n[Overview of what this skill does]\n\n## Prerequisites\n\nThis skill requires the MCP SDK. **The scripts will automatically check and install it if needed.**\n\nIf you want to manually verify or install:\n\n```bash\npython3 -c \"import mcp; print('âœ“ MCP SDK ready!')\" 2>/dev/null || pip3 install mcp --break-system-packages\n```\n\n**Why needed**: This skill uses MCP tools to [brief explanation of what MCP servers do]. The workflow scripts require the `mcp` package to connect to MCP servers.\n\n**Note**: When you run any workflow script, it will automatically check for MCP SDK and display a helpful error message if not installed.\n\n## Workflow Overview\n\n[User's workflow steps in their own language]\n\n[USER PREFERENCES - Embedded as guidance]\nWhen using this skill:\n- [Preference 1]\n- [Preference 2]\n\n[SOPs - Embedded as procedural instructions]\nStandard procedure:\n1. [SOP step 1]\n2. [SOP step 2]\n\n## Quick Start\n\n**Before running workflows, ensure MCP SDK is installed** (see Prerequisites above).\n\n[Simple example of using the main workflow script]\n\n## Available Workflows\n\n### [Primary Workflow Script]\n\n**Use when**: [Scenario]\n\n**Location**: `scripts/workflows/<script>.py`\n\n**Usage**:\n```python\nfrom scripts.workflows import workflow_name\nresult = await workflow_name(params)\n```\n\n**Optimizations**:\n- Parallel execution of [X] data sources\n- Context-efficient data filtering  \n- [Other optimizations]\n\n[Repeat for other workflow scripts]\n\n## MCP Tools Available\n\n[Brief overview of integrated MCP servers]\n\n### [Server Name]\n\n**Tools**: [Count] available\n\n**Location**: `scripts/tools/[server]/`\n\n**Key tools**: [List 3-5 most relevant]\n\n**Discovery**: Use `ls scripts/tools/[server]/` to see all tools\n\n[Repeat for each server]\n\n## Advanced Usage\n\n[Guidance on combining scripts, customization, etc.]\n\n## Performance Notes\n\n[Context optimization benefits, speedups from parallelization]\n```\n\n**Critical**: Embed user preferences and SOPs directly into the workflow guidance, not as separate sections. They should inform HOW to use the skill.\n\n**Example of embedded preferences**:\n```markdown\n## Workflow Overview\n\nThis skill automates product research with the following steps:\n\n1. Official website analysis\n2. Community feedback gathering\n3. Report generation\n\n**Research approach**: Always prioritize quantitative metrics (user counts, ratings) over qualitative descriptions. Recent information (last 6 months) is valued over older reviews. Cross-reference official claims against community feedback to identify contradictions.\n```\n\n#### 5.3 Create References (If Needed)\n\nOnly create `references/` files if SKILL.md would exceed 500 lines or if there's detailed reference material that doesn't belong in the main workflow.\n\nPossible reference files:\n- `references/mcp_tools.md` - Detailed catalog of all MCP tools\n- `references/schemas.md` - Data schemas for APIs\n- `references/examples.md` - Additional usage examples\n\n### Step 6: Package and Deliver\n\nOnce the skill is complete:\n\n1. **Review the skill structure**\n   - SKILL.md is clear and under 500 lines\n   - Scripts are tested (or marked as TODO)\n   - User preferences are embedded\n   - MCP tool wrappers are generated\n\n2. **Package the skill**\n   ```bash\n   python /mnt/skills/public/skill-creator/scripts/package_skill.py <skill-dir>\n   ```\n\n3. **Provide to user**\n   - Share the .skill file\n   - Explain key workflows\n   - Highlight personalized aspects (preferences, SOPs)\n\n## Key Differences from Standard Skill-Creator\n\nThis meta-skill extends skill-creator with MCP-specific capabilities:\n\n### 1. MCP Infrastructure (Unique)\n\n**Standard skill-creator**: You manually write scripts or provide instructions\n\n**MCP skill-creator**: Programmatically generates type-safe tool wrappers from MCP servers, enabling progressive disclosure\n\n### 2. Optimization Focus\n\n**Standard skill-creator**: General workflow guidance\n\n**MCP skill-creator**: Specific optimization patterns (parallel execution, data filtering, control flow, privacy)\n\n### 3. Personalization Depth\n\n**Standard skill-creator**: Domain knowledge in references/\n\n**MCP skill-creator**: User preferences and SOPs embedded directly into workflow guidance\n\n## Best Practices\n\n### When to Create Scripts vs Text Guidance\n\n**Create scripts for**:\n- End-to-end workflows with 3+ steps\n- Operations that benefit from parallelization\n- Data processing that should happen in execution environment\n- Polling/monitoring patterns\n- Bulk operations\n\n**Use text guidance for**:\n- Ad-hoc tool usage\n- Workflows with high variability\n- Simple single-tool operations\n- Exploratory tasks\n\n### Embedding User Preferences\n\nâŒ **Don't**: Create separate \"User Preferences\" section\nâœ… **Do**: Weave preferences into workflow guidance\n\nExample:\n```markdown\n## Workflow Overview\n\nThis skill follows your research methodology:\n1. Start with official sources (per your SOP)\n2. Gather community feedback in parallel\n3. Cross-reference claims (highlighting contradictions as you prefer)\n4. Generate report with quantitative metrics emphasized\n```\n\n### Optimization Patterns\n\nAlways consider these opportunities when analyzing workflows:\n\n**Parallel Execution**: Any independent fetch operations\n**Data Filtering**: Processing that reduces data size\n**Control Flow**: Loops, conditionals, error handling  \n**State Persistence**: Long-running or resumable workflows\n**Privacy**: Sensitive data that shouldn't enter context\n\n## Example: Product Research Skill\n\n**User Input**:\n```\nMCP Servers: puppeteer, twitter, reddit\nWorkflow: Research products by visiting official site, checking ProductHunt, \n          searching Twitter/Reddit, then creating markdown report\nPreferences: Quantitative metrics > qualitative, recent info > old\nSOPs: Start with official sources, cross-reference claims, cite sources\n```\n\n**Generated Skill**:\n\n`SKILL.md`:\n```markdown\n---\nname: product-research-workflow  \ndescription: Automated product research integrating official sources and community platforms\n---\n\n# Product Research Workflow\n\nResearch internet products efficiently by gathering data from official sources \nand community platforms, with emphasis on quantitative metrics and recent information.\n\n## Workflow Overview\n\nThis skill implements your standard research process:\n\n1. **Official Source Analysis**: Visit product website and extract key features, \n   pricing, and positioning (per your SOP: always start with official sources)\n\n2. **Community Intelligence**: Gather feedback from ProductHunt, Twitter, and Reddit \n   in parallel (optimized for speed)\n\n3. **Cross-Reference**: Identify contradictions between official claims and community \n   feedback (your preference for critical analysis)\n\n4. **Report Generation**: Create comprehensive markdown report with quantitative \n   metrics emphasized (ratings, user counts, pricing comparisons)\n\n## Quick Start\n\n```python\nfrom scripts.workflows import product_research_pipeline\n\nreport = await product_research_pipeline(\n    product_url='https://example.com',\n    product_name='ExampleApp'\n)\n```\n\n## Available Workflows\n\n### product_research_pipeline\n\n**Use when**: Researching any new internet product or SaaS tool\n\n**Optimizations**:\n- 3x faster via parallel social media gathering\n- Context-efficient: processes 1000s of posts, returns top 10 insights\n- Recent info prioritized (last 6 months)\n\n[... rest of SKILL.md with embedded preferences and SOPs ...]\n```\n\n`scripts/workflows/product_research_pipeline.py`:\n```python\nasync def product_research_pipeline(product_url: str, product_name: str):\n    # Official source\n    official = await puppeteer.fetch_page(product_url)\n    \n    # Parallel community research (3x faster)\n    twitter, reddit, ph = await asyncio.gather(\n        twitter_mcp.search_tweets(f'\"{product_name}\"', recent_days=180),\n        reddit_mcp.search(product_name, time_filter='6months'),\n        producthunt_mcp.get_product(product_name)\n    )\n    \n    # Filter in execution env (user preference: quantitative focus)\n    metrics = extract_quantitative_metrics(official)\n    sentiment = calculate_sentiment_score([twitter, reddit, ph])\n    recent_feedback = filter_recent(twitter + reddit, days=180)\n    contradictions = find_contradictions(official, recent_feedback)\n    \n    # Return summary (not raw data)\n    return {\n        'official_metrics': metrics,\n        'sentiment_score': sentiment,\n        'recent_mention_count': len(recent_feedback),\n        'contradictions': contradictions[:5],\n        'top_praise': extract_top_feedback(recent_feedback, 'positive', 3),\n        'top_complaints': extract_top_feedback(recent_feedback, 'negative', 3)\n    }\n```\n\n## References\n\nFor detailed MCP optimization patterns and examples:\n- `references/mcp-best-practices.md` - Comprehensive guide to MCP + code execution\n- `references/quick-start.md` - Step-by-step tutorial\n- `references/example-config.json` - Complete configuration example\n"
      },
      "discovered_at": "2026-01-11T15:36:35.313706Z",
      "fetch_error": null
    },
    {
      "name": "angreal",
      "slug": "angreal",
      "source": "skillsmp",
      "owner": "angreal",
      "repo_name": "angreal",
      "repository_url": "https://github.com/angreal/angreal",
      "skill_path": "skill/skills/angreal",
      "github_metadata": {
        "stars": 10,
        "description": "  Task automation and project templating tool. Define reusable commands in Python, scaffold projects from templates, and let tasks travel with your codebase. Rust core, Python API.",
        "default_branch": "main",
        "pushed_at": "2025-12-31T18:29:18Z",
        "created_at": "2018-06-19T13:26:18Z",
        "language": "Rust",
        "license": null,
        "open_issues": 1,
        "forks": 4
      },
      "skill_md": {
        "found": true,
        "path": "skill/skills/angreal/SKILL.md",
        "branch": "main",
        "content": "---\nname: angreal\ndescription: Task automation and project templating with angreal. Use when running project tasks, creating new tasks, or setting up project automation. Teaches both using existing tasks and authoring new ones.\n---\n\n# Angreal Task Automation Skill\n\nThis skill teaches angreal task automation - both using existing tasks as an AI agent and authoring new tasks as a developer.\n\n## What Angreal Is For\n\nAngreal is focused on **development tasks within software projects**:\n- Building and testing code\n- Running linters and formatters\n- Generating documentation\n- Managing development workflows\n- Project-specific automation\n\n**Angreal is NOT for**:\n- Installing or maintaining software distributions\n- System-level package management\n- Deployment pipelines to production (though it can trigger them)\n- CI/CD infrastructure setup\n\nThink of angreal as your project's `make` or `npm run` - development-time task automation.\n\n## Prerequisites\n\n- Angreal MCP server connected and available\n- Working within an angreal project (has `.angreal/` directory)\n\n## What This Skill Provides\n\nThe Angreal MCP server teaches **how** to call tools (parameters, syntax). This skill teaches **when** and **why**.\n\n- When to use which task\n- How to discover and understand available tasks\n- How to author effective task definitions\n- Common patterns and anti-patterns\n\n## Two Perspectives\n\n### Using Tasks (AI Agent)\n\nSee [using/discovery.md](using/discovery.md) for:\n- Finding available tasks in a project\n- Understanding task descriptions and arguments\n- Choosing the right task for the job\n\nSee [using/execution.md](using/execution.md) for:\n- Invoking tasks correctly\n- Handling arguments and flags\n- Interpreting output and errors\n\nSee [using/workflows.md](using/workflows.md) for:\n- Common multi-task workflows\n- Task sequencing patterns\n- Project lifecycle tasks\n\n### Authoring Tasks (Developer)\n\nSee [authoring/basics.md](authoring/basics.md) for:\n- Creating task files\n- The `@command` decorator\n- Basic task structure\n\nSee [authoring/groups.md](authoring/groups.md) for:\n- Organizing tasks with `@group`\n- Creating command hierarchies\n- Reusable group decorators\n\nSee [authoring/tool-descriptions.md](authoring/tool-descriptions.md) for:\n- Writing effective `ToolDescription`\n- Guiding AI agents with prose\n- Risk levels and annotations\n\nSee [authoring/arguments.md](authoring/arguments.md) for:\n- The `@argument` decorator\n- Argument types and validation\n- Flags, defaults, and requirements\n\nSee [authoring/best-practices.md](authoring/best-practices.md) for:\n- Naming conventions\n- Error handling patterns\n- Organization strategies\n\n## Common Patterns\n\nSee [patterns/testing.md](patterns/testing.md) for test automation patterns.\nSee [patterns/documentation.md](patterns/documentation.md) for doc generation patterns.\nSee [patterns/development.md](patterns/development.md) for dev workflow patterns.\n\n## Quick Reference\n\n### Task File Location\n```\nproject/\nâ””â”€â”€ .angreal/\n    â”œâ”€â”€ utils.py         # Shared utilities across tasks\n    â”œâ”€â”€ task_dev.py      # Development tasks\n    â”œâ”€â”€ task_test.py     # Testing tasks\n    â”œâ”€â”€ task_docs.py     # Documentation tasks\n    â””â”€â”€ task_deploy.py   # Deployment tasks\n```\n\nYou can create shared modules (like `utils.py`) and import them across task files.\n\n### Basic Task Structure\n```python\nimport angreal\n\n@angreal.command(\n    name=\"build\",\n    about=\"Build the project\",\n    tool=angreal.ToolDescription(\"\"\"\nBuild the project for distribution.\n\n## When to use\n- Before releasing a new version\n- Testing production builds\n\n## Examples\n```\nangreal build\nangreal build --release\n```\n\"\"\", risk_level=\"safe\")\n)\n@angreal.argument(name=\"release\", long=\"release\", is_flag=True, takes_value=False, help=\"Build in release mode\")\ndef build(release=False):\n    # Implementation\n    pass\n```\n\n### Key Principles\n\n- **Tasks are discoverable** - MCP exposes all tasks automatically\n- **Descriptions are prompts** - Write `ToolDescription` as guidance for AI\n- **Groups organize** - Related commands should share a group\n- **Arguments are typed** - Specify `python_type` for proper conversion\n- **Errors are informative** - Return meaningful messages on failure\n"
      },
      "discovered_at": "2026-01-11T15:36:35.779232Z",
      "fetch_error": null
    },
    {
      "name": "programming-advisor",
      "slug": "programming-advisor",
      "source": "skillsmp",
      "owner": "gaupoit",
      "repo_name": "programming-advisor",
      "repository_url": "https://github.com/gaupoit/programming-advisor",
      "skill_path": "skills/programming-advisor",
      "github_metadata": {
        "stars": 10,
        "description": "Claude Code skill: Build vs Buy advisor that searches for existing solutions before vibe coding",
        "default_branch": "main",
        "pushed_at": "2025-12-31T04:16:12Z",
        "created_at": "2025-12-30T09:28:13Z",
        "language": null,
        "license": "MIT",
        "open_issues": 0,
        "forks": 3
      },
      "skill_md": {
        "found": true,
        "path": "skills/programming-advisor/SKILL.md",
        "branch": "main",
        "content": "---\nname: programming-advisor\ndescription: \"Build vs Buy advisor. Use when users say: 'I want to build...', 'Help me create...', 'Can you code...', 'I need a tool/app/script'. Searches for existing libraries, SaaS, and open source solutions before vibe coding. Estimates token costs and provides comparison tables.\"\n---\n\n# Programming Advisor - \"Reinventing the Wheel\" Detector\n\n## Core Philosophy\n\nBefore writing a single line of code, determine if the wheel already exists. Vibe coding burns tokens, time, and creates maintenance burden. Existing solutions often provide better quality, security patches, and community support.\n\n## Workflow\n\n### Step 1: Capture Intent\n\nExtract from user request:\n- **What**: Core functionality needed\n- **Why**: Use case / problem being solved\n- **Constraints**: Language, platform, budget, licensing requirements\n\n### Step 2: Search for Existing Solutions\n\nSearch strategy (use web_search):\n1. `\"{functionality} library {language}\"` \n2. `\"{functionality} open source\"`\n3. `\"{functionality} SaaS tool\"`\n4. `\"best {functionality} solution 2024\"`\n5. `\"{functionality} npm/pip/cargo package\"` (based on ecosystem)\n\nCategorize findings:\n- **Libraries/Packages**: npm, pip, cargo, etc. (free, integrate into code)\n- **Open Source Tools**: Full applications (free, self-host)\n- **SaaS/Commercial**: Paid services (cost, no maintenance)\n- **Frameworks**: Scaffolding for common patterns\n\n### Step 3: Estimate Vibe Coding Cost\n\nUse the token estimation reference: [references/token-estimates.md](references/token-estimates.md)\n\nFactors to estimate:\n| Factor | Low | Medium | High |\n|--------|-----|--------|------|\n| Lines of Code | <200 | 200-1000 | >1000 |\n| Token Burn (est.) | 5-20K | 20-100K | 100K+ |\n| Development Iterations | 1-3 | 4-10 | 10+ |\n| Debugging Sessions | Minimal | Moderate | Extensive |\n| Maintenance Burden | Low | Medium | High |\n\n### Step 4: Generate Comparison Table\n\nAlways present a decision table:\n\n```markdown\n| Option | Type | Cost | Setup Time | Maintenance | Token Burn | Verdict |\n|--------|------|------|------------|-------------|------------|---------|\n| [Solution A] | Library | Free | 5 min | Updates only | 0 | âœ… Recommended |\n| [Solution B] | SaaS | $X/mo | Instant | None | 0 | âš¡ Fastest |\n| Vibe Code | Custom | Free | X hrs | You own it | ~XK tokens | ğŸ”§ Full control |\n```\n\n### Step 5: Recommendation Framework\n\nRecommend **existing solutions** when:\n- Mature library exists with >1K GitHub stars\n- SaaS solves it for <$20/mo\n- Common problem with well-tested solutions\n- Security-sensitive (auth, crypto, payments)\n\nRecommend **vibe coding** when:\n- Highly specific business logic\n- Simple glue code (<50 lines)\n- Learning exercise (explicitly stated)\n- No good existing solution found\n- Integration requirements are unusual\n\n### Step 6: If Vibe Coding Proceeds\n\nIf user chooses to build after seeing alternatives:\n1. Acknowledge the valid reasons\n2. Suggest existing code as reference/inspiration\n3. Recommend libraries for sub-components\n4. Provide a hybrid approach when possible\n\n### Step 7: Integration Planning (When User Accepts Recommendation)\n\nWhen the user accepts a recommended solution, provide a complete integration plan:\n\n#### 7.1 Detect Project Context\n\nBefore generating the plan, analyze the user's project:\n- **Package manager**: Check for `package.json` (npm/yarn/pnpm), `requirements.txt`/`pyproject.toml` (pip/poetry), `Cargo.toml` (cargo), `go.mod` (go)\n- **Framework**: Identify React, Vue, Next.js, Rails, Django, FastAPI, etc.\n- **Existing dependencies**: Check for conflicts or complementary packages\n- **Project structure**: Understand where new code should live (src/, lib/, app/, etc.)\n- **Code style**: Match existing patterns (TypeScript vs JS, ESM vs CJS, etc.)\n\n#### 7.2 Generate Installation Commands\n\nProvide ready-to-run commands for the detected package manager:\n\n```bash\n# npm\nnpm install <package>\n\n# yarn\nyarn add <package>\n\n# pnpm\npnpm add <package>\n\n# pip\npip install <package>\n\n# poetry\npoetry add <package>\n```\n\n#### 7.3 Provide Integration Steps\n\nCreate a numbered action plan:\n1. **Install dependencies** - Exact commands\n2. **Create/update config files** - If the library needs configuration\n3. **Add to existing code** - Where to import and initialize\n4. **Create new files** - With suggested file paths matching project structure\n5. **Update related files** - Any existing files that need modification\n\n#### 7.4 Generate Starter Code\n\nProvide code scaffolding that:\n- Matches the user's detected code style (TypeScript/JavaScript, etc.)\n- Uses their existing patterns and conventions\n- Includes necessary imports\n- Shows basic usage with comments\n- Handles common edge cases\n\n#### 7.5 Warn About Potential Issues\n\nFlag any concerns:\n- **Dependency conflicts**: \"Note: This requires React 18+, you have React 17\"\n- **Breaking changes**: \"This library had major changes in v3, examples are for v3\"\n- **Peer dependencies**: \"You'll also need to install X\"\n- **Config requirements**: \"Requires adding to your tsconfig/babel/webpack config\"\n\n### Step 8: Cost Analysis (For Significant Decisions)\n\nFor features with meaningful cost implications (auth, payments, email, infrastructure), provide a Total Cost of Ownership (TCO) comparison.\n\n#### 8.1 When to Include Cost Analysis\n\nInclude cost table when:\n- SaaS options have monthly fees > $10\n- DIY token estimate > 50K tokens\n- User asks about costs or \"is it worth it\"\n- Comparing multiple paid services\n- Security-sensitive features (auth, payments)\n\n#### 8.2 Cost Calculation\n\nUse the pricing reference: [references/pricing-data.md](references/pricing-data.md)\n\n**Formula:**\n```\nYear N Cost = Setup Cost + (Monthly Ã— 12 Ã— N) + (Maintenance Ã— N)\n\nWhere:\n- Setup Cost (DIY) = Token Estimate Ã— $0.015/1K tokens\n- Maintenance (DIY) = 20% of Setup Cost annually\n- Maintenance (SaaS) = $0\n```\n\n#### 8.3 Cost Table Format\n\n```markdown\n## ğŸ’° Cost Analysis\n\n| Option | Setup | Monthly | Year 1 | Year 3 | Notes |\n|--------|-------|---------|--------|--------|-------|\n| [SaaS A] | 10min | $25 | $300 | $900 | Free tier: 10K MAU |\n| [SaaS B] | 15min | $35 | $420 | $1,260 | More features |\n| [Free/OSS] | 1hr | $0 | $0 | $0 | Self-host required |\n| DIY | Xhrs | $0 | ~$Y | ~$Z | + maintenance burden |\n\nğŸ’¡ **Break-even:** [When DIY becomes cheaper, if ever]\nâš ï¸ **Hidden costs:** [Security audits, compliance, on-call burden]\n```\n\n#### 8.4 Hidden Costs to Surface\n\nAlways mention relevant hidden costs:\n- **Security audits**: $5K-50K for custom auth systems\n- **Compliance**: SOC2, GDPR, PCI implementation time\n- **On-call burden**: DIY = you're the support team\n- **Opportunity cost**: Time not spent on core product\n- **Technical debt**: Custom code needs maintenance forever\n\n#### 8.5 Red Flags to Call Out\n\nWarn users when they say:\n- \"It's just a simple auth system\" â†’ Auth is never simple\n- \"We can build it in a weekend\" â†’ You can't, securely\n- \"We'll add security later\" â†’ Security debt is expensive\n- \"It's cheaper long-term\" â†’ Usually false under 10K users\n\n## Response Template\n\n```\n## ğŸ” Existing Solutions Found\n\nI found [N] existing solutions before we write custom code:\n\n### Libraries/Packages\n- **[Name]**: [one-line description] | [stars/downloads] | [link]\n\n### Open Source Tools  \n- **[Name]**: [one-line description] | [stars] | [link]\n\n### SaaS Options\n- **[Name]**: [one-line description] | [pricing] | [link]\n\n## ğŸ“Š Build vs Buy Comparison\n\n| Option | Type | Cost | Setup | Maintenance | Est. Tokens |\n|--------|------|------|-------|-------------|-------------|\n| ... | ... | ... | ... | ... | ... |\n\n## ğŸ’° Cost Analysis (for significant decisions)\n\n| Option | Setup | Monthly | Year 1 | Year 3 | Notes |\n|--------|-------|---------|--------|--------|-------|\n| ... | ... | ... | ... | ... | ... |\n\nğŸ’¡ **Break-even:** [analysis]\nâš ï¸ **Hidden costs:** [security, compliance, maintenance]\n\n## ğŸ’¡ Recommendation\n\n[Clear recommendation with reasoning]\n\n## ğŸ”§ If You Still Want to Build\n\n[Only if user wants custom solution - suggest hybrid approach]\n```\n\n### Integration Plan Template (When User Accepts)\n\nWhen the user says \"let's use [recommended solution]\" or \"how do I add this?\", respond with:\n\n```\n## ğŸš€ Integration Plan: [Solution Name]\n\n### Your Project Context\n- **Detected**: [framework], [package manager], [language]\n- **Project structure**: [src/app/lib layout]\n\n### Step 1: Install Dependencies\n\n\\`\\`\\`bash\n[exact install command for their package manager]\n\\`\\`\\`\n\n### Step 2: Configuration (if needed)\n\n[Any config file changes needed]\n\n### Step 3: Create New Files\n\nğŸ“ `[suggested/file/path.ts]`\n\\`\\`\\`typescript\n[starter code matching their project style]\n\\`\\`\\`\n\n### Step 4: Update Existing Files\n\nğŸ“ `[existing/file/to/modify.ts]`\n\\`\\`\\`typescript\n// Add this import\nimport { X } from '[package]'\n\n// Use it like this\n[integration code]\n\\`\\`\\`\n\n### âš ï¸ Notes\n- [Any warnings about versions, conflicts, or requirements]\n\n### ğŸ“š Resources\n- [Official docs link]\n- [Relevant examples]\n```\n\n## Anti-Patterns to Flag\n\nAlert users when they're about to reinvent:\n- Authentication systems â†’ \"Use Auth0, Clerk, Supabase Auth\"\n- State management â†’ \"Consider Zustand, Redux Toolkit, Jotai\"\n- Form validation â†’ \"Check out Zod, Yup, React Hook Form\"\n- API clients â†’ \"Look at Axios, ky, ofetch\"\n- Date handling â†’ \"Use date-fns, dayjs, Luxon\"\n- CLI tools â†’ \"Consider Commander, yargs, oclif\"\n- PDF generation â†’ \"Use pdf-lib, jsPDF, Puppeteer\"\n- Email sending â†’ \"Check Resend, SendGrid, Nodemailer\"\n- Cron jobs â†’ \"Use node-cron, Bull, Agenda\"\n- Database ORMs â†’ \"Consider Prisma, Drizzle, TypeORM\"\n\n## Quick Reference: Common Token Burns\n\n| Task Complexity | Typical Token Burn | Time Equivalent |\n|-----------------|-------------------|-----------------|\n| Simple script (<100 LOC) | 5-15K | 30min-1hr |\n| Utility module (100-500 LOC) | 15-50K | 2-4hrs |\n| Feature component (500-2K LOC) | 50-150K | 1-2 days |\n| Full application | 150K-500K+ | Days-weeks |\n\nSee [references/token-estimates.md](references/token-estimates.md) for detailed breakdowns.\n\nSee [references/common-solutions.md](references/common-solutions.md) for exhaustive list of commonly reinvented wheels.\n\nSee [references/integration-patterns.md](references/integration-patterns.md) for project detection and starter code patterns.\n\nSee [references/pricing-data.md](references/pricing-data.md) for SaaS pricing and cost calculation data.\n"
      },
      "discovered_at": "2026-01-11T15:36:36.098780Z",
      "fetch_error": null
    },
    {
      "name": "content-documenter",
      "slug": "content-documenter",
      "source": "skillsmp",
      "owner": "memorysaver",
      "repo_name": "looplia-core",
      "repository_url": "https://github.com/memorysaver/looplia-core",
      "skill_path": "docs/writing-agent-example/writing-agent/.claude/skills/content-documenter",
      "github_metadata": {
        "stars": 10,
        "description": "Universal agentic workflow CLI â€” compose AI agents and skills for any task.",
        "default_branch": "main",
        "pushed_at": "2026-01-08T10:27:25Z",
        "created_at": "2025-12-05T07:24:43Z",
        "language": "TypeScript",
        "license": "NOASSERTION",
        "open_issues": 1,
        "forks": 0
      },
      "skill_md": {
        "found": true,
        "path": "docs/writing-agent-example/writing-agent/.claude/skills/content-documenter/SKILL.md",
        "branch": "main",
        "content": "---\nname: content-documenter\ndescription: Write comprehensive markdown documentation from analyzed media content with structured sections, quotes, timestamps, and citations. Use after media-reviewer analysis to create final documentation.\n---\n\n# Content Documenter Skill\n\nExpert at writing clear, well-structured documentation that preserves original meaning while providing comprehensive context.\n\n## What This Skill Does\n\n- Takes analyzed content and writes enriched markdown\n- Creates structured sections (overview, themes, analysis, quotes, etc.)\n- Preserves original meaning without interpretation\n- Includes timestamps and citations\n- Provides context for future readers and writers\n\n## Input\n\nYou receive:\n- Material ID and metadata\n- All available source materials\n- Analysis from media-reviewer skill\n- Original frontmatter to preserve\n\n## Output\n\nMarkdown document with structure:\n\n```markdown\n# [Extracted Title]\n\n## Overview\n[2-3 paragraph summary from analysis]\n\n## Key Themes\n- [Theme 1]\n- [Theme 2]\n...\n\n## Detailed Analysis\n[Detailed breakdown of content following its structure]\n\n## Structure & Narrative Flow\n[How the content progresses and why]\n\n## Core Ideas\n[Main concepts and their explanations]\n\n## Important Quotes & Moments\n> \"Quote with context\" (timestamp if applicable)\n\n[More quotes with proper attribution]\n\n## Context & Background\n[What reader needs to understand the content]\n\n## Related Concepts\n[Connections to other topics]\n```\n\n## Writing Guidelines\n\n1. **Overview**: 2-3 sentences introducing the material\n2. **Key Themes**: Bullet list of main topics (3-7 items)\n3. **Detailed Analysis**: Follow the structure of the original content, breaking it into logical sections\n4. **Narrative Flow**: Explain how ideas build on each other\n5. **Core Ideas**: Define key concepts with examples from the material\n6. **Important Quotes**: Extract 3-5 verbatim quotes with timestamps\n7. **Context**: Explain what background knowledge helps understand this\n8. **Related**: Link to other concepts mentioned or implied\n\n## Important Rules\n\nâœ… Preserve every important detail from source\nâœ… Include timestamps when available (format: HH:MM:SS)\nâœ… Use exact quotes (no paraphrasing)\nâœ… Document what's actually there, not what should be there\nâœ… Provide sufficient detail for future reference\nâœ… Use clear, professional markdown formatting\nâŒ Never add interpretation or analysis\nâŒ Never add opinions\nâŒ Never modify frontmatter when writing\nâŒ Never omit important information\nâŒ Never paraphrase direct quotes\n\n## Timestamp Format\n\nFor video/audio content, include timestamps:\n- `(0:30)` - 30 seconds\n- `(2:45:30)` - 2 hours 45 minutes 30 seconds\n- Quote context: `\"The main issue is...\" (12:34)`\n\n## Citation Format\n\nReference materials where available:\n- From same source: Just note the section or timestamp\n- From other materials: `[Topic](path/to/file.md) - Source Name`\n\n## Quality Checklist\n\nBefore completing:\n- âœ… All important points are included\n- âœ… Quotes are exact and have context\n- âœ… Timestamps are accurate\n- âœ… Structure is logical and readable\n- âœ… No interpretation added\n- âœ… Enough detail for future use\n- âœ… Formatting is clean and consistent\n\n## File Update Process\n\nAfter generating markdown documentation, update the material file:\n\n### Step 1: Locate Material File\n\nSearch for the file matching the material ID:\n```\n*/items/ai.{material-id}.md\n```\n\nCommon locations:\n- `youtube-channels/{channel-name}/items/ai.{id}.md`\n- `podcasts/{podcast-name}/items/ai.{id}.md`\n- `rss-feeds/{feed-name}/items/ai.{id}.md`\n\n### Step 2: Write File Using Python Script\n\nUse the Bash tool to invoke the update script:\n\n```bash\npython .claude/skills/content-documenter/scripts/update_material.py \"path/to/items/ai.{id}.md\" << 'EOF'\n# Your markdown documentation here\n## Section 1\nContent...\n\n## Section 2\nMore content...\nEOF\n```\n\nThe script will:\n- âœ… Preserve the YAML frontmatter exactly\n- âœ… Replace content below the frontmatter\n- âœ… Update `ai_status` to \"documented\"\n- âœ… Update `generated_at` timestamp\n- âœ… Handle YAML parsing safely\n\n### Example\n\nIf documenting a video with ID `v123` from Anthropic channel:\n\n```bash\npython .claude/skills/content-documenter/scripts/update_material.py \"youtube-channels/Anthropic/items/ai.v123.md\" << 'EOF'\n# Understanding Constitutional AI\n\n## Overview\nThis video discusses the Constitutional AI approach...\n\n## Key Themes\n- Safety in AI systems\n- Alignment techniques\n...\nEOF\n```\n\n### Important Notes\n\nâœ… Pass the **complete markdown content** (without frontmatter) to stdin\nâœ… The script handles file path validation and YAML parsing\nâœ… Always update the material file after generating documentation\nâœ… Check for success message in stderr output\n"
      },
      "discovered_at": "2026-01-11T15:36:36.487770Z",
      "fetch_error": null
    },
    {
      "name": "media-reviewer",
      "slug": "media-reviewer",
      "source": "skillsmp",
      "owner": "memorysaver",
      "repo_name": "looplia-core",
      "repository_url": "https://github.com/memorysaver/looplia-core",
      "skill_path": "docs/writing-agent-example/writing-agent/.claude/skills/media-reviewer",
      "github_metadata": {
        "stars": 10,
        "description": "Universal agentic workflow CLI â€” compose AI agents and skills for any task.",
        "default_branch": "main",
        "pushed_at": "2026-01-08T10:27:25Z",
        "created_at": "2025-12-05T07:24:43Z",
        "language": "TypeScript",
        "license": "NOASSERTION",
        "open_issues": 1,
        "forks": 0
      },
      "skill_md": {
        "found": true,
        "path": "docs/writing-agent-example/writing-agent/.claude/skills/media-reviewer/SKILL.md",
        "branch": "main",
        "content": "---\nname: media-reviewer\ndescription: Analyze media content structure, narrative flow, key themes, and important moments from videos, podcasts, and articles. Use when you need to understand content organization before documenting.\n---\n\n# Media Reviewer Skill\n\nExpert at analyzing media content to understand structure, ideas, and narrative flow.\n\n## What This Skill Does\n\n- Reads media materials (captions, transcripts, blog posts)\n- Understands the ideas and concepts being presented\n- Identifies narrative structure and how content progresses\n- Discovers key moments, turning points, and themes\n- Recognizes how content is organized and why\n\n## Input\n\nYou receive:\n- Material ID (e.g., 'v123')\n- All available source files (captions, transcripts, HTML)\n- Material metadata from frontmatter\n\n## Output (Implicit)\n\nInternal analysis (structured as assistant's thinking) that will be used by content-documenter skill to generate documentation.\n\nFocus on:\n- **Content structure**: How is this organized?\n- **Core ideas**: What are the main concepts?\n- **Narrative flow**: How does it progress?\n- **Key moments**: What are important moments?\n- **Themes**: What topics emerge?\n- **Documentary angle**: How would you structure this for a documentary?\n\n## Analysis Approach\n\n1. **Read all available materials** for the given material ID\n2. **Understand the context** from metadata (title, source, date)\n3. **Identify main topics** and how they connect\n4. **Track narrative progression** from beginning to end\n5. **Extract key insights** and memorable moments\n6. **Note important quotes** and timestamps\n7. **Understand the author's intent** (if applicable)\n8. **Recognize patterns** and recurring themes\n\n## Example Analysis\n\nGiven a video about Constitutional AI:\n- **Structure**: Introduction â†’ Problem statement â†’ Solution â†’ Examples â†’ Conclusion\n- **Core ideas**: Alignment, interpretability, harmlessness\n- **Key moments**: When method is first introduced (timestamp), key examples\n- **Themes**: Safety in AI, human values, transparency\n- **Documentary angle**: How safety concerns drive the approach, specific breakthrough moments\n\n## Important Rules\n\nâœ… Be thorough and comprehensive\nâœ… Understand the material deeply\nâœ… Preserve nuance and detail\nâœ… Note what makes this content unique\nâŒ Don't add your own analysis or interpretation\nâŒ Don't skip important details\nâŒ Don't oversimplify complex concepts\n"
      },
      "discovered_at": "2026-01-11T15:36:36.891028Z",
      "fetch_error": null
    },
    {
      "name": "content-analysis",
      "slug": "content-analysis",
      "source": "skillsmp",
      "owner": "memorysaver",
      "repo_name": "looplia-core",
      "repository_url": "https://github.com/memorysaver/looplia-core",
      "skill_path": "packages/provider/src/claude-agent-sdk/skills/content-analysis",
      "github_metadata": {
        "stars": 10,
        "description": "Universal agentic workflow CLI â€” compose AI agents and skills for any task.",
        "default_branch": "main",
        "pushed_at": "2026-01-08T10:27:25Z",
        "created_at": "2025-12-05T07:24:43Z",
        "language": "TypeScript",
        "license": "NOASSERTION",
        "open_issues": 1,
        "forks": 0
      },
      "skill_md": {
        "found": true,
        "path": "packages/provider/src/claude-agent-sdk/skills/content-analysis/SKILL.md",
        "branch": "main",
        "content": "---\nname: content-analysis\ndescription: Analyze content for writing opportunities. Use when processing articles, videos, or podcasts to extract insights and generate writing materials.\n---\n\n# Content Analysis Skill\n\nThis skill helps analyze content and extract:\n- Key themes and topics\n- Writing hooks and angles\n- Exploratory questions\n- Article outlines\n\n## Usage\n\nInvoke this skill when the user wants to transform raw content into writing materials.\n\n## Workflow\n\n1. **Summarization**: Extract key insights, create headline and TL;DR\n2. **Ideation**: Generate hooks, angles, and questions\n3. **Outlining**: Create structured article outline\n\n## Output Formats\n\nAll outputs follow the Looplia core schemas:\n- ContentSummary for summaries\n- WritingIdeas for creative expansion\n- OutlineSection[] for article structure\n"
      },
      "discovered_at": "2026-01-11T15:36:37.300846Z",
      "fetch_error": null
    }
  ]
}